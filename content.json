{"meta":{"title":"EpsilonJohn's Blog","subtitle":"","description":"","author":"EpsilonJohn","url":"http://yoursite.com","root":"/"},"pages":[{"title":"About","date":"2022-02-01T12:41:23.436Z","updated":"2021-02-09T01:38:41.000Z","comments":true,"path":"aboutcpp/index.html","permalink":"http://yoursite.com/aboutcpp/index.html","excerpt":"","text":"Editor-Enter"},{"title":"Categories","date":"2022-02-01T12:41:23.436Z","updated":"2020-02-13T14:13:11.000Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2022-02-01T12:41:23.436Z","updated":"2021-02-09T01:38:43.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"Editor-Enter"},{"title":"Tags","date":"2022-02-01T12:41:23.436Z","updated":"2021-02-09T01:38:40.000Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"M_LOAM论文阅读","date":"2022-04-11T15:57:06.316Z","updated":"2022-04-11T15:57:06.316Z","comments":true,"path":"2022/04/11/M_LOAM论文阅读/","link":"","permalink":"http://yoursite.com/2022/04/11/M_LOAM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Robust Odometry and Mapping for Multi-LiDAR Systems with Online Extrinsic Calibration 摘要 组合多个LIDARS使机器人能够最大化其对环境的感知意识，并获得足够的测量。本文提出了一种实现鲁棒和同步的外参标定，里程计和多个LIDAR的建图系统。 我们的方法从测量预处理开始，从原始测量中提取边缘和平面特征，在运动和外参初始化过程之后，基于滑动窗口的多激光雷达里程计将板载运行，以估计具有在线标定和收敛性检测的位姿。 我们进一步开发了一种建图算法来构造全局地图，并优化具有足够特征的Pose以及捕获和减少数据不确定性的方法。 介绍 如果没有手动干预，我们的系统可以从多个未知外参的激光雷达开始，自动校准其外参，并提供准确的姿势以及全局一致的地图。先前的工作（LIOM），启发了本文，我们尝试解决多激光雷达融合问题的地方。此外，我们介绍了一种基于运动的方法[4]以初始化外参的方法，并使用[19]中的工具来表示不确定性。 本文贡献如下： 自动初始化，计算所有关键状态，包括连续帧之间的运动以及后续阶段的外参。它可以在任意位置开始，而无需任何先前的机械配置或校准对象知识(Section VI) 使用常规收敛准则的在线自标定与里程计同时执行，它具有以完全无监督的方式监控收敛性和触发终止的能力(Section VII-B) 基于滑动窗口的里程计，充分利用来自多个 LiDAR 的信息，该实现可以解释为小规模的帧到地图注册表，这进一步减少了连续帧到帧的帧累积的漂移(Section VII-C) 使用二阶段方法进行建图，捕获传感器噪声并传播不确定性，来消除姿势估计和外参估计的外部扰动，这种方法使建图过程能够了解不确定性，并有助于我们保持全局地图的一致性以及提高系统的鲁棒性以进行长期导航任务。 据我们所知，M-LOAM是第一个对多激光雷达外参标定和SLAM的完整解决方案，该系统在手持设备和自动驾驶汽车上进行了广泛的实验评估，从室内办事处到户外城市道路的各种情景，优于基于Sota Lidar的方法。关于各种平台上的校准，我们的方法实现了外参上的平移的厘米级精度和旋转的分数。对于不同尺度的SLAM，已成功应用M-LOAM以提供准确的姿势和地图结果。 图1可视化每个阶段的M-Loam的输出。 相关工作 LiDAR-Based SLAM Multi-Sensor Calibration Kummerle等 [52]开创了一个超图优化框架，用于校准带轮式编码器的车载激光扫描仪，Teichman等人[53] 同时，提出了一种迭代的SLAM-Fitting Pipline，以解决两个RGB-D相机的畸变，为了恢复多摄像时系统的空间偏移，恒等人[54]将问题转换为为Bundle Adjustment，而欧阳展鹏等[55]采用Ackermann转向模型来限制外参。 如[47]所示，[56] - [58]，传感器之间的时间偏移的在线估计对IMU的系统至关重要。 Qin等 [56]利用QIU等人的视觉特征的重新注入误差制定时间校准问题。 [58]提出了一种通过分析传感器的运动相关来校准异质传感器的更一般的方法。 本文隐含地同步了基于硬件的外部时钟的多个激光雷达的时间系统，并明确关注外参标定。 我们的方法包括在线程序，以实现灵活的多激光雷达外参标定。 要监控估计的外部的融合，我们提出了一般标准。 此外，我们对外部扰动进行建模，以减少其对长期导航任务的负面影响。 问题描述 我们根据最大似然估计（Maximum Like- lihood Estimation， MLE）制定M-LOAM，MLE导致非线性优化问题，其中，高斯协方差的逆对残差函数进行加权。 在深入研究 M-LOAM 的细节之前，我们先介绍一些基本概念： 第 III-A 节介绍了符号 第 III-B 节介绍了 MLE 第 III-C 节描述了合适的模型来表示 \\(\\mathbb{R}^{3}\\)中的不确定测量和 SE(3) 中的变换。 最后，第 III-D 节简要介绍了 MLE 在 M-LOAM 中具有近似高斯噪声的实现 符号约定 命名法如表I所示 我们考虑一个由一个主要激光雷达和多个辅助灵敏器组成的系统，主激光雷达作为base_frame，我们使用()\\(^{l^{1}} /()^{b}\\)来表示，对于其他辅助雷达，使用()\\(^{l^{i, i&gt;1}}\\)来表示。 我们记\\(\\mathcal{F}\\)为从原始激光雷达提取的有效特征，每个特征都表示为3D空间中的一个点：\\(\\mathbf{p}=[x, y, z]^{\\top}\\)。 状态向量，由平移和旋转部件组成，记为\\(\\mathbf{x}=[\\mathbf{t}, \\mathbf{q}]\\)，其中\\(\\mathbf{t}\\)是3x1向量，\\(\\mathbf{q}\\)是汉密尔顿四元数，但在我们需要旋转向量的情况下，我们在SO(3)中使用3×3旋转矩阵\\(\\mathbf{R}\\). 第VIII节将不确定性与矢量空间上的构成相关联，我们使用SE（3）中的4×4变换矩阵T表示Pose: \\[ \\mathbf{T}=\\left[\\begin{array}{cc} \\mathbf{R} &amp; \\mathbf{p} \\\\ \\mathbf{0}^{\\top} &amp; 1 \\end{array}\\right] \\] 最大似然估计 我们为MLE问题制定了多激光雷达系统的姿势和外参估计[60] 式（1）： \\[ \\hat{\\mathbf{x}}_{k}=\\underset{\\mathbf{x}_{k}}{\\arg \\max } p\\left(\\mathcal{F}_{k} \\mid \\mathbf{x}_{k}\\right)=\\underset{\\mathbf{x}_{k}}{\\arg \\min } f\\left(\\mathbf{x}_{\\mathbf{k}}, \\mathcal{F}_{k}\\right) \\] 其中， \\(\\mathcal{F}_{k}\\)表示第k帧的有效特征 \\(\\mathbf{x}_{k}\\)表示待优化的状态 \\(f(\\cdot)\\)表示目标函数 假设观测模型使用高斯噪声[3]来替换，那么式（1）变成非线性最小二乘(NLS)问题: \\[ \\hat{\\mathbf{x}}_{k}=\\underset{\\mathbf{x}_{k}}{\\arg \\min } \\sum_{i=1}^{m} \\rho\\left(\\left\\|\\mathbf{r}\\left(\\mathbf{x}_{k}, \\mathbf{p}_{k i}\\right)\\right\\|_{\\mathbf{\\Sigma}_{i}}^{2}\\right) \\] 其中， \\(\\rho(\\cdot)\\)表示鲁棒性Huber损失[61]，用于处理outlier \\(\\mathbf{r}(\\cdot)\\)表示残差函数 \\(\\Sigma_i\\)表示协方差矩阵 迭代方法如高斯牛顿、LM等方法常用于解决NLS问题，这些方法通过计算目标函数相对于状态向量\\(\\mathbf{x}_k\\)的Jacobian来进行局部线性化，即\\(\\mathbf{J}=\\partial f / \\partial \\mathbf{x}_{k}\\)。通过给定初始值，\\(\\mathbf{x}_k\\)通过使用\\(\\mathbf{J}\\)进行迭代优化，直到收敛到局部最优。 在最终的迭代中，状态的最小二乘协方差计算为\\(\\boldsymbol{\\Xi}=\\boldsymbol{\\Lambda}^{-1}\\)[62]，其中，\\(\\boldsymbol{\\Lambda}=\\mathbf{J}^{\\top} \\mathbf{J}\\)称为信息矩阵。 不确定性表示 我们使用[19]中的工具来表示数据不确定性，首先，考虑噪声的激光点如下，式（3）： \\[ \\mathbf{p}=\\overline{\\mathbf{p}}+\\boldsymbol{\\zeta}, \\quad \\boldsymbol{\\zeta} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Z}) \\] 其中, \\(\\bar{\\mathbf{p}}\\)表示不含噪声的点 \\(\\zeta \\in \\mathbb{R}^{3}\\)是零均值的高斯扰动变量，\\(\\mathbf{Z}\\)是激光测量的噪声协方差 为了使得式（3）与转换矩阵(i.e., \\(\\left.\\mathbf{p}_{h}^{\\prime}=\\mathbf{T} \\mathbf{p}_{h}\\right)\\)更加紧凑，我们使用齐次坐标系来表示： \\[ \\mathbf{p}_{h}=\\left[\\begin{array}{l} \\overline{\\mathbf{p}} \\\\ 1 \\end{array}\\right]+\\mathbf{D} \\boldsymbol{\\zeta}=\\overline{\\mathbf{p}}_{h}+\\mathbf{D} \\boldsymbol{\\zeta}, \\quad \\boldsymbol{\\zeta} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Z}) \\] 其中， \\(\\mathbf{D}\\)是将3x1向量转换为齐次坐标的矩阵 如[63]中的研究，LIDARS深度测量误差（也称为传感器噪声）主要受目标距离的影响，矩阵\\(\\mathbf{Z}\\)被简单的设置为常值矩阵。 然后，我们定义SE(3)中受小扰动的随机变量： \\[ \\mathbf{T}=\\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\overline{\\mathbf{T}}, \\quad \\boldsymbol{\\xi} \\sim \\mathcal{N}(\\mathbf{0}, \\boldsymbol{\\Xi}) \\] 其中， \\(\\overline{\\mathbf{T}}\\)是不含噪声的变换矩阵 \\(\\xi \\in \\mathbb{R}^{6}\\)是协方差为\\(\\Xi\\)的小扰动变量 这种表示允许我们在状态空间中储存变换的均值作为\\(\\overline{\\mathbf{T}}\\)，并使用\\(\\xi\\)作为扰动。 我们考虑\\(\\Xi\\)包含两个部分的来源： Degenerate Pose Estimatio，来自案例，例如在受限制的环境中缺乏几何结构[34]，它通常在其退化方向上不确定姿势[62]，[64]，现有工程诉诸基于模型和基于学习的[65]方法来估算ICP的背景下的姿势协方差。 Extrinsic Perturbation，该项始终存在，由于外参误差的存在[12]。这种扰动不利于多传感器系统的测量精度 [66]、[67] 但很难测量。 特别的，\\(\\Xi\\)的详细计算在Section VIII M-LOAM中的MLE问题 我们扩展了 MLE 以设计多个 M-LOAM 估计器，以从粗到细的方式解决机器人姿态和外参。最重要的步骤是将高斯噪声协方差\\(\\Sigma\\)近似于现实的测量模型。 根据第 III-C 节中的（上述）讨论，我们确定了三个可能使地标不确定的误差源：传感器噪声、退化姿态估计和外参扰动。 帧到帧运动估计（部分VI-A）归结于传感器噪声，紧耦合的里程计（第VII-C部分）建立了局部地图用于位姿优化，因此我们应该传播位姿的不确定性到每一个地图点。尽管如此，如果涉及更多的雷达和滑动窗口，这种操作通常是耗时的（大约10ms-20ms）。为了保证里程计的实时性，我们不在此处计算的位姿不确定性。 因此，我们简单地设置\\(\\Sigma=\\mathbf{Z}\\)作为残差的协方差。在建图部分，我们有足够的时间来获得准确的姿势和全局地图，因此，我们考虑所有不确定性来源。 第VIII部分解释了姿势不确定性如何影响建图精度和\\(\\Sigma\\)的传播。 系统概览 我们制作三个假设来简化系统设计 Lidars是同步的，这意味着不同雷达之间的时间延迟几乎为零 该平台在校准初始化期间经历了足够的旋转和平移运动 主激光雷达的局部地图应与辅助LIDAR共享重叠的FOV，用于在改进中匹配以缩短校准阶段，这可以通过移动机器人来实现 图 2 展示了 M-LOAM 的流水线。 系统从测量预处理（第 V 部分）开始，即从去噪点云中提取和跟踪边缘和平面特征 初始化模块（第VI部分）提供了所有必要的值，包括姿势和外参，用于启动后续的非线性优的M-LO。M-LO融合多激光雷达测量在滑动窗口内优化里程计和外参，如果外参已经收敛，我们跳过外参初始化以及细化步骤，然后进入纯里程计和建图阶段。 概率建图模块（第VIII节）构造了一种具有足够特征的全局地图，以消除里程计累计漂移。 里程计和建图模块分别运行在隔离的线程上。 测量预处理 我们实施三个顺序步骤来处理LiDARS'raw测量，我们首先将点云分割成许多簇以去除嘈杂的对象，然后提取边缘和平面特征。 为了将连续帧之间的特征关联起来，我们匹配了一系列的对应关系。 在本节中，每个 LiDAR 都是独立处理的。 噪声去除分割 通过了解LIDAR的垂直扫描角度，我们可以将原始点云投影到没有数据丢失的范围图像上,在图像中，每个有效点由像素表示。像素值记录了该点到原点的欧几里德距离。我们将[68]中提出的分割方法应用于将像素分组到多个集群中。 我们假设，如果两个相邻点的连接线大致垂直于（大于60度）激光束，则认为这两个相邻点属于相同的对象。我们采用广度第一搜索算法来遍历所有像素，确保恒定的时间复杂度，特别的，我们丢弃小集群，因为它们可能会在优化中提供不可靠的约束。 特征提取和匹配 我们有兴趣提取一般边缘和平面特征，我们遵循[16]选择根据其曲率从测量中选择一组特征点。该组提取的特征\\(\\mathcal{F}\\)由两个子集组成：边缘子集（高曲率）\\(\\mathcal{E}\\)和平面子集（低曲率）\\(\\mathcal{H}\\)。我们进一步从\\(\\mathcal{E}\\)收集曲率最高边缘点，从平面\\(\\mathcal{H}\\)收集曲率最低的平面点，得到另外两组点\\(\\hat{\\mathcal{E}},\\hat{\\mathcal{H}}\\)。 下一步是确定两个连续帧之间的特征对应关系，()\\(^{l_{k-1}^{i}} \\rightarrow()^{l_{k}^{i}}\\)，以构造几何约束： 对于边缘点集合\\(\\hat{\\mathcal{E}}^{l_{k}^{i}}\\)中的点，将从前一帧的边缘点集合\\(\\mathcal{E}^{l_{k-1}^{i}}\\)中查找两个最近邻的边缘点以形成边缘线关联。 对于平面点集合\\(\\hat{\\mathcal{H}}^{l_{k}^{i}}\\)中的点，则从上一帧的边缘点集合\\(\\mathcal{H}^{l_{k-1}^{i}}\\)中查找3个最近邻点作为平面关联。 初始化 优化多个LIDARS的状态是高度非线性的，需要给出初始估计值。本节介绍了我们的运动和外在初始化方法，不需要任何先前的传感器套件的机械配置。 它还不涉及任何手动努力，使其对自主机器人特别有用。 Scan-Based Motion Estimation 在每个LIDAR的两个连续帧之间找到了相应的对应关系，我们通过最小化所有功能的残差误差来估计帧到帧变换。如图3所示，残差由边缘和平面对应关系制定，设\\(\\mathbf{x}_k\\)为第k帧的相对变换，对于平面特征，对于平面点\\(\\mathbf{p} \\in \\hat{\\mathcal{H}}^{l_{k}^{i}}\\)，如果\\(\\Pi\\)是关联的平面，那么该平面点对应的残差如下计算，式（6）： \\[ \\mathbf{r}_{\\mathcal{H}}\\left(\\mathbf{x}_{k}, \\mathbf{p}, \\Pi\\right)=a \\mathbf{w}, \\quad a=\\mathbf{w}^{\\top}\\left(\\mathbf{R}_{k} \\mathbf{p}+\\mathbf{t}_{k}\\right)+d \\] 其中， \\(a\\)是点到平面的距离 \\([\\mathbf{w}, d]\\)是平面的参数 对于边缘线特征点\\(\\mathbf{p} \\in \\hat{\\mathcal{E}}^{l_{k}^{i}}\\)，如果\\(L\\)是与之关联的边缘线，那么我们使用如式（6）的两个平面特征的组合来表示点与边缘线的残差： \\[ \\mathbf{r}_{\\mathcal{E}}\\left(\\mathbf{x}_{k}, \\mathbf{p}, L\\right)=\\left[\\mathbf{r}_{\\mathcal{H}}\\left(\\mathbf{x}_{k}, \\mathbf{p}, \\Pi_{1}\\right), \\mathbf{r}_{\\mathcal{H}}\\left(\\mathbf{x}_{k}, \\mathbf{p}, \\Pi_{2}\\right)\\right] \\] 其中， \\(\\left[\\mathbf{w}_{1}, d_{1}\\right]\\),\\(\\left[\\mathbf{w}_{2}, d_{2}\\right]\\)分别是平面\\(\\Pi_{1}\\)、\\(\\Pi_{2}\\)的系数 \\(\\mathbf{w}_{1}\\)恰好与点\\(\\mathbf{p}\\)到直线\\(L\\)的投影方向一致 并且平面\\(\\Pi_{2}\\)垂直于\\(\\Pi_{1}\\)，满足s.t. \\(\\mathbf{w}_{2} \\perp \\mathbf{w}_{1}\\), and \\(\\mathbf{w}_{2} \\perp L\\) 上述定义与LOAM[16]有所不同，其中有两个好处，一是边缘残差为状态量提供了额外的约束，其次，残差可以使用向量表示，这允许我们乘以3x3的协方差矩阵 我们最小化所有残差项的总和以获得MLE： \\[ \\hat{\\mathbf{x}}_{k}=\\underset{\\mathbf{x}_{k}}{\\arg \\min } \\sum_{\\mathbf{p} \\in \\hat{\\mathcal{F}}^{i \\atop k}} \\rho\\left(\\left\\|\\mathbf{r}_{\\mathcal{F}}\\left(\\mathbf{x}_{k}, \\mathbf{p}\\right)\\right\\|_{\\boldsymbol{\\Sigma}_{\\mathbf{p}}}^{2}\\right) \\] \\[ \\mathbf{r}_{\\mathcal{F}}\\left(\\mathbf{x}_{k}, \\mathbf{p}\\right)=\\left\\{\\begin{array}{ll} \\mathbf{r}_{\\mathcal{E}}\\left(\\mathbf{x}_{k}, \\mathbf{p}, L\\right) &amp; \\text { if } \\mathbf{p} \\in \\hat{\\mathcal{E}}^{i_{k}^{i}} \\\\ \\mathbf{r}_{\\mathcal{H}}\\left(\\mathbf{x}_{k}, \\mathbf{p}, \\Pi\\right) &amp; \\text { if } \\mathbf{p} \\in \\hat{\\mathcal{H}}^{i_{k}^{i}} \\end{array}\\right. \\] 特别的，关于\\(\\mathbf{r}_{\\mathcal{F}}(\\cdot)\\)的雅克比在Appendix A进行详细讨论。 在实践中，在带滚动快门扫描的LiDars运动后，点存在一些倾斜畸变，在求出增量运动\\(\\mathbf{x}_k\\)后，我们将这些点转换到前一帧扫描的最后时刻（即第k帧扫描的起始）以矫正畸变。 令\\(t_{k-1},t_{k}\\)表示激光扫描的起始和结束，对于每一个扫描点\\(\\mathbf{p}\\)，都可以进行转换如下： \\[ \\mathbf{p}^{l_{k-1}^{i}}=\\mathbf{R}_{k}^{\\tau} \\mathbf{p}+\\mathbf{t}_{k}^{\\tau}, \\quad \\tau=\\frac{t-t_{k-1}}{t_{k}-t_{k-1}} \\] 其中，旋转和平移部分使用se(3)进行插值？参考文献[5] \\[ \\mathbf{R}_{k}^{\\tau}=\\exp \\left(\\boldsymbol{\\phi}_{k}^{\\wedge}\\right)^{\\tau}=\\exp \\left(\\tau \\boldsymbol{\\phi}_{k}^{\\wedge}\\right), \\quad \\mathbf{t}_{k}^{\\tau}=\\tau \\mathbf{t}_{k} \\] Calibration of Multi-LiDAR System 通过对准两个传感器的运动序列来获得初始外参，即这被称为手眼标定问题\\(\\mathbf{A X}=\\mathbf{X B}\\)，其中\\(\\mathbf{A},\\mathbf{B}\\)是两个传感器的位姿增量，\\(\\mathbf{B}\\)是他们的外参。 当机器人移动时，第i个激光雷达的第k帧时刻，有： 式（11）： \\[ \\mathbf{R}_{l_{k}^{i}}^{l_{k-1}^{i}} \\mathbf{R}_{l^{i}}^{b}=\\mathbf{R}_{l^{i}}^{b} \\mathbf{R}_{b_{k}}^{b_{k-1}} \\] 式（12）： \\[ \\left(\\mathbf{R}_{l_{k}^{i}}^{l_{k-1}^{i}}-\\mathbf{I}_{3}\\right) \\mathbf{t}_{l^{i}}^{b}=\\mathbf{R}_{l^{i}}^{b} \\mathbf{t}_{b_{k}}^{b_{k-1}}-\\mathbf{t}_{l_{k}^{i}}^{l_{k-1}^{i}} \\] 上面两式实际上是根据[14]，将情况下原始问题\\(\\mathbf{A X}=\\mathbf{X B}\\)分解为旋转和平移部分。我们实现了此方法可在线初始化外参。 旋转初始化 通过使用四元数，可以将式（11）重写成如下式（13）： \\[ \\begin{aligned} &amp; \\mathbf{q}_{l_{k}^{i}}^{l_{k-1}} \\otimes \\mathbf{q}_{l^{i}}^{b}=\\mathbf{q}_{l^{i}}^{b} \\otimes \\mathbf{q}_{b_{k}}^{b_{k-1}} \\\\ \\Rightarrow &amp;\\left[\\mathbf{Q}_{1}\\left(\\mathbf{q}_{l_{k-1}^{i}}^{l_{k}}\\right)-\\mathbf{Q}_{2}\\left(\\mathbf{q}_{b_{k}}^{b_{k-1}}\\right)\\right] \\mathbf{q}_{l^{i}}^{b}=\\mathbf{Q}_{k}^{k-1} \\mathbf{q}_{l^{i}}^{b} = 0 \\end{aligned} \\] 其中，\\(\\otimes\\)表示四元数乘法，\\(\\mathbf{Q}_{1}(\\cdot)，\\mathbf{Q}_{1}(\\cdot)\\)表示四元数的左乘、右乘等价矩阵[59]。 通过多次时间间隔，可以将式（13）就行堆叠，形成超定线性方程组： 式（14）： \\[ \\left[\\begin{array}{c} w_{1}^{0} \\cdot \\mathbf{Q}_{1}^{0} \\\\ \\vdots \\\\ w_{K}^{K-1} \\cdot \\mathbf{Q}_{K}^{K-1} \\end{array}\\right]_{4 K \\times 4} \\mathbf{q}_{l^{i}}^{b}=\\mathbf{Q}_{K} \\mathbf{q}_{l^{i}}^{b}=\\mathbf{0}_{4 K \\times 4} \\] 其中， \\(K\\)表示约束的数量 \\(w_{k}^{k-1}\\)是鲁棒性权重，定义为残差四元素的角度轴表示中的角度？ \\[ w_{k}^{k-1}=\\rho^{\\prime}(\\phi), \\quad \\phi=2 \\arctan \\left(\\left\\|\\mathbf{q}_{x y z}\\right\\|, q_{w}\\right) \\] \\[ \\mathbf{q}=\\left(\\check{\\mathbf{q}}_{l^{i}}^{b}{ }\\right)^{*}\\otimes\\left(\\mathbf{q}_{l_{k}^{i}}^{l_{k-1}^{i}}\\right)^{*} \\otimes \\check{\\mathbf{q}}_{l^{i}}^{b} \\otimes \\mathbf{q}_{b_{k}}^{b_{k-1}} \\] 其中， \\(\\rho^{\\prime}(\\cdot)\\)是Huber loss的微分 \\(\\check{\\mathbf{q}}_{l^{i}}^{b}\\)是当前估计的旋转外参 \\(\\mathbf{q}^{*}\\)是\\(\\mathbf{q}\\)的逆 令\\(\\| \\mathbf{q}_{l^{\\prime}}^{b}\\|=1\\)，我们可以使用SVD来获取式（14）的close form解。 对于3-DOF旋转的全部可观察性，需要足够的运动激励，在足够的约束下，\\(Q_k\\)的零空间的秩应为1，也就是说，我们只有1个零奇异值（4个变量，3个维度，剩下一个为0）。 否则，由于在一个轴或多个轴上的运动退化会导致\\(Q_k\\)的零空间&gt;1。因此，我们需要确保第二小的奇异值\\(\\sigma_{min2}\\)足够大以确保条件满足。我们设置了阈值\\(\\sigma_{\\mathbf{R}}\\)，and terminate the rotation calibration if σmin2&gt; σR. ??? 越来越多的数据会使得\\(Q_k\\)行数迅速增长，为了维持计算时间，我们使用优先级队列[69]，长度k = 300逐渐存储历史约束，并删除小旋转的约束。 平移初始化 一旦旋转校准完成，我们通过式（12）将所有可用数据结合，构造一个线性系统： 式（16）： \\[ \\left[\\begin{array}{c} \\mathbf{R}_{l_{1}^{i}}^{l_{0}}-\\mathbf{I}_{3} \\\\ \\vdots \\\\ \\mathbf{R}_{l_{K}^{i}}^{l_{K-1}^{i}}-\\mathbf{I}_{3} \\end{array}\\right]_{3 K \\times 3} \\mathbf{\\mathbf { t }}_{l^{i}}^{b}=\\left[\\begin{array}{c} \\hat{\\mathbf{R}}_{l^{i}}^{b} \\mathbf{t}_{b_{1}}^{b_{0}}-\\mathbf{t}_{l_{1}^{i}}^{l_{0}^{i}} \\\\ \\vdots \\\\ \\hat{\\mathbf{R}}_{l^i}^{b} \\mathbf{t}_{b_{K}}^{b_{K-1}}-\\mathbf{t}_{l_{K}^{i}}^{l^{i}_{K-1}} \\end{array}\\right]_{3 K \\times 1} \\] 其中， \\(\\mathbf{t}_{l^{i}}^{b}\\)通过使用最小二乘法获取 然而，如果机器人只在平面上运动，z轴方向上的平移是不可观的，在这种情况下，我们设置\\(t_z=0\\)然后重写式（16）以移除\\(\\mathbf{t}_{l^{i}}^{b}\\)中的Z轴分量。 不像文献[4]，我们的方法不能通过地面来初始化\\(t_z\\)，因此需要在后续的refinement阶段来恢复\\(t_z\\).(Section VII-B) 具备传感器外参细化的紧耦合多激光雷达里程计 将最初的猜测作为输入，我们提出了一个紧密耦合的M-LO，以优化滑动窗口内的所有状态，该过程的灵感来自多传感器系统的BA，Graph-Based和marginalization的启发[5],[15],[70]. 问题构造 滑动窗口中的全部状态向量如下定义： $$ \\[\\begin{aligned} \\mathcal{X} &amp;= [\\mathcal{X}_{f},\\qquad \\mathcal{X}_{v}, \\qquad \\qquad \\qquad \\mathcal{X}_{e}] \\\\ &amp;= [\\mathbf{x}_{1}, \\cdots, \\mathbf{x}_{p}, \\mathbf{x}_{p+1}, \\cdots, \\mathbf{x}_{N+1}, \\mathbf{x}_{l^{2}}^{b}, \\cdots, \\mathbf{x}_{l^{l}}^{b}] \\end{aligned}\\] $$ \\[ \\begin{aligned} \\mathbf{x}_{k} &amp;=\\left[\\mathbf{t}_{b_{k}}^{w}, \\mathbf{q}_{b_{k}}^{w}\\right], \\quad k \\in[1, N+1] \\\\ \\mathbf{x}_{l^{i}}^{b} &amp;=\\left[\\mathbf{t}_{l^{i}}^{b}, \\mathbf{q}_{l^{i}}^{b}\\right], \\quad i \\in[1, I], \\end{aligned} \\] 其中， \\(\\mathbf{x}_k\\)是主激光雷达在世界坐标系下不同时间戳的状态 \\(\\mathbf{x}_{l^{i}}^{b}\\)表示主激光雷达到第i辅助激光雷达的外参 \\(N+1\\)是滑动窗口中的状态数量 为了建立这些状态之间的数据关联，我们建立了局部地图 图4对Graph-base的构造进行了可视化，我们使用\\(p\\)来索引滑动窗口中的枢轴状态，并设置\\(\\mathbf{x}_p\\)作为局部地图的原点（起始）。 利用从枢轴帧到其他帧的相对变换，通过连接前N帧（如\\(\\mathcal{F}^{l_{k}^{i}}, k \\in[1, N]\\)）的特征点来构造局部地图。第i个激光雷达的局部特征地图由局部边缘地图和局部平面地图组成，记为\\(\\mathcal{M}^{l^{i}}\\)。 我们分割全状态向量\\(\\mathcal{X}\\)为3个部分：\\(\\mathcal{X}_{f},\\mathcal{X}_{v},\\mathcal{X}_e\\)： \\(\\mathcal{X}_{f}=[\\mathbf{x}_1,\\dots,\\mathbf{x}_p]\\)是由已经固定的准确状态组成 \\(\\mathcal{X}_{v}=\\left[\\mathbf{x}_{p+1}, \\cdots, \\mathbf{x}_{N+1}\\right]\\)被考虑作为在优化过程中迭代更新的变量 \\(\\mathcal{X}_{e}=\\left[\\mathbf{x}_{l^{2}}^{b}, \\cdots, \\mathbf{x}_{l^I}^{b}\\right]\\)是外参向量，它们的设置取决于在线校准的收敛性。 我们最小化滑动窗口内所有残差的总和以获得 MAP 估计为： \\[ \\hat{\\mathcal{X}}=\\underset{\\mathcal{X}}{\\arg \\min }\\left\\{\\left\\|\\mathbf{r}_{p r i}(\\mathcal{X})\\right\\|^{2}+f_{\\mathcal{M}}(\\mathcal{X})\\right\\} \\] 其中， \\(\\mathbf{r}_{p r i}(\\mathcal{X})\\)是VII-E节中定义的边缘化状态的先验项 \\(f_{\\mathcal{M}}(\\mathcal{X})\\)是基于地图的残差的总和，其式（18）的雅克比矩阵推导见Appendix A 本文呈现的滑动窗口估计器与帧到帧估计不同，该估计器联合优化了窗口中的所有状态。这种方法，输出更准确的结果，因为局部地图提供了密集和可靠的对应关系。如果传感器精确标定，还使用来自其他雷达的约束。根据标定的收敛性，我们将问题分为两个子任务： 在线标定online calibration (variable \\(\\mathcal{X}_e\\)) 纯里程计pure odometry (fixed \\(\\mathcal{X}_e\\)) 在每个任务中，\\(f_{\\mathcal{M}}(\\mathcal{X})\\)的定义是不同的，我们在第 VII-B 和 VII-C 节中介绍了详细信息 考虑在线标定的优化 我们利用基于地图的测量来改进粗略初始化结果，在这里，我们将标定问题视为配准问题，\\(f_{\\mathcal{M}}(\\mathcal{X})\\)分为两个函数，分别相对于\\(\\mathcal{X}_{v}\\)和\\(\\mathcal{X}_{e}\\)。 对于\\(\\mathcal{X}_{v}\\)中的状态，这些约束由主传感器的最新帧的特征如\\(\\mathcal{F}^{b_{k}}, k \\in[p+1, N+1]\\)，与主激光雷达的局部地图\\(\\mathcal{M}^{b}\\)之间的关联构成。 对于\\(\\mathcal{X}_{e}\\)中的状态，这些约束由第i辅助激光雷达的第p帧的特征\\(\\mathcal{F}^{l_{p}^{i}}\\)与局部地图\\(\\mathcal{M}^{b}\\)的特征关联构成。 \\(\\mathcal{F}^{b_{k}}\\)与局部特征地图\\(\\mathcal{M}^{b}\\)的关联使用[16]中的方法进行寻找，其中特征地图\\(\\mathcal{M}^{b}\\)使用了KD-TREE进行索引。 对于边缘点，我们在局部边缘地图中的指定范围查找与之最近邻的点集合，记为\\(\\mathcal{S}\\)，然后计算点集的方差。点集的最大特征值对应的特征向量表示了与该边缘点所关联的直线的方向。通过计算点集的均值，即可确定边缘点对应的边缘线。 对于平面点，通过求解线性系统\\(\\mathbf{w s}+d=0, \\forall \\mathbf{s} \\in \\mathcal{S}\\)，可以得到在局部平面点云地图中与之关联的平面的系数，同样的，我们寻找\\(\\mathcal{F}^{l_{p}^{i}}\\)和\\(\\mathcal{M}^{b}\\)的关联。 最后，我们将目标定义为在线标定的所有测量残差的总和，式（19）： \\[ \\begin{aligned} f_{\\mathcal{M}}(\\mathcal{X}) &amp;=f_{\\mathcal{M}}\\left(\\mathcal{X}_{v}\\right)+f_{\\mathcal{M}}\\left(\\mathcal{X}_{e}\\right) \\\\ &amp;=\\sum_{k=p+1}^{N+1} \\sum_{\\mathbf{p} \\in \\mathcal{F}^{b_{k}}} \\rho\\left(\\left\\|\\mathbf{r}_{\\mathcal{F}}\\left(\\mathbf{x}_{p}^{-1} \\mathbf{x}_{k}, \\mathbf{p}\\right)\\right\\|_{\\Sigma_{\\mathrm{p}}}^{2}\\right) +\\sum_{i=2}^{I} \\sum_{\\mathbf{p} \\in \\mathcal{F}^{l_{p}^{i}}} \\rho\\left(\\left\\|\\mathbf{r}_{\\mathcal{F}}\\left(\\mathbf{x}_{l^{i}}^{b}, \\mathbf{p}\\right)\\right\\|_{\\boldsymbol{\\Sigma}_{\\mathbf{p}}}^{2}\\right) \\end{aligned} \\] 其中， \\(\\mathbf{x}_{p}^{-1} \\mathbf{x}_{k}\\)表示从中枢坐标系到第k帧的变换 \\(\\mathbf{x}_{p}\\)作为局部地图的起点状态 纯里程计的优化 一旦我们通过满足收敛标准完成在线校准（VII-D部分），然后就可以在给定准确外参的情况下进行纯里程计的优化。在这种情况下，我们没有优化外参，并利用基于地图的测量来改善单激光的里程计。 我们将所有 LiDAR 和局部地图的特征之间的约束合并到成本函数中： \\[ \\begin{aligned} f_{\\mathcal{M}}(\\mathcal{X}) &amp;=f_{\\mathcal{M}}\\left(\\mathcal{X}_{v}\\right) \\\\ &amp;=\\sum_{k=p+1}^{N+1} \\sum_{\\mathbf{p} \\in \\mathcal{F}^{b_{k}}} \\rho\\left(\\left\\|\\mathbf{r}_{\\mathcal{F}}\\left(\\mathbf{x}_{p}^{-1} \\mathbf{x}_{k}, \\mathbf{p}\\right)\\right\\|_{\\Sigma_{\\mathbf{p}}}^{2}\\right) \\\\ &amp;+ \\sum_{i=2}^{I} \\sum_{k=p+1}^{N+1} \\sum_{\\mathbf{p} \\in \\mathcal{F}^{l^{i}_{k}}} \\rho\\left(\\left\\|\\mathbf{r}_{\\mathcal{F}}\\left(\\mathbf{x}_{p}^{-1} \\mathbf{x}_{k} \\mathbf{x}_{l^{i}}^{b}, \\mathbf{p}\\right)\\right\\|_{\\boldsymbol{\\Sigma}_{\\mathbf{p}}}^{2}\\right) \\end{aligned} \\] 其中， \\(\\mathbf{x}_{p}^{-1} \\mathbf{x}_{k} \\mathbf{x}_{l^{i}}^{b}\\)表示第k帧下，从主激光雷达的局部地图坐标系（pivot frame）到辅助激光雷达坐标系的变换。 外参标定收敛性管理 在以无人监督的方式工作在线标定时，判断标定是否收敛是有意义的，收敛后，我们就可以固定外参。这对我们的系统有益，因为里程计和建图都是从辅助雷达获得更多几何约束，以便更准确地进行位姿估计。 如[34]中得出，作为信息矩阵的最小特征值的退化因子λ揭示了基于优化的状态估计问题的条件。通过这项工作的影响，我们使用λ表示是否包含足够的约束来获取准确的外参。 更新外参和收敛性监视器的详细流水线总结如算法1所示： 算法采用式（19）定义的函数\\(f_{\\mathcal{M}}(\\cdot)\\)，以及使用当前的外参作为输入，并返回优化后的外参。 在第4行，我们从cost function的信息矩阵中计算\\(\\lambda\\)， 在5-7行，如果\\(\\lambda\\)大于阈值，则对外参进行更新。 在第8行，我们使用的外参候选值来检查收敛性。 在第9-10行，收敛性判断条件满足，因此触发停止标定。然后计算\\(\\mathcal{L}\\)的采样均值，作为输出的外参结果，并且采样协方差作为标定的协方差。 边缘化 我们应用边缘化技术来删除滑动窗口中的最旧变量状态，边缘化是将历史约束作为目标融合的过程，这是维持里程计和标定结果一致性的重要步骤。 在我们的系统中，\\(\\mathbf{x}_{p}\\)是在每次优化后被边缘化的唯一的状态，通过应用Schur Complement，我们得到关于保留状态的信息矩阵\\(\\mathbf{A}_{rr}^{*}\\)和残差\\(\\mathbf{g}_{r}^{*}\\)。因此，由边缘化得到的先验残差项可写成：\\(\\left\\|\\mathbf{r}_{p r i}\\right\\|^{2}=\\mathbf{g}_{r}^{* \\top} \\boldsymbol{\\Lambda}_{r r}^{*-1} \\mathbf{g}_{r}^{*}\\)，Appendix B会给出更加详细的数学推导。 考虑不确定性的多激光雷达建图 我们首先回顾了典型 LiDAR SLAM 系统的建图模块的管道 [16]-[18]，以里程计先验作为输入，算法构建全局地图并使用足够的约束来对pose关键帧进行精细化调整。这通过最小化所有基于地图的残差项之和来实现，式（21）： \\[ \\hat{\\mathbf{x}}_{b_{k}}^{w}=\\underset{\\mathbf{x}_{b_{k}}^{w}}{\\arg \\min } \\sum_{i=1}^{I} \\sum_{\\mathbf{p} \\in \\mathcal{F}_{k}^{l^{i}_{k}}} \\rho\\left(\\left\\|\\mathbf{r}_{\\mathcal{F}}\\left(\\mathbf{x}_{b_{k}}^{w} \\mathbf{x}_{l^{i}}^{b}, \\mathbf{p}\\right)\\right\\|_{\\boldsymbol{\\Sigma}_{\\mathbf{p}}}^{2}\\right) \\] 其中, \\(\\mathcal{F}^{l_{k}^{i}}\\)是第k帧点云的特征点 \\(\\mathcal{G}_{\\mathcal{F}}^{w_{k}}\\)是全局地图 \\(\\mathbf{x}_{b_{k}}^{w} \\mathbf{x}_{l^{i}}^{b}\\)表示第k帧时刻第i个激光雷达的状态 我们使用Section VII-B中的方法查找\\(\\mathcal{F}^{l_{k}^{i}}\\)和\\(\\mathcal{G}_{\\mathcal{F}}^{w_{k}}\\)之前的特征关联。在求解式（21）之后，求解的位姿将用于将特征点转换到世界坐标系，然后添加到全局地图上。为了降低计算和内存复杂性，地图也使用体素滤波器[71]进行降采样。但是，优化的精度取决于地图质量。图5展示了使用不确定的pose得到的带有噪声的地图点。我们认为，三个不确定性来源使地图点嘈杂：传感器噪声，退化姿态估计和外参扰动。 在下一节中，我们将激光测量点和位姿求解的不确定性传播到地图点上。结果，每个地图点都被建模为高斯变量。 然后，我们提出了一种考虑不确定性的方法来提高多激光雷达建图算法的鲁棒性和准确性。 不确定性传播 继续在第III-C节中描述，我们现在计算协方差\\(\\Xi\\)，mapping的位姿通过求解式（21）的NLS问题得到，我们直接计算信息矩阵的逆，即\\(\\mathbf{\\Xi}_{\\mathbf{x}_{b_{k}}^{w}}=\\boldsymbol{\\Lambda}^{-1}\\)作为协方差。 外参协方差的设置取决于特定的情况，我们通用的把外参协方差定义如下： \\[ \\boldsymbol{\\Xi}_{\\mathbf{x}_{l^{i}}^{b}}=\\alpha \\cdot \\boldsymbol{\\Xi}_{\\text {calib }}, \\quad \\boldsymbol{\\xi}_{l^{i}}^{b} \\sim \\mathcal{N}\\left(\\mathbf{0}, \\boldsymbol{\\Xi}_{\\mathbf{x}_{l^{i}}^{b}}\\right) \\] 其中， \\(\\boldsymbol{\\xi}_{l^{i}}^{b}\\)是外参的扰动变量 \\(\\boldsymbol{\\Xi}_{\\text {calib }}\\)是通过算法1计算得到的标定协方差 \\(\\alpha\\)是缩放系数，用于控制协方差的量级 如果多激光雷达系统最近被标定过，我们设置\\(\\alpha=1\\)，如果系统使用了很长时间且没有进行重新标定，激光雷达之间的外参会存在小的偏差，\\(\\alpha\\)将被设置为更大的值。它具有与时间和外部影响的隐含关系，以及温度漂移。 给定主激光雷达的pose均值以及外参的均值和协方差，然后计算其他雷达pose的均值和协方差，如\\(\\left\\{\\mathbf{T}_{l_{k}^{i}}^{w}, \\boldsymbol{\\Xi}_{l_{k}^{i}}^{w}\\right\\}\\)，这是一个关于两个含有噪声的复合pose的问题，我们遵循[19]中的4阶近似来计算他们。 然后，我们需要通过一个包含噪声的位姿变换来传播高斯不确定性，以产生新的地图点（landmark），如\\(\\mathbf{y} \\in \\mathcal{G}_{\\mathcal{F}}^{w_{k+1}}\\)，其均值和方差为\\(\\{\\overline{\\mathbf{y}}, \\boldsymbol{\\Sigma}\\}\\)，利用将点进行坐标变换的公式，可得： \\[ \\begin{aligned} \\mathbf{y} \\triangleq \\mathbf{T}_{l_{k}^{i}}^{w} \\mathbf{p}_{h} &amp;=\\exp \\left(\\boldsymbol{\\xi}_{e l_{k}^{i}}^{w^{\\wedge}}\\right) \\overline{\\mathbf{T}}_{l_{k}^{i}}^{w}\\left(\\overline{\\mathbf{p}}_{h}+\\mathbf{D} \\boldsymbol{\\zeta}\\right) \\\\ &amp; \\approx\\left(\\mathbf{I}+\\boldsymbol{\\xi}_{l_{k}^{i}}^{w^{\\wedge}}\\right) \\mathbf{\\mathbf { T }}_{l_{k}^{i}}^{w}\\left(\\overline{\\mathbf{p}}_{h}+\\mathbf{D} \\boldsymbol{\\zeta}\\right) \\end{aligned} \\] 其中，我们只保留指数映射\\(\\exp(\\cdot)\\)的一阶近似。 进一步的，如果我们展开等式，并仅保留一阶项，我们有： \\[ \\mathbf{y} \\approx \\mathbf{h}+\\mathbf{H} \\boldsymbol{\\theta} \\] 其中， \\[ \\mathbf{h}=\\overline{\\mathbf{T}}_{l_{k}^{i}}^{w} \\overline{\\mathbf{p}}_{h}, \\quad \\mathbf{H}=\\left[\\left(\\overline{\\mathbf{T}}_{l_{k}^{i}}^{w} \\overline{\\mathbf{p}}_{h}\\right)^{\\odot} \\quad \\overline{\\mathbf{T}}_{l_{k}^{i}}^{w} \\mathbf{D}\\right] \\] \\[ \\boldsymbol{\\theta}=\\left[\\boldsymbol{\\xi}_{l_{k}^{i}}^{w \\top}, \\boldsymbol{\\zeta}^{\\top}\\right]^{\\top}, \\quad \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\mathbf{0}, \\boldsymbol{\\Theta}), \\quad \\boldsymbol{\\Theta}=\\operatorname{diag}\\left(\\boldsymbol{\\Xi}_{l_{k}^{i}}^{w}, \\mathbf{Z}\\right) \\] 特别的，操作符\\(\\odot\\)表示将4x1的向量转换为4x6的矩阵： \\[ \\left[\\begin{array}{l} \\varepsilon \\\\ \\eta \\end{array}\\right]^{\\odot}=\\left[\\begin{array}{cc} \\eta \\mathbf{I} &amp; -\\boldsymbol{\\varepsilon}^{\\wedge} \\\\ \\mathbf{0}^{\\top} &amp; \\mathbf{0}^{\\top} \\end{array}\\right], \\quad \\boldsymbol{\\varepsilon} \\in \\mathbb{R}^{3}, \\quad \\eta=1 \\]","categories":[],"tags":[]},{"title":"ROLI激光雷达IMU初始化及标定","slug":"Fast-LIO系列/ROLI激光雷达IMU初始化及标定","date":"2022-03-06T04:02:22.000Z","updated":"2022-04-11T15:57:06.233Z","comments":true,"path":"2022/03/06/Fast-LIO系列/ROLI激光雷达IMU初始化及标定/","link":"","permalink":"http://yoursite.com/2022/03/06/Fast-LIO%E7%B3%BB%E5%88%97/ROLI%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BEIMU%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%8A%E6%A0%87%E5%AE%9A/","excerpt":"","text":"Robust and Online LiDAR-inertial Initialization 介绍 摘要：对于大多数LiDAR惯性里程计来说，精确的初始状态，包括时间偏差和LiDAR与6轴IMU之间的外参，起着重要的作用，通常被认为是前提条件。然而，在定制的激光雷达惯性系统中，这样的信息并不总是可用的，本文提出了一种完全在线的激光雷达惯性系统初始化过程，该过程通过校准激光雷达和IMU之间的时间偏差和外参，并通过将激光雷达测量的状态估计值与IMU测量的状态值对齐来校正重力矢量和IMU偏差。我们将所提出的方法实现为一个初始化模块，如果启用该模块，它将自动检测采集数据的激发程度，同时校准时间偏移量、外参偏移量、重力矢量和惯性测量单元偏差，然后将其用作在线激光雷达惯性里程仪系统的高质量初始状态值。对不同类型的激光雷达和激光雷达-惯性组合进行的实验表明了该初始化方法的鲁棒性、适应性和有效性。 我们的LiDAR-惯性初始化法的主要目的之一是在没有任何初始估计的情况下校准LiDAR和IMU之间的外特性。现有的一些外部标定方法是基于批量优化的，数据关联性很强，耗时较大。例如，Lveal。[14]提出了一种基于连续时间批优化的标定方法。B样条的使用使得需要估计的参数较多，计算量也较大。[15]使用扩展卡尔曼过滤估计运动补偿复杂的外域变换，收敛速度有限。与这些方法相比，我们的方法更轻量级，能够快速运行，同时仍然可以获得足够精确的外部校准，以便后续的在线估计(例如，通过[1])。我们的方法还校准了[14，15]中没有考虑的时间偏移。此外，文献[14，15]所采用的基于NDT的扫描-扫描匹配通常不适用于具有非重复扫描模式的激光雷达。相比之下，我们的方法采用了扫描到地图的匹配策略，可以很容易地应用重复扫描和非重复扫描的LiDAR。 方法 系统框架 由于IMU只有在运动时才被激发[15]，所以我们的初始化过程是基于运动的方法，这意味着充分的激励是必要的。我们工作流程的概述如图2所示，一些重要符号如表一所示。我们建议的LiDAR里程计(参见第III-B节)由FAST-LIO2[1]改进而来，采用恒定(角和线)速度(CV)模型来预测LiDAR运动并进行畸变矫正。 为了缓解恒速模型与传感器实际运动之间的失配，通过将输入帧分割成几个子帧来提高LiDAR里程计速率。 如果LiDAR里程计没有失效(例如，退化)，并且估计的LiDAR角速度和线速度满足我们建议的评估标准(参见第III-C5节)，则认为激励是足够的，并且LiDAR里程计输出和相应的IMU数据都被馈送到初始化模块(参见第III-C节) 在初始化中，首先通过移动IMU测量值来校准时间偏移，以与LiDAR里程计对准，然后进行优化处理，进一步细化时间偏移，校准外参，估计IMU偏差和重力矢量。通过融合后续的LiDAR和IMU数据，可以将初始化的状态附加到紧耦合的LiDAR惯性里程计(例如，[1])，用于在线状态估计。 激光里程计 我们的LiDAR里程计是建立在恒速(CV)运动模型上的，该模型假设在tk和tk+1接收到的两个连续扫描之间的角速度和线速度是恒定的，即，在tk和tk+1接收到的两个连续扫描之间，有： 其中\\(\\Delta t\\)是两帧扫描的时间间隔，状态向量\\(\\mathbf{x}\\)、噪声\\(\\mathbf{w}\\)和离散的状态转移函数\\(\\mathbf{f}\\)定义如下： 其中： \\({ }^{G} \\mathbf{R}_{L} \\in S O(3)\\)和\\({ }^{G} \\mathbf{p}_{L}\\)分别表示激光雷达在全局坐标系（此处为第0帧激光坐标系）的姿态的位置 \\({ }^{G} \\mathbf{v}_{L}\\)是激光雷达在全局坐标系的速度表示 \\(\\omega_{L}\\)是激光雷达线速度（在激光雷达坐标系） 上述两个速度被分别被建模为由高斯噪声\\(\\mathbf{n}_{\\mathbf{v}}\\)和\\(\\mathbf{n}_{\\omega}\\)驱动的随机游走过程。 在对于公式（1），使用文献[22]的记号\\(\\boxplus / \\boxminus\\)紧凑地表示状态流形上的“+”。具体地说，对于公式(2)中的状态流形\\(S O(3) \\times \\mathbb{R}^{n}\\)，运算及其逆定义如下： 其中： \\(\\mathbf{R}, \\mathbf{R}_{1}, \\mathbf{R}_{2} \\in S O(3)\\)， \\(\\mathbf{r}, \\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^{n}\\) \\(\\operatorname{Exp}(\\cdot): \\mathbb{R}^{3} \\mapsto S O(3)\\) 表示指数映射 \\(\\log (\\cdot): S O(3) \\mapsto \\mathbb{R}^{3}\\)是指数映射的逆，即对数映射 在实践中，传感器的运动可能不具有恒定速度。为了减轻这种模型误差的影响，我们可以将输入的LiDAR扫描分割成多个持续时间较短的子帧，在这些子帧上传感器的运动更符合CV模型。 误差迭代卡尔曼 基于流形上的系统表示(1)，我们使用误差状态迭代卡尔曼过滤(ESIKF)[23]来估计其状态，ESIKF的预测步骤由状态预测和协方差传播组成，如下所示： 其中， \\(\\mathbf{P}\\)表示状态估计的协方差 \\(\\mathbf{Q}\\)表示过程噪声\\(\\mathbf{w}\\)对应的协方差 \\(\\mathbf{F}_{\\tilde{\\mathbf{x}}}\\) 和 \\(\\mathbf{F}_{\\mathbf{w}}\\)定义如下： 由误差状态微分方程可导出（上述Fx Fw是离散时间下的） 运动补偿 在我们考虑的问题中，IMU和LiDAR是不同步的，因此文献[14，15]所采用的IMU辅助运动补偿方法是不可行的。 在时间戳\\(t_{k+1}\\)处接收到新的激光雷达扫描之后，为了补偿运动失真，我们将在时间戳\\(\\rho_{j} \\in\\left(t_{k}, t_{k+1}\\right)\\)处采样的每个包含点\\({ }^{L_{j}} \\mathbf{p}_{j}\\)投影到扫描端激光雷达帧\\(L_{k+1}\\)中，也就是将激光矫正到扫描结束时刻。 在恒速模型下，我们有\\({}^G \\widehat{\\mathbf{v}}_{L_{k+1}}={}^G{\\overline{\\mathbf{v}}}_{L_{k}}, \\widehat{\\boldsymbol{\\omega}}_{L_{k+1}}=\\overline{\\boldsymbol{\\omega}}_{L_{k}}\\)，因此，可以导出\\({}^{L_{k+1}} \\check{\\mathbf{T}}_{L_{j}}=\\left({ }^{L_{k+1}} \\check{\\mathbf{R}}_{L_{j}},{ }^{L_{k+1}} \\check{\\mathbf{p}}_{L_{j}}\\right)\\)的计算如下： 然后，在时间段\\(\\rho_{j} \\in\\left(t_{k}, t_{k+1}\\right)\\)内的测量\\({ }^{L_{j}} \\mathbf{p}_{j}\\)可以被投影到扫描结束时刻，即： 矫正之后的激光扫描\\(\\left\\{ {}^{L_{k+1}} \\mathbf{p}_{j}\\right\\}\\)用于提供未知状态\\({}^G \\mathbf{T}_{L_{k+1}}\\)的隐式测量，表示为点到面距离残差，在此基础上，在迭代卡尔曼滤波器框架中迭代估计完整状态\\(\\mathbf{x}_{k+1}\\)，直到收敛。这种迭代估计的细节可以参考FAST-LIO2[1]或[23]，以便更一般地处理流形约束。 收敛后的状态估计记为\\(\\overline{\\mathbf{x}}_{k+1}\\)，将用于传播后续IMU测量，如第III-B1节所述。 图3中示出了使用有运动补偿和无运动补偿的扫描的映射结果比较。 激光-惯性初始化 第III-B节中的激光雷达里程计在每个扫描结束时间\\(t_{k}\\)输出激光雷达的角速度\\(\\boldsymbol{\\omega}_{L_{k}}\\)和线速度\\({ }^{G} \\mathbf{V}_{L_{k}}\\)。同时，惯性测量单元提供了原始测量，包括时间戳\\(\\tau_{i}\\)的body系角速度\\(\\omega_{m}\\)和线加速度\\(\\mathbf{a}_{m_{i}}\\)。这些数据按照第III-C5节所示的激励标准进行累积和重复评估。 一旦收集到足够激励的数据，就调用初始化模块，然后输出如下信息： 时间偏移\\({ }^{I} t_{L} \\in \\mathbb{R}\\) 外参\\({ }^{I} \\mathbf{T}_{L}=\\left({ }^{I} \\mathbf{R}_{L},{ }^{I} \\mathbf{p}_{L}\\right) \\in SE(3)\\) IMU Bias\\(\\mathbf{b}_{\\omega}, \\mathbf{b}_{\\mathbf{a}} \\in \\mathbb{R}^{3}\\) 以及全局坐标系下的重力向量\\({ }^{G} \\mathbf{g} \\in \\mathbb{R}^{3}\\) 数据处理 IMU原始测量数据收到噪声\\(\\mathbf{n}_{\\omega_{i}}\\) 和 \\(\\mathbf{n}_{\\mathbf{a}}\\)的影响，因此IMU测量模型如下： 其中， \\(\\omega_{i}^{\\mathrm{gt}}, \\mathbf{a}_{i}^{\\mathrm{gt}}\\)是测量真值 同时，从激光里程计估计出来的\\(\\boldsymbol{\\omega}_{L_{k}},{ }^{G} \\mathbf{v}_{L_{k}}\\)也包含了噪声 为了消除这些通常是高频的噪声，使用了非因果零阶低通滤波器[24]来过滤噪声，而不会引入任何过滤延迟。零相位过滤是通过巴特沃斯低通滤波器的前向和后向运行来实现的[24]，得到噪声衰减（去除噪声影响的测量）的IMU测量\\(\\boldsymbol{\\omega}_{I_{i}}=\\boldsymbol{\\omega}_{i}^{\\mathrm{gt}}+\\mathbf{b}_{\\omega}, \\mathbf{a}_{I_{i}}=\\mathbf{a}_{i}^{\\mathrm{gt}}+\\mathbf{b}_{\\mathbf{a}}\\)为表示简单起见，噪声衰减的激光里程计速度估计值仍然表示为\\(\\boldsymbol{\\omega}_{L_{k}},{ }^{G} \\mathbf{v}_{L_{k}}\\)。 从激光雷达里程计得到的\\(\\boldsymbol{\\omega}_{L_{k}},^{G} \\mathbf{v}_{L_{k}}\\)，通过非因果中心差分[25]得到激光雷达角加速度和线加速度\\(\\boldsymbol{\\Omega}_{L_{k}},{ }^{G} \\mathbf{a}_{L_{k}}\\)，因此，根据激光里程计得到的数据记为： 类似地，我们从噪声衰减的陀螺测量\\(\\omega_{I}\\)得到角加速度\\(\\boldsymbol{\\Omega}_{I_{i}}\\)，因此有： 由于IMU频率通常高于LiDAR odometer的频率，因此两个序列\\(\\mathcal{I}_{i}\\)和\\(\\mathcal{L}_{k}\\)的长度并不相同。为了解决这一问题，我们提取在同一时间段内接收的LiDAR和IMU数据，并通过在每个LiDAR里程计时间\\(t_{k}\\)对\\(\\mathcal{I}_{i}\\)进行线性插值来实现下采样(参见图4)。 降采样的IMU数据记为\\(\\mathcal{I}_{k}\\)： 其中，\\(\\mathcal{I}_{k}\\)具有与\\(\\mathcal{L}_{k}\\)相同的时间戳\\(t_{k}\\)(但是数据实际上被已知的时间常数\\({ }^{I} t_{L}\\)延迟)。 用互相关法进行时间初始化(Temporal Initialization by Cross-Correlation) 在大多数情况下，由于LiDAR惯性里程计模块受到接收数据之前不可避免的传输和处理延迟，在LiDAR \\(\\mathcal{L}_{k}\\)和IMU \\(\\mathcal{I}_{k}\\)之间将存在未知但恒定的偏移\\({ }^{I} t_{L}\\)（例如IMU数据，全部向前推进\\({ }^{I} t_{L}\\)，则与激光雷达数据对齐）。 由于激光雷达数据公式(9)和IMU数据公式(11)处于离散时间\\(t_{k}\\)，因此IMU数据的推进实质上是以离散时间步\\(d={ }^{I} t_{L} / \\Delta t\\)进行的，其中\\(\\Delta t\\)是两次激光雷达扫描之间的时间间隔。具体地说，对于角速度，我们有： [[Pasted image 20220306235340.png]] 忽略通常很小的陀螺偏置bω，我们发现\\(\\boldsymbol{\\omega}_{I_{k+d}}\\)和\\(\\boldsymbol{\\omega}_{L_{k}}\\)的大小(模长)应该是相同的，而与外参\\({ }^{I} \\mathbf{R}_{L}\\)无关。受[16]的启发，我们使用互相关来量化它们之间的相似度。然后，偏移量\\(d\\)可以从下面的优化问题中求解： 通过枚举\\(\\mathcal{L}_{k}\\)的索引范围内的偏移量\\(d\\)。 这里是通过对IMU数据逐个前挪来实现对齐，所以\\(d\\)的理解是：IMU前移1个数据，即前移了\\(\\Delta t\\)时间，所以\\({ }^{I} t_{L}= d * \\Delta t\\) 统一的旋转外参和时间校准 (2)中的互相关法对噪声和小尺度陀螺偏差具有较强的鲁棒性。但其的一个明显缺陷是，时间偏移的校准分辨率只能达到激光雷达里程计的一个采样间隔\\(\\Delta t\\)，不能识别任何小于\\(\\Delta t\\)的剩余偏移δt。 设\\({ }^{I} t_{L}\\)为激光雷达里程计ωL与IMU数据ωi之间的总偏移量，则\\({ }^{I_{t}} t_{L}=d^{*} \\Delta t+\\delta t\\)。与公式(12)类似，如果IMU测量\\(\\boldsymbol{\\omega}_{I}\\)提前时间\\({ }^{I} t_{L}\\)，则通过下式将与激光雷达里程计\\(\\omega_{L}\\)对齐： 由于公式(9)中的实际激光雷达里程计\\(\\boldsymbol{\\omega}_{L}\\)仅在时间戳\\(t_{k}\\)处可用，用\\(t=t_{k}\\)和\\({ }^{I} t_{L}=d^{*} \\Delta t+\\delta t\\)代入到公式(14)，并注意到\\(\\boldsymbol{\\omega}_{L}\\left(t_{k}\\right)=\\boldsymbol{\\omega}_{L_{k}}\\)，我们有： 注意到，\\(\\boldsymbol{\\omega}_{I}\\left(t_{k}+d^{*} \\Delta t+\\delta t\\right)\\)是在时间戳为\\(t_{k}+d^{*} \\Delta t\\)之后紧跟的IMU角速度，而时间戳为\\(t_{k}+d^{*} \\Delta t\\)对应的角速度和角加速度分别为\\(\\omega_{I}\\left(t_{k}+d^{*} \\Delta t\\right)=\\omega_{I_{k}}\\)和\\(\\boldsymbol{\\Omega}_{I}\\left(t_{k}+d^{*} \\Delta t\\right)=\\boldsymbol{\\Omega}_{I_{k^{\\prime}}}\\)，假设角加速度在小量\\(\\delta t\\)上恒定，我们可以插值得到\\(\\boldsymbol{\\omega}_{I}\\left(t_{k}+d^{*} \\Delta t+\\delta t\\right)\\)： 将上式（16）代入公式（16），可以获得： 最后，基于公式(17)中的约束，统一的时空优化问题可以表述为： 上述问题可通过Ceres迭代求解(由于非线性约束\\({ }^{I} \\mathbf{R}_{L} \\in S O(3)\\))，并且给定初始值为\\(\\left({ }^{I} \\mathbf{R}_{L}, \\mathbf{b}_{\\omega}, \\delta t\\right)=\\left(\\mathbf{I}_{3 \\times 3}, \\mathbf{0}_{3 \\times 1}, 0\\right)\\) 平移外参与重力向量初始化 在第III-C3节中，我们得到了外旋转\\({ }^{I} \\mathbf{R}_{L}\\)、陀螺偏置\\(\\mathbf{b}_{\\omega}\\)和时间偏移量\\({ }^{I} t_{L}\\)。在这一部分中，我们将固定这些值，然后进行平移外参、重力矢量和加速度偏差的校准。 首先，我们使用之前得到的偏移\\(d^{*}\\)和\\(\\delta t\\)来对齐IMU数据\\(\\mathcal{I}_{k}\\)和雷达数据\\(\\mathcal{L}_{k}\\)。对齐的IMU数据表示为̄\\(\\overline{\\mathcal{I}}_{k}\\)，现在认为它与\\(\\mathcal{L}_{k}\\)完全对齐，没有时间偏移。 具体地，在时间\\(t_{k}\\)对应于LiDAR角速度̄\\(\\boldsymbol{\\omega}_{L_{k}}\\)的IMU角速度\\(\\bar{\\omega}_{I_{k}}\\)为（其实就是公式（15））： 相似的，与时刻\\(t_{k}\\)的LiDAR加速度\\({ }^{G} \\mathbf{a}_{L_{k}}\\)对应的IMU加速度̄\\(\\overline{\\mathbf{a}}_{I_{k}}\\)为： 与公式（14）类似，我们可以找到IMU和LiDAR之间的加速度约束。如文献[26]所述，具有固定外参的两个坐标系A、B的加速度具有以下关系： 其中， \\({ }^{A} \\mathbf{R}_{B},{ }^{A} \\mathbf{p}_{B}\\)表示从B系到A系的外参变换 \\(\\mathbf{a}_{A}, \\mathbf{a}_{B}\\)分别是加速度在两个坐标系的表示 上面公式（21）怎么来的，为啥不是 \\({ }^{A} \\mathbf{R}_{B} \\mathbf{a}_{B}=\\mathbf{a}_{A}\\) 对于LiDAR-惯性系统，我们有两种选择：A用于IMU，B用于LiDAR，或者相反的情况。值得注意的是，在第一种情况下，\\(\\boldsymbol{\\omega}_{A}=\\overline{\\boldsymbol{\\omega}}_{I_{k}}-\\mathbf{b}_{\\omega}\\)的精度受到陀螺仪偏差估计的影响，并且\\(\\boldsymbol{\\Omega}_{A}\\)的误差会因角速度测量中的噪声而被放大。 为了避免这一问题，增加外源平移校准的鲁棒性，我们将LiDAR设置为A，将IMU设置为B，由于LiDAR的加速度\\({ }^{G} \\mathbf{a}_{L_{k}}\\)是在全局坐标系中（即第0帧激光坐标系）描述的，所以我们需要将这个加速度转换到激光雷达坐标系下，记为\\(\\mathbf{a}_{L_{k}}\\)： 其中，\\({ }^{G} \\mathbf{R}_{L}\\)是LiDAR在激光里程计全局坐标系的姿态，由第III-B节中的LiDAR里程计获得。 最后，平移外参、加速度计偏置和重力矢量可以从以下优化问题中联合估计： 上述问题可以由ceres求解器迭代求解(由于约束\\({ }^{G} \\mathbf{g} \\in \\mathrm{S}_{2}\\))，并且指定初始值\\(\\left({ }^{I} \\mathbf{p}_{L}, \\mathbf{b}_{\\mathbf{a}},{ }^{G} \\mathbf{g}\\right)= \\left(\\mathbf{0}_{3 \\times 1}, \\mathbf{0}_{3 \\times 1}, 9.81 \\mathbf{e}_{3}\\right)\\)。 在估计\\({ }^{L} \\mathbf{p}_{I}\\)之后，从激光雷达到IMU的转换计算如下：\\({ }^{I} \\mathbf{p}_{L}=-{ }^{I} \\mathbf{R}_{L}^{L} \\mathbf{p}_{I}\\) 数据累积评估 提出的初始化方法依赖于LiDAR惯性器件的充分激励(充分运动)。因此，系统应该能够自行评估激励是否足以执行初始化。 理想情况下，可以通过公式（18）关于\\(\\left({ }^{I} \\mathbf{R}_{L}, \\mathbf{b}_{\\omega}, \\delta t\\right)\\)和公式（23）关于\\(\\left({ }^{I} \\mathbf{p}_{L}, \\mathbf{b}_{\\mathbf{a}},{ }^{G} \\mathbf{g}\\right)\\)的的全雅可比矩阵的秩来评估激励。 在实际中，我们发现，使用关于外参\\({ }^{I} \\mathbf{R}_{L}\\)和\\({ }^{I} \\mathbf{p}_{L}\\)的雅可比来评估运动就足够了，因为对外参的激发通常需要复杂的运动，这也会激发其他状态。因此，记\\(\\mathbf{J}_{r}\\)为公式（18）对旋转外参\\({ }^{I} \\mathbf{R}_{L}\\)的雅可比，\\(\\mathbf{J}_{t}\\)为公式（23）对平移外参\\({ }^{I} \\mathbf{p}_{L}\\)的雅可比，如下： 那么，激励可以通过对以下矩阵的秩来进行评估： \\(\\mathbf{J}_{r}^{T} \\mathbf{J}_{r}=\\sum\\left\\lfloor\\boldsymbol{\\omega}_{L_{k}}\\right\\rfloor{ }_{\\wedge}^{T}\\left\\lfloor\\boldsymbol{\\omega}_{L_{k}}\\right\\rfloor \\wedge\\) \\(\\mathbf{J}_{t}^{T} \\mathbf{J}_{t}=\\sum\\left(\\left\\lfloor\\boldsymbol{\\omega}_{L_{k}}\\right\\rfloor_{\\wedge}^{2}+ \\left\\lfloor\\boldsymbol{\\Omega}_{\\left.L_{k}\\right\\rfloor}\\right\\rfloor_{\\wedge}\\right)^{T}\\left(\\left\\lfloor\\boldsymbol{\\omega}_{L_{k}}\\right\\rfloor_{\\Lambda}^{2}+\\left\\lfloor\\boldsymbol{\\Omega}_{L_{k}}\\right\\rfloor \\wedge\\right)\\) 更定量地，用\\(\\mathbf{J}_{r}^{T} \\mathbf{J}_{r}\\)和\\(\\mathbf{J}_{t}^{T} \\mathbf{J}_{t}\\)的奇异值来表示激发的程度。根据这一原理，我们开发了一个评估程序，可以指导用户如何移动他们的设备以获得足够的激励。我们根据雅可比矩阵的奇异值来量化激励，并用来评估激励是否充分。 参考","categories":[{"name":"Fast-LIO系列","slug":"Fast-LIO系列","permalink":"http://yoursite.com/categories/Fast-LIO%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"IEKF迭代扩展卡尔曼滤波器","slug":"Fast-LIO系列/IEKF迭代扩展卡尔曼滤波器","date":"2022-02-28T14:02:22.000Z","updated":"2022-04-11T15:57:06.238Z","comments":true,"path":"2022/02/28/Fast-LIO系列/IEKF迭代扩展卡尔曼滤波器/","link":"","permalink":"http://yoursite.com/2022/02/28/Fast-LIO%E7%B3%BB%E5%88%97/IEKF%E8%BF%AD%E4%BB%A3%E6%89%A9%E5%B1%95%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8/","excerpt":"","text":"Performance evaluation of iterated extended Kalman filterwith variable step-length 介绍 优化方法主要基于最小化均方误差准则，对于线性高斯系统，导致了著名的卡尔曼滤波。与提供状态的条件PDF的贝叶斯方法不同，最优化方法提供状态的点估计和估计误差的相应协方差矩阵(CM)。与贝叶斯方法一样，基于最优化方法的状态估计问题只能在少数特殊情况下得到解析解。对于其他情况，估计方法通常遵循卡尔曼滤波框架，并利用非线性函数的线性化等逼近技术，例如，扩展(EKF)和二阶扩展卡尔曼滤波器[6]、[1]分别通过围绕当前估计到一阶或二阶的泰勒级数展开来逼近非线性函数，当线性化误差的影响往往会扰乱过滤的性能或其收敛性时，在更新状态附近重新线性化测量方程可能会减轻困难。 这种方法被称为迭代扩展卡尔曼过滤(IEKF)[6]。 IEKF计算状态估计不是作为近似条件平均值(就像EKF那样)，而是作为最大后验(MAP)估计[7]。文献[8]证明了IEKF量测更新是高斯-牛顿(GN)方法的应用，而EKF是仅用一次GN方法迭代的IEKF的特例。 第二节简要介绍了EKF和IEKF的非线性状态估计及其求解方法。第三节简要介绍了IEKF的最新发展。第四节介绍了分析中使用的各种性能度量。接下来，在第五节中，通过两个数值例子对两种滤波器进行了比较，并在第六节中对本文进行了总结。 Nonlinear state estimation by EKF and IEKF 系统描述 离散时间非线性随机系统的状态空间形式如下： 其中， 向量\\(\\mathbf{x}_{k} \\in \\mathbb{R}^{n_{x}}\\)和\\(\\mathbf{z}_{k} \\in \\mathbb{R}^{n_{z}}\\)分别表示在时间k下，系统的状态和观测。 \\(\\mathbf{f}_{k}: \\mathbb{R}^{n_{x}} \\rightarrow \\mathbb{R}^{n_{x}}\\) and \\(\\mathbf{h}_{k}: \\mathbb{R}^{n_{x}} \\rightarrow \\mathbb{R}^{n_{z}}\\)是已知的向量函数。 \\(\\mathbf{w}_{k} \\in \\mathbb{R}^{n_{x}}\\)和\\(\\mathbf{v}_{k} \\in \\mathbb{R}^{n_{z}}\\)是相互独立的状态白噪声和测量白噪声。 噪声的概率密度函数是零均值且已知协方差矩阵\\(\\Sigma_{k}^{\\mathbf{w}}\\) and \\(\\Sigma_{k}^{\\mathbf{v}}\\)的高斯分布，即有\\(p\\left(\\mathbf{w}_{k}\\right)=\\mathcal{N}\\left\\{\\mathbf{w}_{k} ; \\mathbf{0}_{n_{x} \\times 1}, \\Sigma_{k}^{\\mathbf{w}}\\right\\} *\\)和\\(p\\left(\\mathbf{v}_{k}\\right)=\\mathcal{N}\\left\\{\\mathbf{v}_{k} ; \\mathbf{0}_{n_{z} \\times 1}, \\Sigma_{k}^{\\mathbf{v}}\\right\\}\\)。初始态的概率密度函数是高斯的，也是已知的，即\\(p\\left(\\mathbf{x}_{0}\\right)=\\mathcal{N}\\left\\{\\mathbf{x}_{0} ; \\hat{\\mathbf{x}}_{0}, \\mathbf{P}_{0}\\right\\}\\)。初始状态与噪声无关 扩展卡尔曼 最初，卡尔曼过滤是在1960年利用正交性原理[13]推导出来的。给出了具有线性函数\\(\\mathbf{f}_{k}\\) and \\(\\mathbf{h}_{k}\\)的系统(1)和(2)的最小均方误差估计。 对于非线性函数\\(\\mathbf{f}_{k}\\) and \\(\\mathbf{h}_{k}\\)，必须使用近似，例如在EKF中使用的近似。EKF基于一阶泰勒级数展开(TE1)。在假设状态预测平均值\\(\\hat{\\mathbf{x}}_{k \\mid k-1}=\\mathrm{E}\\left[\\mathbf{x}_{k} \\mid \\mathbf{z}^{k-1}\\right]\\)(定义线性化点)已知的条件下，函数\\(\\mathbf{h}_{k}\\)的泰勒一阶展开由下式给出： 其中，矩阵\\(\\mathbf{H}_{k}=\\left.\\frac{\\partial \\mathbf{h}\\left(\\mathbf{x}_{k}\\right)}{\\partial \\mathbf{x}_{k}}\\right|_{\\mathbf{x}_{k}=\\hat{\\mathbf{x}}_{k \\mid k-1}}\\)是测量函数\\(\\mathbf{h}_{k}(\\cdot)\\)关于\\(\\mathbf{X}_{k}\\)在线性化点\\(\\hat{\\mathbf{X}}_{k \\mid k-1}\\)的雅可比。 预测更新步骤的TE1近似的使用是类似的。在已知滤波均值\\(\\hat{\\mathbf{x}}_{k \\mid k}=\\mathrm{E}\\left[\\mathbf{x}_{k} \\mid \\mathbf{z}^{k}\\right]\\)的假设下，(1)中的\\(\\mathbf{f}_{k}\\)的TE1具有如下形式： 其中，\\(\\mathbf{F}_{k}=\\left.\\frac{\\partial \\mathbf{f}\\left(\\mathbf{x}_{k}\\right)}{\\partial \\mathbf{x}_{k}}\\right|_{\\mathbf{x}_{k}=\\hat{\\mathbf{x}}_{k \\mid k}}\\)是系统矩阵\\(\\mathbf{f}_{k}(\\cdot)\\)关于关于\\(\\mathbf{X}_{k}\\)在线性化点\\(\\hat{\\mathbf{X}}_{k \\mid k}\\)的雅可比。 扩展卡尔曼算法如下： 对于具有轻度非线性函数\\(\\mathbf{f}_{k}\\) and \\(\\mathbf{h}_{k}\\)的系统，扩展卡尔曼滤波性能良好，但是如果测量方程(2)是强非线性的(例如在纯方位跟踪问题中)，滤波器的性能就会恶化。在这种情况下，IEKF往往比EKF提供更准确的估计。 迭代扩展卡尔曼 IEKF[6]的想法是在存在显著非线性的情况下改进参考轨迹，从而改进估计。这些改进是通过EKF测量更新的局部迭代实现的(参见算法2)。迭代通常在连续迭代中没有显著变化或满足其他标准(如最大迭代次数)时停止。算法如下： 翻译一下，就是以下步骤: 初始化：设置迭代次数\\(i=0\\)，此时有\\(\\hat{\\mathbf{x}}_{k}^{0}=\\hat{\\mathbf{x}}_{k \\mid k-1}\\)，表示在第k次观测的第0次迭代的状态\\(\\mathbf{x}_{k}^{0}\\)等于利用前\\(k-1\\)次观测以及所预测的k时刻的状态\\(\\hat{\\mathbf{X}}_{k \\mid k-1}\\) 测量更新：计算测量函数在迭代状态\\(\\mathbf{x}_{k}^{i}\\)处的雅可比\\(\\mathbf{H}_{k}^{i}\\)，更新第i次迭代的卡尔曼增益\\(\\mathbf{K}_{k}^{i}\\)，更新第i次迭代后的状态\\(\\hat{\\mathbf{x}}_{k}^{i+1}\\),如下： 其中， \\(\\mathbf{H}_{k}^{i}\\)是测量函数在迭代状态\\(\\mathbf{x}_{k}^{i}\\)处 \\(\\mathbf{P}_{k \\mid k-1}\\)是利用前\\(k-1\\)次观测以及所预测的k时刻的协方差，即第0次迭代前的协方差 \\(\\hat{\\mathbf{x}}_{k \\mid k-1}\\)是利用前\\(k-1\\)次观测以及所预测的k时刻的状态，即第0次迭代前的状态 \\(\\hat{\\mathbf{x}}_{k}^{i}\\)是第k观测下，迭代i次后的状态 \\(\\hat{\\mathbf{x}}_{k}^{i+1}\\)是第k观测下，迭代i+1次后的状态 迭代完成后，需要更新（保存）状态和协方差： 即协方差是在迭代结束后再更新的，迭代过中一直使用的是\\(\\mathbf{P}_{k \\mid k-1}\\)，即上一次更新完后又预测到k时刻的协方差。 值得一提的是，即使在IEKF算法中发生的重新线性化也不能保证滤波器的收敛性，IEKF也不总是比扩展卡尔曼滤波性能好。不过，IEKF测量更新有两个非常有趣的属性： 它可以看作是高斯-牛顿法的一种应用 它生成最大后验（MAP）估计：\\(\\hat{\\mathbf{x}}_{k \\mid k}^{\\mathrm{MAP}}=\\underset{\\mathbf{x}_{k}}{\\arg \\max } p\\left(\\mathbf{x}_{k} \\mid \\mathbf{z}^{k}\\right)\\) 对迭代扩展卡尔曼过滤算法的改进 如上所述，IEKF可以看作是求解非线性最小二乘问题的GN方法的一种应用。因此，在IEKF中可以使用对GN方法的改进来提高方法的性能和收敛性，以提高估计的质量。改变步长是常用的改进措施之一。首先，介绍了IEKF最小化的MAP准则。 MAP criterion 如果使用系统(1)和(2)的概率描述，则使用先验的概率密度函数\\(p\\left(\\mathbf{x}_{k} \\mid \\mathbf{z}^{k-1}\\right)\\)来求后验PDF\\(p\\left(\\mathbf{x}_{k} \\mid \\mathbf{z}^{k}\\right)\\)。 先验的概率分布\\(p\\left(\\mathbf{x}_{k} \\mid \\mathbf{z}^{k-1}\\right)\\)的均值\\(\\hat{\\mathbf{X}}_{k \\mid k-1}\\)和协方差\\(\\mathbf{P}_{k \\mid k-1}\\)在算法1的时间更新步骤中计算。其假设为高斯，并且在算法2的测量更新中计算后验PDF\\(p\\left(\\mathbf{x}_{k} \\mid \\mathbf{z}^{k-1}\\right)\\)的均值\\(\\hat{\\mathbf{x}}_{k \\mid k}\\)和方差\\(\\mathbf{P}_{k \\mid k}\\)。 后验概率\\(p\\left(\\mathbf{x}_{k} \\mid \\mathbf{z}^{k}\\right)\\)与似然\\(p\\left(\\mathbf{z}_{k} \\mid \\mathbf{x}_{k}\\right)=p_{\\mathbf{v}_{k}}\\left(\\mathbf{z}_{k}-\\mathbf{h}_{k}\\left(\\mathbf{x}_{k}\\right)\\right)\\)与先验\\(p\\left(\\mathbf{x}_{k} \\mid \\mathbf{z}^{k-1}\\right)\\)的乘积成正比，即有： 其中，为方便起见，不依赖于\\(\\mathbf{X}_{k}\\)的项已被删除。然后由下式给出MAP估计： 现在，有了MAP模型，可以使用GN方法来找到\\(\\hat{\\mathbf{x}}_{k \\mid k}\\)，以达到最小化函数。理想情况下，每次GN方法迭代(即IEKF测量更新迭代)都应该减小准则\\(\\mathbf{V}_{k}\\)。 IEKF测量更新(16)可以用隐式方式被重写： 本次迭代更新偏移量\\(\\Delta_{k}^{i}\\)如下： 其中，\\(\\hat{\\mathbf{x}}_{k}^{0}=\\hat{\\mathbf{x}}_{k \\mid k-1}\\)，即在第k次观测的第0次迭代的状态\\(\\mathbf{x}_{k}^{0}\\)等于利用前\\(k-1\\)次观测以及所预测的k时刻的状态\\(\\hat{\\mathbf{X}}_{k \\mid k-1}\\)（先验） 对于高斯牛顿方法，也可以求出更新偏移量\\(\\Delta_{k}^{i}\\)的另一种表达形式： 高斯牛顿法就是将\\(f(\\mathbf{x})\\)进行一届泰勒展开（注意这里的\\(f(\\mathbf{x})\\)不是目标函数，而是原函数，即\\(f(\\mathbf{x}) = z-h(\\mathbf{x})\\) 因此，有： \\[ f(\\mathbf{x}+\\Delta{\\mathbf{x}}) \\approx f(\\mathbf{x}) + \\mathbf{J}(\\mathbf{x})\\Delta{\\mathbf{x}} \\] 其中，\\(\\mathbf{J}(\\mathbf{x})\\)为\\(f(\\mathbf{x})\\)关于\\(\\mathbf{x}\\)的雅克比。 经过系列变换，最终可以得到正规方程： \\[ \\mathbf{J}(\\mathbf{x})^{T}\\mathbf{J}(\\mathbf{x}) \\Delta{\\mathbf{x}} = -\\mathbf{J}(\\mathbf{x})^{T} f(\\mathbf{x}) \\] 因此有： \\[ \\Delta{\\mathbf{x}} = - \\left (\\mathbf{J}(\\mathbf{x})^{T}\\mathbf{J}(\\mathbf{x})\\right)^{-1} \\mathbf{J}(\\mathbf{x})^{T} f(\\mathbf{x}) \\] 对于式（17）（18）所展示的MAP问题，可以进一步建模为： \\[ \\begin{aligned} \\hat{\\mathbf{x}}_{k \\mid k} &amp;=\\underset{\\mathbf{x}_{k}}{\\arg \\min } \\frac{1}{2}\\left(\\left[\\mathbf{z}_{k}-\\mathbf{h}_{k}\\left(\\mathbf{x}_{k}\\right)\\right]^{T}\\left(\\Sigma_{k}^{v}\\right)^{-1}\\left[\\mathbf{z}_{k}-\\mathbf{h}_{k}\\left(\\mathbf{x}_{k}\\right)\\right]+\\left[\\hat{\\mathbf{x}}_{k \\mid k-1}-\\mathbf{x}_{k}\\right]^{T} \\mathbf{P}_{k \\mid k-1}^{-1}\\left[\\hat{\\mathbf{x}}_{k \\mid k-1}-\\mathbf{x}_{k}\\right]\\right) \\\\ &amp;=\\underset{\\mathbf{x}_{k}}{\\arg \\min } \\frac{1}{2} r(\\mathbf{X})^{T}r(\\mathbf{X}) \\end{aligned} \\] 其中， \\[ r(\\mathbf{X})=\\left[\\begin{array}{c} \\left(\\mathbf{R}_{k}\\right)^{-\\frac{1}{2}}(\\mathbf{z}_k-h(\\mathbf{x}_k)) \\\\ \\mathbf{P}_{k \\mid k-1}^{-\\frac{1}{2}}\\left(\\hat{\\mathbf{x}}_{k \\mid k-1}- \\mathbf{x}_k \\right) \\end{array}\\right] \\] 雅克比\\(J(\\mathbf{X})\\)如下： \\[ \\mathbf{J}_{k}=-\\left[\\begin{array}{c} \\mathbf{R}_{k}^{-1 / 2} \\mathbf{H}_{k} \\\\ \\mathbf{P}_{k \\mid k-1}^{-1 / 2} \\end{array}\\right] \\] \\[ \\mathbf{H}_{k}=\\left.\\frac{\\partial h(s)}{\\partial s}\\right|_{s=\\mathbf{x}_{k}} \\] 将信息回代到高斯牛顿正规方程，可以得到增量\\(\\Delta{\\mathbf{x}}\\)如下： \\[ \\begin{aligned} \\Delta{\\mathbf{x}} &amp;= - \\left (\\mathbf{J}(\\mathbf{x})^{T}\\mathbf{J}(\\mathbf{x})\\right)^{-1} \\mathbf{J}(\\mathbf{x})^{T} f(\\mathbf{x}) \\\\ &amp;= \\left( \\left[\\begin{array}{c} \\mathbf{R}_{k}^{-1 / 2} \\mathbf{H}_{k} \\\\ \\mathbf{P}_{k \\mid k-1}^{-1 / 2} \\end{array}\\right]^{T} \\left[\\begin{array}{c} \\mathbf{R}_{k}^{-1 / 2} \\mathbf{H}_{k} \\\\ \\mathbf{P}_{k \\mid k-1}^{-1 / 2} \\end{array}\\right] \\right)^{-1} \\left[\\begin{array}{c} \\mathbf{R}_{k}^{-1 / 2} \\mathbf{H}_{k} \\\\ \\mathbf{P}_{k \\mid k-1}^{-1 / 2} \\end{array}\\right]^{T} \\left[\\begin{array}{c} \\left(\\mathbf{R}_{k}\\right)^{-\\frac{1}{2}}(\\mathbf{z}_k-h(\\mathbf{x}_k)) \\\\ \\mathbf{P}_{k \\mid k-1}^{-\\frac{1}{2}}\\left(\\hat{\\mathbf{x}}_{k \\mid k-1}- \\mathbf{x}_k \\right) \\end{array}\\right]\\\\ &amp;= \\left( \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k + \\mathbf{P}_k^{-1} \\right)^{-1} \\left( \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} (\\mathbf{z}_k-h(\\mathbf{x}_k)) + \\mathbf{P}_k^{-1}(\\hat{\\mathbf{x}}_{k \\mid k-1}- \\mathbf{x}_k) \\right) \\\\ &amp;= \\left( \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k + \\mathbf{P}_k^{-1} \\right)^{-1} \\{ \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} (\\mathbf{z}_k-h(\\mathbf{x}_k) - \\mathbf{H}_k (\\hat{\\mathbf{x}}_{k \\mid k-1}- \\mathbf{x}_k)) + \\\\ &amp; \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k (\\hat{\\mathbf{x}}_{k \\mid k-1}- \\mathbf{x}_k) + \\mathbf{P}_k^{-1}(\\hat{\\mathbf{x}}_{k \\mid k-1}- \\mathbf{x}_k) \\} \\\\ &amp;= \\hat{\\mathbf{x}}_{k \\mid k-1}- \\mathbf{x}_k + \\left( \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k + \\mathbf{P}_k^{-1} \\right)^{-1} \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\left ( \\mathbf{z}_k-h(\\mathbf{x}_k) - \\mathbf{H}_k (\\hat{\\mathbf{x}}_{k \\mid k-1}- \\mathbf{x}_k) \\right) \\end{aligned} \\] 此时，如果令\\(\\mathbf{K}_{k}\\)满足: \\[\\mathbf{K}_{k} = \\left( \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k + \\mathbf{P}_k^{-1} \\right)^{-1} \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\] 定睛一看，这货不就是公式（20）由IEKF的增量吗？ 所以，IEKF实际上是高斯牛顿的一种应用，如果多个观测放在一起来求解，就是最小二乘，如果迭代的求解，就成了IEKF。 IEKF在Fast-LIO系列的应用 回顾Fast-LIO1论文，公式(17)，要优化的目标函数是： 其中，包含了先验项和观测项 先验项 第一项\\(\\left\\|\\mathbf{x}_{k} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right\\|_{\\widehat{\\mathbf{P}}_{k}^{-1}}^{2}\\)是先验项，其表述有点奇怪 原文描述如下： 其中， \\(\\mathbf{X}_{k}\\)表示状态真值 \\(\\widehat{\\mathbf{x}}_{k}\\)表示k时刻预测值 \\(\\mathbf{J}^{\\kappa}\\)表示\\(\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxplus \\widetilde{\\mathbf{x}}_{k}^{\\kappa}\\right) \\boxminus \\widehat{\\mathbf{x}}_{k}\\)关于误差状态\\(\\tilde{\\mathbf{x}}_{k}^{\\kappa}\\)的雅克比 按照原文的意思是，\\(\\left\\|\\mathbf{x}_{k} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right\\|_{\\widehat{\\mathbf{P}}_{k}^{-1}}^{2}\\)用于约束预测值\\(\\widehat{\\mathbf{x}}_{k}\\)不应该离状态真值太远，即误差状态应尽可能小（这个先验看起来跟平时的形式不一样，难以理解）。 下面，按照我们通用的理解去描述： 先验一般约束着迭代状态值\\(\\widehat{\\mathbf{x}}_{k}^{\\kappa}\\)不应该离预测值\\(\\widehat{\\mathbf{x}}_{k}\\)太远，因此，先验对应的残差项可以写为： \\[ \\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k} \\] 因此，个人认为，原文公式（17）第一项不应该为\\(\\mathbf{x}_{k} \\boxminus \\widehat{\\mathbf{x}}_{k}\\)，替换为\\(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\)更合理 观测项 第二项\\(\\left\\|\\mathbf{z}_{j}^{\\kappa}+\\mathbf{H}_{j}^{\\kappa} \\widetilde{\\mathbf{x}}_{k}^{\\kappa}\\right\\|_{\\mathbf{R}_{j}^{-1}}^{2}\\)在原文中的表述比较牵强： 原文公式如下： 上面\\(\\mathbf{h}_{j}\\left(\\mathbf{x}_{k},{ }^{L_{j}} \\mathbf{n}_{f_{j}}\\right)\\)的意思是，给定状态真值\\(\\mathbf{x}_{k}\\)和测量噪声\\({ }^{L_{j}} \\mathbf{n}_{f_{j}}\\)，那么理论上得到的观测值（即点到平面的距离）为0。 然而，由于无法得知状态真值，因此使用一阶近似得到的公式（14）。此处使用的\\(\\mathbf{z}_{j}^{\\kappa}+\\mathbf{H}_{j}^{\\kappa} \\widetilde{\\mathbf{x}}_{k}^{\\kappa}\\)让人容易混淆，还是看下文的另外一种描述。 前面提到，实际的观测值其实不用去观测，因为点就在平面上，所以实际的观测值为0，即\\(\\mathbf{z_{true}} = 0\\)。 为了衡量当前估计的状态是否足够接近真值，我们利用迭代的状态去计算点-面距离，这一个操作称为观测预测，\\(\\mathbf{h}_{j}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa}, \\mathbf{0}\\right)\\)为观测预测模型，即通过给定状态来计算在该状态下得到的观测值，此处为计算得到的点-面距离。 因此，残差项可以写为： \\[ \\mathbf{z_{true}} -\\mathbf{h}_{j}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa}, \\mathbf{0}\\right) \\] 其中，已知\\(\\mathbf{z_{true}} = 0\\)，因此，残差项就是利用迭代的状态计算得到的点-面距离\\(\\mathbf{h}_{j}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa}\\right)\\)。 因此，个人认为，原文描述的第二项不应该为\\(\\left\\|\\mathbf{z}_{j}^{\\kappa}+\\mathbf{H}_{j}^{\\kappa} \\widetilde{\\mathbf{x}}_{k}^{\\kappa}\\right\\|_{\\mathbf{R}_{j}^{-1}}^{2}\\)，替换为\\(\\left\\| \\mathbf{z_{true}} -\\mathbf{h}_{j}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa}, \\mathbf{0}\\right)\\right\\|_{\\mathbf{R}_{j}^{-1}}^{2} = \\left\\|\\mathbf{h}_{j}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa}, \\mathbf{0}\\right)\\right\\|_{\\mathbf{R}_{j}^{-1}}^{2}\\)更为合适。 推导 综上，我们继续使用上面的方法再一次推导： 假设目标函数\\(r(\\mathbf{X})\\)如下: \\[ r(\\mathbf{X})=\\left[\\begin{array}{c} \\left(\\mathbf{R}_{k}\\right)^{-\\frac{1}{2}}\\left ( \\mathbf{z_{true}} -\\mathbf{h}_{j}(\\widehat{\\mathbf{x}}_{k}^{\\kappa}, \\mathbf{0}) \\right) \\\\ \\mathbf{P}_{k \\mid k-1}^{-\\frac{1}{2}}\\left(\\mathbf{x}_{k} \\boxminus \\widehat{\\mathbf{x}}_{k} \\right) \\end{array}\\right] = \\left[\\begin{array}{c} \\left(\\mathbf{R}_{k}\\right)^{-\\frac{1}{2}}\\left ( \\mathbf{h}_{j}(\\widehat{\\mathbf{x}}_{k}^{\\kappa}, \\mathbf{0}) \\right) \\\\ \\mathbf{P}_{k \\mid k-1}^{-\\frac{1}{2}}\\left(\\mathbf{x}_{k} \\boxminus \\widehat{\\mathbf{x}}_{k} \\right) \\end{array}\\right] \\] 其中， \\(\\mathbf{h}_{j}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa}, \\mathbf{0}\\right)\\)是观测模型，对其进行泰勒一阶展开，可得：\\(\\mathbf{h}_{j}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa}\\boxplus\\tilde{\\mathbf{x}}_{k}^{\\kappa}, \\mathbf{0}\\right) \\approx \\mathbf{z}_{j}^{\\kappa}+\\mathbf{H}_{j}^{\\kappa} \\tilde{\\mathbf{x}}_{k}^{\\kappa}\\)，其中\\(\\mathbf{z}_{j}^{\\kappa}\\)就是利用状态\\(\\widehat{\\mathbf{X}}_{k}^{\\kappa}\\)计算得到的点到平面距离 \\(j\\)表示第j个激光点 根据高斯牛顿的思想，对残差函数进行一阶泰勒展开如下： \\[ \\begin{aligned} r(\\mathbf{X^{\\kappa} +\\Delta \\mathbf{x}}) = r(\\mathbf{X^{\\kappa} +\\tilde{\\mathbf{x}}_{k}^{\\kappa}}) &amp;= r(\\mathbf{X^{\\kappa}})+ J(\\mathbf{X}^{\\kappa})\\tilde{\\mathbf{x}}_{k}^{\\kappa} \\\\ &amp;= \\left[\\begin{array}{c} \\left(\\mathbf{R}_{k}\\right)^{-\\frac{1}{2}}(\\mathbf{z}_{j}^{\\kappa}+\\mathbf{H}_{j}^{\\kappa} \\tilde{\\mathbf{x}}_{k}^{\\kappa}) \\\\ \\mathbf{P}_{k \\mid k-1}^{-\\frac{1}{2}}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}+\\mathbf{J}^{\\kappa} \\widetilde{\\mathbf{x}}_{k}^{\\kappa}\\right) \\end{array}\\right] \\\\ &amp;= \\left[\\begin{array}{c} \\left(\\mathbf{R}_{k}\\right)^{-\\frac{1}{2}}(\\mathbf{z}_{j}^{\\kappa}) \\\\ \\mathbf{P}_{k \\mid k-1}^{-\\frac{1}{2}}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) \\end{array}\\right] + \\left[\\begin{array}{c} \\left(\\mathbf{R}_{k}\\right)^{-\\frac{1}{2}}(\\mathbf{H}_{j}^{\\kappa}) \\\\ \\mathbf{P}_{k \\mid k-1}^{-\\frac{1}{2}}\\left(\\mathbf{J}^{\\kappa} \\right) \\end{array}\\right] \\widetilde{\\mathbf{x}}_{k}^{\\kappa} \\end{aligned} \\] 其中 \\(\\mathbf{H}^{\\kappa}_{j}\\)是激光投影点到地图上最近的平面的距离关于误差状态的雅克比，其推导可从R2LIVE中找到。 \\(\\mathbf{J}^{\\kappa}\\)表示\\(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\)关于误差状态\\(\\tilde{\\mathbf{x}}_{k}^{\\kappa}\\)的雅克比 雅克比\\(J(\\mathbf{X}^{\\kappa})\\)如下： \\[ \\mathbf{J}_{k}^{\\kappa} =\\left[\\begin{array}{c} \\mathbf{R}_{k}^{-1 / 2} \\mathbf{H}_{k}^{\\kappa} \\\\ \\mathbf{P}_{k \\mid k-1}^{-1 / 2} \\mathbf{J}^{\\kappa} \\end{array}\\right] \\] \\[ \\mathbf{H}_{k}^{\\kappa} =\\left.\\frac{\\partial h(s)}{\\partial s}\\right|_{s=\\mathbf{x}_{k}^{\\kappa} } \\] \\[ \\mathbf{J}^{\\kappa}=\\left[\\begin{array}{cc} \\mathbf{A}\\left({ }^{G} \\widehat{\\mathbf{R}}_{I_{k}}^{\\kappa} \\boxminus^{G} \\widehat{\\mathbf{R}}_{I_{k}}\\right)^{-T} &amp; \\mathbf{0}_{3 \\times 15} \\\\ \\mathbf{0}_{15 \\times 3} &amp; \\mathbf{I}_{15 \\times 15} \\end{array}\\right] \\] 这里注意区分\\(\\mathbf{J}_{k}\\)和\\(\\mathbf{J}^{\\kappa}\\)。 将\\(r(\\mathbf{X^{\\kappa}})\\)以及雅克比\\(J(\\mathbf{X}^{\\kappa})\\)回代到高斯牛顿正规方程，可以得到增量\\(\\Delta{\\mathbf{x}}\\)如下： \\[ \\begin{aligned} \\Delta{\\mathbf{x}} &amp;= - \\left (\\mathbf{J}(\\mathbf{x})^{T}\\mathbf{J}(\\mathbf{x})\\right)^{-1} \\mathbf{J}(\\mathbf{x})^{T} f(\\mathbf{x}) \\\\ &amp;= - \\left( \\left[\\begin{array}{c} \\mathbf{R}_{k}^{-1 / 2} \\mathbf{H}_{k}^{\\kappa} \\\\ \\mathbf{P}_{k \\mid k-1}^{-1 / 2} \\mathbf{J}^{\\kappa} \\end{array}\\right]^{T} \\left[\\begin{array}{c} \\mathbf{R}_{k}^{-1 / 2} \\mathbf{H}_{k}^{\\kappa} \\\\ \\mathbf{P}_{k \\mid k-1}^{-1 / 2} \\mathbf{J}^{\\kappa} \\end{array}\\right] \\right)^{-1} \\left[\\begin{array}{c} \\mathbf{R}_{k}^{-1 / 2} \\mathbf{H}_{k}^{\\kappa} \\\\ \\mathbf{P}_{k \\mid k-1}^{-1 / 2} \\mathbf{J}^{\\kappa} \\end{array}\\right]^{T} \\left[\\begin{array}{c} \\left(\\mathbf{R}_{k}\\right)^{-\\frac{1}{2}}(\\mathbf{z}_{j}^{\\kappa}) \\\\ \\mathbf{P}_{k \\mid k-1}^{-\\frac{1}{2}}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) \\end{array}\\right] \\\\ &amp;= - \\left( \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k + (\\mathbf{J}^{\\kappa})^{T}\\mathbf{P}_k^{-1}(\\mathbf{J}^{\\kappa}) \\right)^{-1} \\left \\{ \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{z}_k^{\\kappa} + (\\mathbf{J}^{\\kappa})^{T}\\mathbf{P}_k^{-1} \\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) \\right \\} \\\\ &amp;= - \\left( \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k + (\\mathbf{J}^{\\kappa})^{T}\\mathbf{P}_k^{-1}(\\mathbf{J}^{\\kappa}) \\right)^{-1} \\{ \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{z}_k^{\\kappa} + (\\mathbf{J}^{\\kappa})^{T}\\mathbf{P}_k^{-1}(\\mathbf{J}^{\\kappa})(\\mathbf{J}^{\\kappa})^{-1} \\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) \\\\ &amp;+ \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k (\\mathbf{J}^{\\kappa})^{-1} \\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) - \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k (\\mathbf{J}^{\\kappa})^{-1} \\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) \\} \\\\ &amp;= -(\\mathbf{J}^{\\kappa})^{-1} \\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) - \\left( \\mathbf{H}_k^{T} \\mathbf{R}_k^{-1} \\mathbf{H}_k + (\\mathbf{J}^{\\kappa})^{T}\\mathbf{P}_k^{-1}(\\mathbf{J}^{\\kappa}) \\right)^{-1} (\\mathbf{H}_k^{T} \\mathbf{R}_k^{-1}) \\left ( \\mathbf{z}_k^{\\kappa} + \\mathbf{H}_k(\\mathbf{J}^{\\kappa})^{-1} \\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) \\right ) \\\\ &amp;= -(\\mathbf{J}^{\\kappa})^{-1} \\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) - \\mathbf{K}_{k}^{\\kappa} \\left ( \\mathbf{z}_k^{\\kappa} + \\mathbf{H}_k(\\mathbf{J}^{\\kappa})^{-1} \\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) \\right ) \\\\ &amp;= -\\mathbf{K} \\mathbf{z}_{k}^{\\kappa}-(\\mathbf{I}-\\mathbf{K} \\mathbf{H})\\left(\\mathbf{J}^{\\kappa}\\right)^{-1}\\left(\\widehat{\\mathbf{x}}_{k}^{\\kappa} \\boxminus \\widehat{\\mathbf{x}}_{k}\\right) \\end{aligned} \\] 按照上述推导，即可得到与论文公式（18）一致的结果。 参考 知乎：迭代扩展卡尔曼滤波(IEKF) 论文：Performance evaluation of iterated extended Kalman filter with variable step-length","categories":[{"name":"Fast-LIO系列","slug":"Fast-LIO系列","permalink":"http://yoursite.com/categories/Fast-LIO%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"IKFOM论文阅读","slug":"Fast-LIO系列/IKFOM论文阅读","date":"2022-02-27T12:22:58.000Z","updated":"2022-04-11T15:57:06.238Z","comments":true,"path":"2022/02/27/Fast-LIO系列/IKFOM论文阅读/","link":"","permalink":"http://yoursite.com/2022/02/27/Fast-LIO%E7%B3%BB%E5%88%97/IKFOM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Kalman Filters on Differentiable Manifolds 摘要 卡尔曼滤波是现代控制系统中最重要和应用最广泛的滤波技术之一。然而，几乎所有当前的卡尔曼滤波器的变体都是在欧几里得空间Rn中制定的，而许多现实世界的系统(例如，机器人系统)实际上是在流形上进化的。 在本文中，我们提出了一种为这类流形上系统设计卡尔曼滤波器的方法。利用运算\\(\\boxplus \\backslash \\boxminus\\)，并进一步定义了相应流形上的⊕运算，给出了流形上系统的规范表示。这种非正则形式使我们能够在卡尔曼过滤的每一步中将多种约束从系统行为中分离出来，最终产生一个在流形上自然演化的通用的和象征性的卡尔曼过滤框架。 此外，这种流形上的卡尔曼滤波器集成了C++包实现，它使用户能够实现集成卡尔曼滤波器，就像在\\(\\mathbb{R}^{n}\\)空间中的普通卡尔曼过滤一样：用户只需要提供系统特定的描述，然后调用各自的过滤步骤(例如，预测、更新)，而不需要处理任何流形约束。 PRELIMINARIES OF DIFFERENTIABLE MANIFOLDS 可微分流形（Differentiable manifolds） 如文[34]所示，维数为n的流形是局部同胚于\\(\\mathbb{R}^{n}\\)的集合M(称为homeomorphicspace)。、 也就是说，对于任意一个点\\(\\mathbf{x} \\in \\mathcal{M}\\)以及一个包含该点的开子集\\(U \\subset \\mathcal{M}\\)，存在一个双射函数(称为homeomorphism)φ，它将\\(U\\)中的点映射到\\(\\mathbb{R}^{n}\\)的开子集。该对\\((\\phi, U)\\)称为局部坐标图，如果任何两个图\\((\\phi, U)\\)和\\((\\psi, V)\\)共享重叠的合成映射\\(\\phi \\circ \\psi^{-1}\\)是可微的，则该流形称为可微流形。 \\(\\boxplus \\backslash \\boxminus\\)操作 流形M中任意点周围homeomorphisms的存在使我们能够封装两个算子\\(\\boxplus_{\\mathcal{M}}\\)(“boxplus”)和\\(\\boxminus_{\\mathcal{M}}\\)(“boxminus”)到流形[25]： 其中，\\(\\mathcal{M}_{\\varphi_{\\mathrm{x}}}\\)是点\\(\\mathbf{x} \\in \\mathcal{M}\\)的一个homeomorphism. \\(\\mathbf{y}=\\mathbf{x} \\boxplus_{\\mathcal{M}} \\mathbf{u}\\)的物理含义是向点\\(\\mathbf{x} \\in \\mathcal{M}\\)添加一个扰动\\(\\mathbf{u}\\)，然后产生了流形上的\\(\\mathbf{y} \\in \\mathcal{M}\\)， 如图2所示。 其中，逆操作\\(\\mathbf{u}=\\mathbf{y} \\boxminus_{\\mathcal{M}} \\mathbf{x}\\)可以确定扰动量\\(\\mathbf{u}\\)，该扰动量\\(\\mathbf{u}\\)就是产生\\(\\mathbf{y} \\in \\mathcal{M}\\)时，对点\\(\\mathbf{x} \\in \\mathcal{M}\\)进行\\(\\boxplus_{\\mathcal{M}^{-}}\\)操作所添加的扰动。 这两个操作符创建了一个局部的、矢量化视角，对应于流形上复杂的全局结构。 对于李群来说，当\\(\\mathcal{M}\\)是Lie group (e.g., \\(\\left.\\mathbb{R}^{n}, S O(3), S E(3)\\right)\\)，正切空间具有表示为m的李代数结构和指数映射\\(\\exp : \\mathfrak{m} \\mapsto \\mathcal{M}\\)。 令\\(\\mathfrak{f}: \\mathbb{R}^{n} \\mapsto \\mathfrak{m}\\)作为从最小参数化空间到李代数、指数映射\\(\\operatorname{Exp}=\\exp \\circ f\\)以及其逆操作\\(\\log\\)的的映射，那么\\(\\boxplus \\backslash \\boxminus\\)操作的定义如下： 其中·是M上的二元运算，使得\\((\\mathcal{M}, \\cdot)\\)形成李群，\\(\\mathbf{x}^{-1}\\)是\\(\\mathbf{X}\\)的逆，对于李群上的元素，它总是存在。 当流形M不是李群时，找出流形与其切空间参数化之间的同胚没有一般准则。例如，2球面流形\\(\\mathbb{S}^{2}(r) \\triangleq\\{\\mathbf{x} \\in \\left.\\mathbb{R}^{3} \\mid\\|\\mathbf{x}\\|=r, r&gt;0\\right\\}\\)在点x处的切线空间就是在点\\(\\mathbf{X}\\)的简单正切平面，如图3所示。 对于点\\(\\mathbf{x} \\in \\mathbb{S}^{2}(r)\\)，扰动可以通过沿着正切平面上的向量旋转来实现，结果仍将保留在\\(\\mathbb{S}^{2}(r)\\)上。 正切平面中的旋转向量被\\(\\mathbf{u} \\in \\mathbb{R}^{2}\\)最小参数化表达，其中，所在的空间为由两个bias向量\\(\\mathbf{b}_{1}, \\mathbf{b}_{2} \\in \\mathbb{R}^{3}\\)所展开的正切平面。也就是说： 其中，\\(\\mathbf{R}(\\mathbf{w})=\\operatorname{Exp}(\\mathbf{w}) \\in S O(3)\\)记为关于由向量\\(\\mathbf{w} \\in \\mathbb{R}^{3}\\)所表示的轴-角旋转。特别的，\\(\\mathbf{b}_{1}, \\mathbf{b}_{2}\\)的选择不是唯一的，只要它们是正交的并且都垂直于x。 \\(\\mathbb{S}^{2}\\)常用于重力的表示，如VINS-Mono就用这个来表示并进一步refine重力向量。 \\(\\oplus\\)操作符 现实世界的系统通常是由一些外在的输入驱动的。为了模拟这一现象，除了描述流形本身所在的状态之外，还需要一个额外的操作来描述流形上的状态是如何在无限小的时间周期内由恒定的外生速度驱动的。 尽管速度对状态的影响增加了对流形上其原始位置的扰动，这在流形上有很好的描述运算符\\(\\boxplus\\)，则外部速度不一定在相同的homeomorphic空间(即，切线空间)中，该空间定义操作，因此需要表示为\\(\\oplus_{\\mathcal{M}}\\)的新操作。 假设外部速度的维度是l，那么新的操作为：\\(\\oplus_{\\mathcal{M}}: \\mathcal{M} \\times \\mathbb{R}^{l} \\mapsto \\mathcal{M}\\) 具体地说，当\\(\\mathcal{M}\\)是李群时，外生速度通常位于正切空间，同时也定义了公式(2)中的\\(\\boxplus \\backslash \\boxminus\\)操作，因此操作⊕与\\(\\boxplus\\)重合，即： 。。。 差分 \\((((\\mathbf{x} \\boxplus \\mathbf{u}) \\oplus \\mathbf{v}) \\boxminus \\mathbf{y})\\)相对于\\(\\mathbf{u}\\)和\\(\\mathbf{V}\\)的差分将会在后面的卡尔曼滤波器中用到，其中，\\(\\mathbf{x}, \\mathbf{y} \\in \\mathcal{M}, \\mathbf{u} \\in \\mathbb{R}^{n}\\)，\\(\\mathbf{v} \\in \\mathbb{R}^{l}\\)。 由链式法则，可得： 对于某些流形(例如，SO(3))，计算微分通常更为方便，而不用使用链式法则展开。 复合可微流形 基于流形的笛卡儿积原理，给出了流形的定义由两个子流形(归纳为任意个子流形)组成的复合流形上的\\(\\boxplus \\backslash \\boxminus\\) and \\(\\oplus\\)操作定义如下： 因此复合流形上的偏微分满足(见引理)： \\(\\boxplus \\backslash \\boxminus\\) and \\(\\oplus\\)运算及其在复合流形上的偏微分非常有用，使用户能够定义\\(\\boxplus \\backslash \\boxminus\\) and \\(\\oplus\\)运算及其导数(例如，\\(\\mathbb{R}^{n}, S O(3), \\mathbb{S}^{2}(r)\\))，然后将这些定义推广到更复杂的复合流形。 例如，根据前面讨论\\(\\boxplus \\backslash \\boxminus\\) and \\(\\oplus\\)的定义，总结了几个重要流形，包括\\(\\mathbb{R}^{n}, S O(3), \\mathbb{S}^{2}(r)\\)的运算，并在表中总结了它们的局部微分，其中： 其中，\\(\\lfloor\\mathbf{u}\\rfloor\\)记为反对称矩阵，并且有： 总结表如下： （详细推导见附录B） 流形系统的规范表示","categories":[{"name":"Fast-LIO系列","slug":"Fast-LIO系列","permalink":"http://yoursite.com/categories/Fast-LIO%E7%B3%BB%E5%88%97/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"","slug":"传感器标定/LIDAR_CAMERA标定_6","date":"2022-02-01T12:41:23.436Z","updated":"2022-01-03T02:48:17.997Z","comments":true,"path":"2022/02/01/传感器标定/LIDAR_CAMERA标定_6/","link":"","permalink":"http://yoursite.com/2022/02/01/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/LIDAR_CAMERA%E6%A0%87%E5%AE%9A_6/","excerpt":"","text":"","categories":[{"name":"传感器标定","slug":"传感器标定","permalink":"http://yoursite.com/categories/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/"}],"tags":[]},{"title":"Cyber-RT系列之中枢调度Scheduler","slug":"Cyber-RT系列之中枢调度Scheduler","date":"2021-11-28T15:10:29.000Z","updated":"2022-04-11T15:57:06.233Z","comments":true,"path":"2021/11/28/Cyber-RT系列之中枢调度Scheduler/","link":"","permalink":"http://yoursite.com/2021/11/28/Cyber-RT%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%AD%E6%9E%A2%E8%B0%83%E5%BA%A6Scheduler/","excerpt":"","text":"前言 Scheduler是Cyber-RT的调度核心，是协程的调度载体。特别的，对于自动驾驶任务而言，任务调度的实时性发挥至关重要的作用，因此有必要对各种任务的优先级进行分类排序，如对于控制任务而言，需要单独分配CPU以供实时运行，Cyber-RT通过Scheduler来实现这种功能。 Cyber/Scheduler目录 1234567891011121314151617181920212223242526├── BUILD├── CMakeLists.txt├── common│ ├── cv_wrapper.h│ ├── mutex_wrapper.h│ ├── pin_thread.cc│ ├── pin_thread.h├── policy│ ├── choreography_context.cc│ ├── choreography_context.h│ ├── classic_context.cc│ ├── classic_context.h│ ├── scheduler_choreography.cc│ ├── scheduler_choreography.h│ ├── scheduler_classic.cc│ └── scheduler_classic.h├── processor.cc├── processor_context.cc├── processor_context.h├── processor.h├── processor_test.cc├── scheduler.cc├── scheduler_factory.cc├── scheduler_factory.h├── scheduler.h└── scheduler_test.cc Scheduler类图 两种策略 通过阅读上面的类图可以发现，Scheduler类是基类，其拥有两个子类，分别为SchedulerClassic和SchedulerChoreography，分别对应两种策略，Classic(经典)策略与Choreophgray(编排)策略。两者并不是互斥关系，后者可看作对前者的扩展。它们的介绍和示例可参考官方文档 Cyber RT Scheduler，这里暂不详细展开，下面的叙述以SchedulerClassic策略为主。 调度策略配置文件用protobuf定义，协议格式文件在cyber/proto目录下：scheduler_conf.proto，classic_conf.proto和choreography_conf.proto。调度策略配置文件在cyber/conf目录下。对于上面mkz_close_loop.pb.txt中的两个process group：compute_sched和control_sched，根据调度策略不同分别有两个版本 一个Scheduler实例 Scheduler是个单例，因此在程序启动时就被初始化了，尽管它不是程序的入口，但是从它却是系统子模块Component调度的管理者。 实例化 Scheduler的实例化过程由scheduler_factory.cc提供，其调用函数如下： 12345678910111213141516171819202122232425262728293031323334353637383940Scheduler* Instance() &#123; // instance是原子模板的 Scheduler* obj = instance.load(std::memory_order_acquire); // 如果obj为空 if (obj == nullptr) &#123; // 加锁 std::lock_guard&lt;std::mutex&gt; lock(mutex); obj = instance.load(std::memory_order_relaxed); // 双检查 if (obj == nullptr) &#123; // 默认策略 std::string policy(\"classic\"); std::string conf(\"conf/\"); // conf = conf/xxxxx.conf conf.append(GlobalData::Instance()-&gt;ProcessGroup()).append(\".conf\"); // cfg_file = CYBER_PATH + 相对路径 auto cfg_file = GetAbsolutePath(WorkRoot(), conf); // 检查配置文件是否存在，并读取配置到proto类型 apollo::cyber::proto::CyberConfig cfg; if (PathExists(cfg_file) &amp;&amp; GetProtoFromFile(cfg_file, &amp;cfg)) &#123; // 从配置文件读取策略 policy = cfg.scheduler_conf().policy(); &#125; else &#123; AWARN &lt;&lt; \"No sched conf found, use default conf.\"; &#125; // 根据策略，实例化不同的调度器 if (!policy.compare(\"classic\")) &#123; obj = new SchedulerClassic(); &#125; else if (!policy.compare(\"choreography\")) &#123; obj = new SchedulerChoreography(); &#125; else &#123; AWARN &lt;&lt; \"Invalid scheduler policy: \" &lt;&lt; policy; obj = new SchedulerClassic(); &#125; // 保存到instance单例 instance.store(obj, std::memory_order_release); &#125; &#125; return obj;&#125; 实例化主要做了几个事情： 获取配置文件conf/xxxx.conf 读取策略配置项policy 根据policy配置项来选择实例化SchedulerClassic()还是SchedulerChoreography()，如果没有提供，则默认选择实例化SchedulerClassic() 这个实现确保了线程安全，即Scheduler单例只能被创建一个 以SchedulerClassic()为例，接下来看其实例化过程（构造函数）： 123456789SchedulerClassic::SchedulerClassic()&#123; // 由于函数篇幅较长，下面用文字描述 1. 再次获取配置文件\"conf/xxxxx.conf\" 2. 解析proto配置文件 3. 读取threads字段的配置 ===&gt; 这个暂时还不知道用来干嘛 4. 读取cpu编号配置[process_level_cpuset_]，根据这个配置项来设置当前调度线程的CPU亲和性,这样就指定了该进程中的所有任务都只能在限定的CPU核上运行 5. 读取[classic_conf]配置项，遍历配置项中的每一个[group]配置，而每个[group]内又包含若干个[task]，目的是把所有[task]的配置都保存下来，记录到成员变量cr_confs_内。需要注意的点是，在这个过程中，会根据每个[task]所在的[group]填充group_name，后面会用到。 6. 最后为每个group创建对应数量的Processor，并设置相关策略&#125; 实例化过程中，有很多部分都与配置文件直接相关，这里我们以conf/example_sched_classic.conf为例展开： 我们从第4点开始看，首先是读取配置项process_level_cpuset_,根据配置文件，这个字符串一般填\"0-7,16-23\"形式的内容，表示当前调度线程可以由0-7,16-23号CPU核心来执行。最终实现这个功能的函数是Scheduler::ProcessLevelResourceControl()，其内部是通过glibc提供的接口pthread_setaffinity_np(pthread_self(), sizeof(set), &amp;set);来实现对线程设置CPU亲和性。 注意配置文件中有两个优先级： 一个是processor_prio，对应系统Linux中线程的优先级，即nice值，范围从-20到19，值越低优先级越高，默认值为0； 另一个是task的prio，它是Cyber RT中的协程调度的优先级，共20级，值越高优先越高 接下来第5点，简单来说就是读取每个[task]字段的配置项，并保存下来，其代码如下: 123456789101112classic_conf_ = cfg.scheduler_conf().classic_conf();// 遍历每一个groupfor (auto&amp; group : classic_conf_.groups()) &#123; auto&amp; group_name = group.name(); // 遍历group内的task配置项 for (auto task : group.tasks()) &#123; // 对task反过来设置group_name task.set_group_name(group_name); // 保存起来 cr_confs_[task.name()] = task; &#125;&#125; 对应配置文件举例如下： 这里有一点需要注意的是，由于配置文件中每个[task]内部没有写明其所在的[group]名称，因此在读取配置的时候，通过task.set_group_name(group_name);进行了设置，这个group_name相当的重要，接下来会用到。 最后看第6点，为每个group创建对应数量的Processor，并设置相关策略，这是由函数SchedulerClassic::CreateProcessor()来实现的。 12345678910111213141516171819202122232425void SchedulerClassic::CreateProcessor() &#123; // 遍历每一个group for (auto&amp; group : classic_conf_.groups()) &#123; 1. 获取该group的group_name、proc_num配置参数 2. 获取该group的affinity、processor_policy、processor_prio配置参数 3. 内部再进行一次遍历，为每个组创建对应数量的processor,部分代码如下： for (uint32_t i = 0; i &lt; proc_num; i++) &#123; 3.1 先创建执行器的上下文ClassicContext，并放入全局的pctxs_队列中 auto ctx = std::make_shared&lt;ClassicContext&gt;(group_name); pctxs_.emplace_back(ctx); 3.2 创建执行器Processor，并将上面创建的上下文与之绑定 auto proc = std::make_shared&lt;Processor&gt;(); 3.3 关键： proc-&gt;BindContext(ctx); 3.4 设置该Processor的CPU亲和性，根据affinity = \"range\" or \"1to1\"来决定该Processor在多个CPU上进行还是单个CPU上进行 SetSchedAffinity(proc-&gt;Thread(), cpuset, affinity, i); 3.5 设置调度策略 SetSchedPolicy(proc-&gt;Thread(), processor_policy, processor_prio, proc-&gt;Tid()); 3.6 将这个新创建的Processor保存到容器 processors_.emplace_back(proc); &#125; &#125;&#125; 其中，通过SetSchedAffinity()函数对新创建的某个Processor对象内部的thread进行CPU亲和性设置，以实现CPU的分配，特别的，根据该group的affinity配置项，有两种CPU分配策略： range: 采用range策略，即每个Processor对象内部的thread都可以由cpuset字段给定的范围内自由调度，即范围内的CPU都可以处理 1to1: 即每个Processor对象内部的thread只能对应一个CPU核心，cpuset字段提供的是有多少个CPU可分配，但是个Processor对象内部的thread只能对应cpuset字段的第i个核心 以上是关于线程的CPU亲和性设置，接下来的一个关键问题是，创建这么多Processor，如何真正处理我们的任务? 代码片段中的3.3是关键，proc-&gt;BindContext(ctx)将新创建的ProcessorContext上下文保存到成员变量Processor::context_，然后开启线程来执行Processor::Run，该函数代码不长，就两句： 12345void Processor::BindContext(const std::shared_ptr&lt;ProcessorContext&gt;&amp; context) &#123; context_ = context; std::call_once(thread_flag_, [this]() &#123; thread_ = std::thread(&amp;Processor::Run, this); &#125;);&#125; 该函数首先保存传进来的ProcessorContext对象指针，然后启动了一个线程，看来Processor::Run这个线程就是实际执行任务的线程了， 1234567891011121314151617181920212223242526void Processor::Run() &#123; // 暂时先忽略snap_shot_这个对象的内容 // 这是一个循环，只要Processor的running_状态weitrue while (cyber_likely(running_.load())) &#123; // 检查context_不为空 if (cyber_likely(context_ != nullptr)) &#123; // 尝试从cr_group_获取下一个协程 auto croutine = context_-&gt;NextRoutine(); // 如果获取成功 if (croutine) &#123; // 恢复协程运行 croutine-&gt;Resume(); // 释放协程锁( 上面获取协程context_-&gt;NextRoutine()时，调用了croutine-&gt;Aquire() ) croutine-&gt;Release(); &#125; else &#123; // 阻塞等待，超时自动解除阻塞 context_-&gt;Wait(); &#125; &#125; else &#123; // 如果context_为空，阻塞10毫秒，超时后结束阻塞，下一次循环 std::unique_lock&lt;std::mutex&gt; lk(mtx_ctx_); cv_ctx_.wait_for(lk, std::chrono::milliseconds(10)); &#125; &#125;&#125; Processor::Run这个线程不断的尝试从context_成员变量中获取协程，并恢复协程运行，一个协程的任务处理完后，继续从上下文获取下一个协程context_-&gt;NextRoutine();。至于这个协程的切入和切出，到后面协程篇章的时候再详细讨论。接下来，就要看看这个上下文成员变量context_是啥。 processor.h头文件内可知，成员变量context_声明如下: 12// ProcessorContext只是基类，实际保存下来的是 ClassicContext 或 ChoreographyContextstd::shared_ptr&lt;ProcessorContext&gt; context_; 即每个Processor对象内维护着一个ProcessorContext。 ProcessorContext 实际上，ProcessorContext只是基类，根据Scheduler的两种策略，分别对应着两种ProcessorContext，分别是: ClassicContext ChoreographyContext uml类图如下： 接下来，以ClassicContext为主进行展开： ProcessorContext实例化 ProcessorContext实例化不是在Processor内部进行，而是在上面提到的SchedulerClassic::CreateProcessor()函数中进行，具体代码片段为: 1auto ctx = std::make_shared&lt;ClassicContext&gt;(group_name); 接下来，看ClassicContext的构造函数： 12345678ClassicContext::ClassicContext()&#123; InitGroup(DEFAULT_GROUP_NAME);&#125;ClassicContext::ClassicContext(const std::string&amp; group_name) &#123; InitGroup(group_name);&#125; ClassicContext类有两个构造函数，其中一个需要传参[group_name],另外一个不需传参。两个构造函数内部都调用了ClassicContext::InitGroup函数，该函数从全局静态容器中取对应[group_name]的引用并保存到ClassicContext类的成员变量中，目的是，当其他地方向全局静态容器添加元素时，直接调用ClassicContext类的成员变量即可访问到新增加的元素。该函数代码如下： 12345678910void ClassicContext::InitGroup(const std::string&amp; group_name) &#123; // cr_group_是ClassicContext类静态成员变量 // cr_group_包含了多个组，每个组有分为多个优先级，每个优先级对应着多个协程 multi_pri_rq_ = &amp;cr_group_[group_name]; // 取cr_group_中对应group_name的组，保存到multi_pri_rq_ lq_ = &amp;rq_locks_[group_name]; // 取rq_locks_中对应group_name的组，保存到lq_ mtx_wrapper_ = &amp;mtx_wq_[group_name]; // 取mtx_wrapper_中对应group_name的组，保存到mtx_wrapper_ cw_ = &amp;cv_wq_[group_name]; // 取cv_wq_中对应group_name的组，保存到cw_ notify_grp_[group_name] = 0; current_grp = group_name;&#125; ClassicContext的静态容器 上面提到ClassicContext类里面有几个全局静态容器，其在classic_context.h中声明如下: 123456789101112131415161718Class ClassicContext&#123;...public: // CR_GROUP: 容器[组名] = std::array&lt;std::vector&lt;std::shared_ptr&lt;CRoutine&gt;&gt;, MAX_PRIO&gt;&gt; alignas(CACHELINE_SIZE) static CR_GROUP cr_group_; ///&lt; cr_group_包含了多个组，每个组有分为多个优先级，每个优先级对应着多个协程 // RQ_LOCK_GROUP: 容器[组名] = std::array&lt;base::AtomicRWLock, MAX_PRIO&gt;; alignas(CACHELINE_SIZE) static RQ_LOCK_GROUP rq_locks_; ///&lt; rq_locks_包含多个组，每组分为多个优先级，每个优先级对应一个base::AtomicRWLock，关于cr_group_变量的锁 // GRP_WQ_CV: 容器[组名] = CvWrapper alignas(CACHELINE_SIZE) static GRP_WQ_CV cv_wq_; ///&lt; cv_wq_包含多个组，每组对应一个CvWrapper // GRP_WQ_MUTEX: 容器[组名] = MutexWrapper alignas(CACHELINE_SIZE) static GRP_WQ_MUTEX mtx_wq_; ///&lt; mtx_wq_包含多个组，每组对应一个MutexWrapper，是关于notify_grp_[group_name]的锁 // NOTIFY_GRP: 容器[组名] = int alignas(CACHELINE_SIZE) static NOTIFY_GRP notify_grp_; ///&lt; notify_grp_包含多个组，每组对应一个int&#125; 这几个容器都是Public的且静态的，所以其他地方可以直接往里面读写数据，而线程问题则通过rq_locks_容器和mtx_wq_容器进行加锁控制。 实际上，Scheduler要调度的任务，都保存到了这几个静态容器内部，如何存进去，以及存了什么进去，SchedulerClassic::DispatchTask函数给出了答案，该函数以一个协程指针作为参数，做了以下几个工作: 首先把这个新协程放入Scheduler::id_cr_中， 然后根据[协程名]查找保存的构造Scheduler单例时，产生的cr_confs_中是否有该task对应的策略，如果有就根据策略设置该协程的[优先级]和[group_name] 最后往ClassicContext中的全局静态变量ClassicContext::cr_group_中对应该协程的[group_name]和优先级的队列中加入该协程 最后调用ClassicContext::Notify(来通知该协程所属的组，让Processor::Run()结束阻塞，马上运行一次 这个函数，着重看以下代码块: 1234567891011121314151617181920212223242526272829bool SchedulerClassic::DispatchTask(const std::shared_ptr&lt;CRoutine&gt;&amp; cr) &#123; ... // 根据协程名进行查表，cr_confs_在实例化SchedulerClassic对象时，就根据配置文件读取配置进去了，对应的是sched_classic.conf配置文件中的\"tasks:\"项 if (cr_confs_.find(cr-&gt;name()) != cr_confs_.end()) &#123; // 找到配置项，则取对应的value ClassicTask task = cr_confs_[cr-&gt;name()]; // 协程设置属性（从ClassicTask获取） cr-&gt;set_priority(task.prio()); // 设置优先级? cr-&gt;set_group_name(task.group_name()); // 设置分组名? 如果没有给这个值呢？ ==&gt; 在SchedulerClassic::SchedulerClassic()构造时，会设置值的 &#125; else &#123; // 如果cr_confs_没有这个协程名的条目，直接设置分组名为默认的 classic_conf_.groups(0).name() // croutine that not exist in conf cr-&gt;set_group_name(classic_conf_.groups(0).name()); &#125; // Enqueue task. &#123; // 取ClassicContext::cr_group_对应该组该优先级的写锁 WriteLockGuard&lt;AtomicRWLock&gt; lk( ClassicContext::rq_locks_[cr-&gt;group_name()].at(cr-&gt;priority())); // 将输入参数中的协程添加到ClassicContext::cr_group_，等待被调度 ClassicContext::cr_group_[cr-&gt;group_name()] .at(cr-&gt;priority()) .emplace_back(cr); &#125; ...&#125; 所以说，需要调度的协程，都通过这个函数，根据协程所在的组，把协程指针保存到ClassicContext::cr_group_静态变量中。 ClassicContext::cr_group数据结构 ClassicContext::cr_group_是一张大的表格，分为多个[group]，每个[group]又分多个优先级，每个优先级对应着一个std::vector，vector内部存放着多个协程。 一个需要注意的点是，由于ClassicContext::cr_group_是静态变量，多个线程访问时会有data race的问题，因此cyber-rt增加了对应的锁ClassicContext::rq_locks_来解决。 ClassicContext::rq_locks数据结构 显然，ClassicContext::rq_locks_内按group_name进行分组，每个组内又按优先级进行划分，因此，这里一个锁对应ClassicContext::cr_group_中的一个std::vector&lt;CRoutine&gt;，其对应关系如下图所示： ClassicContext的动态容器 前面讨论了ClassicContext的静态成员变量，接下来我们看其类内动态成员变量。代码片段如下： 12345678910class ClassicContext : public ProcessorContext &#123; ...private: // std::array&lt;std::vector&lt;std::shared_ptr&lt;CRoutine&gt;&gt;, MAX_PRIO&gt; MULTI_PRIO_QUEUE *multi_pri_rq_ = nullptr; ///&lt; 优先队列，每个优先级有一个协程列表 LOCK_QUEUE *lq_ = nullptr; MutexWrapper *mtx_wrapper_ = nullptr; ///&lt; 这个是对成员notify_grp_[current_grp]的锁 CvWrapper *cw_ = nullptr; std::string current_grp;&#125; ClassicContext::multi_pri_rq队列 在函数ClassicContext::InitGroup中，将ClassicContext::cr_group_的某个组的引用赋值给了成员变量ClassicContext::multi_pri_rq_，因此，ClassicContext::multi_pri_rq_的数据结构如下: ClassicContext::multi_pri_rq_与ClassicContext::cr_group_的映射关系如下: 所以，通过向全局静态表ClassicContext::cr_group_写入协程后，可以通过ClassicContext::multi_pri_rq_来读取对应的协程，最后通过Processor::Run来完成协程的调用。 重要过程时序流图 创建SchedulerClassic实例 创建Processor并绑定上下文 创建Task并分配给Processor Scheduler::CreateTask这个函数是Scheduler基类的函数，其内部会调用子类SchedulerClassic或SchedulerChoreography的DispatchTask()函数，最后将子类的NotifyProcessor函数注册给DataVistor对象，其详细的时序流程如下： 运转核心Processor::Run 唤醒机制SchedulerClassic::NotifyProcessor","categories":[],"tags":[{"name":"Cyber_RT","slug":"Cyber-RT","permalink":"http://yoursite.com/tags/Cyber-RT/"}]},{"title":"Cyber-RT系列之协程Croutine","slug":"Cyber-RT系列之协程Croutine","date":"2021-11-28T15:10:29.000Z","updated":"2022-02-27T12:13:36.000Z","comments":true,"path":"2021/11/28/Cyber-RT系列之协程Croutine/","link":"","permalink":"http://yoursite.com/2021/11/28/Cyber-RT%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%8F%E7%A8%8BCroutine/","excerpt":"","text":"前言 协程是Cyber-RT的实现任务轮转的最小单位，是处理数据回调的运行模块。协程可以理解为“可以暂停”的函数，相比于线程，其具有中断可恢复的特性，那么只需要在开一个全局的数组存储所有的协程，在协程中断时，不断轮转调用下一个协程继续运行即可达到类似线程的效果。 为什么选用协程，因为基于协程的特性再加上Cyber中枢调度Scheduler的线程调度，可以避免回调时由于阻塞导致其他回调不能被执行的情况；此外，协程是在用户态来完成上下文切换的，所以切换耗时只有区区100ns多一些，比进程切换要高30倍。 Cyber/croutine目录 12345678910├── BUILD├── CMakeLists.txt├── croutine.cc├── croutine.h├── detail│ ├── routine_context.cc│ ├── routine_context.h│ ├── swap_aarch64.S│ └── swap_x86_64.S└── routine_factory.h Croutine类图 ... 结构图 协程的创建 Cyber-RT中有两个地方创建了协程： Component的初始化 Reader的初始化 两处地方的创建大同小异，这里给出Component&lt;M0, NullType, NullType, NullType&gt;::Initialize函数中关于创建协程的代码片段: 1234567891011121314151617181920template &lt;typename M0&gt;bool Component&lt;M0, NullType, NullType, NullType&gt;::Initialize( ... // lambda函数 （这个后面作为） auto func = [self](const std::shared_ptr&lt;M0&gt;&amp; msg) &#123; // 处理msg ... &#125;; ... // 构造 data::DataVisitor auto dv = std::make_shared&lt;data::DataVisitor&lt;M0&gt;&gt;(conf); // 创建协程工厂 croutine::RoutineFactory factory = croutine::CreateRoutineFactory&lt;M0&gt;(func, dv); auto sched = scheduler::Instance(); return sched-&gt;CreateTask(factory, node_-&gt;Name()); 其流程大概是这样: 写出一个lambda函数，内部进行msg的回调处理 构造一个DataVistor 将lambda函数和创建的DataVistor一并作为参数，用于创建协程工厂croutine::RoutineFactory 将协程工厂作为参数，调用中枢调度Scheduler::CreateTask(...)函数 Why RoutineFactory? 看到上面的代码片段可能会觉得奇怪，为什么需要协程工厂这一层，直接创建一个协程不好吗？ 这其实是一种封装，假设我们直接创建一个协程，那么需要传入一个回调函数，用于处理msg，然而Cyber-RT一共考虑了1-4种msg的情况，那么创建协程时传入的回调函数的参数就有4种情况，这使得接口不能统一。使用协程工厂就是为了对4种情况进行封装，并统一接口，即创建协程时只需要把协程工厂传入作为参数即可。 What is RoutineFactory? 重要过程时序流图","categories":[],"tags":[{"name":"Cyber_RT","slug":"Cyber-RT","permalink":"http://yoursite.com/tags/Cyber-RT/"}]},{"title":"FAST-LIO论文阅读","slug":"FAST-LIO论文阅读","date":"2021-10-13T13:03:53.000Z","updated":"2022-04-11T15:57:06.355Z","comments":true,"path":"2021/10/13/FAST-LIO论文阅读/","link":"","permalink":"http://yoursite.com/2021/10/13/FAST-LIO%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"FAST-LIO: A Fast, Robust LiDAR-inertial Odometry Package by Tightly-Coupled Iterated Kalman Filter 摘要 方法 架构总览 本文使用的符号如表一所示 系统的流图如图2所示 将激光雷达输入输入特征提取模块，获取平面和边缘特征。然后将提取的特征和IMU测量值输入状态估计模块进行10Hz和50Hz的状态估计。然后，估计的姿态将特征点注册到全局坐标系，并将它们与到目前为止建立的特征点地图合并，最后，在下一步中使用更新后的特征地图来注册更多的新点。 系统描述 操作符 设M为考虑维度n的流形(如： \\(\\mathcal{M}=S O(3)\\)），因为流形对于\\(\\mathbb{R}^{n}\\)是局部homeomorphic的，因此我们可以建立双向的映射，即通过操作符\\(\\boxplus,\\boxminus\\)[23]，从流形 \\(\\mathcal{M}\\)的局部邻域映射到其正切空间\\(\\mathbb{R}^{n}\\)： 其中，\\(\\operatorname{Exp}(\\mathbf{r})=\\mathbf{I}+\\frac{\\mathbf{r}}{\\|\\mathbf{r}\\|} \\sin (\\|\\mathbf{r}\\|)+\\frac{\\mathbf{r}^{2}}{\\|\\mathbf{r}\\|^{2}}(1-\\cos (\\|\\mathbf{r}\\|))\\)是指数映射[23]，\\(\\log (\\cdot)\\)则是其逆映射。对于组合的流形\\(\\mathcal{M}=S O(3) \\times \\mathbb{R}^{n}\\)，我们有： 利用上述定义，我们可以得到： 连续时间模型 假设IMU与激光雷达之间是刚体变换，其中外参是\\({ }^{I} \\mathbf{T}_{L}=\\left({ }^{I} \\mathbf{R}_{L},{ }^{I} \\mathbf{p}_{L}\\right)\\)。以IMU坐标系（记为\\(I\\)）作为body坐标系，可得运动学模型： 其中， \\({ }^{G} \\mathbf{p}_{I},{ }^{G} \\mathbf{R}_{I}\\)分别是IMU在全局坐标系（如第一帧IMU坐标系，记为\\(G\\)）的位置和姿态。 \\({ }^{G} \\mathbf{g}\\)是全局坐标系下未知的重力向量 \\(\\mathbf{a}_{m}\\),\\(\\boldsymbol{\\omega}_{m}\\)是IMU测量 \\(\\mathbf{n}_{\\mathbf{a}}\\) and \\(\\mathbf{n}_{\\boldsymbol{\\omega}}\\)是IMU测量白噪声 \\(\\mathbf{b}_{\\mathbf{a}}\\) and \\(\\mathbf{b}_{\\boldsymbol{\\omega}}\\)是由高斯噪声\\(\\mathbf{n}_{\\mathbf{b a}}\\) , \\(\\mathbf{n}_{\\mathbf{b} \\omega}\\)随机游走过程建模的bias \\(\\lfloor\\mathbf{a}\\rfloor_{\\wedge}\\)表示向量\\(\\mathbf{a} \\in \\mathbb{R}^{3}\\)的反对称矩阵 离散时间模型 基于上面的\\(\\boxplus\\)操作符，我们在IMU采样周期\\(\\Delta t\\)内使用零阶保持器来对式（1）的连续时间模型进行离散化，得到： 其中，i表示IMU测量的索引，函数\\(\\mathbf{f}\\)，状态\\(\\mathbf{x}\\)，输入\\(\\mathbf{u}\\)，噪声\\(\\mathbf{w}\\)定义如下： 激光测量预处理 激光雷达测量是点坐标在它的局部坐标系。由于原始激光雷达点的采样速率非常高(例如，200kHz)，通常不可能在接收到每个新点后马上进行处理，一种更实际的方法是在一段时间内积累这些点，然后一次性处理它们。 FAST-LIO中，最小积累间隔设置为20毫秒，可产生高达50 Hz的全状态估计(即里程计输出)和地图更新，如图2 （a）所示。这种累积的点集称为scan，其处理时间记为\\(t_k\\)(见图2 (b)。 我们从原始点中提取局部光滑度高的平面点[8]和局部光滑度低的边缘点[10]，假设特征点的数量为m，每个特征点在\\(\\rho_{j} \\in\\left(t_{k-1}, t_{k}\\right]\\)时刻采样，特征点记为\\({ }^{L_{j}} \\mathbf{p}_{f_{j}}\\)，其中\\(L_{j}\\)是\\(\\rho_{j}\\)时刻下激光雷达坐标系。 在激光扫描期间，通常会收到几帧IMU测量，假设每一个IMU采样时间\\(\\tau_{i} \\in\\left[t_{k-1}, t_{k}\\right]\\)，其对应的状态\\(\\mathbf{x}_i\\)如式（2）。注意，最后一个激光雷达特征点是扫描的结束，即\\(\\rho_{m}=t_{k}\\)，而IMU测量值不一定与扫描开始或结束时对齐。 状态估计 为了估计状态公式(2)中的状态，我们使用了迭代扩展卡尔曼滤波器，此外，我们刻画了状态估计的正切空间中的估计协方差，如[23,24]。 假设在\\(t_{k-1}\\)时刻下最后一次激光雷达扫描的最佳状态估计为\\(\\bar{\\mathbf{x}}_{k-1}\\)，协方差为\\(\\overline{\\mathbf{P}}_{k-1}\\)。其中，\\(\\overline{\\mathbf{P}}_{k-1}\\)代表了如下误差状态向量的协方差： 其中， \\(\\delta \\boldsymbol{\\theta}=\\log \\left({ }^{G} \\overline{\\mathbf{R}}_{I}^{T G} \\mathbf{R}_{I}\\right)\\)是姿态误差 剩下的其他都是直接相减 直觉的，\\(\\delta \\boldsymbol{\\theta}\\)描述了姿态真值和估计值之间的小偏差，使用这个来定义姿态误差的好处是允许使用3x3协方差矩阵\\(\\mathbb{E}\\left\\{\\delta \\boldsymbol{\\theta} \\delta \\boldsymbol{\\theta}^{T}\\right\\}\\)来描述姿态的不确定性。因为姿态是3自由度，因此这是最小表达。 1）前向传播 一旦接收到IMU输入，则执行一次前向传播（如图2所示），特别的，前向传播根据式（2）进行，且把噪声\\(\\mathbf{W}_{i}\\)设置为零，（相当于nominal state）： 其中，\\(\\Delta t=\\tau_{i+1}-\\tau_{i}\\)，为了传播协方差，我们使用下面的误差状态动态模型： 矩阵\\(\\mathbf{F}_{\\widetilde{\\mathbf{x}}}\\)和\\(\\mathbf{F}_{\\mathbf{w}}\\)为误差状态模型(实际上就是误差分析，可参考博客)，具体计算见附录A. 此处直接给出结果： 其中， \\(\\widehat{\\boldsymbol{\\omega}}_{i}=\\boldsymbol{\\omega}_{m_{i}}-\\widehat{\\mathbf{b}}_{\\boldsymbol{\\omega}_{i}}\\) \\(\\widehat{\\mathbf{a}}_{i}=\\mathbf{a}_{m_{i}}-\\widehat{\\mathbf{b}}_{\\mathbf{a}_{i}}\\) 且\\(\\mathbf{A}(\\mathbf{u})^{-1}\\)遵循[25]中的定义，如下计算： 记白噪声\\(\\mathbf{w}\\)的协方差为Q，然后可以通过下式来迭代传播协方差\\(\\widehat{\\mathbf{P}}_{i}\\)： 前向传播直到新的一帧数据结束\\(t_k\\)，传播的状态和协方差分别记为\\(\\widehat{\\mathbf{x}}_{k}, \\widehat{\\mathbf{P}}_{k}\\)，协方差表示状态真值与传播值之间的误差协方差。 2）反向传播和运动补偿 当在时间\\(t_k\\)，新一帧的特征点应该与传播状态\\(\\widehat{\\mathbf{x}}_{k}\\)和协方差\\(\\widehat{\\mathbf{P}}_{k}\\)进行结合以产生最优状态更新。然而，尽管新的一帧是在\\(t_k\\)到达，实际上特征点是在各自的采样时刻\\(\\rho_j\\)下得到的，因此要进行运动畸变矫正。 为了补偿\\(\\rho_j\\)到\\(t_k\\)之间的相对运动（即运动畸变），根据式（2），可得传播方程\\(\\check{\\mathbf{x}}_{j-1}=\\check{\\mathbf{x}}_{j}\\) 田 \\(\\left(-\\Delta t \\mathbf{f}\\left(\\check{\\mathbf{x}}_{j}, \\mathbf{u}_{j}, \\mathbf{0}\\right)\\right)\\)。 向后传播在特征点的频率下执行，这通常远高于IMU速率，对于在两个IMU测量之间采样的所有特征点，我们使用左IMU测量作为后传播中的输入。 此外，注意到\\(\\mathbf{f}\\left(\\mathbf{x}_{j}, \\mathbf{u}_{j}, \\mathbf{0}\\right)\\)中最后三个块元素（对应于gyro bias，accelerometer bias和外参）都是零，因此，反向传播可以简化为： 其中， \\(\\rho_{j-1} \\in\\left[\\tau_{i-1}, \\tau_{i}\\right)\\)表示一帧扫描内的某个时刻 \\(\\Delta t=\\rho_{j}-\\rho_{j-1}\\)表示两个点之间的时间差 \\(s.f.\\)表示“starting form”的意思 反向传播会计算出时间\\(\\rho_{j}\\)到时间\\(t_k\\) 的相对位姿变换\\({ }^{I_{k}} \\check{\\mathbf{T}}_{I_{j}}=\\left({ }^{I_{k}} \\check{\\mathbf{R}}_{I_{j}},{ }^{I_{k}} \\check{\\mathbf{p}}_{I_{j}}\\right)\\)，这个相对位姿变换运行我们将激光扫描观测点\\({ }^{L_{j}} \\mathbf{p}_{f_{j}}\\)投影到扫描结束时刻下的坐标系，如下： 其中，\\({ }^{I} \\mathbf{T}_{L}\\)是已知外参，投影点\\({ }^{L_{k}} \\mathbf{p}_{f_{j}}\\)用于下一步构造残差。 3）残差计算 使用式（10）的运动补偿，我们可以看到在\\(t_k\\)时刻下所有特征点\\(\\left\\{ { }^{L_{k}} \\mathbf{p}_{f_{j}}\\right\\}\\)正确的位置，并且用来构造残差。 假设当前IEKF迭代为\\(\\kappa\\)，对应的状态估计为\\(\\widehat{\\mathbf{x}}_{k}^{\\kappa}\\)。当\\(\\kappa=0\\)，\\(\\widehat{\\mathbf{x}}_{k}^{\\kappa}=\\widehat{\\mathbf{x}}_{k}\\)，预测的状态即为式（4）传播的状态。因此，特征点可以被投影到全局坐标系，如下： 对于每一个激光特征点，假设其附近的附近特征点定义的最接近的平面或边缘是与之关联的特征。残差即为特征点与关联特征（平面、边缘）的欧式距离（全局坐标系下）。 记\\(\\mathbf{u}_{j}\\)为平面法向量或者边缘方向，对于根据状态估计投影到全局坐标系的特征点\\({ }^{G} \\widehat{\\mathbf{p}}_{f_{j}}^{\\kappa}\\)，假设平面/边缘上有点\\({ }^{G} \\mathbf{q}_{j}\\)，残差\\(\\mathbf{z}_{j}^{\\kappa}\\)如下计算： 其中， \\(\\mathbf{G}_{j}=\\mathbf{u}_{j}^{T}\\)是平面特征 \\(\\mathbf{G}_{j}=\\left\\lfloor\\mathbf{u}_{j}\\right\\rfloor_{\\wedge}\\)是边缘特征 \\(\\mathbf{u}_{j}\\)的计算和最近邻点的搜索是通过构建局部地图KD-TREE来实现的 此外，我们只考虑norm低于某些阈值（例如，0.5米）的残差。 超过此阈值的残差是异常值或新观察点","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"FAST-LIO2论文阅读","slug":"FAST-LIO2论文阅读","date":"2021-09-11T06:03:53.000Z","updated":"2022-04-11T15:57:06.370Z","comments":true,"path":"2021/09/11/FAST-LIO2论文阅读/","link":"","permalink":"http://yoursite.com/2021/09/11/FAST-LIO2%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"FAST-LIO2: Fast Direct LiDAR-inertial Odometry 摘要 在高效的紧密耦合迭代卡尔曼滤波器上，FAST-LiO2有两个关键的新科技，可允许快速，强大，准确的LIDAR导航（和建图）。 直接将原始点注册到地图（随后更新地图）而不提取特征点。这使得能够利用环境中的微妙特征，因此提高了准确性。取消手工设计的特征提取模块也使其自然适应不同扫描模式的新兴 LiDAR。 第二个主要新颖性是通过增量K-D树数据结构，来维护地图，该映射可以增量更新（即点插入，删除）和动态重新平衡。与现有的动态数据结构相比（Octree，R * -tree，Nanoflann K-D树），IKD-Tree实现了卓越的整体性能，同时支持基于数的降采样 我们在来自各种开放式LIDAR数据集中的19个序列中进行详尽的基准比较，与其他最先进的 LiDAR 惯性导航系统相比，FAST-LIO2 以更低的计算负载持续实现更高的精度，还进行了关于具有小FOV的固态激光雷达的各种真实实验。 总的来说，FAST-LiO 2是计算上有效的（例如，高达100 Hz的里程计和大型环境中的建图），鲁棒（例如，杂乱的室内环境中具有旋转的杂乱的室内环境的可靠姿态估计，多功能（即， 适用于多线和固态LIDARS，UAV和手持平台，英特尔和基于ARM的处理器），同时仍然比现有方法实现更高的准确性。 介绍 我们开发一个增量K-D树数据结构，IKD树，有效地表示大规模稠密点云地图。 除了有效的最近邻搜索之外，新的数据结构还支持增量地图更新（即，点插入，基于数的降采样，点删除）和最小计算成本的动态重新平衡。 这些功能使IKD树非常适合基于激光雷达的里程计和建图应用，在计算限制平台上实现100 Hz 里程计和建图，如微型UAV板载计算机（英特尔I7）甚至基于ARM的处理器。 通过增加IKD树的计算效率允许，我们直接将原始点注册到地图，即使具有激进的运动和非常杂乱的环境，也能够更准确和可靠的扫描配准。我们将此使用原始点的配准称为类似于Visual Slam的直接方法[21]。消除手工工程特征提取使得系统自然适用于不同的激光雷达传感器。 我们将以上两个改进整合到先前的工作FAST-LIO中，该系统使用IMU通过严格的反向传播步骤来遵从每个点的运动，并通过迭代扩展卡尔曼滤波器估计系统的完整状态。为了进一步加速计算，使用新的和数学上等同的计算卡尔曼增益的公式用于将计算复杂性降低到状态的维度（而不是观测的维度）。 新的系统称为FAST-LIO2，关于各种尺寸的18个序列的实验表明，IKD树在应用激光雷达测量和测绘时实现了相比于现有动态数据结构（Octree，R * -Tree，Nanoflann K-D树）的卓越性能 系统概述 FAST-LIO2的数据流如图所示，为了执行状态估计，新扫描中的点被通过紧密耦合的迭代卡尔曼滤波器框架（有红色的大虚线块）注册到大型局部地图中。大型局部地图中的全局地图点由增量K-D树结构IKD-Tree组织（蓝色虚线块）。如果当前LIDAR的FOV范围交叉地图边界，则将删除IKD树中，从LIDAR位置到最远地图区域中的历史点。 结果，IDK-TREE跟踪在一个大范围立方体区域（map size）中的所有地图点，并用于计算状态估计模块中的残差。优化后的位姿最后将新扫描中的点注册到全局坐标系，并通过以里程计频率插入到IKD树，来将它们合并到地图中。 状态估计 FAST-LIO2的状态估计是从FAST-LIO[22]继承的，且进一步整合了Lidar-IMU的外参在线标定。在这里，我们简要解释滤波器的基本配方和工作流程，并参考[22]了解更多细节。 系统模型 我们首先导出系统模型，由状态转换模型和测量模型组成 状态转移模型 取第一个 IMU 帧（记为 I）作为全局帧（记为 G），记\\({ }^{I} \\mathbf{T}_{L}=\\left({ }^{I} \\mathbf{R}_{L},{ }^{I} \\mathbf{p}_{L}\\right)\\)为激光雷达到IMU的外参（未知），那么模型如下： \\[ \\begin{aligned} { }^{G} \\dot{\\mathbf{R}}_{I} &amp;={ }^{G} \\mathbf{R}_{I}\\left\\lfloor\\boldsymbol{\\omega}_{m}-\\mathbf{b}_{\\boldsymbol{\\omega}}-\\mathbf{n}_{\\boldsymbol{\\omega}}\\right\\rfloor_{\\wedge}\\\\ { }^{G} \\dot{\\mathbf{p}}_{I} &amp;={ }^{G} \\mathbf{v}_{I} \\\\ { }^{G} \\dot{\\mathbf{v}}_{I} &amp;={ }^{G} \\mathbf{R}_{I}\\left(\\mathbf{a}_{m}-\\mathbf{b}_{\\mathbf{a}}-\\mathbf{n}_{\\mathbf{a}}\\right)+{ }^{G} \\mathbf{g} \\\\ \\dot{\\mathbf{b}}_{\\boldsymbol{\\omega}} &amp;=\\mathbf{n}_{\\mathbf{b} \\omega}, \\dot{\\mathbf{b}}_{\\mathbf{a}}=\\mathbf{n}_{\\mathbf{b a}} \\\\ { }^{G} \\dot{\\mathbf{g}} &amp;=\\mathbf{0},{ }^{I} \\dot{\\mathbf{R}}_{L}=\\mathbf{0},{ }^{I} \\dot{\\mathbf{p}}_{L}=\\mathbf{0} \\end{aligned} \\] 其中， \\({ }^{G} \\mathbf{p}_{I},{ }^{G} \\mathbf{R}_{I}\\)分别为全局坐标系下的IMU的位置和姿态 \\({ }^{G} \\mathbf{g}\\)是全局坐标系下的重力向量 \\(\\mathbf{a}_{m}\\)，\\(\\omega_{m}\\)是IMU测量 \\(\\mathbf{b}_{\\mathbf{a}}\\)，\\(\\mathbf{b}_{\\boldsymbol{\\omega}}\\)是由噪声\\(\\mathbf{n}_{\\mathbf{b a}},\\mathbf{n}_{\\mathbf{b \\omega}}\\)驱动的随机游走过程建模的IMU偏置 \\(\\lfloor\\mathbf{a}\\rfloor_{\\wedge}\\)表示由向量\\(\\mathbf{a}\\)构成的反对称矩阵 记\\(i\\)为IMU测量的索引，基于[22]中定义的\\(\\boxplus\\) 操作符，连续时间下的动态模型可以根据IMU采样周期\\(\\Delta t\\)进行离散化，如下： \\[ \\mathbf{x}_{i+1}=\\mathbf{x}_{i} \\boxplus \\left(\\Delta t \\mathbf{f}\\left(\\mathbf{x}_{i}, \\mathbf{u}_{i}, \\mathbf{w}_{i}\\right)\\right) \\] 其中，函数\\(\\mathbf{f}\\)，状态\\(\\mathbf{x}\\)，输入\\(\\mathbf{u}\\)和噪声\\(\\mathbf{w}\\)定义如下： \\[ \\mathcal{M} \\triangleq S O(3) \\times \\mathbb{R}^{15} \\times S O(3) \\times \\mathbb{R}^{3} ; \\operatorname{dim}(\\mathcal{M})=24 \\] \\[ \\mathbf{x} \\triangleq\\left[\\begin{array}{llllllll} { }^{G} \\mathbf{R}_{I}^{T} &amp; { }^{G} \\mathbf{p}_{I}^{T} &amp; { }^{G} \\mathbf{v}_{I}^{T} &amp; \\mathbf{b}_{\\boldsymbol{\\omega}}^{T} &amp; \\mathbf{b}_{\\mathbf{a}}^{T} &amp; { }^{G} \\mathbf{g}^{T} &amp; { }^{I} \\mathbf{R}_{L}^{T} &amp; { }^{I} \\mathbf{p}_{L}^{T} \\end{array}\\right]^{T} \\in \\mathcal{M} \\] \\[ \\mathbf{u} \\triangleq\\left[\\begin{array}{ll} \\boldsymbol{\\omega}_{m}^{T} &amp; \\mathbf{a}_{m}^{T} \\end{array}\\right]^{T} \\] \\[ \\mathbf{w} \\triangleq\\left[\\begin{array}{llll} \\mathbf{n}_{\\boldsymbol{\\omega}}^{T} &amp; \\mathbf{n}_{\\mathbf{a}}^{T} &amp; \\mathbf{n}_{\\mathbf{b} \\boldsymbol{\\omega}}^{T} &amp; \\mathbf{n}_{\\mathbf{b a}}^{T} \\end{array}\\right]^{T} \\] \\[ \\mathbf{f}(\\mathbf{x}, \\mathbf{u}, \\mathbf{w})=\\left[\\begin{array}{c} \\boldsymbol{\\omega}_{m}-\\mathbf{b}_{\\boldsymbol{\\omega}}-\\mathbf{n}_{\\boldsymbol{\\omega}} \\\\ { }^{G} \\mathbf{v}_{I}+\\frac{1}{2}\\left({ }^{G} \\mathbf{R}_{I}\\left(\\mathbf{a}_{m}-\\mathbf{b}_{\\mathbf{a}}-\\mathbf{n}_{\\mathbf{a}}\\right)+{ }^{G} \\mathbf{g}\\right) \\Delta t \\\\ { }^{G} \\mathbf{R}_{I}\\left(\\mathbf{a}_{m}-\\mathbf{b}_{\\mathbf{a}}-\\mathbf{n}_{\\mathbf{a}}\\right)+{ }^{G} \\mathbf{g} \\\\ \\mathbf{n}_{\\mathbf{b} \\omega} \\\\ \\mathbf{n}_{\\mathbf{b a}} \\\\ \\mathbf{0}_{3 \\times 1} \\\\ \\mathbf{0}_{3 \\times 1} \\\\ \\mathbf{0}_{3 \\times 1} \\end{array}\\right] \\in \\mathbb{R}^{24} \\] 量测模型 LIDAR通常是一个接一个地点的样品。 因此，当激光雷达经历连续运动时，所得到的点在不同的姿势处采样，为了纠正这种扫描运动，我们采用[22]中提出的反向传播，其估计每个激光点时刻下的激光雷达位姿相对于该帧激光扫描最后时刻的激光雷达位姿。估计的相对姿势使我们能够基于扫描中每个单独点的精确采样时间将所有点投影到扫描结束时间，以实现校正。 记\\(k\\)为激光扫描的索引，\\(\\{ { }^{L} \\mathbf{p}_{j}, j = 1,\\dots,m\\}\\)是第\\(k\\)帧激光坐标系下的激光点（扫描结束时刻），由于激光测量存在噪声，每一个点\\(\\mathbf{p}_{j}\\)都会受到由测距和方向组合的噪声项\\({ }^{L} \\mathbf{n}_{j}\\)影响。因此，真正的激光点与测量值之间存在如下关系： \\[ { }^{L} \\mathbf{p}_{j}^{\\mathrm{gt}}={ }^{L} \\mathbf{p}_{j}+{ }^{L} \\mathbf{n}_{j} \\] 真正的激光点\\({ }^{L} \\mathbf{p}_{j}^{\\mathrm{gt}}\\)，根据对应的激光雷达位姿\\({ }^{\\mathbf{G}}\\mathbf{T}_{I_{k}}=\\left({ }^{G} \\mathbf{R}_{I_{k}},{ }^{G} \\mathbf{p}_{I_{k}}\\right)\\)以及外参\\({ }^{I} \\mathbf{T}_{L}\\)进行坐标转换，其应该准确的位于地图中的局部的平面上，满足： \\[ \\mathbf{0}={ }^{G} \\mathbf{u}_{j}^{T}\\left({ }^{G} \\mathbf{T}_{I_{k}}{ }^{I} \\mathbf{T}_{L}\\left({ }^{L} \\mathbf{p}_{j}+{ }^{L} \\mathbf{n}_{j}\\right)-{ }^{G} \\mathbf{q}_{j}\\right) \\] 其中， \\({ }^{G} \\mathbf{u}_{j}\\)是对应关联平面的法向量 \\({ }^{G} \\mathbf{q}_{j}\\)是平面上的点 值得注意的是，\\({ }^{G} \\mathbf{T}_{I_{k}},{ }^{I} \\mathbf{T}_{L}\\)都包含在状态向量\\(\\mathbf{x}_k\\)中 因此，第\\(j\\)个点的测量\\({ }^{L} \\mathbf{p}_{j}\\)，可以写成统一紧凑形式如下： \\[ \\mathbf{0}=\\mathbf{h}_{j}\\left(\\mathbf{x}_{k},{ }^{L} \\mathbf{p}_{j}+{ }^{L} \\mathbf{n}_{j}\\right) \\] 这定义了状态矢量\\(\\mathbf{x}_k\\)的隐式测量模型 迭代卡尔曼滤波器 基于上面的状态模型和基于流形\\(\\mathcal{M} \\triangleq S O(3) \\times \\mathbb{R}^{15} \\times S O(3) \\times \\mathbb{R}^{3}\\)的量测模型，我们使用迭代卡尔曼滤波器直接在流形\\(\\mathcal{M}\\)上进行操作，遵循文献[55][22]。 其包含两个关键步骤： 在每个IMU测量上传播 在每一帧激光扫描上进行迭代 这两个步骤都自然地估计流形\\(\\mathcal{M}\\)上的状态，从而避免了renormalization。 1）传播 假设最优状态估计在融合完最后一帧（如\\(k-1\\)帧）激光扫描后的状态为\\(\\overline{\\mathbf{x}}_{k-1}\\)，且协方差矩阵为\\(\\overline{\\mathbf{P}}_{k-1}\\)，前向传播是在IMU测量到达时进行的，更具体地说，通过将过程噪声\\(\\mathbf{w}_i\\)设置为零，状态和协方差将按照状态转移模型进行传播：","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"Camera与单线激光标定","slug":"传感器标定/Camera与单线激光标定","date":"2021-09-04T08:44:05.000Z","updated":"2022-04-11T15:57:06.233Z","comments":true,"path":"2021/09/04/传感器标定/Camera与单线激光标定/","link":"","permalink":"http://yoursite.com/2021/09/04/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/Camera%E4%B8%8E%E5%8D%95%E7%BA%BF%E6%BF%80%E5%85%89%E6%A0%87%E5%AE%9A/","excerpt":"","text":"Camera-单线激光标定 本文来源于 《标定系列三 | 实践之Camera-Lidar标定》 1. 前言 从理论上看，相机和激光之间外参数的标定原理非常简单，但在实际标定过程中，特别是一个初学者采集数据进行标定时，却发现标定结果非常不理想。如何采集有效的标定数据（何种运动轨迹，如何晃动标定板）对于激光相机标定而言非常重要。 读完本文，你会发现原来采集数据时标定板和传感器之间只做纯粹的平移运动是没有意义的。本文也对相机激光标定的一些基础知识和小细节进行讨论，主要贡献点有三： 从理论开始对激光（单线、多线都适用）和相机外参数的标定进行简要推导（公式多但简单），然后给出一些可以提升标定精度的改进建议。 给出一个简单的开源代码对上述标定原理进行实践。 提供一个仿真程序，可以直观感受标定数据对系统可观性的影响。 2.理论 通常，标定激光和相机之间的外参数有两类方法：一类是利用 3D-3D 的约束，即利用激光测量的三维激光点 (3D) 和相机测量的标定板三维坐标 (3D) 两者来构建约束；另一类是利用 3D-2D 的约束，即利用激光测量的三维激光点 (3D) 和图像二维特征（2D、点特征、线段特征）来构建约束。 本文主要讲解利用 3D-3D 约束来进行外参数标定的方法，而 3D-2D 这一方法和 PnP 或 PnL 问题类似，这里不做展开。另外，标定过程的通常做法是先利用少量观测求解外参数的初始值，然后利用多帧数据的约束进行最小二乘优化对初始值进行 refine。接下来，将按照这个逻辑对标定算法进行讲解并推荐一些改进的算法。 2.1 基于平面约束的相机激光标定算法 如下图所示，相机可以通过标定板平面的二维码或棋盘格来计算标定板平面在相机坐标系下的表示。同时，激光发出的光束落在标定板平面上（图中红点），利用激光点在激光坐标系下的坐标和平面方程在相机坐标系下的坐标，构建点在平面上的约束从而求解外参数。 2.1.1 平面约束 假设标定板平面在相机坐标系\\(c\\)中的参数为\\(\\pi^{c}=\\left[\\mathrm{n}^{c}, d\\right] \\in \\mathbb{R}^{4}\\)，其中\\(\\mathrm{n}^{c} \\in \\mathbb{R}^{3}\\)是平面法向量，\\(d\\)是相机坐标系原点到平面的距离。 假设平面上的一个三维空间点在相机坐标系的坐标为\\(\\mathbf{P}^{c} \\in \\mathbb{R}^{3}\\)，那么该点满足如下约束方程： \\[ \\mathbf{n}^{c \\top} \\mathbf{P}^{c}+d=0 \\] 假设从激光雷达坐标系\\(l\\)到相机坐标系\\(c\\)的旋转和平移表示为：\\(\\mathbf{R}_{c l}, \\mathbf{t}_{c l}\\)，一旦知道激光坐标系中的某个激光点\\(\\mathbf{P}^{l}\\)落在标定板上，则通过点在平面上的约束可以构建关于外参的方程（1）： \\[ \\mathbf{n}^{c \\top}\\left(\\mathbf{R}_{c l} \\mathbf{P}^{l}+\\mathbf{t}_{c l}\\right)+d^{c}=0 \\] 上述方程能够提供一个约束，通过多个这样的约束就能求解外参数。求解时，一个直观的想法是利用 g2o 或者 ceres 等优化工具构建非线性最小二乘进行优化求解。但是对于非线性最小二乘问题，需要知道外参数的一个初始值，如果初始值不准确，则有可能会优化到局部最小值。因此，一个合理的求解流程应该是闭式解提供初始值，对该初始值利用多帧数据进行优化，得到更准确的标定结果。 虽然平面约束对于 2D 激光和 3D 激光而言是一样的，但 2D 激光和 3D 激光闭式求解外参数的方式稍有不同。因为 3D 激光的激光点更多，从而可以直接计算激光点云的法向量，利用这个法向量简化外参数计算流程，下文将详述。接下来，介绍 2D 激光和相机外参数的求解。 2.1.2 2D 激光和相机外参数初始值求解 这里主要参考 2004 年 Zhou 等人的论文【1】，该论文是比较早期的工作，求解思路清晰。论文中估计的参数为从相机坐标系到激光坐标系的变换矩阵\\(\\mathbf{R}_{c l},\\mathbf{t}_{c l}\\)，因此，激光点从激光雷达坐标系到相机坐标系的变换如下： \\[ \\mathbf{P}^{c}=\\mathbf{R}_{l c}^{\\top}\\left(\\mathbf{P}^{l}-\\mathbf{t}_{l c}\\right) \\] 考虑到，激光为 2D 激光，激光束形成的平面不妨假设为 xy 平面，即\\(z=0\\)，此时，激光点形如\\(\\mathbf{P}^{l}=[x, y, 0]^{\\top}\\)，因此，上面的坐标变换可以写成更紧凑（矩阵、向量相乘）的形式： \\[ \\mathbf{P}^{c}=\\mathbf{R}_{l c}^{\\top}\\left(\\left[\\begin{array}{l} x \\\\ y \\\\ 0 \\end{array}\\right]-\\mathbf{t}_{l c}\\right)=\\underbrace{\\mathbf{R}_{l c}^{\\top}\\left[\\begin{array}{lll} 1 &amp; 0 &amp; \\\\ 0 &amp; 1 &amp; -\\mathbf{t}_{l c} \\\\ 0 &amp; 0 &amp; \\end{array}\\right]}_{\\mathbf{H} }\\left[\\begin{array}{l} x \\\\ y \\\\ 1 \\end{array}\\right]=\\mathbf{H} \\overline{\\mathbf{P} }^{l} \\] 因此，将紧凑形式的坐标变换代入公式（1），得到： \\[ \\mathbf{n}^{c \\top} \\mathbf{H} \\overline{\\mathbf{P} }^{l}=-d^{c} \\] 如果把 3 乘 3 的\\(\\mathbf{H}\\)矩阵当做新的未知量（ 9 个参数）进行估计，那上述约束就变成了一个线性最小二乘问题。 对于单线激光而言，一帧激光可以提供两个有效约束（直线上两个点在平面上即能确定直线在平面上），因此大于等于 5 帧激光（不同姿态）就能得到 10 个以上的约束，来直接求得 9 参数的\\(\\mathbf{H}\\)矩阵，然后还原出\\(\\mathbf{R}_{c l}, \\mathbf{t}_{c l}\\)： \\[ \\begin{aligned} \\mathbf{R}_{l c} &amp;=\\left[\\begin{array}{lll} \\mathbf{h}_{1} &amp; \\mathbf{h}_{2} &amp; \\mathbf{h}_{1} \\times \\mathbf{h}_{2} \\end{array}\\right]^{\\top} \\\\ \\mathbf{t}_{l c} &amp;=-\\left[\\begin{array}{lll} \\mathbf{h}_{1} &amp; \\mathbf{h}_{2} &amp; \\mathbf{h}_{1} \\times \\mathbf{h}_{2} \\end{array}\\right]^{\\top} \\mathbf{h}_{3} \\end{aligned} \\] 简单推导： 但是，利用上述方式求得的旋转矩阵并不满足旋转矩阵的性质\\(\\mathbf{R}^{\\top} \\mathbf{R}=\\mathbf{I}_{3 \\times 3}\\)，假设期望的旋转矩阵为\\(\\hat{\\mathbf{R} }_{l c}\\)，则可通过计算带约束的最小化F范数问题来估计出期望的旋转矩阵\\(\\hat{\\mathbf{R} }_{l c}\\)： \\[ \\arg \\min \\left\\|\\hat{\\mathbf{R} }_{l c}-\\mathbf{R}_{l c}\\right\\|_{F}, \\quad \\text { subject to } \\hat{\\mathbf{R} }_{l c}^{\\top} \\hat{\\mathbf{R} }_{l c}=\\mathbf{I} \\] 其意义为：找一个最接近\\(\\mathbf{R}_{c l}\\)又满足旋转矩阵质\\(\\mathbf{R}^{\\top} \\mathbf{R}=\\mathbf{I}_{3 \\times 3}\\)的矩阵\\(\\hat{\\mathbf{R} }_{l c}\\)作为要求的旋转矩阵。此外，参考文献【2，3】给出了闭式解。 然而，文献【3】指出，上述方式求解的精度不高，实际应用过程并不推荐，正如多视角几何中估计本征矩阵E矩阵一样，也分为 DLT 算法（直接计算 8 个参数）和其他算法。 因此，在这里，优雅的方式应该是直接闭式求解 6 自由度的外参数，即旋转矩阵只用 3 个参数而不是上述方法中先估计 9 个参数。参考文献【4】给出了一种闭式求解 6 自由度外参数的方法，由于估计的参数为 6 ，因此需要的最少激光观测变成了 3 帧（每帧提供两个有效约束）。 2.1.3 3D 激光和相机外参数初始值求解 跟 2D 激光的单线数据仅仅能提供一条线相比， 3D 激光的多线数据能提供点云面的信息。因此，同样是利用激光点在标定板平面上这个约束，3D 激光的约束可以比 2D 激光更多一个。 3D 的激光的点云平面和标定板平面重合，意味着单帧 3D激光提供的有效约束为 3 个（即点云平面上的3个点落在标定板平面上），从而可以用 3 个激光点来构建公式 (1) 的约束。这样两帧激光（6个约束）就能求解外参数了，求解方式可以利用前面 2D 激光所描述的方法（则同样存在 DLT 方法初始值不准的问题）。 这里给出了 3D 激光求解外参数的另一个思路，该方法中，求解的旋转矩阵能自然地满足旋转矩阵的性质：\\(\\mathbf{R}^{\\top} \\mathbf{R}=\\mathrm{I}, \\operatorname{det}(\\mathrm{R})=1\\)。 将单帧激光的点云平面和标定板平面重合的约束进行简单置换，如下公式（2）： \\[ \\begin{aligned} \\mathbf{R}_{c l} \\mathbf{n}^{l} &amp;=\\mathbf{n}^{c} \\\\ \\mathbf{n}^{c \\top}\\left(\\mathbf{R}_{c l} \\mathbf{P}^{l}+\\mathbf{t}_{c l}\\right)+d^{c} &amp;=0 \\end{aligned} \\] 公式 (2) 中的两个方程中，第一个方程能提供 2 个有效约束，第二个方程提供 1 个有效约束。虽然公式 (2) 和三个点落在平面上的物理意义一样，但是，公式 (2) 中第一个方程只和旋转矩阵有关，和平移无关。意味着可以先求解旋转矩阵，再线性求解平移向量，从而简化参数估计。 当激光帧数 N 大于等于 2 时，可以求解如下非线性最小二乘问题来计算旋转矩阵，如下公式（3）： \\[ C=\\sum_{i=1}^{N}\\left\\|\\mathbf{n}_{i}^{c}-\\mathbf{R}_{c l} \\mathbf{n}_{i}^{l}\\right\\|^{2} \\] 这里基于参考文献【5】介绍上述问题的通用解法。将公式 (3) 进行展开有： \\[ \\begin{aligned} C &amp;=\\sum_{i=1}^{N}\\left(\\mathbf{n}_{i}^{c}-\\mathbf{R}_{c l} \\mathbf{n}_{i}^{l}\\right)^{\\top}\\left(\\mathbf{n}_{i}^{c}-\\mathbf{R}_{c l} \\mathbf{n}_{i}^{l}\\right) \\\\ &amp;=\\sum_{i=1}^{N}\\left(\\mathbf{n}_{i}^{c \\top} \\mathbf{n}_{i}^{c}+\\mathbf{n}_{i}^{l \\top} \\mathbf{n}_{i}^{l}-2 \\mathbf{n}_{i}^{c \\top} \\mathbf{R}_{c l} \\mathbf{n}_{i}^{l}\\right) \\end{aligned} \\] 由于两个坐标系下的平面法向量\\(n\\)已知，因此，最小化损失函数 C 转化成最大化如下目标： \\[ \\begin{aligned} F &amp;=\\sum_{i=1}^{N} \\mathbf{n}_{i}^{c \\top} \\mathbf{R}_{c l} \\mathbf{n}_{i}^{l} \\\\ &amp;=\\operatorname{Trace}\\left(\\sum_{i=1}^{N} \\mathbf{R}_{c l} \\mathbf{n}_{i}^{l} \\mathbf{n}_{i}^{c \\top}\\right)=\\operatorname{Trace}(\\mathbf{R} \\mathbf{H}) \\end{aligned} \\] 此处应用了迹的性质 （跟ICP的推导一样） - 常数等于常数的迹 - 迹内的元素顺序可交换 其中，这里引入了一个中间矩阵\\(\\mathbf{H}\\) \\[ \\mathbf{H}=\\sum_{i=1}^{N} \\mathbf{n}_{i}^{l} \\mathbf{n}_{i}^{c \\top} \\] 下面还要用到一个引理： 对于任意的正定矩阵\\(\\mathrm{AA}^{\\top}\\)以及任意正交矩阵B，有下面的不等式成立： \\[ \\operatorname{Trace}\\left(\\mathbf{A} \\mathbf{A}^{\\top}\\right) \\geq \\operatorname{Trace}\\left(\\mathbf{B A A}^{\\top}\\right) \\] 接下来，回到之前的推导，我们对中间矩阵\\(\\mathbf{H}\\)进行SVD分解，有： \\[ \\mathbf{H}=\\mathbf{U} \\mathbf{\\Lambda} \\mathbf{V}^{\\top} \\] 其中，\\(\\mathbf{U}, \\mathbf{V}\\)是3x3矩阵，\\(\\mathbf{\\Lambda}\\) 是3x3的对角阵，其元素非负。 下面做一个假设，令\\(\\mathbf{R}_{c l}=\\mathbf{V} \\mathbf{U}^{\\top}\\)，那么上面的\\(\\operatorname{Trace}(\\mathbf{R} \\mathbf{H})\\)可以重写为： \\[ \\begin{aligned} \\mathbf{R}_{c l} \\mathbf{H} &amp;=\\mathbf{V} \\mathbf{U}^{\\top} \\mathbf{U} \\mathbf{\\Lambda} \\mathbf{V}^{\\top} \\\\ &amp;=\\mathbf{V} \\mathbf{\\Lambda} \\mathbf{V}^{\\top} \\end{aligned} \\] 此时，\\(\\mathbf{R}_{c l} \\mathbf{H}\\)是对称的正定矩阵，这时候就要使用前面埋下的引理，来证明\\(\\mathbf{R}_{c l}=\\mathbf{V} \\mathbf{U}^{\\top}\\)即为解。 反证：如果\\(\\mathbf{R}_{c l}=\\mathbf{V} \\mathbf{U}^{\\top}\\)不是解，那么它和正确解之前存在一个增量旋转矩阵\\(\\mathbf{R}_{\\Delta}\\)，即\\(\\mathbf{R}_{c l}=\\mathbf{R}_{\\Delta}\\mathbf{V} \\mathbf{U}^{\\top}\\) ，此时根据上面的引理，可得，这个解不会使得损失函数F的值取最大，因为： \\[ \\operatorname{Trace}\\left(\\mathbf{R}_{c l} \\mathbf{H}\\right) \\geq \\operatorname{Trace}\\left(\\mathbf{R}_{\\Delta} \\mathbf{R}_{c l} \\mathbf{H}\\right) \\] 最后，还需要做旋转矩阵性质的判断，如果\\(\\operatorname{det}\\left(\\mathbf{V} \\mathbf{U}^{\\top}\\right)=1\\)，则说明所求得的正交矩阵\\(\\mathbf{R}_{c l}=\\mathbf{V} \\mathbf{U}^{\\top}\\)是旋转矩阵。如果\\(\\operatorname{det}\\left(\\mathbf{V} \\mathbf{U}^{\\top}\\right)=-1\\)，则说明这个正交矩阵是镜面反射矩阵，不是旋转矩阵。幸运的是，在实际应用中，采集的多帧不同姿态下的激光数据并不会出现镜面反射矩阵的情况。 在旋转矩阵已知的情况下，利用公式 (1) 就可以求解平移向量\\(\\mathbf{t}_{c l}\\)，这时候求解只涉及到平移，是个线性最小二乘问题\\(\\mathbf{A} \\mathbf{t}_{c l}=\\mathbf{b}\\)，可以使用闭式解求解。 最后，关于上面使用的引理\\(\\operatorname{Trace}\\left(\\mathbf{A} \\mathbf{A}^{\\top}\\right) \\geq \\operatorname{Trace}\\left(\\mathbf{B A A}^{\\top}\\right)\\)，证明如下： 假设\\(a_{i}\\)是矩阵\\(\\mathbf{A}\\)的第i列，则有： \\[ \\begin{aligned} \\operatorname{Trace}\\left(\\mathbf{B A} \\mathbf{A}^{\\top}\\right) &amp;=\\operatorname{Trace}\\left(\\mathbf{A}^{\\top} \\mathbf{B} \\mathbf{A}\\right) \\\\ &amp;=\\sum_{i} \\mathbf{a}_{i}^{\\top}\\left(\\mathbf{B} \\mathbf{a}_{i}\\right) \\end{aligned} \\] 根据Cauchy-Schwarz不等式\\(x y \\leq \\sqrt{x^{2} y^{2} }\\)，且矩阵B为正交矩阵，有： \\[ \\mathbf{a}_{i}^{\\top}\\left(\\mathbf{B} \\mathbf{a}_{i}\\right) \\leq \\sqrt{\\left(\\mathbf{a}_{i}^{\\top} \\mathbf{a}_{i}\\right)\\left(\\mathbf{a}_{i}^{\\top} \\mathbf{B}^{\\top} \\mathbf{B a}_{i}\\right)}=\\mathbf{a}_{i}^{\\top} \\mathbf{a}_{i} \\] 因此，可证得： \\[ \\operatorname{Trace}\\left(\\mathbf{A} \\mathbf{A}^{\\top}\\right)=\\sum_{i} a_{i}^{\\top} a_{i} \\geq \\operatorname{Trace}\\left(\\mathbf{B A} \\mathbf{A}^{\\top}\\right) \\] 2.1.4 联合优化进行调优 通过上述方式计算出外参数的初始值之后，再对采集的N组数据进行联合优化得到最优估计，假设第i帧激光有\\(N_{i}\\)个激光点落在标定板上，同时第i帧激光时刻下对应的标定板平面方程在相机坐标系的表示为\\(\\left[\\mathbf{n}_{i}^{c}, d_{i}^{c}\\right]^{\\top}\\)，则问题可以描述为： \\[ \\hat{\\mathbf{R} }_{c l}, \\hat{\\mathbf{t} }_{c l}=\\arg \\min _{\\mathbf{R}_{cl}, t_{cl} } \\sum_{i=1}^{N} \\frac{1}{N_{i} } \\sum_{m=1}^{N_{i} }\\left\\|\\mathbf{n}_{i}^{c \\top}\\left(\\mathbf{R}_{c l} \\mathbf{P}_{i m}^{l}+\\mathbf{t}_{c l}\\right)+d_{i}^{c}\\right\\|^{2} \\] 优化过程中，对于旋转矩阵\\(\\mathbf{R}_{c l}\\)，可以使用 SO3 的参数化方式，也可以采用四元数的参数化方式。优化方法 (LM算法），雅克比的推导等知识点这里不再赘述，大家可以对照开源的代码自行推导验证雅克比。 2.2 推论：所有平行的平面提供的约束等价 前面求解过程中，是假设采集的数据足够有效，即采集了不同姿态下标定板和激光数据的数据。那么，如何摆放标定板来采集数据是有效的呢？这里将证明只平移标定板对标定没有意义，标定过程中只需要旋转标定板。推荐阅读参考文献【6】 平移标定板意味着不同时刻之间的标定板平面是平行的。假设有两个平行平面\\(\\pi_{1}, \\pi_{2}\\)，它们在相机坐标系中的参数分别为\\(\\left[\\mathbf{n}^{c}, d_{1}^{c}\\right]^{\\top}\\)和\\(\\left[\\mathbf{n}^{c}, d_{2}^{c}\\right]^{\\top}\\)。另外，假设在激光坐标系下，激光测量了两个平面上任意的一个点\\(\\mathbf{P}_{1}^{l}, \\mathbf{P}_{2}^{l}\\)，考虑点在平面上的约束有： \\[ \\begin{array}{l} \\mathbf{n}^{c \\top}\\left(\\mathbf{R}_{c l} \\mathbf{P}_{1}^{l}+\\mathbf{t}_{c l}\\right)+d_{1}^{c}=0 \\\\ \\mathbf{n}^{c \\top}\\left(\\mathbf{R}_{c l} \\mathbf{P}_{2}^{l}+\\mathbf{t}_{c l}\\right)+d_{2}^{c}=0 \\end{array} \\] 通过简单的变换，可以发现上面两个等式能够相互转换，即表示平行的平面只能提供相同的约束信息。 变换如下：首先将\\(\\mathbf{n}^{c \\top} \\mathbf{t}_{c l}\\)这部分从两个等式中移除，然后有： \\[ \\begin{aligned} &amp; \\mathbf{n}^{c \\top} \\mathbf{R}_{c l} \\mathbf{P}_{1}^{l}+d_{1}^{c} \\\\ =&amp; \\mathbf{n}^{c \\top} \\mathbf{R}_{c l}\\left(\\mathbf{P}_{2}^{l}+\\mathbf{P}_{1}^{l}-\\mathbf{P}_{2}^{l}\\right)+d_{2}^{c}+d_{1}^{c}-d_{2}^{c} \\\\ =&amp; \\mathbf{n}^{c \\top} \\mathbf{R}_{c l} \\mathbf{P}_{2}^{l}+d_{2}^{c}+\\left(\\mathbf{n}^{c \\top} \\mathbf{R}_{c l}\\left(\\mathbf{P}_{1}^{l}-\\mathbf{P}_{2}^{l}\\right)+d_{1}^{c}-d_{2}^{c}\\right) \\\\ =&amp; \\mathbf{n}^{c \\top} \\mathbf{R}_{c l} \\mathbf{P}_{2}^{l}+d_{2}^{c} \\end{aligned} \\] 其中，\\(\\mathbf{n}^{c \\top} \\mathbf{R}_{c l}\\left(\\mathbf{P}_{1}^{l}-\\mathbf{P}_{2}^{l}\\right)\\)和\\(d_{1}^{c}-d_{2}^{c}\\)表示两个平面之间的距离，式中，它们两个方向符号相反可以抵消。 由此证明：所有平行的平面物体提供的约束是等价的。这意味着：采集数据用于标定时，如果只平移标定板来采集数据，那就做了很多无用功。比如不断平移标定板采集了 100 个时刻的数据，那这 100 次的数据仅相当于 1 次有效数据。所以，采集标定数据时，只要不断旋转标定板采集数据就足够了，而不是不断平移。 2.3 拓展：标定板的边界约束 上述标定过程只利用了平面标定板的平面约束来进行标定，也清楚了这个约束对于单次测量而言，其提供的有效约束 (2个或者3个) 不足以完成单帧标定，而采集多帧数据又容易由于采集轨迹不充分，导致外参在某些维度标定不好。 因此，如果标定板一次就能够提供 6 个以上的约束，那意味着单帧数据就能完成标定，并且多约束的加入能够提升标定精度。这方面的工作有两类方式，一种是改变标定板的形状，比如两个垂直的标定板，或者三个垂直的标定板，V 形标定板等。 另一种是充分利用其他约束，比如激光点落在标定板边缘直线上（标定板边缘的直线方程以及哪个激光点落在上面是可以计算出来的）。这里不作详细的推导和解释，仅推荐两篇2018年的经典论文，见参考文献【6】和参考文献【7】。论文【6】是利用标定板的边缘直线约束来标定3D激光，论文【7】对2D激光的多种标定板的有效约束进行了充分讨论。 3. 实践 根据上述的理论推导，本文完成了一个简单的 2D 激光和相机之间外参数的标定代码： https://github.com/MegviiRobot/CamLaserCalibraTool 3.1 代码梳理和上手操作 关于数据的采集，标定板的制作，标定的流程以及标定结果等上手操作细节在项目的 README.md 里已经进行了详细说明，这里对系统中的几个主要文件进行简单梳理，帮助大家更快熟悉代码。 大家关注的外参数的代码大多都在 src 文件夹里的 LaserCamCalCeres.cpp，其中： CamLaserCalClosedSolution() ：闭式求解外参数初始值。 CamLaserCalibration() ：采用非线性最小二乘对初始值进行优化。 另外，比较重要的为 main 文件夹中的三个主程序： kalibratag_detector_node.cpp : 相机利用二维码或者棋盘格估计标定板平面和相机之间的姿态。 calibr_offline.cpp : 处理激光数据（获取在标定板上的激光点云），读取事先处理好的相机姿态，利用这些数据构建平面约束进行外参数求解。 calibr_simulation.cpp : 生成仿真数据，验证系统参数是否可观。后面小结讲着重说明。 3.2 仿真代码的特别说明 仿真代码可以帮助大家理解采集数据的有效性对标定结果的影响，对理解系统辨识（系统参数是否可观）非常有意义，因此在这里进行特别说明。 代码中的 GenerateSimData() 函数主要用来生成仿真数据，原理为利用激光射线和标定板平面相交，从而得到激光点在标定板上的三维坐标，通过不断变换标定板的姿态，得到多组有效数据（激光点云+标定板在相机中的姿态）用来完成标定。 其中标定板和相机之间的姿态保存在变量\\(\\mathbf{R}_{c a}, \\mathbf{t}_{c a}\\)，代码中采用利用随机数的方式来生成标定板姿态，并可以通过对标定板参数进行不同的设置来对系统的可观性进行验证。 3.2.1 系统可观性的判断 熟悉 VIO(visual inertial odometry) 系统也会熟知可观性问题。实际上，系统的可观性在线代控制理论中有专门论述，涉及到可观性矩阵等知识点，但是那套从线性系统出发的理论可能容易让大家迷惑。这里会从大家熟知的非线性优化求解的角度来简单描述可观性问题。 关于状态量参数是否可观的一个简单解释是：如果改变状态向量\\(\\mathbf{X}\\)的值，系统对应的观测函数\\(\\mathrm{f}(\\mathrm{x})\\)不发生变化，即\\(\\mathbf{f}(\\mathbf{x})=\\mathbf{f}\\left(\\mathbf{x}^{\\prime}\\right)\\)，则说明系统在某些维度上不可观。直观的理解就是，系统有无数个解从而使得状态量无法辨识。在非线性最小二乘问题中，通过构建误差函数利用高斯牛顿算法进行优化求解时，通常需要求解如下 normal equation： \\[ \\mathbf{J}^{\\top} \\mathbf{J} \\delta \\mathbf{x}=-\\mathbf{J}^{\\top} \\mathbf{r} \\Rightarrow \\mathbf{H} \\delta \\mathbf{x}=\\mathbf{b} \\] 其中， \\(\\mathbf{J}\\)是残差对状态量求导的雅克比矩阵 \\(\\mathbf{r}\\)是利用约束构建的残差 如果系统求解过程中\\(\\mathbf{H}\\)矩阵不满秩，假设其零空间为\\(\\mathbf{N}\\)，有\\(\\mathbf{H} \\mathbf{N}=0\\)，意味着求解存在多个解： \\[ \\begin{array}{r} \\mathbf{H} \\delta \\mathbf{x}=\\mathbf{b} \\\\ \\mathbf{H} \\delta \\mathbf{x}+\\mathbf{H N}=\\mathbf{b} \\end{array} \\] 即系统有无穷多个解\\(\\delta \\mathbf{x}+\\lambda \\mathbf{N}\\)使得残差最小，零空间\\(\\mathbf{N}\\)的基底对应不可观的方向。所以可以通过判断\\(\\mathbf{H}\\)矩阵的秩来判断系统的可观性，比如\\(\\mathbf{H}\\)矩阵为 6 维的方阵，而秩等于 4，则意味着零空间维度为 2 ，有两个不可观的方向，这个结论在后面将用来指导采集数据。 那么，如果你熟悉 VIO，自然要问既然线性系统中的可观性矩阵和优化方法中的 H 矩阵都能够判断系统可观性？这两者之间存在什么样的联系呢？这里不再展开推导，推荐阅读参考文献【8】，读完第二章你将豁然开朗。 3.2.2 利用仿真代码验证平行平面提供的约束等价 为了生成平行的标定板平面，只需要把代码中的\\(\\mathbf{R}_{c a}\\)设置成常数，如单位矩阵。这时，标定板只有平移，意味着生成的所有数据里标定板平行。编译并运行仿真程序后会有如下信息： 由于估计的外参数为 6 维，其中 H 矩阵的奇异值有 4 个接近 0，意味着只产生了两个维度的有效信息。这和之前的推论结论一致，即多帧数据中平行的标定板产生的约束等效于一帧，而单线激光落在平面上的有效约束为 2。 另外利用数值的方法计算了 H 矩阵的零空间基底，从图中可以看到最右边两列的两个基底，它们是对应平移 x,y 不可观，而左边两列对应的的两个基底为旋转矩阵角度的两个维度不可观。不可观基底对应的方向表示外参数对应的维度无法求出正确解。 3.2.2 利用仿真代码指导采集数据：如何充分旋转标定板 既然采集数据时只平移标定板不行，那是否意味着简单旋转一下标定板就可以了呢？比如标定板只绕着 y 轴旋转。这里可通过设置不同的旋转矩阵去验证 H 矩阵是否有零空间。通过简单修改代码（注释或反注释设置旋转矩阵的那几行代码），运行后会发现：标定时需要充分旋转 x 和 y 两个轴，标定过程中标定板只旋转一个轴一样会存在零空间基底。 这意味着拿着标定板旋转时，需要充分旋转 roll 和 pitch。更直白一点，假设在长方形的标定板中心画了个十字线，那请绕着十字线的两个轴充分旋转，比如绕着竖轴旋转，然后还要绕着横轴旋转。 4. 结语 至此，相机和激光标定从理论到实践就基本完成了。本文抛砖引玉，介绍了比较基础的标定原理，开源了相应的代码（包括求解代码、仿真代码、debug 验证代码），大家可以进一步改进和拓展（支持边界约束、V 形标定板等）。 最后，这种标定相机和激光外参数的方法估计可以有效避开两个传感器之间的时间延时问题，因为两个传感器都是静止的，晃动标定板时每摆好一个 pose 稍微静止几十毫秒就能避免传感器延时的问题。 5. 参考文献 Qilong Zhang, Extrinsic Calibration of a Camera and Laser Range Finder (improves camera calibration) On Closed-Form Formulas for the 3D Nearest Rotation Matrix Problem, Finding the Nearest Orthonormal Matrix, A Minimal Solution for the Extrinsic Calibration of a Camera and a Laser-Rangefinder K.S. Arun, Least Squares Fitting of Two 3-d Point Set, Automatic Extrinsic Calibration of a Camera and a 3D LiDAR using Line and Plane Correspondences Wenbo Dong, A Novel Method for the Extrinsic Calibration of a 2D Laser Rangefinder and a Camera B.T. Hinson,Observability-based guidance and sensor placement, 作者简介 贺一家，中科院自动化所博士毕业，目前为旷视研究院 SLAM 组研究员，研究方向为基于多传感器融合的 SLAM，结构化特征 SLAM 等。乐于分享和开源，对机器人、AR 等领域有浓厚兴趣。","categories":[{"name":"传感器标定","slug":"传感器标定","permalink":"http://yoursite.com/categories/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"外参未知的立体相机|对极几何","slug":"First_Principles_of_CV/外参未知的立体相机_对极几何.md","date":"2021-08-08T14:42:16.000Z","updated":"2022-04-11T15:57:06.238Z","comments":true,"path":"2021/08/08/First_Principles_of_CV/外参未知的立体相机_对极几何.md/","link":"","permalink":"http://yoursite.com/2021/08/08/First_Principles_of_CV/%E5%A4%96%E5%8F%82%E6%9C%AA%E7%9F%A5%E7%9A%84%E7%AB%8B%E4%BD%93%E7%9B%B8%E6%9C%BA_%E5%AF%B9%E6%9E%81%E5%87%A0%E4%BD%95.md/","excerpt":"","text":"回顾 问题描述 所谓的未标定立体相机问题，就是不知道相机外参而进行3D空间点恢复，其中包含以下几个议题： 总结步骤如下：","categories":[{"name":"First_Principles_of_CV","slug":"First-Principles-of-CV","permalink":"http://yoursite.com/categories/First-Principles-of-CV/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"外参未知的立体相机|概述","slug":"First_Principles_of_CV/外参未知的立体相机_概述.md","date":"2021-08-08T14:42:16.000Z","updated":"2022-04-11T15:57:06.238Z","comments":true,"path":"2021/08/08/First_Principles_of_CV/外参未知的立体相机_概述.md/","link":"","permalink":"http://yoursite.com/2021/08/08/First_Principles_of_CV/%E5%A4%96%E5%8F%82%E6%9C%AA%E7%9F%A5%E7%9A%84%E7%AB%8B%E4%BD%93%E7%9B%B8%E6%9C%BA_%E6%A6%82%E8%BF%B0.md/","excerpt":"","text":"回顾 问题描述 所谓的未标定立体相机问题，就是不知道相机外参而进行3D空间点恢复，其中包含以下几个议题： 总结步骤如下：","categories":[{"name":"First_Principles_of_CV","slug":"First-Principles-of-CV","permalink":"http://yoursite.com/categories/First-Principles-of-CV/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"相机标定|内参和外参矩阵提取","slug":"First_Principles_of_CV/相机标定_提取内外参矩阵.md","date":"2021-08-08T07:52:26.000Z","updated":"2022-04-11T15:57:06.238Z","comments":true,"path":"2021/08/08/First_Principles_of_CV/相机标定_提取内外参矩阵.md/","link":"","permalink":"http://yoursite.com/2021/08/08/First_Principles_of_CV/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A_%E6%8F%90%E5%8F%96%E5%86%85%E5%A4%96%E5%8F%82%E7%9F%A9%E9%98%B5.md/","excerpt":"","text":"从投影矩阵提取内/外参矩阵 首先忽略齐次形式，重写成内参矩阵*旋转矩阵， 又因为： 内参矩阵是上三角矩阵 旋转矩阵是正交矩阵 qr分解可以将矩阵分解为 [上三角矩阵]和[正交矩阵] 所以，对投影矩阵的前3x3个元素构成的子矩阵进行qr分解，就可以得到内参矩阵 畸变的讨论（比较简略）","categories":[{"name":"First_Principles_of_CV","slug":"First-Principles-of-CV","permalink":"http://yoursite.com/categories/First-Principles-of-CV/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"相机标定|相机标定过程","slug":"First_Principles_of_CV/相机标定_相机标定过程.md","date":"2021-08-08T07:52:26.000Z","updated":"2022-04-11T15:57:06.239Z","comments":true,"path":"2021/08/08/First_Principles_of_CV/相机标定_相机标定过程.md/","link":"","permalink":"http://yoursite.com/2021/08/08/First_Principles_of_CV/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A_%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E8%BF%87%E7%A8%8B.md/","excerpt":"","text":"相机标定过程 以立方体的一个角作为世界坐标系原点，相机拍摄图片，就可以得到一系列3D-2D关联。 对投影模型展开，得到线性等式如下： 将矩阵中的12个参数作为向量，可以重写方程如下： 由于尺度不确定，所以通常有如下解决方法： 对上面的Loss func求导，可以得到一个关于特征值的问题，所以问题转化为求解矩阵\\(A^TA\\)最小特征值对应的特征向量，即","categories":[{"name":"First_Principles_of_CV","slug":"First-Principles-of-CV","permalink":"http://yoursite.com/categories/First-Principles-of-CV/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"相机标定|简单立体相机","slug":"First_Principles_of_CV/相机标定_简单立体相机.md","date":"2021-08-08T07:52:26.000Z","updated":"2022-04-11T15:57:06.238Z","comments":true,"path":"2021/08/08/First_Principles_of_CV/相机标定_简单立体相机.md/","link":"","permalink":"http://yoursite.com/2021/08/08/First_Principles_of_CV/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A_%E7%AE%80%E5%8D%95%E7%AB%8B%E4%BD%93%E7%9B%B8%E6%9C%BA.md/","excerpt":"","text":"Backward Projection: 2D to 3D 假设给定一个标定好的相机，如何从2D图像恢复3D点？ 双目 深度与视差成反比 深度与基线成正比 基线越大，精度越高 立体匹配（寻找视差）","categories":[{"name":"First_Principles_of_CV","slug":"First-Principles-of-CV","permalink":"http://yoursite.com/categories/First-Principles-of-CV/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"相机标定|线性相机模型","slug":"First_Principles_of_CV/相机标定_线性相机模型.md","date":"2021-08-08T07:52:26.000Z","updated":"2022-04-11T15:57:06.316Z","comments":true,"path":"2021/08/08/First_Principles_of_CV/相机标定_线性相机模型.md/","link":"","permalink":"http://yoursite.com/2021/08/08/First_Principles_of_CV/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A_%E7%BA%BF%E6%80%A7%E7%9B%B8%E6%9C%BA%E6%A8%A1%E5%9E%8B.md/","excerpt":"","text":"Forward Imaging Model： 3D to 2D Perspective Projection 相机成像平面与图像的映射 点的齐次坐标表示 矩阵表示透视投影模型 坐标变换（外参） 从世界坐标系到相机坐标系的旋转矩阵\\(R\\)的特性： 第一行： \\(\\hat{x}_c\\)在世界坐标系的方向 第二行： \\(\\hat{y}_c\\)的方向 第三行： \\(\\hat{z}_c\\)的方向 旋转矩阵是正交的，也就是说： 因此，当已知： 从世界坐标系到相机坐标系的旋转矩阵\\(R\\) 相机坐标系在世界坐标系的位移\\(c_w\\) 就可以将一个点从世界坐标系变换到相机坐标系如下： 使用齐次表达如下： 两个过程合起来的表示 标定相机，就是求解矩阵的12个元素","categories":[{"name":"First_Principles_of_CV","slug":"First-Principles-of-CV","permalink":"http://yoursite.com/categories/First-Principles-of-CV/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"Localization_for_Ground_Robots论文阅读","slug":"Localization_for_Ground_Robots论文阅读","date":"2021-07-25T11:03:53.000Z","updated":"2022-04-11T15:57:06.233Z","comments":true,"path":"2021/07/25/Localization_for_Ground_Robots论文阅读/","link":"","permalink":"http://yoursite.com/2021/07/25/Localization_for_Ground_Robots%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Localization for Ground Robots: On Manifold Representation, Integration, Re-Parameterization, and Optimization 摘要 本文专注于通过概率融合里程计和单目相机进行地面机器人定位的任务。具体而言，(1) 提出了一种新的方法，通过参数重表示的方法形成motion manifold (2) 使用轮式里程计进行6D的整合 (3) 重新参数化流形等式，减少误差。最后，提出一种基于流形辅助的滑动窗口估计器的完整定位算法，其中使用轮式里程计、单目相机以及可选的IMU。 符号标记和传感器模型 符号 在这项工作中，我们假设关于全局参考框架{G}的地面机器人，其车轮始终与路面接触。我们使用{C}和{O}来表示相机和里程计的坐标系。 里程计坐标系{O}的中心位于机器人的轮子中间，其中x轴向前，z轴向上，如图2所示。 另外，我们使用\\({ }^{\\mathbf{A}} \\mathbf{p _ { B }}\\)和\\({ }^{\\mathbf{A}}_{\\mathbf{B}}\\bar {\\mathbf{q}}\\)来表示B系相对于A系的位置和旋转。\\({ }^{A}_{B} \\mathbf{R}\\)表示与\\({ }^{\\mathbf{A}}_{\\mathbf{B}}\\bar {\\mathbf{q}}\\)对应的旋转矩阵。 另外， \\(\\hat{a}\\)表示估计值 \\(\\tilde{a}\\)表示误差 \\(a^{T}\\)表示转置 \\(\\dot{a}\\)表示微分 \\(\\|a\\|\\)表示二范数 \\(e_i\\)是 3x1的向量，其中第i个元素为1，其他为0 \\(e_{ij}=[e_i,e_j]\\) 轮式里程计观测模型 与[1,6,21]相似，在时间t，经过标定后的轮式里程计测量值如下： 其中， \\({}^{\\mathbf{O}(t)} {\\mathbf{v}}\\)表示车轮坐标系{0}的线速度在车轮坐标系{0}的表示 \\({}^{\\mathbf{O}(t)} {\\mathbf{\\omega}}\\)表示车轮坐标系{0}的角速度在车轮坐标系{0}的表示 \\(n_{v o}\\) and \\(n_{\\omega o}\\)是测量噪声 \\(\\mathbf{n}_{v}=\\left[\\begin{array}{lll}n_{v o} &amp; 0 &amp; 0\\end{array}\\right]^{\\top}\\) \\(\\mathbf{n}_{\\omega}=\\left[\\begin{array}{lll}0 &amp; 0 &amp; n_{\\omega o}\\end{array}\\right]^{\\top}\\) 等式(1)清晰的展示了轮式里程计测量仅提供2D的运动信息，即向前的线速度和关于yaw角的旋转速度。因此，通过使用等式1提供的测量值，理论上可以进行基于平面表面的位姿整合，而执行6D姿态集成。 基于流形的6D位姿整合 流形表示 为了允许使用车轮测量测量的6D姿态集成，我们首先通过参数方程式进行运动建模。特别的，我们选用了通过二次多项式来对3D位置p的运动流形进行近似： 其中， 流形的参数如下： 我们注意到，传统方法[1,6,21]假设平面环境，等同于流形参数为\\(\\mathbf{m}=[c, 0,0,0,0,0]^{T}\\)。他们的设计选择不能代表室外路面的一般情况，因此不适合高精度估计 现有的工作如[6,21]展示了使用里程计观测对6D定位的困难，这主要是轮速计仅提供2D的测量，仅使用这些测量值，在6D空间进行姿态估计是不可行的。 然而，使用如式(4)的流形参数定义，6D的位姿估计变得可行，为了进一步描述，我们记姿态微分方程： 其中， 为了进行旋转积分，由轮速计提供的角速度\\({}^{\\mathbf{O}(t)} {\\mathbf{\\omega}}\\)需要知道。然而，显然式(1)中的轮速计只能提供向量\\({}^{\\mathbf{O}(t)} {\\mathbf{\\omega}}\\)的第三个元素。 为了获取另外两个元素，需要使用流形的参数表达，首先： 这个式子的物理意义是，机器人的旋转矢量与机器人所处位置的流形的法向量是垂直的。 这个式子表达的是，运动流形\\(\\mathcal{M}\\)已经显式定义了地面机器人的roll和pitch，其应该与\\({}_{\\mathbf{O}(t)}^{G} {\\mathbf{R}}\\)具有一致性。换句话说，流形的梯度向量应该与机器人z轴方向平行。 因此，对式(7)进行微分，得到： 通过使用\\(\\mathcal{M}(t)=\\mathcal{M}\\left({ }^{\\mathrm{G}} \\mathbf{p}_{\\mathbf{O}(t)}\\right)\\)作为缩写，然后将式（5）和（7）代入式（8），得到： 根据上述等式，\\({}^{\\mathbf{O}(t)} {\\mathbf{\\omega}}\\)的前两个元素可以被计算，而第3个元素不能被识别，因为\\({}^{\\mathbf{O}(t)} {\\mathbf{\\omega}}\\)被\\([e_3]_{\\times}\\)左乘，其中： 另一方面，\\({}^{\\mathbf{O}(t)} {\\mathbf{\\omega}}\\)被\\([e_3]_{\\times}\\)的第三个元素起始可以直接从轮速计中读取。这些观测结果验证了我们将轮速计观测和流形表示进行结合的动机，依赖于他们的互补特性，以实现6D的位姿估计。 为了从式（11）寻找\\({}^{\\mathbf{O}(t)} {\\mathbf{\\omega}}\\)的前两个元素，为了实现这个目的，基于式（7）可以写出如下： 这是基于两个向量平行得到的，不信的话等式两边同时叉乘一个\\(({}_{\\mathbf{O}(t)}^{G} {\\mathbf{R}} e_3)\\) 结果，等式（11）变成： 其中，还用到了如下性质： 且有：\\({}^{\\mathbf{O}^{(t)}} \\boldsymbol{\\omega}_{12}=\\mathbf{e}_{12}^{T} {}^{\\mathbf{O}^{(t)}} \\boldsymbol{\\omega}\\) 通过考虑里程计的测量，我们有： 通过整合式（18），就可以计算3D的旋转估计了。一旦旋转被计算，就可以进一步通过积分计算位置： 我们同样注意到我们的流形表示，如式（2），其隐式定义了运动模型的积分位置必须满足\\(\\mathcal{M}\\left({ }^{\\mathbf{G}} \\mathbf{p}_{\\mathbf{O}(t)}\\right)=0\\)。 实际上，等式（19）确实满足这个流形约束，为了展示，我们记： 应用到了链式求导，矩阵求导法则，以及等式（13） 其中，在等式（21）中\\({}_{\\mathbf{G}}^{\\mathbf{O}(t)} \\mathbf{R}^{T} \\mathbf{e}_{3}\\)与\\(\\nabla \\mathcal{M}\\left({ }^{\\mathbf{G}} \\mathbf{p}_{\\mathbf{O}(t)}\\right)\\)成比例，（根据等式13的结果）。 可以发现，等式（19）中\\({ }^{\\mathrm{G}} \\mathbf{v}_{\\mathbf{O}(t)}\\)的表达明确的满足等式（21）中的manifold约束（天向速度为0呗）。 随着等式（18）和（19），我们可以进行在流形上的基于里程计的6D位姿整合。整个过程不需要IMU的使用，为了直观地解释这个过程，我们注意到，执行6D姿态估计需要使用传感器测量值或者运动约束来解析6个自由度。在我们的系统中，两个自由度来自轮式里程计测量，两个自由度来自车辆约束（非完整性约束），最后两个自由度由流形等式决定（如等式（18）），并且直觉的解释与数学推导相符。 非完整性约束：来源于等式（19），这个约束表明局部线速度只有在x轴有非零值。 然而当底盘是麦克纳姆轮时，机器人不受该约束，并且必须重新设计方程。然而，这类型的底盘不常用于商业户外机器人或车辆。 状态和误差状态预测 本节，将描述使用提出的流形表示来进行状态和误差状态的传播。由于积分过程需要姿态(位置和方向向量)和流形方程的显式表示，我们定义状态向量如下 状态向量微分方程如下： 其中， 我们指出，流形参数的运动动力学将在后面的小节中详细描述，在式（25）这里先忽略。 进一步的，有： 其中， 式（27）到（29）可以基于轮式里程计进行数值积分（如龙格库塔）。 为了描述误差状态的传播细节，我们首先对式（18）进行一阶泰勒展开，得到： 其中， 这是角速度对状态和噪声求导 本文定义的误差角\\(\\delta \\theta\\)是local的[48]，因此，有： 这个推导可以参见深蓝多传感器融合ppt 进一步的，参考附录，我们可以写出等式（35），关于误差角的微分方程： 附录A： 因为\\(\\delta \\theta\\)是误差状态\\(\\tilde{x}\\)的一部分，式（35)的前两项可以结合，因此得到： 关于位置项，基于等式（19），可以直接得到如下： 对于流形参数，我们有： 结合等式（35）（38）（39），误差状态的微分方程已经推导完成，我们可以进行6D的误差状态集成，把所有的等式放到向量中，我们可以得到误差状态模型： 其中， 需要注意的是： \\((\\cdot)_{[:, i]}\\)表示矩阵的第i列 我们注意到，\\(\\mathbf{F}_{c}\\)和\\(\\mathbf{G}_{c}\\)是连续时间下的误差状态转移矩阵和噪声雅可比矩阵，为了实现离散时间的概率估计器，则需要离散时间下的误差状态转移矩阵\\(\\boldsymbol{\\Phi}(t, \\tau)\\)，这可以通过积分得到： 数值积分的具体实现和剩下的步骤是离散时间局部化估计的标准步骤，可以参考[12,48] 流形重新参数化 等式（2）定义了全局参考坐标系的运动流形，其数值上是正确的，并且能够很容易地给出一个随机估计量。然而，这种表示方式使得流形参数m的传播过程极具挑战性。具体地说，很难描述流形的运动动力学，它随时间而变化。文献[24]简单使用\\(\\dot{\\mathbf{m}}=\\mathbf{n}_{\\omega m}\\)，其中\\(\\mathbf{n}_{\\omega m}\\)是零均值高斯噪声向量。然而，这个方法受限于大规模应用。为了说明细节，让我们以下面的方程为例： 等式绘制如图3所示。 实际上，等式（44）可以考虑为一个二维的流形，如果一个二次二维流形可以用如下方程表示： 等式（44）实际上是一个分段二次二维流形，其分段形式的参数是： 可以清晰的看见，当\\(x=1000\\)时，会有明显的jump，在所估计的流形参数，由于我们选择了二次表示来模拟一个非二次方程。 如果我们能用无穷多个多项式来近似流形，这个问题就不会产生了，然而，这在计算上是不可行的。因此，流形参数的正常传播过程(见Eq. 25)无法捕捉这种类型的变化。 虽然流形表示在此条件下仍然可行，但通过去除和重新初始化流形参数，这肯定不是高精度姿态估计的首选。为此，我们建议将Eq. 45修改为： 其中，\\(x_{o}\\)是固定的常值参数，可以通过当前\\(x\\)的估计来得到。如果当\\(x=1000\\)，我们得到一个估计的\\(x_{o}=999.9\\)，来代替等式（46）所展示的jump，即我们的流形参数为： 通过使用参数\\(x_{o}\\)，流形参数的jump大幅减小。这使得流形的传播等式（状态、误差状态估计）变得可行。 通过用上面的例子说明我们的动机和高级概念，我们介绍了我们的正式数学-局部流形表示和重新参数化的数学方程。通过假设前一个重新参数化步骤是在时间t k时执行的，下一个步骤是在t k+1时触发的，我们有： 其中，等式（49）： \\(\\mathbf{R}_{o}\\)和\\(\\mathbf{x}_{o}\\)是m(tk)的固定重参数化参数 \\(\\mathbf{R}_{1}\\)和\\(\\mathbf{x}_{1}\\)是m(tk+1)的固定重参数化参数 \\(\\gamma, \\Xi,\\boldsymbol{\\Psi}\\)都是关于\\(\\delta \\mathbf{R}\\)和\\(\\delta \\mathbf{x}\\)的函数 为了选择重新参数化参数，类似于等式（48），我们为\\(\\mathbf{x}_{o}\\)的选择\\({ }^{\\mathbf{G}} \\mathbf{p}_{\\mathbf{O}\\left(t_{k}\\right)}\\)的第一次估计和为\\(\\mathbf{x}_{1}\\)选择\\({ }^{\\mathbf{G}} \\mathbf{p}_{\\mathbf{O}\\left(t_{k+1}\\right)}\\)的第一次估计 等式（49）的详细推导和 \\(\\mathbf{R}_{o}，\\mathbf{R}_{1}\\)的选择参见附录C。 因此，通过式（49），对于状态估计及其相应的不确定性，我们能够在任何时间t周围重新参数化流形表示。我们注意到，这类似于用逆深度参数化重新参数化SLAM特征[15][35]。重要的是要指出，在我们的重新参数化过程中，\\(\\mathbf{R}_{o}，\\mathbf{x}_{o}, \\mathbf{R}_{1} ，\\mathbf{x}_{1}\\)被用作固定的常量向量和矩阵，而不是随机变量。这样就不需要计算它们对应的雅可比矩阵，这也是SLAM特征重参数化中广泛使用的技巧[35]，[15]。 需要指出的是，我们的数值微分和重表示都是基于参数\\(m\\)的，如（Sec. IV-A - IV-B and Appendix B），并且这个参数\\(m\\)还未被任何重新参数化的步骤之前。 一旦引入重参数化，在\\(t_{k+1}\\)时刻存储在状态向量中的流形变为\\(m(t_{k+1})\\)，而在状态积分中使用的相应流形参数仍为\\(m\\)，这是由于全局流形表示保持不变的事实，\\(\\mathbf{m}\\)和\\(\\mathbf{m}(t_{k+1})\\)的关系如下： 因此，在状态预测和雅可比计算过程中，我们可以简单应用\\(\\mathbf{m}=\\left(\\prod_{i=0}^{k} \\mathbf{\\Lambda}\\left(t_{i}\\right)\\right)^{-1} \\mathbf{m}\\left(t_{k}\\right)\\)，这允许明确考虑\\(\\mathbf{m}(t_{k+1})\\)的不确定性，而不产生额外的计算成本和复杂的软件设计 通过定义流形的重新参数化过程，我们重新讨论了运动流形的运动动力学特征问题。由于地面机器人所在的表面上导航的流形实际会随着时间的推移而变化，为了保证准确性，必须明确地建模这一事实，具体地说，我们建议在重新参数化过程中考虑这一点： 其中， \\(\\mathcal{N}\\left(0, \\sigma_{i, w m}^{2}\\right)\\)表示零均值且方差为\\(\\sigma_{i, w m}^{2}\\)的高斯分布。 特别的，标准差\\(\\sigma_{i, w m}\\)可以定义如下： 其中，\\(\\alpha_{i,p},\\alpha_{i,q}\\)是控制参数。需要指出的是，在我们提出的公式中，流形不确定性(如\\(\\sigma_{i, w m}\\))是空间位移的函数(见Eq. 54)。这与VIO文献[12]、[30]中的标准噪声传播方程不同，在这些方程中，噪声的特征是时间函数。因为运动流形是一个空间概念而不是时间概念，所以我们的设计选择更适合我们的定位问题。 定位算法 为了实现地面机器人的高精度定位，在本节中，我们提出了一种详细的定位算法，用于融合来自单目摄像机、车轮里程表和可选IMU的测量数据。具体地说，我们提出了一种基于滑动窗口迭代优化的算法来最小化来自传感器测量和流形约束的代价函数。在接下来的内容中，我们首先描述我们提出的不使用IMU的方法，与IMU相关的额外操作将在第二节中讨论。 数据插值 在本文中，我们假设车轮里程表和摄像机传感器在硬件上完全同步，摄像机与机器人刚性连接。在介绍概率传感器融合的细节之前，我们首先注意到我们的系统中需要数据插值，这是由于提出的系统中的一些操作需要执行基于里程计的位姿积分（两帧图像之间）。然而，由于多传感器系统的特性，我们可能无法在捕获图像的同时精确地获取里程计信息。为此，我们建议通过插值图像时间戳前后的最近测量值来计算额外的虚拟车轮里程表测量值。由于车轮里程表测量的频率相对较高(例如，在我们的例子中是100Hz)，而且在人造环境中的地面机器人通常处于平滑运动状态，因此我们选择应用线性插值。 图像处理 一旦接收到新图像，我们继续执行位姿积分，通过车轮里程表测量和流形表示计算相应的预测位姿，一旦通过姿态预测检测到足够的平移或旋转位移(例如，在我们的测试中，20厘米和3度)，新图像将被处理，否则它将被丢弃。 对于特征处理，提取FAST特征[49]，计算FREAK[50]描述符，这是由于它们在低成本处理器上的效率，然后是特征匹配和RANSAC几何验证步骤 状态向量与迭代优化 为了说明定位算法，首先介绍状态向量，在时间\\(t_k\\)，状态向量为： 为了更简单的表示，我们在本节的介绍中忽略了传感器的外部参数。然而，在我们的一些实际实验中，当离线传感器外部标定精度不高时，这些参数被明确地建模在我们的公式中，并用于优化。 其中，\\(x\\)在等式（22）中定义，\\(\\mathrm{O}_{k}\\)式在k时刻下滑动窗口中的位姿： 当在\\(t_{k+1}\\)记录到新的图像，将会执行pose积分来计算\\(\\mathbf{X} \\mathbf{O}_{k+1}\\)，随后，我们使用如下cost func来调整我们的状态： 其中， \\(\\boldsymbol{\\eta}_{k}\\)和\\(\\boldsymbol{\\Sigma}_{k}\\)分别是在之前的时间步中估计的先验信息向量和矩阵。 \\(\\|\\mathbf{a}\\|_{\\Sigma}\\)由\\(\\mathbf{a}^{T} \\mathbf{\\Sigma} \\mathbf{a}\\)计算得到 \\(\\mathbf{f}_{k+1}\\)是被包含到优化过程中的视觉landmarks的集合 \\(\\mathbf{S}_{i, j}\\)表示关键帧和观测到的特征的匹配对集合 \\(\\gamma_{i, j}\\)是计算的视觉重投影残差向量 \\(\\boldsymbol{\\psi}_{i}\\)是与运动流形相关联的残差 \\(\\boldsymbol{\\beta}_{i}\\)是在\\(t_k\\)和\\(t_{k+1}\\)时间内，基于轮速里程计测量的位姿预测残差（Sec. IV-B） 特别的，视觉重投影残差计算如下： 其中， \\(\\mathbf{Z}_{i j}\\)表示与位姿\\(i\\)和视觉landmark \\(\\mathbf{f}_{j}\\)相关的相机观测 （图像点） \\(\\boldsymbol{\\Sigma}_{C}\\)是观测的信息矩阵 函数\\(h(\\cdot)\\)表示经过校准的相机模型[20]","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"MSCKF论文阅读","slug":"MSCKF论文阅读","date":"2021-07-20T14:03:53.000Z","updated":"2022-04-11T15:57:06.316Z","comments":true,"path":"2021/07/20/MSCKF论文阅读/","link":"","permalink":"http://yoursite.com/2021/07/20/MSCKF%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"A Multi-State Constraint Kalman Filter for Vision-aided Inertial Navigation 摘要 本文介绍了一个基于扩展卡尔曼滤波器的算法，用于实时视觉辅助的惯性导航算法。本项工作的主要贡献是观测模型的导出，其能够表达从多个相机pose观察到静态特征所构成的几何约束。该测量模型不需要在EKF的状态向量中包含3D特征点的位置。 提出的视觉辅助惯性导航算法的计算复杂性只与特征点数量线性相关，并且能够在大型现实环境中进行高精度的姿态估计。 系统描述 目标是估计与IMU固定的坐标系相对于全局参考坐标系的3D位姿。 为了简化地球自转对IMU测量的影响，本文选取全局坐标系为ECEF坐标系，整体算法流程如算法1所示. IMU测量被用于进行实时处理，用于传播EKF状态和协方差（Section III-B）。另一方面，每一帧图像到达时，相机的位姿估计被添加到状态向量中（Section III-C）。状态增广是为了处理特征观测所必须的，因为每个跟踪的特征点的观测用于在所有相机位姿中施加约束，从而用于对观测到该特征点的相机位姿进行约束。 因此，在任何时候，EKF状态向量都包含： IMU状态 过去Nmax帧相机位姿 EKF状态向量的结构 IMU状态： \\[ \\mathbf{X}_{\\mathrm{IMU} }=\\left[\\begin{array}{lllll} { }_{G}^{I} \\bar{q}^{T} &amp; \\mathbf{b}_{g}{ }^{T} &amp; { }^{G} \\mathbf{v}_{I}^{T} &amp; \\mathbf{b}_{a}{ }^{T} &amp; { }^{G} \\mathbf{p}_{I}^{T} \\end{array}\\right]^{T} \\] 其中， 单位四元数[19] \\({ }_{G}^{I} \\bar{q}\\)用于描述从全局坐标系\\(G\\)到IMU坐标系\\(I\\)的旋转 \\({ }^{G} \\mathbf{p}_{I}\\)和\\({ }^{G} \\mathbf{v}_{I}\\)分别描述了IMU位置和速度，相对于全局坐标系\\(G\\) \\(b_g\\)和\\(b_a\\)是 3x1的向量，描述IMU的bias，IMU Biases被建模为受高斯噪声\\(n_{wg},n_{wa}\\)驱动的随机游走过程。 因此，IMU的误差状态模型被定义为如下： \\[ \\widetilde{\\mathbf{X} }_{\\mathrm{IMU} }=\\left[\\begin{array}{lllll} \\boldsymbol{\\delta} \\boldsymbol{\\theta}_{I}^{T} &amp; \\widetilde{\\mathbf{b} }_{g}^{T} &amp; { }^{G} \\widetilde{\\mathbf{v} }_{I}^{T} &amp; \\widetilde{\\mathbf{b} }_{a}^{T} &amp; { }^{G} \\widetilde{\\mathbf{p} }_{I}^{T} \\end{array}\\right]^{T} \\] 对于位置、速度、biases，使用了标准的误差add定义，如位置误差\\(\\widetilde{x}=x-\\hat{x}\\)，然而，对于四元数，则使用另外的准则。 实际上，如果\\(\\hat{\\bar{q} }\\)是四元数\\(\\bar{q}\\)的估计值，那么，旋转误差可以描述为四元数误差\\(\\delta \\bar{q}\\)，其中\\(\\bar{q}=\\delta \\bar{q} \\otimes \\hat{\\bar{q} }\\) (这个要区分误差是定义在哪里，这里跟ESKF一样，定义在局部的，只不过这里的q是从全局坐标系到机体坐标系) 此处，误差四元数如下： \\[ \\delta \\bar{q} \\simeq\\left[\\begin{array}{ll} \\frac{1}{2} \\boldsymbol{\\delta} \\boldsymbol{\\theta}^{T} &amp; 1 \\end{array}\\right]^{T} \\] 直观的，误差四元数\\(\\delta \\bar{q}\\)描述了一个估计姿态和真实姿态之间的小角度旋转。因为姿态包含了3个自由度，使用\\(\\delta \\theta\\)来描述姿态误差才是最小的表示。 假设在时间步骤k的EKF状态向量中包含N个相机姿势，该向量具有以下形式： \\[ \\hat{\\mathbf{X} }_{k}=\\left[\\begin{array}{llllll} \\hat{\\mathbf{X} }_{\\mathrm{IMU}_{k} }^{T} &amp; { }_{G}^{C_{1} } \\hat{\\bar{q} }^{T} &amp; { }^{G} \\hat{\\mathbf{p} }_{C_{1} }^{T} &amp; \\ldots &amp; { }_{G}^{C_{N} } \\hat{q}^{T} &amp; { }^{G} \\hat{\\mathbf{p} }_{C_{N} }^{T} \\end{array}\\right]^{T} \\] 其中，\\({}_G^{G_i} \\hat{\\bar{q} }, {}^G {\\hat{p}_{C_i}, i=1\\dots N}\\)是N个相机的姿态和位置。 因此，EKF的误差状态向量定义如下： \\[ \\widetilde{\\mathbf{X} }_{k}=\\left[\\begin{array}{llllll} \\widetilde{\\mathbf{X} }_{\\mathrm{IMU}_{k} }^{T} &amp; \\boldsymbol{\\delta} \\boldsymbol{\\theta}_{C_{1} }^{T} &amp; { }^{G} \\widetilde{\\mathbf{p} }_{C_{1} }^{T} &amp; \\ldots &amp; \\boldsymbol{\\delta} \\boldsymbol{\\theta}_{C_{N} }^{T} &amp; { }^{T} \\widetilde{\\mathbf{p} }_{C_{N} }^{T} \\end{array}\\right]^{T} \\] 传播 滤波器传播的等式通过连续时间模型的离散化形式导出，定义如下： 连续时间系统模型 IMU状态微分方程描述： \\[ { }_{G}^{I} \\dot{\\bar{q} }(t)=\\frac{1}{2} \\boldsymbol{\\Omega}(\\boldsymbol{\\omega}(t))_{G}^{I} \\bar{q}(t) \\] \\[ \\dot{\\mathbf{b} }_{g}(t)=\\mathbf{n}_{w g}(t) \\] \\[ { }^{G} \\dot{\\mathbf{v} }_{I}(t)={ }^{G} \\mathbf{a}(t) \\] \\[ \\dot{\\mathbf{b} }_{a}(t)=\\mathbf{n}_{w a}(t) \\] \\[ { }^{G} \\mathbf{p}_{I}(t)={ }^{G} \\mathbf{v}_{I}(t) \\] 其中，\\({ }^{G} \\mathbf{a}\\)表示机体加速度在全局坐标系的表示，\\(\\boldsymbol{\\omega}=\\left[\\begin{array}{lll}\\omega_{x} &amp; \\omega_{y} &amp; \\omega_{z}\\end{array}\\right]^{T}\\)表示IMU坐标系的旋转角速度。 另外的计算符号定义如下： \\[ \\boldsymbol{\\Omega}(\\boldsymbol{\\omega})=\\left[\\begin{array}{cc} -\\lfloor\\boldsymbol{\\omega} \\times\\rfloor &amp; \\boldsymbol{\\omega} \\\\ -\\boldsymbol{\\omega}^{T} &amp; 0 \\end{array}\\right], \\quad\\lfloor\\boldsymbol{\\omega} \\times\\rfloor=\\left[\\begin{array}{ccc} 0 &amp; -\\omega_{z} &amp; \\omega_{y} \\\\ \\omega_{z} &amp; 0 &amp; -\\omega_{x} \\\\ -\\omega_{y} &amp; \\omega_{x} &amp; 0 \\end{array}\\right] \\] 陀螺仪和加速度计的测量描述如下 [20 ]： \\[ \\boldsymbol{\\omega}_{m}=\\boldsymbol{\\omega}+\\mathbf{C}\\left({ }_{G}^{I} \\bar{q}\\right) \\boldsymbol{\\omega}_{G}+\\mathbf{b}_{g}+\\mathbf{n}_{g} \\] \\[ \\begin{aligned} \\mathbf{a}_{m}=&amp; \\mathbf{C}\\left({ }_{G}^{I} \\bar{q}\\right)\\left({ }^{G} \\mathbf{a}-{ }^{G} \\mathbf{g}+2\\left\\lfloor\\boldsymbol{\\omega}_{G} \\times\\right\\rfloor^{G} \\mathbf{v}_{I}+\\left\\lfloor\\boldsymbol{\\omega}_{G} \\times\\right\\rfloor^{2}{ }^{G} \\mathbf{p}_{I}\\right) \\\\ &amp;+\\mathbf{b}_{a}+\\mathbf{n}_{a} \\end{aligned} \\] 其中， \\(C(\\cdot)\\)表示旋转矩阵 \\(n_g,n_a\\)为零均值高斯白噪声 值得注意的是，IMU测量结合了星球的旋转，\\(w_{G}\\)的效果 此外，加速度计测量包括引力加速度,\\({ }^{G} \\mathbf{g}\\), (expressed in the local frame) 在上面的连续时间状态方程中，应用这些运算符，就可以得到了IMU的状态估计方程： \\[ {}_{G}^{I} \\dot{\\hat{\\bar{q} } }=\\frac{1}{2} \\boldsymbol{\\Omega}(\\hat{\\boldsymbol{\\omega} })_{G}^{I} \\hat{\\bar{q} } \\] \\[ \\dot{\\hat{\\mathbf{b} } }_{g}=\\mathbf{0}_{3 \\times 1} \\] \\[ { }^{G} \\dot{\\hat{\\mathbf{v} } }_{I}=\\mathbf{C}_{\\hat{q} }^{T} \\hat{\\mathbf{a} }-2\\left\\lfloor\\boldsymbol{\\omega}_{G} \\times\\right\\rfloor^{G} \\hat{\\mathbf{v} }_{I}-\\left\\lfloor\\boldsymbol{\\omega}_{G} \\times\\right\\rfloor^{2}{ }^{G} \\hat{\\mathbf{p} }_{I}+{ }^{G} \\mathbf{g} \\] \\[ \\dot{\\hat{\\mathbf{b} } }_{a}=\\mathbf{0}_{3 \\times 1} \\] \\[ { }^{G} \\dot{\\hat{\\mathbf{p} } }_{I}={ }^{G} \\hat{\\mathbf{v} }_{I} \\] 其中， \\(\\mathbf{C}_{\\hat{q} }=C({}_G^{I}\\hat{\\bar{q} })\\) \\(\\hat{a}=a_m-\\bar{b}_{a}\\) \\(\\hat{\\omega}=\\omega_{m}-\\hat{b}_{g}-C_{\\hat{q} }\\omega_{G}\\) IMU误差状态的线性化连续时间模型如下表示： \\[ \\dot{\\widetilde{\\mathbf{X} } }_{\\mathrm{IMU} }=\\mathbf{F} \\tilde{\\mathbf{X} }_{\\mathrm{IMU} }+\\mathbf{G} \\mathbf{n}_{\\mathrm{IMU} } \\] 其中， \\(\\mathbf{n}_{\\mathrm{IMU} }=\\left[\\begin{array}{llll}\\mathbf{n}_{g}^{T} &amp; \\mathbf{n}_{w g}^{T} &amp; \\mathbf{n}_{a}^{T} &amp; \\mathbf{n}_{w a}^{T}\\end{array}\\right]^{T}\\)是系统噪声 关于\\(\\mathbf{n}_{IMU}\\)的协方差矩阵，\\(\\mathbf{Q}_{\\mathrm{IMU} }\\)，取决于IMU噪声特性，可以再传感器标定期间离线计算。 最后，F矩阵和G矩阵可以整理如下： \\[ \\mathbf{F}=\\left[\\begin{array}{ccccc} -\\lfloor\\hat{\\boldsymbol{\\omega} } \\times\\rfloor &amp; \\mathbf{- I}_{3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} \\\\ \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} \\\\ -\\mathbf{C}_{\\hat{q} }^{T}\\lfloor\\hat{\\mathbf{a} } \\times\\rfloor &amp; \\mathbf{0}_{3 \\times 3} &amp; -2\\left\\lfloor\\boldsymbol{\\omega}_{G} \\times\\right\\rfloor &amp; -\\mathbf{C}_{\\hat{q} }^{T} &amp; -\\left\\lfloor\\boldsymbol{\\omega}_{G} \\times\\right\\rfloor^{2} \\\\ \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} \\\\ \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{I}_{3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} \\end{array}\\right] \\] \\[ \\mathbf{G}=\\left[\\begin{array}{cccc} -\\mathbf{I}_{3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} \\\\ \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{I}_{3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} \\\\ \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; -\\mathbf{C}_{\\hat{q} }^{T} &amp; \\mathbf{0}_{3 \\times 3} \\\\ \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{I}_{3} \\\\ \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 3} \\end{array}\\right] \\] 离散时间模型实现 由于IMU在周期T内进行采样，得到采样信号\\(\\omega_{m},a_{m}\\)，每次接收到新的IMU测量时，IMU状态估计采用5阶龙哥库塔(RK-5)记性积分传播。 此外，EKF的协方差矩阵必须传播，因此，我们介绍对协方差的分区： \\[ \\mathbf{P}_{k \\mid k}=\\left[\\begin{array}{ll} \\mathbf{P}_{I I_{k \\mid k} } &amp; \\mathbf{P}_{I C_{k \\mid k} } \\\\ \\mathbf{P}_{I C_{k \\mid k} }^{T} &amp; \\mathbf{P}_{C C_{k \\mid k} } \\end{array}\\right] \\] 其中， \\(\\mathbf{P}_{I I_{k \\mid k} }\\)是 15x15的协方差矩阵，关于IMU状态 \\(\\mathbf{P}_{C C_{k \\mid k} }\\)是6Nx6N的协方差矩阵，关于相机位姿估计的 \\(\\mathbf{P}_{I C_{k \\mid k} }\\)是IMU状态和相机位姿估计误差的相关性 通过这样的分块，传播状态的协方差矩阵按如下进行： \\[ \\mathbf{P}_{k+1 \\mid k}=\\left[\\begin{array}{cc} \\mathbf{P}_{I I_{k+1 \\mid k} } &amp; \\mathbf{\\Phi}\\left(t_{k}+T, t_{k}\\right) \\mathbf{P}_{I C_{k \\mid k} } \\\\ \\mathbf{P}_{I C_{k \\mid k} }^{T} \\mathbf{\\Phi}\\left(t_{k}+T, t_{k}\\right)^{T} &amp; \\mathbf{P}_{C C_{k \\mid k} } \\end{array}\\right] \\] 其中， \\(\\mathbf{P}_{I I_{k+1 \\mid k} }\\)有李雅普诺夫(Lyapunov)等式进行数值积分得到： \\[ \\dot{\\mathbf{P} }_{I I}=\\mathbf{F} \\mathbf{P}_{I I}+\\mathbf{P}_{I I} \\mathbf{F}^{T}+\\mathbf{G} \\mathbf{Q}_{\\mathrm{IMU} } \\mathbf{G}^{T} \\] 数值积分即以初始值\\(\\mathbf{P}_{I I_{k\\mid k} }\\)对时间间隔\\((t_k,t_{k+T})\\)进行积分。 误差转移矩阵\\(\\mathbf{\\Phi}\\left(t_{k}+T, t_{k}\\right)\\)由微分方程进行数值积分来近似得到： \\[ \\dot{\\boldsymbol{\\Phi} }\\left(t_{k}+\\tau, t_{k}\\right)=\\mathbf{F} \\boldsymbol{\\Phi}\\left(t_{k}+\\tau, t_{k}\\right), \\quad \\tau \\in[0, T] \\] 其中，初始条件为 \\[ \\mathbf{\\Phi}\\left(t_{k}, t_{k}\\right)=\\mathbf{I}_{15\\times 15} \\] 状态增广 当接受到新的图像时，首先聪IMU姿态估计来计算相机的姿态估计初值： \\[ _{G}^{C} \\hat{\\bar{q} }=\\underset{I}{C} \\bar{q} \\otimes_{G}^{I} \\hat{\\bar{q} } \\] \\[ { }^{G} \\hat{\\mathbf{p} }_{C}={ }^{G} \\hat{\\mathbf{p} }_{I}+\\mathbf{C}_{\\hat{q} }^{T}{ }^{I} \\mathbf{p}_{C} \\] 其中， \\({}_I^C \\bar{q}\\)表示从IMU坐标系到相机坐标系的变换 \\({ }^{I} \\mathbf{p}_{C}\\)表示相对于IMU坐标系的原点，相机坐标系的位置。 由于相机位姿估计附加到状态向量中，因此EKF的协方差矩阵也进行增广: \\[ \\mathbf{P}_{k \\mid k} \\leftarrow\\left[\\begin{array}{c} \\mathbf{I}_{6 N+15} \\\\ \\mathbf{J} \\end{array}\\right] \\mathbf{P}_{k \\mid k}\\left[\\begin{array}{c} \\mathbf{I}_{6 N+15} \\\\ \\mathbf{J} \\end{array}\\right]^{T} \\] 其中，雅克比\\(J\\)根据式(14)进行微分推导 （谁对谁求导？） 式(14)截图如下： 最后得到雅克比如下： \\[ \\mathbf{J}=\\left[\\begin{array}{cccc} \\mathbf{C}\\left({ }_{I}^{C} \\bar{q}\\right) &amp; \\mathbf{0}_{3 \\times 9} &amp; \\mathbf{0}_{3 \\times 3} &amp; \\mathbf{0}_{3 \\times 6 N} \\\\ \\left\\lfloor\\mathbf{C}_{\\hat{q} }^{T I} \\mathbf{p}_{C} \\times\\right\\rfloor &amp; \\mathbf{0}_{3 \\times 9} &amp; \\mathbf{I}_{3} &amp; \\mathbf{0}_{3 \\times 6 N} \\end{array}\\right] \\] 测量模型 我们现在介绍用于更新状态估计的测量模型，这是本文的主要贡献。 由于EKF用于状态估计，因此对于构造测量模型，需要定义残差r ， 这取决于误差状态\\(\\widetilde{\\mathbf{X} }\\)，因此，根据通用形式，有： \\[ \\mathbf{r}=\\mathbf{H} \\widetilde{\\mathbf{X} }+ noise \\] 在这个表达式中，H是测量雅比亚矩阵。对于EKF框架，应用的对于误差状态的噪声项必须是零均值、不相关的白噪声。 为了衍生我们的测量模型，我们的动机是通过多个相机的静态特征来实现涉及所有这些姿势的约束。在我们的工作中，相机观测按跟踪的特征进行分组，而不是每个相机姿势记录对应的观测（如[7,13,14]）。 同一个3D点的所有测量值都用于定于约束方程（在后面的等式24），与测量发生的所有相机姿势所相关联。这样的方法实现了在状态向量中可以不包含特征点的位置。 我们通过考虑单个特征 \\(f_j\\) 被多个相机pose\\(\\left({ }_{G}^{C_{i} } \\bar{q},{ }^{G} \\mathbf{p}_{C_{i} }\\right), i \\in \\mathcal{S}_{j}\\)所构成的集合\\(M_{j}\\)所共同观测到的情况来提出测量模型。 \\(M_{j}\\)中的每个观测都可以使用如下模型来描述： \\[ \\mathbf{z}_{i}^{(j)}=\\frac{1}{ { }^{C_{i} } Z_{j} }\\left[\\begin{array}{c} { }^{C_{i} } X_{j} \\\\ { }^{C_{i} } Y_{j} \\end{array}\\right]+\\mathbf{n}_{i}^{(j)}, \\quad i \\in \\mathcal{S}_{j} \\] 其中， \\(\\mathbf{n}_{i}^{(j)}\\)是2x1的图像噪声向量，具有协方差矩阵\\(\\mathbf{R}_{i}^{(j)}=\\sigma_{i m}^{2} \\mathbf{I}_{2}\\) 特征点的位置\\({ }^{C_{i} } \\mathbf{p}_{f_{j} }\\)被表示为在相机坐标系中，如下得到： \\[ { }^{C_{i} } \\mathbf{p}_{f_{j} }=\\left[\\begin{array}{c} { }^{C_{i} } X_{j} \\\\ { }^{C_{i} } Y_{j} \\\\ { }^{C_{i} } Z_{j} \\end{array}\\right]=\\mathbf{C}\\left({ }_{G}^{C_{i} } \\bar{q}\\right)\\left({ }^{G} \\mathbf{p}_{f_{j} }-{ }^{G} \\mathbf{p}_{C_{i} }\\right) \\] 其中， \\({ }^{G} \\mathbf{p}_{f_{j} }\\)表示特征点在全局坐标系的3D位置，由于这是未知的，在我们的算法的第一步中，我们使用最小二乘最小化以获得估计值\\({ }^{G} \\hat{\\mathbf{p} }_{f_{j} }\\)。 这是利用观测值\\(\\mathbf{z}_{i}^{(j)}, i \\in \\mathcal{S}_{j}\\)以及滤波器估计值关于相机姿态来实现的（具体参考附录） 一旦获得了特征位置的估计，我们计算观测的残差： \\[ \\mathbf{r}_{i}^{(j)}=\\mathbf{z}_{i}^{(j)}-\\hat{\\mathbf{z} }_{i}^{(j)} \\] 其中， \\[ \\hat{\\mathbf{z} }_{i}^{(j)}=\\frac{1}{ {}^{C_{i} } \\hat{Z}_{j} }\\left[\\begin{array}{c} { }^{C_{i} } \\hat{X}_{j} \\\\ { }^{C_{i} } \\hat{Y}_{j} \\end{array}\\right] \\] \\[ \\left[\\begin{array}{c} { }^{C_{i} } \\hat{X}_{j} \\\\ { }^{C_{i} } \\hat{Y}_{j} \\\\ { }^{C_{i} } \\hat{Z}_{j} \\end{array}\\right]=\\mathbf{C}\\left({ }_{G}^{C_{i} } \\hat{q}\\right)\\left({ }^{G} \\hat{\\mathbf{p} }_{f_{j} }-{ }^{G} \\hat{\\mathbf{p} }_{C_{i} }\\right) \\] 对上式( 等式20 )中关于相机位姿和特征点位置进行线性化，得到近似如下： \\[ \\mathbf{r}_{i}^{(j)} \\simeq \\mathbf{H}_{\\mathbf{X}_{i} }^{(j)} \\widetilde{\\mathbf{X} }+\\mathbf{H}_{f_{i} }^{(j) G} \\widetilde{\\mathbf{p} }_{f_{j} }+\\mathbf{n}_{i}^{(j)} \\] 其中， \\(\\mathbf{H}_{\\mathbf{X}_{i} }^{(j)}\\)是观测\\(\\mathbf{z}_{i}^{(j)}\\)对状态的雅克比 \\(\\mathbf{H}_{f_{i} }^{(j)}\\)是观测\\(\\mathbf{z}_{i}^{(j)}\\)对特征点位置的雅克比 ( \\(\\mathbf{z}_{i}^{(j)}\\) 难道不是直接从图像获取的特征点吗) \\(\\widetilde{\\mathbf{X} }\\)滤波器的误差状态 \\({ }^{G} \\widetilde{\\mathbf{p} }_{f_{j} }\\) 关于特征点\\(f_j\\)的误差 上面H矩阵的具体推导可参见[21] 通过叠加关于特征点\\(f_j\\)的相机位姿集合\\(M_j\\)中所有的残差，可以得到： \\[ \\mathbf{r}^{(j)} \\simeq \\mathbf{H}_{\\mathbf{X} }^{(j)} \\widetilde{\\mathbf{X} }+\\mathbf{H}_{f}^{(j) G} \\widetilde{\\mathbf{p} }_{f_{j} }+\\mathbf{n}^{(j)} \\] 其中，\\(\\mathbf{r}^{(j)}, \\mathbf{H}_{\\mathbf{X} }^{(j)}, \\mathbf{H}_{f}^{(j)}\\), and \\(\\mathbf{n}^{(j)}\\)都是分别包含如下元素\\(\\mathbf{r}_{i}^{(j)}, \\mathbf{H}_{\\mathbf{X}_{i} }^{(j)}, \\mathbf{H}_{f_{i} }^{(j)}\\), and \\(\\mathbf{n}_{i}^{(j)}\\)的向量或矩阵。 并且由于不同图像中的特征观测是独立的，因此\\(\\mathbf{n}^{(j)}\\)的协方差矩阵为\\(\\mathbf{R}^{(j)}=\\sigma_{\\mathrm{im} }^{2} \\mathbf{I}_{2 M_{j} }\\)。 请注意，由于状态估计值\\(\\mathbf{X}\\)，用于计算特征点的位置估计（参考附录），式(22) 即线性化后的残差等式与误差状态\\(\\mathbf{\\tilde{X} }\\)相关联。因此，残差\\(\\mathbf{r}^{(j)}\\)并非如等式(17)的形式(\\(\\mathbf{r}=\\mathbf{H} \\tilde{\\mathbf{X} }+\\) noise)，不能直接用于EKF的测量更新步骤。 为了克服这个问题，我们通过将\\(\\mathbf{r}^{(j)}\\)投影到矩阵\\(\\mathbf{H}_{f}^{(j)}\\)的左零空间，从而定义了一个新的残差\\(\\mathbf{r}_{o}^{(j)}\\)。特别的，如果我们使用酉矩阵来表示\\(\\mathbf{A}\\)，其中它的列形成了关于\\(\\mathbf{H}_{f}\\)左零空间中的bias （这说的啥意思） \\[ \\begin{aligned} \\mathbf{r}_{o}^{(j)} &amp;=\\mathbf{A}^{T}\\left(\\mathbf{z}^{(j)}-\\hat{\\mathbf{z} }^{(j)}\\right) \\simeq \\mathbf{A}^{T} \\mathbf{H}_{\\mathbf{X} }^{(j)} \\widetilde{\\mathbf{X} }+\\mathbf{A}^{T} \\mathbf{n}^{(j)} \\\\ &amp;=\\mathbf{H}_{o}^{(j)} \\widetilde{\\mathbf{X} }^{(j)}+\\mathbf{n}_{o}^{(j)} \\end{aligned} \\] 因为 \\(2M_j \\times 3\\)的矩阵\\(\\mathbf{H}_{f}^{(j)}\\)是列满秩的，他的左零空间维度为\\(2 M_{j}-3\\)。因此\\(\\mathbf{r}_{o}^{(j)}\\)是\\(\\left(2 M_{j}-3\\right) \\times 1\\)的向量。这种残差独立于特征坐标中的误差，因此可以基于它执行EKF更新。 式\\(\\mathbf{H}_{o}^{(j)} \\widetilde{\\mathbf{X} }^{(j)}+\\mathbf{n}_{o}^{(j)}\\)定义了所有观测到特征点\\(f_j\\)。这表达了测量\\(\\mathbf{z}_{i}^{(j)}\\)为\\(M_j\\)的状态提供所有的有效信息，因此产生的EKF更新是最优的，除了由于线性化所引起的不准确性。 应该提到的是，为了计算残差\\(\\mathbf{r}_{O}^{(j)}\\)和观测矩阵\\(\\mathbf{H}_{o}^{(j)}\\)，酉矩阵\\(\\mathbf{A}\\)不需要显式地被评估。相反，残差\\(\\mathbf{r}\\)和矩阵\\(\\mathbf{H}_{\\mathbf{X} }^{(j)}\\)在\\(\\mathbf{H}_{f}^{(j)}\\)矩阵左零空间的投影可以通过使用Givens旋转[22]来计算得到，操作复杂度为\\(O\\left(M_{j}^{2}\\right)\\)。另外，\\(\\mathbf{A}\\)是酉矩阵，因此向量\\(\\mathbf{n}_{o}^{(j)}\\)的协方差可以如下计算： \\[ E\\left\\{\\mathbf{n}_{o}^{(j)} \\mathbf{n}_{o}^{(j) T}\\right\\}=\\sigma_{\\mathrm{im} }^{2} \\mathbf{A}^{T} \\mathbf{A}=\\sigma_{\\mathrm{im} }^{2} \\mathbf{I}_{2 M_{j}-3} \\] EKF更新 在前面的部分中，我们呈现了一种测量模型，其表示通过观察来自多个相机姿势的静态特征而施加的几何约束。 我们现在详细介绍了EKF的更新阶段，其中使用从观察多个特征的约束。 EKF更新由以下两个事件之一触发 当检测不到之前在多个图像跟踪的特征时，则使用第III-D部分中呈现的方法处理此特征的所有测量。 这种情况最常出现，因为特征点有可能在相机视野范围之外。 每次记录新图像时，当前相机姿势估计将被包含在状态向量中，如果已经达到了设定的最大相机位姿数\\(N_{max}\\)，则必须删除最少一个旧的相机位姿。在丢弃状态之前，使用在相应的时间瞬间发生的所有特征观测，以便利用其局部信息。在我们的算法中，从第二最旧的相机位姿开始，我们选择均匀间隔的\\(\\frac{N_{max} }{3}\\)的位姿，在使用这些姿势共有的特征的约束执行 EKF 更新后，这些被丢弃。我们选择始终保持最古老的姿势在状态向量中，因为涉及及时进一步姿势的几何结构通常对应于较大的基线，因此携带更有价值的定位信息，这种方法在实践中表现得非常好。 考虑到在给定的时间步骤中，必须处理由上述两个标准选择的\\(L\\)个特征点的约束。遵循前一节中描述的过程，我们对每一个特征点计算残差向量\\(\\mathbf{r}_{o}^{(j)}, j=1 \\ldots L\\)以及相关联的观测矩阵\\(\\mathbf{H}_{o}^{(j)}, j=1 \\ldots L\\)。通过将所有残差堆叠在一个向量中，我们得到： \\[ \\mathbf{r}_{o}=\\mathbf{H}_{\\mathbf{X} } \\widetilde{\\mathbf{X} }+\\mathbf{n}_{o} \\] 其中， \\(\\mathbf{r}_{o}\\)的块元素为\\(\\mathbf{r}_{o}^{(j)}\\) \\(\\mathbf{n}_{o}\\)的块元素为\\(\\mathbf{n}_{o}^{(j)}, j=1 \\ldots L\\) \\(\\mathbf{H}_{\\mathbf{X} }\\)矩阵具有行块元素\\(\\mathbf{H}_{\\mathbf{X} }^{(j)}, j=1 \\ldots L\\) 由于特征测量是统计上的，因此噪声向量\\(\\mathbf{n}_{o}^{(j)}\\)是不相关的，因此，其协方差矩阵等价于\\(\\mathbf{R}_{o}=\\sigma_{\\mathrm{im} }^{2} \\mathbf{I}_{d}\\)，其中 \\(d=\\sum_{j=1}^{L}\\left(2 M_{j}-3\\right)\\) 是残差\\(\\mathbf{r}_{o}\\)的维度 一个实践中的问题是，\\(d\\)可以是一个相当大的数字，例如，如果10个特征点在10个相机位姿中都被观测到，那么残差的维度是170 {(2x10-3)x10=170}. 为了降低EKF更新的计算复杂度，我们采用QR分解，对\\(\\mathbf{H}_{\\mathbf{X} }\\)，特别的，我们记分解为如下形式： \\[ \\mathbf{H}_{\\mathbf{X} }=\\left[\\begin{array}{ll} \\mathbf{Q}_{1} &amp; \\mathbf{Q}_{2} \\end{array}\\right]\\left[\\begin{array}{c} \\mathbf{T}_{H} \\\\ \\mathbf{0} \\end{array}\\right] \\] 其中， Q1和Q2是关于矩阵\\(\\mathbf{H}_{\\mathbf{X} }\\)列形式的range和nullspace。 \\(\\mathbf{T}_{H}\\)是上三角矩阵 根据这个定义，等式(25)(\\(\\mathbf{r}_{o}=\\mathbf{H}_{\\mathbf{X} } \\widetilde{\\mathbf{X} }+\\mathbf{n}_{o}\\)) 可以产生如下形式： \\[ \\begin{aligned} \\mathbf{r}_{o} &amp;=\\left[\\begin{array}{ll} \\mathbf{Q}_{1} &amp; \\mathbf{Q}_{2} \\end{array}\\right]\\left[\\begin{array}{c} \\mathbf{T}_{H} \\\\ \\mathbf{0} \\end{array}\\right] \\tilde{\\mathbf{X} }+\\mathbf{n}_{o} \\Rightarrow \\\\ \\left[\\begin{array}{c} \\mathbf{Q}_{1}^{T} \\mathbf{r}_{o} \\\\ \\mathbf{Q}_{2}^{T} \\mathbf{r}_{o} \\end{array}\\right] &amp;=\\left[\\begin{array}{c} \\mathbf{T}_{H} \\\\ \\mathbf{0} \\end{array}\\right] \\widetilde{\\mathbf{X} }+\\left[\\begin{array}{c} \\mathbf{Q}_{1}^{T} \\mathbf{n}_{o} \\\\ \\mathbf{Q}_{2}^{T} \\mathbf{n}_{o} \\end{array}\\right] \\end{aligned} \\] 从最后一个等式开始，通过投影\\(\\mathbf{H}_{\\mathbf{X} }\\)范围的基础向量，我们保留了测量中的所有有用信息。 残差中的\\(\\mathbf{Q}_{2}^{T} \\mathbf{r}_{o}\\)只是噪声，并且可以完全丢弃。因此，相比于使用等式(25)中的残差表示，我们使用下面形式的残差来执行EKF更新： \\[ \\mathbf{r}_{n}=\\mathbf{Q}_{1}^{T} \\mathbf{r}_{o}=\\mathbf{T}_{H} \\widetilde{\\mathbf{X} }+\\mathbf{n}_{n} \\] 其中， \\(\\mathbf{n}_{n}=\\mathbf{Q}_{1}^{T} \\mathbf{n}_{o}\\) 是噪声向量，其协方差矩阵等价于\\(\\mathbf{R}_{n}=\\mathbf{Q}_{1}^{T} \\mathbf{R}_{o} \\mathbf{Q}_{1}=\\sigma_{\\operatorname{im} }^{2} \\mathbf{I}_{r}\\)，且r为Q1的列数 EKF更新步骤计算卡尔曼增益： \\[ \\mathbf{K}=\\mathbf{P} \\mathbf{T}_{H}^{T}\\left(\\mathbf{T}_{H} \\mathbf{P} \\mathbf{T}_{H}^{T}+\\mathbf{R}_{n}\\right)^{-1} \\] 并且，矫正的状态按下式给出： \\[ \\Delta \\mathbf{X}=\\mathbf{K} \\mathbf{r}_{n} \\] 最后，状态的协方差矩阵如下更新： \\[ \\mathbf{P}_{k+1 \\mid k+1}=\\left(\\mathbf{I}_{\\xi}-\\mathbf{K} \\mathbf{T}_{H}\\right) \\mathbf{P}_{k+1 \\mid k}\\left(\\mathbf{I}_{\\xi}-\\mathbf{K} \\mathbf{T}_{H}\\right)^{T}+\\mathbf{K} \\mathbf{R}_{n} \\mathbf{K}^{T} \\] 其中， \\(\\xi=6N+15\\)是协方差矩阵的维度 审查EKF更新期间所需的操作的计算复杂性很有意思，残差 \\(\\mathbf{r}_{n}\\)以及矩阵\\(\\mathbf{T}_{H}\\)可以使用 Givens 旋转计算，操作复杂度是\\(O\\left(r^{2} d\\right)\\)，而无需显式地计算Q1的形式。 另一方面，等式(31)包含了\\(\\xi\\)维度的方阵的乘法计算，是\\(O\\left(\\xi^{3}\\right)\\)的操作。因此，EKF更新的复杂度是\\(\\max \\left(O\\left(r^{2} d\\right), O\\left(\\xi^{3}\\right)\\right)\\)。 另一方面，如果使用的残余向量\\(\\mathbf{r}_{o}\\)，而不将其投影在\\(\\mathbf{H}_{\\mathbf{X} }\\)的range内，计算卡尔曼增益的计算成本是\\(O\\left(d^{3}\\right)\\)，然而，通常\\(d \\gg \\xi, r\\)，所以可知，使用残差\\(\\mathbf{r}_{n}\\)可以减少计算量。 实验（暂略）","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"LT-mapper论文阅读","slug":"LT-mapper论文阅读","date":"2021-07-20T01:33:53.000Z","updated":"2022-04-11T15:57:06.316Z","comments":true,"path":"2021/07/20/LT-mapper论文阅读/","link":"","permalink":"http://yoursite.com/2021/07/20/LT-mapper%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"LT-mapper: A Modular Framework for LiDAR-based Lifelong Mapping 摘要 本文开发了一个开源的、模块化的、现成的、基于lidar的城市站点lifelong mapping 这是通过将问题划分为连续的子问题来实现的： - multi-session SLAM (MSS) - high/low dynamic change detection - positive/negative change management 所提出的方法利用MSS，并处理潜在的轨迹误差，因此，change检测不需要良好的初始对齐，我们的change管理方案保留了内存和计算成本的有效性，提供了从大规模点云图中自动分离对象的功能。通过对多个时间间隔(从一天到一年)的广泛实际实验，我们验证了该框架的可靠性和适用性，甚至在永久的年水平变化。 介绍 环境的变化如图1所示 为了更好地处理这种变化，lifelong mapping必须通过检测、更新和管理环境变化来解决自治的建图维护[1] 1）Integration to multi-session SLAM for scalability：一些研究认为，变化检测是比较多个预先构建的地图与时间上遥远和独立的后处理过程。在这项工作中，我们集成了多会话SLAM (MSS)，并将会话与锚节点[2]对齐，以在大型城市环境中执行变化检测，而不是在一个小房间，我们的框架包括一个基于激光雷达的多会话三维同步定位和映射(SLAM)模块，称为LT-SLAM。 2）Change detection under SLAM error：如果地图完全对齐，那么两个地图之间的变化检测就不重要了，早期的地图变化检测工作[5,3,6,7]依赖于全局对齐地图的强假设，没有错误，避免了处理这种模糊性问题。不幸的是，轨迹误差在现实中不可避免地发生。我们在变更检测期间调和了这种潜在的不对准，并使所提出的方法能够稳健地处理潜在的对准误差。为了处理模糊性，我们提出了一种具有投射可见性的scan-to-map方案，使用多个窗口大小的range-image，称为LT-removert 3）Compact place management：除了变更检测之外，我们还提出并证明了变更组合的概念，一旦检测到更改，就应该遵循地图维护的决定，以确定包含或排除什么，利用这一特性，我们不仅可以维护现有作品[1,3]等最新的地图，还可以提取具有较高placeness的稳定结构。因此，我们构建了一个可靠的3D地图，具有真正有意义的结构，用于其他任务，如跨模式定位[9]和长期定位[10]。这个最后的模块，称为LT-map. 总结，提出了一个新颖的基于激光雷达的lifelong mapping，称为LT-mapper. 框架中的每一个模块都可独立运行，基于file-based i/o 协议。与最近(但部分)提供的基于视觉的方法不同的是，3D LiDAR几乎没有实现统一和模块化的终身映射[11,12,13,14,15]。据我们所知，LT-mapper是第一个开放的模块化框架，支持基于lidar的复杂城市站点终身绘图，本文主要贡献： - LT-SLAM 集成变化检测MSS，通过anchor node来解决会话恢复，只使用激光雷达在共享帧中缝合多个会话。 - LT-removert 利用时空轴上的remove-then-revert算法，克服了会话间的对齐模糊性。 - LT-map 能有效地生成最新地图(实时地图)和持久地图(元地图)，同时将更改存储为增量地图，通过增量建图，减少内存和储存的成本。 相关工作 概述 LT-mapper是完全模块化的，并支持上述三个功能。整个pipline有3个模块组成(图3)，顺序运行并且模块独立。不像现有的基于激光雷达的变化检测[21]，装备有昂贵的定位设备，我们的系统只需要一个激光雷达（可选的IMU）。 在真实的户外环境中，暂时不连接的场景之间的准确对齐是难以捉摸的，如图2(a)所示 在LT-SLAM模块中，我们利用多会话SLAM，联合优化多个会话，并使用基于lidar的全局定位器进行鲁棒的会话间闭环检测，在这个模块中，一个查询度量被配准到现有的中心地图中。 我们同样需要考虑观测的变化，如图2(b)，一个构建的点云图可能包含噪声，由于周围的运动物体(红点)，即使是精确的里程表。这些不稳定的物体对一个地方的显著性的贡献不如静止点，因此，在LT-removert模块中，这些高动态(HD)点应该在计算会话间差异之前预先删除。 在对齐查询帧和中心会话并移除高清点后，我们通过应用查询测量和中心地图之间的差分操作来检测变化，如图2(c)。我们称之为低动态变化(LD)，进一步分为新出现点(PD)和消失点(ND)两类。","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"TEB局部路径规划论文阅读","slug":"TEB局部路径规划论文阅读","date":"2021-07-19T09:03:53.000Z","updated":"2022-04-11T15:57:06.316Z","comments":true,"path":"2021/07/19/TEB局部路径规划论文阅读/","link":"","permalink":"http://yoursite.com/2021/07/19/TEB%E5%B1%80%E9%83%A8%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Trajectory modification considering dynamic constraints of autonomous robots 摘要 经典的“松紧带”使由全局规划器生成的路径相对于最短路径长度发生变形，为了避免与障碍物接触。它不直接考虑底层机器人的任何动态约束。本文贡献引入了一种名为“时间弹性带”的新方法，该方法明确地考虑了运动的时间方面的动态约束，如有限的机器人速度和加速度。“时间弹性带”问题用加权多目标优化框架表示。大多数目标是局部的，因为它们依赖于一些邻近的中间配置。这就得到了一个有效的大规模约束最小二乘优化方法存在的稀疏系统矩阵。 仿真和实际机器人的实验结果表明，该方法具有较好的鲁棒性和计算效率，能够实时生成最优机器人轨迹。“时间弹性带”将由一系列路径点组成的初始路径转换为明确依赖于时间的轨迹，从而实现对机器人的实时控制。由于其模块化的形式，该方法很容易扩展到包含额外的目标和约束。 介绍 在运动规划的背景下，本文侧重于局部路径修改，假设初始路径已由全局规划器生成[1]。特别是在服务机器人的环境中，由于动态环境可能是动态的，由于其固有的不确定性，修改路径是一种较好的方法。此外，由于局部、不完整的地图和动态障碍，环境模型可能会发生变化，此外，在实时应用中，大规模全局路径的(重新)计算往往是不可行的。这种观测结果导致了局部修改路径的方法，如[2,3]提出的“弹性带”，“松紧带”方法的主要思想是，将原来给定的路径视为受内外力影响的弹性橡皮筋，使其变形，而内外力相互平衡，使路径收缩，同时与障碍物保持一定距离。 后来这种方法被推广到非完整运动学[4,5,6]、多自由度[7]机器人系统和动态障碍[8]，然而，据我们所知，动态运动约束还没有被认为是对路径变形的一个目标。典型的方法是用样条曲线平滑路径，获得动态可行轨迹。 我们的方法称为“时间弹性带”，是一种新颖的方法，因为它明确地增加了“弹性带”的时间信息，从而允许考虑机器人的动态约束和直接修改轨迹而不是路径。图1展示了使用时间弹性带架构的机器人系统： 通过考虑时间信息，“时间弹性带”也可以用来控制机器人的速度和加速度，这个方法也适用于高维的状态空间，尽管本文只考虑了差分驱动机器人的平面环境移动，有三个全局自由度和两个局部自由度。 时间弹性带 经典的“弹性带”是用n个机器人的中间姿态序列来描述的，\\(\\mathbf{x}_{i}=\\left(x_{i}, y_{i}, \\beta_{i}\\right)^{T} \\in \\R^{2} \\times S^1\\)，下面记为位置(x_i,y_i)和旋转\\(\\beta_i\\)，如图2所示: \\[ Q=\\left\\{\\mathbf{x}_{i}\\right\\}_{i=0 \\ldots n} \\quad n \\in \\mathbb{N} \\] TEB由两个连续的配置之间的时间间隔来进行时间调整，因此一个序列中包含\\(n-1\\)个\\(\\Delta T_i\\)： \\[ \\tau=\\left\\{\\Delta T_{i}\\right\\}_{i=0 \\ldots n-1} \\] 每个时间差表示机器人从一个配置依次过渡到下一个配置的时间(图2)，因此TEB定义为元祖序列： \\[ B:=(Q, \\tau) \\] 其关键思想是通过实时加权多目标优化，在配置和时间间隔两个方面进行调整和优化： \\[ \\begin{aligned} f(B) &amp;=\\sum_{k} \\gamma_{k} f_{k}(B) \\\\ B^{*} &amp;=\\underset{B}{\\operatorname{argmin}} f(B) \\end{aligned} \\] 其中， \\(B*\\)表示优化的TEB \\(f(B)\\)记为目标函数，在本文中由多个加权成分\\(f_k\\)组成，用于面对不同的方面，这是最基本的多目标优化方法，但它已经产生了非常好的结果。 目标函数的大部分分量相对于B是局部的，因为它们只依赖于几个连续的配置，而不是整个可配置空间带。 TEB的这种局部性导致了一个稀疏系统矩阵，为其提供了专门的快速有效的大规模数值优化方法[11]。 TEB的目标函数分为两类： 约束例如速度、加速度限制等惩罚项 目标项如最快、最短路径或者远离障碍等(等式8) 因此，在“时间弹性带”的背景下，这些约束被表述为一个分段连续、可微的代价函数的目标，该函数会惩罚违反约束的行为： \\[ e_{\\Gamma}\\left(x, x_{r}, \\epsilon, S, n\\right) \\simeq \\begin{cases}\\left(\\frac{x-\\left(x_{r}-\\epsilon\\right)}{S}\\right)^{n} &amp; \\text { if } x&gt;x_{r}-\\epsilon \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\] 其中， \\(x_r\\)表示边界 \\(S,n,\\epsilon\\) 影响近似的准确性 特别的，\\(S\\)表示尺度缩放，\\(n\\)表示阶数，\\(\\epsilon\\)是近似的一个位移小量 图3展示了等式6的两个不同的实现。 Approximation 1 （n = 2, S = 0.1, \\(\\epsilon\\)= 0.1） ， Approximation 2 （n = 2, S = 0.05 and \\(\\epsilon\\) = 0.1） ， 这个例子展示了约束\\(x_r=0.4\\)的一个近似。 使用多目标优化框架的一个明显优势是目标函数的模块化表达。目前TEB所采用的目标函数如下： Way points and obstacles TEB同时考虑原始路径的中间路径点的到达和避免静态或者动态的障碍物。这两个目标函数相似，不同之处在于点吸引橡皮筋，而障碍物排斥它。 目标函数企图最小化TEB和way point的距离\\(d_{min,j}\\)，如图4所示： 对于way point的情况，其距离以最大的目标半径\\(r_{pmax}\\)为界，这些约束由公式6中的惩罚函数实现： \\[ \\begin{aligned} f_{\\text {path }} &amp;=e_{\\Gamma}\\left(d_{\\min , j}, r_{p_{\\max }}, \\epsilon, S, n\\right) \\\\ f_{o b} &amp;=e_{\\Gamma}\\left(-d_{\\min , j},-r_{o_{\\min }}, \\epsilon, S, n\\right) \\end{aligned} \\] 由图3可知，必须将Eq. 8中\\(d_{\\min , j}\\)和\\(r_{o_{min}}\\)交换符号来实现下界. 注意，这些目标函数的梯度可以解释为作用在弹性带上的外力 Velocity and acceleration 机器人速度和加速度的动力学约束用与几何约束相似的罚函数来描述，图2展示了TEB的结构，线速度和角速度的均值使用两个连续配置\\(x_i,x_{i+1}\\)之间的欧式距离和角距离和时间差\\(\\Delta T_i\\)来计算： \\[ \\begin{aligned} v_{i} &amp; \\simeq \\frac{1}{\\Delta T_{i}}\\left\\|\\left(\\begin{array}{l} x_{i+1}-x_{i} \\\\ y_{i+1}-y_{i} \\end{array}\\right)\\right\\| \\\\ \\omega_{i} &amp; \\simeq \\frac{\\beta_{i+1}-\\beta_{i}}{\\Delta T_{i}} \\end{aligned} \\] 由于配置的临近，欧几里得距离是两个连续姿态之间的圆路径的真实长度的充分近似值。 加速度涉及两个连续的平均速度，因此考虑三个连续的构型，其中两个对应时间差： \\[ a_{i}=\\frac{2\\left(v_{i+1}-v_{i}\\right)}{\\Delta T_{i}+\\Delta T_{i+1}} \\] 为了清楚起见，用上式两个相关的速度来代替这三个连续的配置，旋转的加速度计算类似。 考虑一个差分驱动的移动机器人，轮速和位移\\(v_i\\)、旋转速度\\(w_i\\)关于机器人中心点的关系如下： \\[ \\begin{aligned} v_{w_{r}, i} &amp;=v_{i}+L \\omega_{i} \\\\ v_{w_{l}, i} &amp;=v_{i}-L \\omega_{i} \\end{aligned} \\] 其中，L为机器人轮距的一半 将公式12和公式13（即上面两个式子）对时间进行微分就得到了相应的车轮加速度。车轮的速度和加速度是有界的，可根据制造商的规格获取。机器人的平移和转动惯量可以以一种明显的方式包括在内，但在这第一个实现中，我们还没有这样做。 Non-holonomic kinematics（非完整约束运动学方程） 差动驱动的机器人只有两个局部自由度，因此，它们只能在机器人当前航向的方向执行运动，这种运动学约束导致了由圆弧段组成的平滑路径。 因此，两个相邻的构型需要位于一个常曲率的公共圆弧上，如图5所示 初始配置\\(x_i\\)和方向\\(d_{i,i+1}\\)之间的角度\\(\\vartheta_{i}\\)必须等于配置\\(x_{i+1}\\)和方向\\(d_{i,i+1}\\)之间的夹角，即： \\[ \\vartheta_{i}=\\vartheta_{i+1} \\] 根据二维叉积（\\(A \\times B=|A|·|B|·\\sin \\alpha\\)），有： \\[ \\Leftrightarrow\\left(\\begin{array}{c} \\cos \\beta_{i} \\\\ \\sin \\beta_{i} \\\\ 0 \\end{array}\\right) \\times \\mathbf{d}_{i, i+1}=\\mathbf{d}_{i, i+1} \\times\\left(\\begin{array}{c} \\cos \\beta_{i+1} \\\\ \\sin \\beta_{i+1} \\\\ 0 \\end{array}\\right) \\] 其中，机器人的绝对旋转为\\(\\beta_i\\)，位移方向向量为： \\[ \\mathbf{d}_{i, i+1}:=\\left(\\begin{array}{c} x_{i+1}-x_{i} \\\\ y_{i+1}-y_{i} \\\\ 0 \\end{array}\\right) \\] 因此，对应的目标函数为： \\[ f_{k}\\left(\\mathbf{x}_{i}, \\mathbf{x}_{i+1}\\right)=\\left\\|\\left[\\left(\\begin{array}{c} \\cos \\beta_{i} \\\\ \\sin \\beta_{i} \\\\ 0 \\end{array}\\right)+\\left(\\begin{array}{c} \\cos \\beta_{i+1} \\\\ \\sin \\beta_{i+1} \\\\ 0 \\end{array}\\right)\\right] \\times \\mathbf{d}_{i, i+1}\\right\\|^{2} \\] 惩罚违反此约束的二次误差。一个潜在的180方向的变化用一个额外的项来处理 Fastest path 以往的“松紧带”方法通过收缩松紧带的内力获得最短路径。由于我们的方法考虑时间信息作为最短路径的目标，我们可以选择用最快路径的目标代替最短路径的目标，或者将这些目标结合起来。 最快路径的目标很容易通过最小化所有时间差的和的平方来实现： \\[ f_{k}=\\left(\\sum_{i=1}^{n} \\Delta T_{i}\\right)^{2} \\] 这一目标导致了一种最快的路径，其中中间配置在时间上均匀分离，而不是在空间上 实现 图6展示了实现TEB的控制流程，在初始化阶段，初始路径被增强为初始轨迹，方法是根据动力学和运动学约束添加默认的时间信息。 在我们的例子中，初始轨迹是由带有纯旋转和平移的分段线性分段组成的，这种以多边形表示的路径通常由概率路线图规划者提供[9]，另外，reed - shepp路径很容易被增强为允许的轨迹[10]。 在每一次迭代中，算法动态地添加新的结构或删除以前的结构，以调整空间和时间分辨率以适应剩余的轨迹长度或规划水平。 一个滞后被实施以避免振荡。将优化问题转化为一个超图，用包含在“g20 -框架”中的大规模稀疏系统优化算法求解[11] 所要求的超图是一条边的连接节点数量不受限制的图,因此，一条边可以连接两个以上的节点。 TEB问题(Eq. 4)可以转化为一个以配置和时间差为节点的超图。它们与表示给定目标函数fk或约束函数的边相连，图7展示了一个两配置一个时间差和一个点状障碍物的超图， 速度边界目标函数要求的平均速度与两个配置之间的欧氏距离和所需的时间有关。因此它形成一条连接B的那些状态的边。 障碍物需要一条与最近的配置相连的边，表示障碍物的节点是固定的(双圆)，因此优化算法无法改变其参数(位置) 在验证优化后的TEB后，可以通过计算控制变量v和ω来直接命令机器人驱动系统。 在每一次新的迭代之前，重新初始化阶段将检查新的和变化的way-points，这将会比较有用如果way-points是在分析相机或者激光数据之后才收到的。","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"Hector-SLAM论文阅读","slug":"Hector-SLAM论文阅读","date":"2021-07-11T06:03:53.000Z","updated":"2022-04-11T15:57:06.316Z","comments":true,"path":"2021/07/11/Hector-SLAM论文阅读/","link":"","permalink":"http://yoursite.com/2021/07/11/Hector-SLAM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"A Flexible and Scalable SLAM System with Full 3D Motion Estimation 摘要 在许多应用场景中，比如城市搜救和搜索（USAR）机器人，需要去获取未知环境的地图。我们提出了一个快速在线学习占用栅格地图、占用较少计算资源的系统。它利用激光雷达系统与基于惯性传感器的3D位姿估计系统进行融合，实现了一种鲁棒的扫描匹配方法。通过地图变化的快速近似和多分辨率栅格地图，在各种有挑战性的环境中实现了可靠的定位与建图。提供了多种数据集以适应嵌入式手持建图系统。我们表明，该系统是足够准确的，在我们考虑的应用场景中，不需要显式闭环检测技术。该软件可作为ROS的开源代码包。 介绍 学习环境模型并定位自身是一个真正的机器人在真实世界运行的最重要的能力。在本文中，我们提出了一种灵活的、可升级的系统来解决SLAM问题，已成功的运用在了UGV、USV和一个小型的室内导航系统上。该方法消耗的计算资源较少，故可以应用于低成本、低功耗的嵌入式系统。该方法是在ROS上实现的开源软件。它适应ROS上的API和导航stack，并可以在ROS的生态中替代其他SLAM方法。 本文介绍的系统旨在保证计算力要求低的前提下，实现足够精确的环境感知和自我定位。它可以应用在小尺度的、不必做大的闭环的系统中，并需要使用高更新速率的激光雷达系统。类似的场景包括RoboCup搜救比赛，可能需要在模拟的地震场景中找到受害者，因此需要对车辆在6Dof上进行姿态估计。或者，比地面机器人更灵活的室内飞行器的导航。有关USAR的结果和模型在参考【2】中可以找到。 我们的方法结合了2D SLAM（基于激光雷达的平面地图）和3D导航（基于IMU）融合了2D的SLAM信息作为辅助（FIG.I）。SLAM过程通常是由激光雷达的数据更新来触发的，而整个3D导航解决方案是需要实时计算的，构成车辆控制系统的一部分。 相关工作 近些年已经有大量的研究关于SLAM的问题，例如作为开源软件的gmapping使用的是Rao-Blackwellized粒子过滤器，可以可靠在的典型办公室室内场景使用。然而，这些解决方案的工作最好在平面环境，依赖于现有的，足够精确的航迹以及不利用现代雷达系统提供的高更新率。对于非结构化环境，会导致载体的显著滚转和俯仰运动，或在空中平台上实现这种系统不适用或必须进行显著修改。 一个SLAM的前端和后端系统之间的区别。在大满贯的前端，用于实时在线估计机器人运动，后端用于优化位姿图，和在使用的前端产生的位姿之间的约束。本文提出的方法可以作为一个SLAM的前端和不提供姿势图优化像[ 4 ]和[ 5 ]提出的解决方案。然而，我们表明，在许多情况下，这种优化并不需要在现实中的一些条件，因为这种方法是足够准确的，可用于机器人来执行他们的任务。 基于激光扫描匹配的室内导航系统提出了对旋翼无人机使用[ 6 ]、[ 7 ]、[ 8 ]。在这里，采用两阶段的方法，前端快速扫描的位姿估计，和用于在后台或远程计算机上进行的较慢的后端建图步骤。从雷达扫描对准的位姿估计不直接纳入车辆的控制回路，因此他们只在低速行驶。 在[ 9 ]和[ 10 ]中描述了移动机器人上使用的其他前端系统。在本文的对比，他们没有提供完整的六自由度位姿估计和开源软件。 使用扫描匹配进行定位的工作始于ICP[ 11 ]，它起源于注册三维点云的一般方法。许多基于ICP的方法的主要缺点是对点对应的高复杂度搜索，这必须在每次迭代中进行。极坐标扫描匹配（PSM）[ 12 ]避免了利用激光扫描的自然极坐标系统来估计它们之间的匹配的对应搜索。扫描进行预处理，可用于极性扫描匹配。实时相关扫描匹配方法[ 13 ]采用穷举抽样方法进行扫描匹配。通过多种优化，这种方法能够实时应用。基于正态分布变换（NDT）[ 14 ]的扫描匹配将扫描对齐到代表前扫描的正态分布混合。 对于沿海的情况，有研究使用昂贵的多传感器扫描仪[ 15 ]，但据笔者的知识，没有单发射器激光雷达为基础的SLAM方法，可在现实世界中的条件下进行测试。 系统概述 相对许多其他基于网格的2D-SLAM来说，本文提供了一种可用的，具有完整的6自由度运动的平台。我们的系统可以预测6自由度的平移和旋转状态。为了实现这一点，我们的系统由两个主要部分组成，导航滤波器融合了来自于惯性传感器和其他可用的传感器到一个可用的3D数据，而2D SLAM则提供平面的位姿信息。这两部分的更新都是单独的，是松耦合系统，他们会定时保持同步。 我们定义导航坐标系统是一个右手系统，它的原点在平台的起点上，Z轴指向上方，X轴在启动时指向平台的朝向。 完整的3D状态表示为\\(\\mathbf{x}=\\left(\\begin{array}{lll}\\mathbf{\\Omega}^{\\mathrm{T}} &amp; \\mathbf{p}^{\\mathrm{T}} &amp; \\mathbf{v}^{\\mathrm{T}}\\end{array}\\right)^{\\mathrm{T}}\\)，其中，\\(\\mathbf{\\Omega}=(\\phi, \\theta, \\psi)^{\\mathrm{T}}\\)表示欧拉角的roll，pitch和yaw，\\(\\mathbf{p}=\\left(p_{x}, p_{y}, p_{z}\\right)^{\\mathrm{T}}\\)和\\(\\mathbf{v}=\\left(v_{x}, v_{y}, v_{z}\\right)^{\\mathrm{T}}\\)分别表示在导航坐标系下的位置和速度。 惯性测量使用\\(\\mathbf{u}=\\left(\\begin{array}{ll}\\omega^{T} &amp; \\mathbf{a}^{T}\\end{array}\\right)^{T}\\)来表示，其中\\(\\mathbf{a}=\\left(a_{x}, a_{y}, a_{z}\\right)^{\\mathrm{T}}\\)和\\(\\mathbf{w}=\\left(w_{x}, w_{y}, w_{z}\\right)^{\\mathrm{T}}\\)分别表示加速度和角速度。任意刚体的运动可以表示为如下非线性微分方程（简化版）： \\[ \\begin{aligned} \\dot{\\mathbf{\\Omega}} &amp;=\\mathbf{E}_{\\Omega} \\cdot \\boldsymbol{\\omega} \\\\ \\dot{\\mathbf{p}} &amp;=\\mathbf{v} \\\\ \\dot{\\mathbf{v}} &amp;=\\mathbf{R}_{\\Omega} \\cdot \\mathbf{a}+\\mathbf{g} \\end{aligned} \\]","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"T-LOAM论文阅读","slug":"T-LOAM论文阅读","date":"2021-06-11T06:03:53.000Z","updated":"2022-04-11T15:57:06.381Z","comments":true,"path":"2021/06/11/T-LOAM论文阅读/","link":"","permalink":"http://yoursite.com/2021/06/11/T-LOAM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"T-LOAM: Truncated Least Squares LiDAR-Only Odometry and Mapping in Real Time 摘要 提出了一个基于截断最小二乘法的新颖的、计算效率高、鲁棒的纯激光里程计。我们的方法侧重于减轻异常值的影响，允许在退化发生的稀疏，嘈杂或杂乱的情况下允许强大的导航。 作为预处理，使用了多区域的地面提取，动态曲率体素的聚类方法来完成3D点云的分割和滤除不稳定目标的工作。 提出一个新颖的特征提取模块，用于区分：边缘特征、球形特征、平面特征、地面特征。 作为前端，是一个基于分层特征的纯激光雷达里程计，通过截断最小二乘法来直接处理不同的特征以进行精确地运动估计。预处理模型和运动估计精度已经在 KITTI 里程计基准以及各种校园场景中进行了评估。 实验结果证明了所提出的T-LOAM的实时能力和优越的精度优于其他最先进的算法。 变量约定 DCVC聚类: Dynamic curved-voxel clustering MRGE地面提取：Dultiregion ground extraction TLS截断最小二乘：Truncated least squares \\(t_k\\): 第k帧激光扫描结束的时间 \\(L_k\\): 时间\\(t_k\\)对应的LiDAR body坐标系 \\(Q_i,S_j\\): MRGE的第i个象限，第j部分 \\(\\mathbb{F}_{k}^{v}, \\mathbb{F}_{k}^{b}\\): 时间\\(t_k\\)MRGE的前景和背景 \\(\\mathbb{F}_{k}^{d}\\)： 在时间\\(t_k\\)由\\(\\mathbb{F}_{k}^{v}\\)输出的DCVC模型 \\(\\mathbb{F}_{k}\\): 在时间\\(t_k\\)对应\\(L_k\\)坐标系的所有特征 \\(F_{k}^{e}, F_{k}^{s}, F_{k}^{p}, F_{k}^{g}\\)：边缘、球形、平面、地面特征 \\(\\mathbb{M} \\mathbb{l}_{k}^{w}\\)：时间\\(t_k\\)的世界坐标系中的子图第k特征点 \\(x_{k}^{w}\\)：时间\\(t_k\\)对应的机器人在全局坐标系的状态 介绍 在本文中，已经实施了一系列改进，以解决当前激光SLAM框架中存在的缺陷。 截断最小二乘（TLS）方法创新的应用于扫描匹配，使T-LOAM对于异常值更加鲁棒，并减轻其对初始值解决方案的依赖性。 原始点云通过精心设计的预处理模块进行了分割，以提取四个独特的功能：边缘特征，球形特征，平面特征和地面地面。 为了实现更加平滑的里程计，通过TLS方法构建了与不同特征相关的三种残差函数。 最后，构建如图1所示全局一致的地图。 使用了KITTI Odomerty数据集来与其他state-of-art的方法相比，如F-LOAM,A-LOAM,SuMa等，实验结果表明T-LOAM在大多数序列实验场景中达到更优越的性能。 本文主要贡献： 提出一个基于截断最小二乘TLS的高效率鲁棒激光里程计，用于进行导航和构建全局一致性高的点云地图。 利用MRGE地面提取和DCVC聚类来实现一系列预处理步骤，提高点云分割的精度 首次使用Open3D进行激光SLAM框架的开发，并开源 本方法受graduated nonconvexity(GNC)方法的启发，这在计算机视觉字段中执行了各种匹配和优化任务，已经证明有效。根据Convex优化理论基于TLS构建一种新颖的姿态优化函数，以估算6自由度的变换。 该实现遵循如图2所示，并通过多线程和OpenMP [28]设置并行化以保证算法的整体运行效率，另外还使用了ROS社区的nodelet功能包来实现Zero copy. 数据集与系统硬件介绍 本文中使用的TX2机器人是远程化的车辆,这是由双无刷电机驱动，由670-WH电池供电。LIDAR的安装高度设置为0.75米，以保证全向扫描。 通过遥控记录实验数据集。 此外，LIDAR采样频率设定为10 Hz。 采用两台计算机评估所提出的框架的实时能力，包括NVIDIA Jetson TX2(ARM Cortex-A57 CPU)以及2.5-GHz i7-10750H CPU的笔记本电脑。 所有模块由C ++实现，并将Nodelet包作为Ubuntu 18.04 Linux中的唯一节点集成到ROS [29]中，以完成它们之间的零拷贝传输。 本文中提出的实验仅利用这些系统中的CPU运行。 预处理模块 框架总览 T-LOAM框架如图2所示 首先，对激光扫描进行关于旋转的畸变矫正，然后，将点云输入到MRGE模块中以获取前景\\(\\mathbb{F}_{k}^{v}\\)和背景\\(\\mathbb{F}_{k}^{b}\\)。随后，使用DCVC方法来对前景进行分割，并滤除不稳定的类别，得到\\(\\mathbb{F}_{k}^{d}\\)。 此外，通过特征提取模块来分别得到特征点\\(\\mathbb{F}_{k}=\\left\\{F_{k}^{e}, F_{k}^{s}, F_{k}^{p}, F_{k}^{g}\\right\\}\\)，通过预处理扫描，关联的特征点通过位姿优化模块配准到子图上，得到全局一致性地图。此外，基于连续的激光扫描位姿优化得到的平移，将用于对当前帧扫描特征点云进行平移量的矫正。 多区域地面提取 地面点云通常占据了车载激光雷达扫描的大部分，并通常具有较简单的数学模型，有利于处理。 特别的，这些特征可以直接用于构造位姿优化的约束。但是，仅使用单个平面模型不足以准确表示复杂地形中的分布，因此，采用了MRGE方法来提高分割精度。 在算法一中，原始的激光扫描首先根据极坐标分为多个象限（默认是4），如图4(a)所示。其次，对于每一个象限，都将继续分为多个子区域（默认为3），如图4(b)所示，其中，每个子区域的边界如下计算： \\[ \\theta_{i}=\\theta_{s}+\\frac{n}{b} \\alpha \\cdot k_{i} \\] \\[ \\lambda_{i}=\\left\\{\\begin{array}{ll} h\\left(\\frac{1}{\\tan \\left(\\theta_{i}\\right)}\\right), &amp; \\text { if } i \\geq 1 \\\\ 0, &amp; \\text { if } i=0 \\end{array}\\right. \\] 其中，\\(\\theta_s\\)是激光扫描的起始仰角，\\(b\\)是子区域数，\\(n\\)是可能包含地面点的激光线束数总和。特别的，\\(\\alpha\\)代表激光雷达的垂直角分辨率，\\(h\\)表示激光雷达的安装高度，\\(k,i\\)分别表示区域的系数和索引。 对于自动驾驶车辆来说，地面点的高度坐标分量通常位于最低位置，因此，可以利用这个先验信息来根据高度值对区域点云进行整理。 种子点在指定的阈值\\(\\tau\\)内进行选择，主要用于拟合初始的平面模型。为了提高模型精度，多轴线性回归方法量身定制以计算相关参数，主要方向被加权，以减轻异常值的影响。线性平面模型被量身定制以反映子区域的分布，通过如下： \\[ \\begin{aligned} a x+b y+c z+d &amp;=0 \\\\ n^{T} \\mathrm{p} &amp;=-d \\end{aligned} \\] 其中， \\(n=\\left[\\begin{array}{lll}a &amp; b &amp; c\\end{array}\\right]^{T}\\)，表示平面法向量 \\(\\mathrm{p}=\\left[\\begin{array}{lll}x &amp; y &amp; z\\end{array}\\right]^{T}\\)，表示平面上的点 特别的，协方差矩阵M用于获取对应的每个子区域中指定的种子点的分散性： \\[ \\mathcal{M}=\\sum_{i=1}^{|s|}\\left(s_{i}-\\bar{s}\\right)\\left(s_{i}-\\bar{s}\\right)^{T}=\\left(\\begin{array}{lll} a_{1} &amp; a_{2} &amp; a_{3} \\\\ b_{1} &amp; b_{2} &amp; b_{3} \\\\ c_{1} &amp; c_{2} &amp; c_{3} \\end{array}\\right) \\] 其中，\\(\\bar{s} \\in \\mathbb{R}^{3}\\)记为子区域中的所有点\\(s_{i} \\in S\\)的均值。 下一步，计算出三个主方向： \\[ \\begin{array}{l} v_{x}=\\left[\\begin{array}{l} b_{2} c_{3}-b_{3} b_{3} \\\\ a_{3} b_{3}-a_{2} c_{3} \\\\ a_{2} b_{3}-a_{3} b_{2} \\end{array}\\right], \\quad v_{y}=\\left[\\begin{array}{l} a_{3} b_{3}-a_{2} c_{3} \\\\ a_{1} c_{3}-a_{3} a_{3} \\\\ a_{2} a_{3}-a_{1} b_{3} \\end{array}\\right] \\\\ v_{z}=\\left[\\begin{array}{l} a_{2} b_{3}-a_{3} b_{2} \\\\ a_{2} a_{3}-a_{1} b_{3} \\\\ a_{1} b_{2}-a_{2} a_{2} \\end{array}\\right] \\end{array} \\] 为了减轻异常值对法向量估计的影响，每个主方向加权，并应用线性回归来细化正常向量。 权重值是所示的每个主方向的二范数，如下： \\[ \\begin{aligned} n &amp;=\\sum_{k \\in\\{x, y, z\\}} w_{k} v_{k} \\\\ w_{x} &amp;=v_{x}[0]^{2}, \\quad w_{y}=v_{y}[1]^{2}, w_{z}=v_{z}[2]^{2} \\end{aligned} \\] 其中，\\([]\\)操作符表示取该向量对应的元素 参数\\(d\\)可以根据平面方程和\\(p,\\bar{s}\\)计算获得，即当法向量\\(n\\)获取后，将一个点代入最终的平面模型即可计算得到。 动态曲率体素聚类 为了准确高效对点云进行分割，提出了DCVC方法。改进的空间体素类型满足[24]中描述的三个重要方面，以及与点云的空间分布更加对应。 定义1： 第i，j，k个动态弯曲的voxel表示一个3D空间的体素单元，其根据配置可以如下计算： \\[ \\begin{aligned} D C V_{i, j, k}=\\left\\{P(\\rho, \\theta, \\phi)=\\mid \\rho_{i}\\right.&amp; \\leq \\rho&lt;\\rho_{i}+\\Delta \\rho_{i} \\\\ \\theta_{j} &amp; \\leq \\theta&lt;\\theta_{j}+\\Delta \\theta_{j} \\\\ \\phi_{k} &amp;\\left.\\leq \\phi&lt;\\phi_{k}+\\Delta \\phi_{k}\\right\\} \\end{aligned} \\] 其中，每个\\(P(\\rho, \\theta, \\phi)\\)是极坐标系中的极径\\(\\rho\\)、方位角（俯仰）\\(\\theta\\)，极角（水平）\\(\\phi\\)。特别的，\\(\\Delta \\rho_i,\\Delta \\theta_j, \\Delta \\phi_k\\)表示根据点云的稀疏性和距离值调整的每个体素单元的边界上下界之差（即体素的尺寸）。 另外，每个方向上的体素的增量可以计算如下： \\[ \\begin{array}{l} \\Delta \\rho_{i}=\\rho_{s}-\\left(a \\times s_{i}+b\\right) \\times \\Delta \\rho \\\\ \\Delta \\theta_{j}=s_{j} \\times \\Delta \\theta \\\\ \\Delta \\phi_{k}=s_{k} \\times \\Delta \\phi \\end{array} \\] 其中， \\(\\rho_s\\)表示起始的体素极径 \\(s\\)表示步长 \\(\\Delta \\rho,\\Delta \\theta, \\Delta \\phi\\)分别对应极径、方位角、极角的增量 \\(a,b\\)是体素系数，其可以根据各种光束的点云和3D LIDAR的密度来确定 为了更好地理解实际分布，在图5中可视化两个相邻的空间动态体素。 这个图右图有点问题，图中的z轴应该是y轴才对，因为右图是俯视图 稀疏系数可用于调节极径方向上不同距离的体积，这有利于防止对空间中相邻物体区分失败。 DCVC方法总结成算法2。 我们首先将笛卡尔坐标系的点云转换到极坐标系中，同时建立弯曲的体素。 然后，将非空的动态体素构建成哈希表，以提高搜索效率。 随后，根据哈希表映射关系，搜索当前点所在体素的周围体素，并将它们合并到统一标签中。 最后，我们返回每个点的类别信息，并提供合成判断，以滤除一组或潜在的动态目标，以获得最终的点云\\(\\mathbb{F}_{k}^{d}\\)。以这种方式，当各种对象彼此依然相邻时，显著抑制了不正确的分割分类的发生。 特征提取 很明显，LOAM[10]中呈现的算法容易受几何退化场景的影响，这将直接衰减激光雷达测量仪的精度甚至使其失败。 为了提高纯激光雷达里程计的稳定性，T-LOAM将从\\(\\mathbb{F}_{k}^{d}\\)和\\(\\mathbb{F}_{k}^{b}\\)提取4个可区分的几何特征，包括边缘特征\\(F_{k}^{e}\\)，球面特征\\(F_{k}^{s}\\)，平面特征\\(F_{k}^{p}\\)和地面特征\\(F_{k}^{g}\\)。 背景\\(\\mathbb{F}_{k}^{b}\\)首先进行降采样，边缘则使用LOAM[10]方法，根据平滑度提取： \\[ c=\\frac{1}{|s| \\cdot\\left\\|p_{i}\\right\\|}\\left\\|\\sum_{m \\in s, m \\neq i}\\left(p_{m}-p_{i}\\right)\\right\\| \\] 其中，\\(s\\)表示同一激光束的连续10个点的集合，即包含点\\(p_i\\)左右两侧的5个点 另外，球面特征\\(F_{k}^{s}\\)和平面特征\\(F_{k}^{p}\\)的垂直部分可以通过PCA算法获取。它用于捕捉局部领域的描述，包括曲率、主方向、次方向、法向量以及相应的特征值。为了实现上述，需要计算的协方差矩阵如下计算： \\[ \\mathcal{M}=\\frac{1}{k} \\sum_{i=1}^{k}\\left(p_{i}-\\overline{p_{k}}\\right)\\left(p_{i}-\\overline{p_{k}}\\right)^{T} \\] 其中，\\(k\\)表示总的点数，\\(\\bar{p_k}\\)表示点集的均值。 进一步的，对协方差矩阵M执行了SVD分解，以获取特征值\\(\\lambda\\)和特征向量\\(v\\)。可以通过协方差矩阵的特征向量来区分各种特征，这些特征向量与最显著的数据方差方向相关联。一些分散点主要根据特征值近似平等的方法来进行过滤。然后，点云的平坦度flatness和球面度sphericity[30]可以计算如下： \\[ \\begin{aligned} \\gamma &amp;=\\frac{\\lambda_{3}}{\\lambda_{1}+\\lambda_{2}+\\lambda_{3}} \\\\ \\sigma &amp;=\\frac{\\lambda_{2}-\\lambda_{3}}{\\lambda_{1}}, \\quad \\psi=\\frac{\\lambda_{3}}{\\lambda_{1}} \\end{aligned} \\] 其中， \\(\\gamma\\)是曲率 \\(\\sigma\\)是平坦度 \\(\\psi\\)是球面系数 需要注意的是，特征值以降序的顺序给出 如算法3展示，如果平坦度系数\\(\\sigma\\)比平面特征阈值\\(\\tau\\)更大，然后将点作为平面特征的垂直部分提取。对于非平面部分，如果球面系数\\(\\psi\\)比球面特征阈值\\(\\pi\\)更大，点将会添加到球面特征中。 来自HDL-64E激光雷达的不同特征的提取示意图如图6所示。 进一步的，主方向和法向量将会在后续残差计算中继续使用，以进一步细化水平和垂直分布的关联特征。 位姿优化","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"LION论文阅读","slug":"LION论文阅读","date":"2021-06-09T02:03:53.000Z","updated":"2022-04-11T15:57:06.316Z","comments":true,"path":"2021/06/09/LION论文阅读/","link":"","permalink":"http://yoursite.com/2021/06/09/LION%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"LION: Lidar-Inertial Observability-Aware Navigator for Vision-Denied Environments Video 摘要 在GPS拒绝和感知的环境中导航的机器人的状态估计，例如地下隧道，矿区和行星子表面空隙[1]，在机器人中仍然具有挑战性。 LION通过融合来自IMU的高频惯性数据和通过固定滞后滑动窗口的LIDAR低频相对位姿观测来提供高频的里程估计。同时也不需要事先获取LiDAR和IMU外参，进行了实时在线外参标定，此外，还使用了可观测性的度量来评估位姿估计是否是几何病态的。 介绍 提出了LiDAR-Inertial的可观测性算法，用于在感知性降低的环境中，这是CoSTAR团队在第一届DARPA Subterranean挑战中的方法。 我们的解决方案依赖于IMU预积分和scan-to-scan的ICP，以及固定滞后的滑动窗口。并且该方法实时在线标定LiDAR和IMU的外参，为了解决潜在的可观测性问题，我们使用了几何可观测性分数[23]，使得LION预测其输出中的观测场景的几何结构。通过该输出的得分，基于监督算法(如HeRO)，我们可以切换到不同的状态估计算法（如轮速编码、视觉惯性等）。该方法保证了状态估计的连续性、可靠性以及重力对齐的特点，为后续级联规划和控制算法提供保障。 具体方法 激光惯性里程计 LION是基于滑动窗口的LIO，分为两个部分，前端由LO和IMU预积分、可观测性检测模块组成，后端是因子图优化，如图2所示。 在下面的叙述中，遵循如下约定： 里程计世界坐标系\\(W\\) 载体坐标系\\(B\\)，即IMU坐标系 激光雷达坐标系\\(L\\) 一个点聪坐标系A到坐标系B的表示为4x4的矩阵：\\(_B\\mathbf{T}_A\\)，由旋转矩阵\\(_B\\mathbf{R}_A\\)和平移向量\\(_Bt_A\\)组成 LO模块使用GICP[31]来获取两帧激光扫描之间的相对位姿变换\\(_{L_{k-1}} \\mathbf{T}_{L_{k}}\\)。为了简化ICP算法的收敛性，对于每一帧激光扫描到达，首先进行重力对齐（使用IMU对其进行旋转部分的坐标表变换作为ICP的初始值）。 IMU预积分模块利用state-of-art的流形积分理论来将关键帧之间的IMU整合成单个运动约束[22,32]。 或者，基于scan-to-scan的前端可以使用LOCUS[33]框架替换，它额外地将新的激光扫描与局部地图进行对齐，以执行一个refinement步骤。 在后端，由前端产生的相对位姿观测与IMU测量结合使用，图3展示了因子图中的状态和因子，其中，在第j个时间步的状态\\(x_j\\)表示如下： \\[ \\mathbf{x}_{j}:=\\left\\{_{W} \\mathbf{T}_{B}, _W \\mathbf{v},{ }_{B} \\mathbf{b}^{a},{ }_{B} \\mathbf{b}^{g},{ }_{B} \\mathbf{T}_{L}\\right\\}_{j} \\] 其中， \\(_W{\\mathbf{T}}_{B}\\)是IMU$到世界坐标系的变换 \\(_Wv\\)是线速度 \\(_Bb^a,_Bb^g\\)是IMU的加速度计bias和陀螺仪bias \\(_BT_L\\)是激光雷达到IMU的变换 遵循[32]，记\\(\\mathcal{K}_{k}:=\\{k-m+1,\\dots,k\\}\\)为滑动窗口中的m个时间步，并记\\(\\mathcal{X}_{k}:={\\mathbf{x}_j}_{j\\in\\mathcal{K}_k}\\)和\\(\\mathcal{Z}_k\\)分别记为滑动窗口中的状态和观测。 因子图优化旨在求解如下[32]函数： \\[ \\mathcal{X}_k^{*}:= \\arg \\min_{\\mathcal{X}_k}(-\\log_c p(\\mathcal{X}_k | \\mathcal{Z}_k)) \\] 其中，\\(p(\\mathcal{X}_k | \\mathcal{Z}_k)\\)是一个后验概率分布。 我们使用GTSAM[29]作为后端，并使用iSAM2[28]求解。 可观测性度量 在地下场景，确定场景的几何特性是否有利于求解平移方向的位移是至关重要的。遵循[23,34]，假设旋转是小量的，那么Point-to-PlaneICP的cost的Hessian使用\\(2A\\)来近似，其中， \\[ \\begin{aligned} A:=\\sum_{i=1}^{M} H_i^TH_i:= \\begin{bmatrix} A_{rr} &amp; A_{rt} \\\\ A_{rt}^{T} &amp; A_{tt} \\end{bmatrix} \\end{aligned} \\] 且有 \\[ H_i:=[-(p_i \\times n_i)^{\\mathbf{T}},-n_i^{\\mathbf{T}}] \\] 其中，\\(n_i\\)是与点\\(p_i\\)对应的平面单位法向量。 因此，矩阵\\(A\\)的最小特征值即为最小可观测性的方向，平移部分通常是位姿估计具有挑战性的部分，主要是环境中可能存在长廊等场景。 因此，我们使用条件\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right):=\\frac{\\left|\\lambda_{\\max }\\left(\\boldsymbol{A}_{t t}\\right)\\right|}{\\left|\\lambda_{\\min }\\left(\\boldsymbol{A}_{t t}\\right)\\right|}\\)作为可观测性的度量。 当\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right)\\)越大，优化问题中在平移部分的约束越差，当高于阈值时，LION向切换逻辑的HeRO[4]模块发出警告，以便可以使用其他更加准确的里程计来源。 实验 2019隧道竞赛 我们首先在美国匹兹堡的Niosh实验矿山举行的两种不同赛道中的两次不同赛道中的两次不同赛道的两次不同。 激光里程计计算频率为10Hz，其中IMU和LION输出可以高达20Hz。LION使用的滑动窗口保持在3s内，并且后端被调整为使用i7 Intel NUC核心的30%。 对于参考，我们将其性能与：轮速惯性里程计（通过扩展卡尔曼滤波器融合的轮速惯性里程计）、scan-to-scan的里程计（LION的相对姿势输入）进行比较，并使用LAMP[35]作为ground-truth。 结果总结在表1中。 我们可以看到，融合惯性数据与前端的里程计中显着降低了纯激光雷达里程计方法的漂移（scan-to-scan）。这从沿图4所示的z轴的z轴尤其明显，另外，LION可靠的估计了机器人的姿态（如图5所示），实现了小的roll和pitch误差 没看出来. 为了展示LION的自动校准能力，我们在模拟中生成了一个数据集，其中LIDAR沿IMU的Y轴相对于IMU转换为0.1米。 在图7中，我们观察到大约20秒后，LION（连续线）估计正确的外参（虚线） &gt; 精度不咋地。 可观测性模块 我们首先展示\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right)\\)如何检测几何上的无约束场景。 要测试这一点并建立直觉，我们首先使用JPL-Corlidor数据集，在JPL的办公室录制，其中主要的挑战是该环境沿长廊方向缺少几何特征。 此外，我们也使用了Arch-Coal-Mine数据集进行测试，它由一条直隧道和一个交叉路口组成。 将JPL-Corlidor数据集中的\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right)\\)以及矩阵特征值进行可视化，如图8所示： 某个方向特征值越小，轴越短，不确定性越小，\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right)\\)越大，约束越少。 在走廊的开始和末尾，所有方向都有足够的特征，条件号是\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right)\\)≈2。但是，在走廊的中间，条件号达到值\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right)\\)&gt; 13，同时特征向量沿着隧道的方向相关的特征值很小 将运行Arch-Coal-Mine数据集时的\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right)\\)以及矩阵特征值进行可视化，如图9所示： 使用此\\(\\kappa\\left(\\boldsymbol{A}_{t t}\\right)\\)作为可观察性度量标准，HeRO可以决定在没有足够的LIDAR功能时切换到不同于LION（如WIO）的其他里程计源。这种行为如图10所示。对于在办公室的环境中进行的真实实验，其中第一走廊的一部分没有足够的激光雷达特征。 如果未使用可观察性模块，则走廊中的这种特征缺乏会造成lidar slip，即无法观测到机器人的运动，这产生了9m的误差（机器人回到原点）。 当使用可观测性模块后，这种特征被检测到，将会切换到WIO模块来暂时代替LION，减少误差，此时误差为1m。 总结 Local state estimator: LION的主要目标是提供高速、连续、平滑的输出给下游算法。因此，LION并不构建任何地图，也不执行回环检测，因此其参考坐标系会逐渐偏移。这个偏移会由LAMP[35]中进行补偿。 Loosely-coupled architecture： 与其他先进工作相比[16-18]，LION的前后端是松耦合的（即估计的状态x不包含特征点或激光扫描），目的是与建图模块[35]共享计算资源。此外，这种架构通过在选择前端/后端算法中的模块化时决定，并在单个估计引擎的情况下分配几个估计引擎之间的风险以消除单点故障。 Not feature-based： 不同于[18],LION并没有使用特征点进行匹配，原因有两个，以是特征提取耗费计算资源，这将会降低板载资源的运行性能，另外，LION旨在探索完全未知的环境，在那里可以有人类制造的结构（充满了角点，平幔和线条）或完全非结构化的地形。这种不确定环境的特征提取的使用造成了在环境中的先验，因此引起风险或故障。 Automatic extrinsic calibration：激光雷达与IMU的标定非常重要，特别是旋转方面，由于小误差可以快速地积累并导致大漂移。离线标定的方法通常需要校准目标[36]或特定运动序列[37]。 Supervisory Algorithm：LION被设计成由HeRO[4]调用的多种里程计源之一，并且根据可观测性度量进行自主切换。","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"UPSLAM论文阅读","slug":"UPSLAM论文阅读","date":"2021-06-08T02:03:53.000Z","updated":"2022-04-11T15:57:06.354Z","comments":true,"path":"2021/06/08/UPSLAM论文阅读/","link":"","permalink":"http://yoursite.com/2021/06/08/UPSLAM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"UPSLAM: Union of Panoramas SLAM 此文表达，晦涩难懂 摘要 提出一种基于全景深度图的建图系统，全景图像可有效捕获由旋转激光雷达获取的范围测量，在大约数百万立方米的空间地图中记录厘米级别的细节。通过手持传感器收集的数据并同时运行建图程序来证明系统的灵活性，在NVIDIA-Jestion-AGX-Xavier系统中，在线的3D建图更新时间小于10毫秒。 介绍 SLAM中的挑战： 运动：运动是否快速？是地面行驶还是空中飞行器？地面是否平坦？ 几何：目标环境是否有足够的特征（平面、角点、边缘）？ 性能：准确性、计算效率、环境规模扩展性 本文提出一种尽可能多的利用传感器数据的方法，并通过以下实验来验证提出方法的鲁棒性，其中包括：行走、跑步、小型轮式机器人、腿式机器人平台、无人机平台，以及汽车从室内杂乱的环境中到地下隧道再到野外森林再到公路。 对实验结果进行量化分析，其轨迹误差仅为轨迹长度的0.05%，其在15W功率的平台上运行，轨迹长度为4.4公里。 在这项工作中，环境被代表为一系列全景深度图，这个选择允许我们使用二维数组的来表示我们的局部地图，我们的实施能够有效利用这种表示所提供的常规内存访问模式和并行性，结果表明，即使在嵌入式GPU平台上也运行很快。 另外一个重要的结论是，我们能够利用所有可用的激光测量数据，并且避免了早期关于特征的决定，或者说，利用所有数据提供了额外的鲁棒性，使得提出的方法可以适用于各种环境。 具体方法 UPSLAM的地图是一个graph，其中，该图以平面法向量估计增强的全景深度图作为节点，并以这些深度图关键帧之间的相对位姿关系作为边。 关键帧可能具有不同的分辨率和扩展区，而不是原始传感器数据，我们通常使用比传感器捕获更宽的关键帧垂直视野进行操作。随着每个帧的LIDAR扫描更新，系统会跟踪当前的关键帧。这里描述的实验使用Ouster os1-64进行，33\\(^\\circ\\)垂直视场角，10Hz。另外，由IMU提供100Hz的加速度、角速度信息。 数据输入 在快速运动期间，LIDAR扫描的100ms周期可包括显着的传感器运动，因此首先在CPU上进行运动畸变矫正。 接下来的所有步骤都在GPU上进行。 经过矫正后的点将投影到一个全景图像中，图像结构有助于计算一个大致的平面法向量估计，即利用某个点与其他两个最近点的叉乘来计算得到。这些表面法向量估计再次使用图像来表示，但是噪声非常大，可以使用如à trous wavelet filter滤波器等边缘敏感的平滑算法进行有效地平滑[12]。 运动估计 对于每一帧新来的深度图和平面法向量估计，都使用基于点-面距离误差衡量的ICP进行配准[13,14]，如下式所示： \\[ \\mathbf{E}(\\mathrm{T})=\\sum_{\\left(s_{1}, s_{2}\\right) \\in C \\wedge \\Omega_{d, \\theta}\\left(s_{1}, s_{2}\\right)}\\left|\\left(\\mathrm{T} s_{2}-s_{1}\\right) \\cdot N\\left(s_{1}\\right)\\right| \\] 其中，我们定义一个位姿变换\\(T\\)，旨在最小化投影点对\\(C\\)之间的距离。另外，还使用了一个相似性滤波器，用于拒绝距离较大、平面法向量夹角相差较大的关联点对。这个方法很容易在GPU上实现[15]。 扫描的表面正常估计可能略微通过à trous wavelet filter滤器平滑，但这种平滑有助于优化收敛，特别的，每次扫描都会更新关键帧表面法线估计，从而恢复因平滑而丢失的一些细节。 在建图系统的鲁棒性方面，一个重要因素是有多少个点参与到优化中。图2显示了典型实验的有效点的数量，其中有效点的定义为：从激光雷达有效测距范围内的点且点的强度值大于给定阈值。在图中所示的示例中，传感器在隧道中的墙壁附近开始，但是一旦出现进入开放环境时，在10Hz扫描速率下达到了40,000~50,000个点。 关键帧更新 优化的变换矩阵为最后的投影关联集合提供了基础，其中，每个关键帧像素都被投影到扫描的深度图上。使用相似性过滤器来确定新的扫描数据是否应该对关键帧像素的进行平均。 在更新关键帧时使用加权平均值：每个关键帧像素跟踪已结合到其中的样本数量，当大于10时，将被用于确定加权权重。 移动物体可以在单个关键帧中应对平滑和响应性的平衡，但考虑多个关键帧重建3D占用率的潜在多假设模型，这是一种从地图中过滤移动对象的有效工具。当切换关键帧时，执行关键帧之间的相互一致性检查，以减少移动对象的影响。 更新后，将决定是否应该继续使用当前关键帧。如果配准的得分定义为ICP配准到深度图上的内点比例低于阈值，则会寻找新的关键帧。并且，会根据pose graph来对最近的节点进行闭环检测。 由于在显着漂移的影响下可能发生闭环配准，因此使用低分辨率的投影配准的方法对数百个网格搜索，得到候选闭环。然后使用full-ICP来进行配准，如果配准的质量高于创建一个新的关键帧的阈值，那么将会增加一条边，并且该闭环候选作为新的关键帧。除此以外，如果内点比例大于75%，将会使用full-ICP的配准结果对pose graph进行更新（反向传播更新），我们将这些分为strong和weak的闭环：这两个闭环都提高了地图的全局准确性，但是强闭合还会减少关键帧的数量。 Pose graph使用了GTSAM，CPU上运行，另外，使用了基于IMU的互补滤波器，用于估计重力向量并对每一个关键帧添加约束到GTSAM，这种观测信息将有助于减少pitch方向的误差。 自带数据集实验 校园——室内 mapping的第一次测试是在实验室空间散步145米，以1-2米/秒的速度移动。 使用50个关键帧图像捕获80个MIB在磁盘上捕获图3所示的地图。 虽然这里的运动是良性的，但是图底部围绕着角截面的玻璃，以及几个狭窄的通道，由于传感器无法可靠地检测玻璃或墙壁近50厘米的玻璃或墙壁，提供了一些挑战 校园——室外 手持传感器，沿着375米的循环沿大学校园内的建筑物群，在2-3米/秒。 所得到的点云，如图4所示，当传感器在其在图4A的下部附近的树木附近的起始位置约为10米的单环闭合时，从单环闭合所形成的。 选择运行的步伐，以强调由于摇动和弹跳而具有高幅度旋转的非平面运动 农场 地下 Robot沿着220米的轨迹在一座古老的煤矿中散步，采集了如图6中所示的底图，共有44个全景图像。该实验提供了与前面描述的运动模型的实际不同的运动模型，因为矿井的湿法砾石地板意味着机器人必须不断地工作以保持其平衡。 滴水，雾和灰尘对单独的激光雷达扫描有很大的噪音 空中 车载 前面几个实验的参数 参数 值 激光雷达 Ouster OS1-64 速度 3m/s 车载实验的参数 参数 值 激光雷达 Ouster OS1-64 速度 13.8m/s 关键帧数量 1045 图片占用 1220MiB 生成地图 20GiB 公开数据集实验 数据集使用了Newer College Dataset[18] 轨迹精度 ATE: 1.4km， 0.77m， 0.05% 算法效率 使用平台：NVIDIA Jetson AGX Xavier 考虑高分辨率，2048x256和低分辨率，1024x128的关键帧 在图13中的每种配置中显示了将新LIDAR扫描到地图中所花费的时间。与Xavier的最大功率预算和高分辨率关键帧采取的中位时间为6毫秒","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"Cross_view_slam论文阅读","slug":"Cross_view_slam论文阅读","date":"2021-06-05T10:03:53.000Z","updated":"2022-04-11T15:57:06.354Z","comments":true,"path":"2021/06/05/Cross_view_slam论文阅读/","link":"","permalink":"http://yoursite.com/2021/06/05/Cross_view_slam%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Any Way You Look at It: Semantic Crossview Localization and Mapping With LiDAR 摘要 GPS是迄今为止最受欢迎的全球本地化方法。 但是，在所有环境中，它并不总是可靠或准确。 SLAM方法使能局部估计能够提供将本地地图注册到全局的局部估计，这对于机器人间协作或人类互动可能是重要的。 在这项工作中，提出了一种利用语义的实时方法，仅使用以自我为中心的 3D 语义标记的 LiDAR 和 IMU 以及从卫星或空中机器人获得的自上而下的 RGB 图像来全局定位机器人。 介绍 提出一种将地面机器人的局部观测信息与来自卫星或无人机的大范围全局地图进行匹配的定位方法，这种方法比传统的基于已知地图定位方法更加具有挑战性，因为对于大多数机器人而言，the overhead views 与 以自我为中心的观测数据有较大不同。因此，在鸟瞰图中直接应用基于特征的配准方法对机器人进行定位通常是无效的。此外，卫星图通常在不同的时间拍摄，这意味着配准方法必须适应季节的变化。 近年来，使用人工神经网络（ANNS）的图像语义分割已成为成熟的技术。地图语义对于cross-view registration是理想的，因为在足够多样化的训练数据中，可提取具有视角和季节不变性的语义信息。此外，从鸟瞰图中提取粗略的语义信息比从the overhead views 中提取更加简单，无论是手工提取还是基于ANN的方法。 与此同时，Lidars在光束密度增加同事，价格和重量下降，因此将它们放在小型移动机器人上现在是实用的。同时应用两种传感技术将可以产生稠密的语义点云。 最近的工作使用了用于cross-view定位的图像语义信息[15]，[16]，但通常没有只有很少的利用了深度信息或环境的有力的结构假设。如基于几何方法如 [3] 通常在没有足够几何结构的环境中失效，相反，我们引入了一种结合这两种信息来源的方法，以实现更强大的语义cross-view定位系统。 主要贡献如下： 提出一种实时的cross-view定位和建图框架，如果鸟瞰地图未知但有界，我们的方法也能够估计它的比例。 我们使用Semantickitti [17]以及我们自己的数据集以及在包括农村和城市环境的各个地点，验证我们所提出的方法。 开源了代码 相关工作 图像匹配 Cross-view localization问题定义为图像匹配问题[12]：给定一个由图片构成的数据库作为全局地图，以及一张待查询的图片作为局部观测。问题可描述为该问题通过获取一些描述符，使得来自多个视图的相同位置的图像在一些潜在的空间中接近。 早期的工作如[18]，[19]，使用局部特征描述符。 Majdik等[11]使用来自Google Street View的图像特征来与四旋翼无人机飞行拍摄图来进行匹配。然而，这些方法往往在极端视角的情况下失效。 这个限制导致了最近兴起的使用孪生神经网络[20], [21]方向，这些网络通过对不同视点的图像使用权重共享的分支网络结构在潜在空间进行交叉关联，来决定两个图像的相似度。整个网络在已知的图像对上训练，在线处理图像对时，这些网络相对较慢，因此不能在机器人应用程序中实时运行，其中必须同时查询许多可能的状态。 基于视觉 图像匹配算法提供了一种将图像与提供的现有图像数据库进行比较的方法，但它们并未明确寻求估计机器人或传感器的位置。定位需要具有pose label或整个航拍地图的图像数据库，如[22]中的描述。在这项工作中，作者使用鸟瞰坐标系中的一系列边缘来代表全局地图，然后在粒子滤波框架中与地面图像进行边缘匹配。但是，通过将全局地图减少为一系列边缘，将会丢弃大量的有用信息。 其他工作如[23]，使用立体图像来生成RGBD图像，然后将它从鸟瞰角度进行渲染生成，然后使用chamfer matching与已知地图进行匹配，尽管如此，这种方法未能解决由季节变化或环境中的动态物体（如人或汽车）等因素引起的摄影变化。 为了更好地应对季节性变化和更加极端的观点变化，最近的工作越来越多地分析了语义的定位使用。Castaldo等 [15]对地面图像分割，并使用homography和地平面将语义特征投影到自上而下的视角。然后开发出一种针对分割图像的语义描述符，并与已知地图进行比较，以在相机位置集合生成对应的热图(heatmap)。然而，改方法并没有利用时间或深度信息，导致大规模定位系统的收敛速度较慢。另外，他们的方法在homography不成立的情况下失效，如路面并非平坦的工况。 类似的工作还有Gawel et al. [16]，为空中图和地面视图生成语意图表示，然后构建描述符以匹配各种合成数据集。 基于激光雷达 Wolcott等人 [24]通过从各种透视图渲染一个已知的高分辨率点云并最大化互相关信息来对相机进行定位。Gawel等人 [3]通过从两个角度构建点云地图并使用几何描述符匹配它们来交叉定位地面和空中机器人。Barsan等人 [25]使用孪生网络实现厘米级定位。虽然上述方法准确和强大，这些方法需要相关环境的预先存在点云图，而我们只需要单个航拍图像。 与基于视觉的方法一样，最先进的基于Lidar的方法利用环境的语义结构。在早期的工作中，Matei等人[26] 从无人机采集的点云来拟合一个最接近的建筑模型，用于创建与地面图像相比的地面预测。 …… 与这些工作相比，我们的框架只需要一个卫星或环境的鸟瞰图，这适合更多的应用。 具体方法 我们的方法由两个主要组件组成：基于ICP的LIDAR SLAM系统 - Panoramas Slam [32]（Upslam） - 以及基于粒子滤波器的语义定位器，如图2所示 定位 粒子滤波器特别擅长处理多模态分布，这在机器人定位问题中经常出现，这将带来计算量的问题，我们通过使用优化策略来减少计算成本： 问题描述 对于2D地图的定位，我们系统状态\\(x\\)由tuple(\\(p\\in SE(2) , s \\in [S_{min},S_{max}]\\))构成，其中，\\(p\\)表示机器人位姿，\\(s\\)表示地图尺度(px/m)。我们还有控制输入量\\(u\\in SE(3)\\)，从上一帧到当前帧的相对位姿变换，该值来源于UPSLAM或者其他里程计。 因此，对于每个时间步t，都有一个运动模型\\(P(x_t|x_{t-1},u_{t-1})\\)。此外，在每个时刻t，我们都有来自LiDAR和cameras的语义扫描\\(z_t\\)，为了定义我们的粒子滤波器，我们必须先定义观测模型\\(P(z_{t}|x_{t})\\) 运动模型 实际上，我们并不能获取真正的控制输入量，而是从frame-to-frame的估计中获取一个近似。 因为UPSLAM在3D空间中操作，因此我们首先将帧间运动投影到local的x-y地平面上，记为\\(\\operatorname{proj}(u) \\in SE(2)\\)。此外，我们只使用UPSLAM的基于ICP的初始解作为运动估计，忽略了来自闭环后的优化位姿（这是为了避免里程的运动不连续性）。 最后，我们假设分布具有恒定的协方差，在log-space中具有尺度噪声，因此，有： \\[ \\begin{aligned} P\\left(x_{t} \\mid x_{t-1}, u_{t-1}\\right)=(&amp;\\left[\\operatorname{proj}\\left(u_{t-1}\\right)+\\mathcal{N}\\left(0, \\Sigma_{p}\\right)\\right] * p_{t-1},\\left.\\mathcal{N}\\left(1, \\Sigma_{s}\\right) * s_{t-1}\\right) \\end{aligned} \\] 另外，我们使用到起点位置的距离的inverse来对协方差\\(\\Sigma_s\\)进行缩放，以使得可以自然的收敛。一旦尺度方差低于阈值，我们则可固定尺度s。 观测模型 我们的观测\\(z\\)是语义的点云，我们可以表示为在机器人坐标系中具有相关性的标签：\\(z=\\{ (p_1,l_1),(p_2,l_2),\\dots,(p_n,l_n) \\}\\)。因此，我们可以将这些点投影到地平面上。 进一步的，对于任意给定的粒子状态，我们可以对机器人坐标系中的点在俯视的空中地图\\(L\\)中查询，比较地图上的类别与预期类别，在给定粒子状态(位姿为\\(d\\))的条件下，一个简单的计算cost方法如下： \\[ C^{\\prime}=\\sum_{i \\in[1, n]} \\mathbf{1}\\left(L\\left(d * p_{i}\\right) \\neq l_{i}\\right) \\] 为了通过扩大局部最小来提高收敛性，我们选择一个更柔软的成本函数。因此，我们不使用以二进制方式评估cost，而是以机器人坐标系中的点对应的类别为目标类别，在空中地图中查询相同类别的最近点，以两点距离作为cost： \\[ C=\\sum_{i \\in[1, n]} \\min _{\\left\\{p \\mid L(p)=l_{i}\\right\\}}\\left(\\left\\|p-p_{i}\\right\\|\\right) \\] 最后，我们通过对\\(C\\)求逆和正则化来计算一个ad-hoc probability，另外，对于每一个类别的点，可以设置一个权重因子\\(\\alpha_l\\)： \\[ P\\left(z_{t} \\mid x_{t}\\right) \\approx \\frac{n}{\\sum_{i \\in[1, n]} \\min _{\\left\\{p \\mid L(p)=l_{i}\\right\\}}\\left(\\alpha_{l_{i}}\\left\\|p-p_{i}\\right\\|\\right)}+\\gamma \\] 其中，\\(\\gamma\\)是正则化常数项，用于slow convergence??? 所有粒子的概率最后都要进行归一化，以使得所有粒子对应的观测模型概率之和为1。 可以注意到，这是一个ad-hoc观测，在实践中可以通过实验对常数进行调整，然而，这对于基于蒙特卡罗的定位方法并不少见，例如 [29]。 性能优化 如果单纯的实现\\(C^{\\prime}\\)的cost计算，将会导致较大计算成本，因为它总结了所有的非凸最小值的情况。我们通过预先计算空中语义地图关于类别的截断场(Truncated Distance Field, TDF)来优化这个问题，这个计算非常直观，大概需要1分钟，但是只需要进行一次。 这个TDF地图对每一个点到其同类别的最近点的距离阈值进行编码，将最小化\\(C^{\\prime}\\)变成了一个简单的查表。另外，相比于简单的对所有点的结果进行求和，使用了如下方法优化：首先将语义激光扫描分散到极坐标系中，统计在每个极坐标系分割中每个类别的点数。然后局部的类别TDF场使用同种方式渲染显示。然后通过对两个图像的元素进行乘法，得到关于每个类别的内积，来近似\\(C^{\\prime}\\)的计算，提高计算效率。 我们发现，对于100x25像素的极坐标地图，每个粒子大概需要500μs来计算，几乎是用于查表的时间，如图3所示。 另外，地图的旋转在极坐标中表示为索引的偏移，计算非常快，可用于初始化阶段。我们随机采样了地图上的道路点，因为我们有强壮的先验信息：因为是从道路上开始的。对于每一个点，我们初始化\\(k_s\\)个在\\(s_{min}\\)和\\(s_{max}\\)(1~10 px/m)尺度内均匀分布的粒子。对于每一个粒子，我们采样\\(k_{\\theta}\\)个可能的观测，使得我们可以高效的对索引进行偏移（可参考scan-context），然后选取最佳的观测作为初始粒子。 为了进一步加速算法，我们使用CPU并行计算每个粒子的cost，我们还基于高斯混合模型（GMM）的协方差的区域的总和适应粒子分布的基础上的粒子数 语义分割 卫星分割 我们使用在 ImageNet 上预训练的 ResNet-34 [34] 骨干训练两个稍微修改过的完全卷积网络 (FCN) [33] 版本以分割卫星图像，图像直接从Google-Earth中获取。 我们使用了4个类别： road（道路） terrain（地面） vegetation（植被） building（建筑） 为了分析卫星图像，256×256 PX RGB图像被传递为图像分割网络的输入，该网络由3个手工标注的卫星图像数据训练得到，如表1所示。 图像是随机缩放，旋转，裁剪的，并翻转以产生更多的训练样本，卫星图像的随机缩放也允许模型在从多个高度收集的图像上概率更好地泛化。 网络输出例子和训练数据如图5所示。 令人惊讶的是，尽管模型只在3张图片上训练，但是每张图片都包含了许多对象实例 激光扫描分割 我们使用图 2 中绿色方框中显示的两个不同的pipline，用于根据数据集生成语义点云。通过使用不同的分割方法进行测试，展示了我们的方法可以适用于不同的传感系统，提供点级别的标签点云。 PC 对于kitti数据集，使用了与卫星图像分割同样的FCN结构，对于激光扫描，使用带有X,Y,Z,Depth通道的64x2048的2D-Poloar-Grid-Map来表示(没有利用强度信息)。 我们在SemanticKITTI数据集上训练，然后使用序列{10}和{00,02,09}作为验证集和测试集。另外，我们添加地面车辆转化为road类别。 RGB 对于我们自己的Morgantown和Ucity数据集，我们使用不同于Kitti的激光雷达（Ouster OS-1），因此不能使用Semantickitti进行训练。因此，我们使用HRNets[13]来对RGB图像进行分割，然后校准到激光扫描中。利用外参信息，可以将激光点云投影到相机图像帧，然后根据RGB的分割对点云进行分配。 建图 我们使用UPSLAM，但此处给出了在本工作中的一些更改的概况。对于这项工作，我们扩展了UPSLAM，整合从图像中提取的语义标签，以形成语义全景。需要注意的是，UPSLAM并没有使用语义信息来进行scan-matching，只是简单的使用刚体变换信息来整合语义信息。因此，由于我们不需要每一帧扫描的语义数据，我们可以以低于LIDAR的速率来运行推断，而无需删除ICP数据，以提高地图质量。深度、法向量、语义全景如图4所示。 除了使用UPSLAM估计的粒子过滤器运动模型之外，我们还计算每个更新的后粒子滤波器估计的协方差和均值。一旦协方差低于阈值\\(\\Sigma_t\\)，我们使用粒子滤波器估计的位置作为位子图中对应状态节点的先验，最终得到如图2所示的pose graph。 通过这样的方式，我们使得图优化结果与地理保持对齐，我们的实验表明，添加这些语义约束边可去除漂移，并有效地构建语义闭环约束。这使得建图器在没有闭环的情况下可以应对更大规模的轨迹，并保持全局一致性。 实验 参考文献 [1] W.Maetal.,“Findyourwaybyobservingthesunandothersemanticcues,”in Proc. IEEE Int. Conf. Robot. Automat., May 2017, pp. 6292–6299. [2] T. Dang et al., “Autonomous search for underground mine rescue using aerial robots,” in Proc. IEEE Aerosp. Conf., 2020, pp. 1–8. [3] A. Gawel et al., “3D registration of aerial and ground robots for disaster response: An evaluation of features, descriptors, and transformation esti- mation,” in Proc. IEEE Int. Symp. Saf., Secur. Rescue Robot., Oct. 2017, pp. 27–34. [4] J. Peterson et al., “Online aerial terrain mapping for ground robot naviga- tion,” Sensors, vol. 18, no. 2, Feb. 2018, Art no. 630. [5] N. Michael et al., “Collaborative mapping of an earthquake-damaged building via ground and aerial robots,” J. Field Robot., vol. 29, no. 5, pp. 832–841, 2012. [6] X. Liang, H. Wang, Y. Liu, W. Chen, and T. Liu, “Formation control of non- holonomic mobile robots without position and velocity measurements,”IEEE Trans. Robot., vol. 34, no. 2, pp. 434–446, Apr. 2018. [7] A. Franchi, G. Oriolo, and P. Stegagno, “Mutual localization in multi- robot systems using anonymous relative measurements,” Int. J. Robot. Res., vol. 32, no. 11, pp. 1302–1322, 2013. [8] A. Howard, “Multi-robot simultaneous localization and mapping using particle filters,” Int. J. Robot. Res., vol. 25, no. 12, pp. 1243–1256, 2006. [9] S. Wang et al., “A novel approach for lidar-based robot localization in a scale-drifted map constructed using monocular slam,” Sensors, vol. 19, no. 10, 2019, Art. no. 2230. [10] F. Dellaert, D. Fox, W. Burgard, and S. Thrun, “Monte Carlo localization for mobile robots,” in Proc. IEEE Int. Conf. Robot. Automat., vol. 2, 1999, pp. 1322–1328 vol.2. [11] A. L. Majdik, Y. Albers-Schoenberg, and D. Scaramuzza, “MAV urban localization from google street view data,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Nov. 2013, pp. 3979–3986. [12] X. Gao, S. Shen, Z. Hu, and Z. Wang, “Ground and aerial meta-data integration for localization and reconstruction: A review,” Adv. Visual Corresp.: Models, Algorithms Appl., Pattern Recognit. Lett. vol. 127, pp. 202–214, 2019. [13] J. Wang et al., “Deep high-resolution representation learning for visual recognition,” IEEE Trans. Pattern Anal. Mach. Intell., early access: Apr. 01, 2020, doi: 10.1109/TPAMI.2020.2983686. [14] M. Wu, C. Zhang, J. Liu, L. Zhou, and X. Li, “Towards accurate high resolution satellite image semantic segmentation,” IEEE Access, vol. 7, pp. 55 609–55 619, 2019. [15] F. Castaldo, A. Zamir, R. Angst, F. Palmieri, and S. Savarese, “Semantic cross-view matching,” in Proc. IEEE Int. Conf. Comput. Vis. Workshops, Dec. 2015, pp. 9–17. [16] A. Gawel, C. D. Don, R. Siegwart, J. Nieto, and C. Cadena, “X-view: Graph-based semantic multi-view localization,” IEEE Robot. Automat. Lett., vol. 3, no. 3, pp. 1687–1694, Jul. 2018. [17] J. Behley et al., “SemanticKITTI: A dataset for semantic scene under- standing of LiDAR sequences,” in Proc. IEEE/CVF Int. Conf. Comput. Vis., 2019, pp. 9297–9307. [18] D.M. Chen et al., “City-scale landmark identification on mobile devices,”in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2011, pp. 737–744. [19] Y. Li, N. Snavely, and D. P. Huttenlocher, “Location recognition using prioritized feature matching,” Computer Vision – ECCV, K. Daniilidis, P. Maragos, and N. Paragios, eds. Springer Berlin Heidelberg, 2010, pp. 791–804. [20] D. Kim and M. R. Walter, “Satellite image-based localization via learned embeddings,” in Proc. IEEE Int. Conf. Robot. Automat., May 2017, pp. 2073–2080. [21] Y. Tian, X. Deng, Y. Zhu, and S. Newsam, “Cross-time and orientation- invariant overhead image geolocalization using deep local features,” in Proc. IEEE Winter Conf. Appl. Comput. Vis., 2020, pp. 2512–2520. [22] K. Y. K. Leung, C. M. Clark, and J. P. Huissoon, “Localization in urban environments by matching ground level video images with an aerial image,” in Proc. IEEE Int. Conf. Robot. Automat., May 2008, pp. 551–556. [23] T. Senlet and A. Elgammal, “A framework for global vehicle localization using stereo images and satellite and road maps,” in Proc. IEEE Int. Conf. Comput. Vis. Workshops, Nov. 2011, pp. 2034–2041. [24] R. W. Wolcott and R. M. Eustice, “Visual localization within lidar maps for automated urban driving,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Sep. 2014, pp. 176–183. [25] I. A. Barsan, S. Wang, A. Pokrovsky, and R. Urtasun, “Learning to localize using a lidar intensity Map,” in Proc. 2nd Conf. Robot Learn., Proc. Mach. Learn. Res., A. A. Billard Dragan, J. Peters, and J. Morimoto, Eds. PMLR, 29-31, vol. 87, Oct. 2018, pp. 605–616. [26] B. C. Matei et al., “Image to LiDar matching for geotagging in urban environments,” in Proc. IEEE Workshop Appl. Comput. Vis., Jan. 2013, pp. 413–420. [27] T. Senlet, T. El-Gaaly, and A. Elgammal, “Hierarchical semantic hashing: Visual localization from buildings on maps,” in Proc. 22nd Int. Conf. Pattern Recognit., Aug. 2014, pp. 2990–2995. [28] Y. Tian, C. Chen, and M. Shah, “Cross-view image matching for geo- localization in urban environments,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jul. 2017, pp. 3608–3616. [29] F. Yan, O. Vysotska, and C. Stachniss, “Global localization on open- streetmap using 4-bit semantic descriptors,” in Proc. Eur. Conf. Mobile Robots, 2019, pp. 1–7. [30] E. Stenborg, C. Toft, and L. Hammarstrand, “Long-term visual localization using semantically segmented images,” in Proc. IEEE Int. Conf. Robot. Automat., 2018, pp. 6484–6490. [31] Y. Liu, Y. Petillot, D. Lane, and S. Wang, “Global localization with object- level semantics and topology,” in Proc. Int. Conf. Robot. Automat., 2019, pp. 4909–4915. [32] A. Cowley, I. D. Miller, and C. J. Taylor, “UPSLAM: Union of panoramas SLAM,” in Proc. Int. Conf. Robot. Automat., 2021. [33] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2015, pp. 3431–3440. [34] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 770–778. [35] M. Cordts et al., “The cityscapes dataset for semantic urban scene un- derstanding,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 3213–3223. [36] A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous driving? The KITTI vision benchmark suite,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2012, pp. 3354–3361. [37] S. S. Shivakumar, T. Nguyen, I. D. Miller, S. W. Chen, V. Kumar, and C. J. Taylor, “Dfusenet: Deep fusion of RGB and sparse depth information for image guided dense depth completion,” in Proc. IEEE Intell. Transp. Syst. Conf., 2019, pp. 13–20.","categories":[],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"}]},{"title":"Incremental-Segment-Based Localization in 3-D Point Clouds","slug":"Incremental_Segmental_localization","date":"2021-05-09T14:55:30.000Z","updated":"2021-05-09T15:02:58.000Z","comments":true,"path":"2021/05/09/Incremental_Segmental_localization/","link":"","permalink":"http://yoursite.com/2021/05/09/Incremental_Segmental_localization/","excerpt":"","text":"Incremental-Segment-Based Localization in 3-D Point Clouds","categories":[],"tags":[]},{"title":"Adjoints and Covariances（伴随与协方差）","slug":"SE3伴随","date":"2021-05-09T14:55:30.000Z","updated":"2022-04-11T15:57:06.354Z","comments":true,"path":"2021/05/09/SE3伴随/","link":"","permalink":"http://yoursite.com/2021/05/09/SE3%E4%BC%B4%E9%9A%8F/","excerpt":"","text":"Adjoints 我们将介绍李群伴随的概念，这将帮助我们将右边的增量或矫正值与左边的增量或校正值联系起来。这种性质使我们能够用代数方法处理李群定义的不确定性，并得到不同协方差变换的表达式。我们将重点讨论3D构造，即 SE (3)，因为它的广泛适用性，但类似的定义应该适用于其他李群，因为他们主要依赖于伴随的定义。 Barfoot 和 Furgale (2014年)和 Mangelson 等人(2020年)的文献中已经出现了大多数这样的表达式，但由于它们遵循左手惯例，所以不能直接用于 GTSAM。我们为 Mangelson 等人之后的协方差变换提供了结果表达式，但是我们建议参考他们的工作来理解这个过程的细节。 让我们考虑一个例子，我们在一个姿态\\(\\mathbf{T}_{WB_i}\\)加入小增量\\(_{B_i}\\mathbf{\\xi}\\): \\[ \\begin{aligned} \\mathbf{T}_{W_i B_{i}} \\text{Exp}( _{B_i}\\mathbf{\\xi}) \\end{aligned} \\] 以上遵循了right-hand定则，与GTSAM一致 然而，一些应用则使用left-hand的形式: \\[\\begin{aligned} \\mathbf{T}_{W_{i+1} B} = \\text{Exp}( _{W_i}\\mathbf{\\xi}) \\mathbf{T}_{W_i B_i} \\end{aligned}\\] 那么，对应的就是参考坐标系的增量变化： 实际上，两种表达的意义都是一样的： 即有如下等式(暂时忽略时间索引)： \\[ \\begin{aligned} \\text{Exp}( _{W}\\mathbf{\\xi}) \\mathbf{T}_{WB} = \\mathbf{T}_{WB} \\text{Exp}( _{B}\\mathbf{\\xi}) \\end{aligned} \\] 进一步的，就可以根据body系的增量来求出world系的增量： \\[ \\begin{aligned} \\text{Exp}( _{W}\\mathbf{\\xi}) = \\mathbf{T}_{WB} \\text{Exp}( _{B}\\mathbf{\\xi}) \\mathbf{T}_{WB}^{-1} \\end{aligned} \\] 对于我们的目的，使用一个等价的替代表达式是有用的，它直接应用于切空间的元素(solà等人给出了一个更完整的推导，由于一些属性我们在这里省略了) : \\[ \\begin{aligned} \\text{Exp}( _{W}\\mathbf{\\xi}) \\mathbf{T}_{WB_i} = \\mathbf{T}_{WB_i} \\text{Exp}( \\text{Ad}_{T_{WB_i}^{-1}} {_{W}}\\mathbf{\\xi}) \\end{aligned} \\] 其中，\\(\\text{Ad}_{T_{WB_i}^{-1}}\\)称为\\(T_{WB_i}^{-1}\\)的伴随，伴随直接作用于切线空间的元素上，改变它们的参考坐标系，即： \\[ {_{B}}\\mathbf{\\xi} = \\text{Ad}_{T_{WB_i}^{-1}} {_{W}}\\mathbf{\\xi} \\] 我们也可以把这解释为一种方法，将左边(在世界坐标系中)施加的增量一致地移动到右边(body坐标系) ，这对于保持右边惯例对于回溯和概率分布的一致性特别有用。 这是我们用来定义一些协方差转换的主要属性，并且它已经在GTSAM的Pose3中实现为AdjointMap。 Distribution of the inverse 考虑这样一种情况: 我们有一个因子图的解，其协方差定义在body坐标系中。我们感兴趣的是获得一个表示world坐标系的协方差表达式. 给定body坐标系的协方差\\(B_i\\)(左图)，然而我们感兴趣的是右图的世界坐标系的协方差\\(W\\) 假设具有正态分布的位姿表达如下： \\[\\begin{aligned} \\mathbf{\\tilde{T}}_{WB} = \\mathbf{T}_{WB} \\text{Exp}( _{B}\\mathbf{\\eta}) \\end{aligned}\\] 其中，\\(_{B}\\mathbf{\\eta}\\)是协方差为\\(\\Sigma_{B}\\)的零均值高斯分布噪声，因此，逆位姿的分布可以通过对位姿表达式求逆： \\[ \\begin{aligned} (\\mathbf{\\tilde{T}}_{WB})^{-1} &amp; = (\\mathbf{T}_{WB} \\text{Exp}( _{B}\\mathbf{\\eta}) )^{-1}\\\\ &amp; = (\\text{Exp}( _{B}\\mathbf{\\eta}) )^{-1}\\ \\mathbf{T}_{WB}^{-1}\\\\ &amp; = \\text{Exp}(- _{B}\\mathbf{\\eta}) \\ \\mathbf{T}_{WB}^{-1} \\end{aligned} \\] 然而，在求逆后，噪声项被定义在左边，并且仍然是body坐标系下的表达，接下来使用伴随来将这一项移到右边: 1.根据前面推导的: \\[ \\begin{aligned} \\text{Exp}( _{W}\\mathbf{\\xi}) \\mathbf{T}_{WB_i} = \\mathbf{T}_{WB_i} \\text{Exp}( \\text{Ad}_{T_{WB_i}^{-1}} {_{W}}\\mathbf{\\xi}) \\end{aligned} \\] 2.应用于位姿的逆表达（等号右侧），则有： \\[ \\begin{aligned} \\text{Exp}( -{_{B}}\\mathbf{\\eta}) \\mathbf{T}_{WB}^{-1} = \\mathbf{T}_{WB}^{-1} \\text{Exp}( -\\text{Ad}_{T_{WB}} {_{B}}\\mathbf{\\eta}) \\end{aligned} \\] 3.因此，有： \\[ \\begin{aligned} (\\mathbf{\\tilde{T}}_{WB})^{-1} = \\ \\mathbf{T}_{WB}^{-1}\\ \\text{Exp}(- \\text{Ad}_{\\mathbf{T}_{WB}} {_{B}}\\mathbf{\\eta}) \\end{aligned} \\] 最终，得到了符合right-hand的分布，其中定义了world坐标系的协方差，如下： \\[ \\begin{aligned} \\Sigma_{W} = \\text{Ad}_{\\mathbf{T}_{WB}} \\Sigma_B \\text{Ad}_{\\mathbf{T}_{WB}}^{T} \\end{aligned} \\]","categories":[],"tags":[]},{"title":"LiDAR-Camera 标定-5","slug":"传感器标定/LIDAR_CAMERA标定_5","date":"2021-04-26T20:55:30.000Z","updated":"2022-04-11T15:57:06.370Z","comments":true,"path":"2021/04/27/传感器标定/LIDAR_CAMERA标定_5/","link":"","permalink":"http://yoursite.com/2021/04/27/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/LIDAR_CAMERA%E6%A0%87%E5%AE%9A_5/","excerpt":"","text":"3D激光雷达与全向相机外参标定 摘要 我们提出了一种使用全向摄像头系统对3D激光扫描仪进行外部校准的方法，该程序要求至少从3个视角同时从激光扫描仪和相机系统观察平面棋盘格图案，棋盘格的平面法向量和位于表面的3D点约束了激光扫描仪和全向相机系统的相对姿态，这些约束可用于形成外参标定的非线性优化问题，用于求解外参以及对应的协方差。 介绍 Scaramuzza et al. (2007).首先提出3d激光雷达与全向相机的外参标定问题，他们提出了使用手动选择关联点的方法完成标定。 本文提出的方法不需要手动选取对应点的3d激光雷达与全向相机的外参标定方法。 方法 在我们的校准程序中，我们使用安装在平面表面上的棋盘图案，我们将从现在开始将其称为目标平面，外部校准的近似设置以及用于实验的感知传感器（Velodyne HDL-64e 3D激光扫描仪和Pointgrey Ladybug3全向相机在图1中示出。 激光雷达内参标定 有关传感器的更多技术细节，参见McBride（2008）。 计算出的范围测量\\(D_l\\)由于TOF计算中的误差而包含一些偏差，因此具有来自实际测量的偏置校正\\(\\delta D\\)，因此制造商通常会为每条线束提供一个标定值\\(\\delta D\\)来进行补偿，通常使用图2的方法： 激光扫描仪安装在壁前的支撑件上，并且通过考虑墙壁和激光扫描仪之间的手动测量距离来计算范围测量中的偏移量： \\[ \\delta D = D_m -D_l \\] \\(D_m\\)是墙与雷达之间的距离手工测量值 \\(D_l\\)是tof测量值 我们提出了一种鲁棒的方法来在范围测量中自动计算这种最佳偏移\\(\\delta D\\)。 与制造商采用的校准方法相反，该方法仅要求用户将激光雷达放置于墙或者平面的前面，然后记录测量数据，如图3所示。 在墙壁或平面表面前方的传感器平台的不同位置记录激光测量。 现在，如果我们使用（1）中计算的\\(\\delta D\\)校正，并考虑躺在墙壁上的点，它们应该都是共面的。 但是由于\\(\\delta D\\)并非真值，因此这些点的重投影误差是显著的。因此可以通过最小化重投影误差来求解。 我们使用Ransac（Fischler和Bolles（1981））来估算在墙壁上的所有点的最佳拟合平面的等式，首先生成一个包含目标平面以及潜在激光点的边界框。然后，这些潜在激光点\\(\\{\\tilde{Q}_l^i ; i=1,2,\\cdots,N\\}\\)用于RANSAC进行平面拟合并返回内点。RANSAC步骤如下： 随机选取3个点from\\(\\{\\tilde{Q}_l^i ; i=1,2,\\cdots,N\\}\\) 求解3个点的平面方程 遍历其他点，寻找内点 重复，直到找到最佳平面方程 对RANSAC的最终结果进行参数化，\\(\\mathbf{N}=[n_x,n_y,n_z]^{\\mathbf{T} }\\)，其中\\(\\|\\mathbf{N}\\|\\)表示平面到坐标系原点的距离。 因此，平面中的点\\(\\tilde{P}=[X,Y,Z]^{T}\\)在平面法向量\\(\\mathbf{N}\\)的投影等价于平面距离\\(\\|\\mathbf{N}\\|\\)，即： \\[ \\mathbf{P}\\cdot\\mathbf{N} = \\|\\mathbf{N}\\|^{2} \\] 记\\(D\\)为点的距离，\\(\\theta\\)和\\(\\omega\\)分别记为俯仰角和方位角，则有： \\[ \\begin{aligned} X &amp;=D \\cos \\theta \\sin \\omega, \\\\ Y &amp;=D \\cos \\theta \\cos \\omega \\\\ Z &amp;=D \\sin \\theta \\end{aligned} \\] 所以，使用平面法向量表示的点距离可以表示为（联合上面所有式子可得）： \\[ D=\\frac{\\|\\mathbf{N}\\|}{n_{x} \\cos \\theta \\sin \\omega+n_{y} \\cos \\theta \\cos \\omega+n_{z} \\sin \\theta} \\] 所以，我们现在获得了从RANSAC方法获得的点距离，以及激光雷达本身直接返回的点距离，可以构造如下非线性最小二乘： \\[ \\delta D_{i}^{\\prime}= \\underset{\\delta D_{i}^{\\prime} }{\\operatorname{argmin} } \\sum_{i=1}^{64} \\sum_{j=1}^{n} \\left\\|D_{i j}-\\left(D_{l_{i j} }+\\delta D_{i}^{\\prime}\\right)\\right\\| \\] \\(D_{i j}\\)是根据RANSAC计算的平面方程后得到的点距离 \\(D_{l_{i j} }\\)是雷达直接返回的测距值 经过补偿之后的结果如图4所示： 全向相机 PointGrey Ladybug 3（LB3）是高分辨率全向摄像机系统，它有六个200万像素摄像头，其中五个CCD位于水平环中，另外一个位于垂直方向，使系统能够从超过80％的球形范围内收集视频。 摄像机由制造商预校准，因此单个相机的内在参数是已知的，同样的，以公共坐标系为参考基准（称为camera head），所有摄像头相对于参考坐标系的刚体变换也是已知的。 因此，我们需要估计camera head的姿势（相对于一些本地参考帧），以便我们可以代表相机头帧中的任何3D点，然后到任何相机的坐标系。 激光雷达与全向相机外参标定 外参标定方法与Zhang(2004)的方法相似，要求系统在不同的位姿观察平面pattern（如棋盘格），并根据激光雷达和相机同时观测的数据建立约束。 目标平面的法向量以及平面上的激光点之间存在关系，可用于约束相机和激光雷达的相对位姿关系。我们已知目标平面的方程，为了方便起见，以该平面构建坐标系，令 \\[ Z=0 \\] 令： \\(\\tilde{P}_{w}\\)为在世界参考坐标系中的点(此处是attach到目标平面的坐标系) \\({ }_{w}^{c_{i} } R\\)是从世界坐标系\\(w\\)到第i帧相机坐标系\\(c_i\\)的旋转变换 \\({}^\\mathrm{c_i}\\mathrm{t}_{\\mathrm{c}_{\\mathrm{i} } \\mathrm{w} }\\)是平移量 因此，将一个世界参考坐标系中的点转换到第i帧相机参考坐标系可表示为： \\[ \\tilde{P}_{c_{i} }={ }_{w}^{c_{i} } R \\tilde{P}_{w}+{ }^{\\mathbf{c}_{\\mathbf{i} } } \\mathbf{t}_{\\mathbf{c}_{\\mathbf{i} \\mathbf{w} } } \\] 其中， \\(\\tilde{P}_{c_{i} }\\)是世界坐标系投影到第i帧相机坐标系的点 由于已知每个相机与camera head的相对位姿\\({ }_{c_{i} }^{h} R,{ }^{\\mathrm{h} } \\mathbf{t}_{\\mathbf{h c}_{\\mathbf{i} } }\\)，因此可以将第i个相机坐标系中的点转换到camera head坐标系中： \\[ \\tilde{P}_{h}= { }_{c_{i} }^{h} R \\tilde{P}_{c_{i} }+{ }^{\\mathbf{h} } \\mathbf{t}_{\\mathbf{h c}_{\\mathbf{i} } } \\] 因此，如果已知\\({ }_{w}^{c_{i} } R\\),\\({}^\\mathrm{c_i}\\mathrm{t}_{\\mathrm{c}_{\\mathrm{i} } \\mathrm{w} }\\)，就可以将世界坐标系中目标平面上的点\\(\\tilde{P}_w\\)转换到camera head坐标系中。 论文采用了(Zhang (1998))的方法来获取相对目标平面（也就是棋盘格坐标系作为世界坐标系）的位姿变换。 特别的，对于pin-hole相机模型，3d点投影关系如下： \\[ \\tilde{p} = K_i T_{w}^{ci} \\tilde{P}_{w} \\] 其中， \\(K_i\\)为3x4矩阵，是第i个相机的内参矩阵 \\(\\tilde{P}_{w}\\)为世界参考坐标系（棋盘格坐标系）下的点的齐次表达形式\\(\\tilde{P}_{w}=\\left[\\begin{array}{llll}X &amp; Y &amp; Z &amp; 1\\end{array}\\right]^{\\top}\\) \\(\\tilde{p}\\)为投影得到的图像点\\(\\tilde{p}=[u , v , 1]^{\\top}\\) \\(T_{w}^{ci}\\)为外参，是世界坐标系到相机坐标系的变换 假设图像点受独立同分布的噪声影响，外参\\(T_{w}^{ci}\\)的最大似然估计可以使用如下最小化重投影误差来表示： \\[ \\underset{ { }_{w}{ }_{i} R,{ }^{\\mathrm{c} } \\mathbf{i} \\mathbf{t}_{\\mathbf{c}_{\\mathbf{w} } \\mathbf{w} } }{\\operatorname{argmin} } \\sum_{k=1}^{n} \\sum_{j=1}^{m}\\left\\|p_{\\hat{k} j}-K_{i}\\left[{ }_{w}^{c_{i} } R{ }^{\\mathbf{c}_{\\mathbf{i} } } \\mathbf{t}_{\\mathbf{c}_{\\mathbf{i} \\mathbf{w} } }\\right] \\tilde{P}_{j}\\right\\| \\] 其中， \\(n\\)表示n张图片 \\(m\\)表示每张图片对应的m个点 \\({ }_{w}^{c_{i} } R=[\\boldsymbol{r}_1,\\boldsymbol{r}_2,\\boldsymbol{r}_3]\\) \\({}^\\mathrm{c_i}\\mathrm{t}_{\\mathrm{c}_{\\mathrm{i} } \\mathrm{w} }\\)使用3维欧氏向量表示 因此，根据: \\[ \\begin{aligned} Rp+t &amp;= P_{new} \\\\ p &amp;= R^{-1}(P_{new}-t) \\end{aligned} \\] 有：在第i个相机坐标系中的目标平面方程可以写成（利用平面\\(Z=0\\)的条件）： \\[ \\mathbf{r}_{3} \\cdot\\left(\\mathbf{p}+{ }^{\\mathbf{c}_{\\mathbf{i} } } \\mathbf{t}_{\\mathbf{c}_{\\mathbf{i} \\mathbf{w} } }\\right)=0 \\] 其中， \\(\\boldsymbol{r}_3\\)是旋转矩阵\\({ }_{w}^{c_{i} } R\\)第三列 旋转矩阵\\({ }_{w}^{c_{i} } R\\)第三列与点做点乘相当于旋转矩阵的转置后的第3行与点做矩阵乘法，得到转换后的点的Z轴分量 同时，\\(\\boldsymbol{r}_3\\)也是世界坐标系（棋盘格坐标系）的法向量方向 \\(\\boldsymbol{p}\\)是相机坐标系中，平面上的点 目标平面的法向量在第i个相机坐标系表示如下： \\[ \\mathbf{N}_{\\mathbf{c}_{\\mathbf{i} } }=\\left(\\mathbf{r}_{\\mathbf{3} } \\cdot{ }^{\\mathbf{c}_{\\mathbf{i} } } \\mathbf{t}_{\\mathbf{c}_{\\mathbf{i} \\mathbf{w} } }\\right) \\mathbf{r}_{\\mathbf{3} } \\] 由于\\(\\boldsymbol{r}_3\\)也是世界坐标系（棋盘格坐标系）的法向量方向，所以\\(\\|\\mathbf{N}_{c_i}\\|= \\mathbf{r}_3 \\cdot { }^{\\mathbf{c}_{\\mathbf{i} } } \\mathbf{t}_{\\mathbf{c}_{\\mathbf{i} \\mathbf{w} } }\\) 表示第i个相机坐标系到目标平面的距离 (注意是点乘) 又因为第i个相机坐标系相对于camera head的位姿变换已知，因此可以计算以camera head坐标系为参考的目标平面法向量\\(\\mathbf{N}_h\\)： （注意，这不是简单的向量做旋转，因为距离也会改变，即\\(\\| N_h\\|\\)是目标平面到camera head坐标系原点的距离），因此还要加上刚体变换的平移部分在法向量方向上的投影 \\[ \\mathbf{N}_{\\mathbf{h} }= \\frac{ { }^{h} R \\mathbf{N}_{\\mathbf{c}_{\\mathbf{i} } } } {\\left\\|\\mathbf{N}_{\\mathbf{c}_{\\mathbf{i} } }\\right\\|} \\left(\\left\\|\\mathbf{N}_{\\mathbf{c}_{\\mathbf{i} } }\\right\\|+\\mathbf{N}_{\\mathbf{c}_{\\mathbf{i} } } \\cdot \\mathbf{h}_{\\mathbf{t} \\mathbf{h c}_{\\mathbf{i} } }\\right) \\] 一旦我们已知了目标平面法向量在camera head坐标系的表示，我们需要找到激光雷达坐标系中在目标平面中的3d点 我们使用上述RANSAC方法来提取这些3d点 上述两种信息为外参标定提供了约束条件 令\\(\\{\\tilde{P}_l^i ; i=1 , 2, \\cdots ,n\\}\\)为提取的目标平面中的激光雷达点，利用待估计的外参，可以转换到camera head坐标系中： \\[ \\tilde{P}_{h}^{i}={ }_{l}^{h} R \\tilde{P}_{l}^{i}+{ }^{\\mathbf{h} } \\mathbf{t}_{\\mathbf{h l} } \\] 现在，如果将一束光线从camera head坐标系开始投射到目标平面上的一点，那么这个射线在平面法向量上的投影就等于从camera head坐标系到目标平面的距离，因此，从m个不同的视角获取数据，可以构造如下目标函数： \\[ F= \\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left(\\frac{\\mathbf{N}_{\\mathbf{h} }^{\\mathbf{i} } }{\\left\\|\\mathbf{N}_{\\mathbf{h} }^{\\mathrm{i} }\\right\\|} \\cdot\\left({ }_{l}^{h} R \\mathbf{P}_{l}^{j}+{ }^{\\mathbf{h} } \\mathbf{t}_{\\mathbf{h l} }\\right)-\\left\\|\\mathbf{N}_{\\mathbf{h} }^{\\mathbf{i} }\\right\\|\\right)^{2} \\] 其中， \\(\\mathbf{N}_{\\mathbf{h} }^{\\mathbf{i} }\\)是目标平面在camera head坐标系中的第i个位姿对应的法向量 第一项表示激光雷达点在camera head坐标系构成的向量，在法向量方向的投影 第二项表示由相机信息获取的camera head坐标系与目标平面的距离 外参标定需要的最少视角个数 需要至少三个目标平面的非共面观点来完全限制优化问题（17）以估计校准参数， 只有一个平面的情况：如图5(a)所示： 当保持姿态不变，沿目标平面萍乡的方向进行平移时，目标函数的值不变 以平面法向量为轴进行旋转时，目标函数的值也不变 相似的，对于只有两个视角的情况：如图5(b)所示： 传感器沿着平面交叉线平移并不改变目标函数值，从而在该方向上产生大的不确定性 估计参数的协方差 通过最小化目标函数得到的参数估计会由于传感器测量的不确定性导致具有一定的误差，如激光雷达测距误差约为0.02m。知道这种不确定性是非常重要的，以便在任何视觉或SLAM算法中使用此处计算的参数。 Haralick（1998）已经描述了通过任何标量非线性优化函数传播测量协方差的方法，唯一的假设是标量函数是非负的，具有有限的第一和二阶偏微分，对于理想数据即其值为零，并且输入中的随机扰动足够小，以便可以近似输出一阶泰勒系列扩张。 前文提出的目标函数满足这些假设，因此可以用这个方法来估计参数的协方差。 假设camera head坐标系相对于激光雷达坐标系可以用参数来表示： \\[ \\Theta=\\left[{ }^{1} \\mathbf{t}_{\\mathbf{l h} }, \\mathbf{\\Phi}_{\\mathbf{l h} }\\right]^{\\top} \\] 其中， \\({ }^{1} \\mathbf{t}_{\\mathbf{l h} }=\\left[t_{x}, t_{y}, t_{z}\\right]^{\\top}\\)表示从h坐标系到l坐标系的平移变换（在l坐标系的表示） \\(\\boldsymbol{\\Phi}_{\\mathrm{lh} }=\\left[\\theta_{x}, \\theta_{y}, \\theta_{z}\\right]^{\\top}\\)表示从h坐标系到l坐标系旋转 关于参数\\(\\Theta\\)的协方差如下： \\[ \\Sigma_{\\Theta}=\\left[\\frac{\\partial^{2} F}{\\partial \\Theta^{2} }(X, \\Theta)\\right]^{-1} \\frac{\\partial^{2} F^{T} }{\\partial X \\partial \\Theta}(X, \\Theta) \\Sigma_{X} \\frac{\\partial^{2} F}{\\partial X \\partial \\Theta}(X, \\Theta)\\left[\\frac{\\partial^{2} F}{\\partial \\Theta^{2} }(X, \\Theta)\\right]^{-1} \\] 其中， \\(X=\\left[\\mathbf{N}_{\\mathbf{h} }^{\\mathbf{1} }, \\tilde{P}_{l}^{1}, \\tilde{P}_{l}^{2} \\ldots \\mathbf{N}_{\\mathbf{h} }^{\\mathbf{i} }, \\tilde{P}_{l}^{1}, \\ldots\\right]^{T}\\)表示观测信息（包括平面法向量和目标平面中的激光点） 实验 仿真实验（略） 真实环境实验 所提出的外在校准方法已经在由安装有3D激光传感器和全向相机系统的车辆收集的实际数据上进行了测试，如图8所示。 我们有两套结果验证算法的准确性，在第一种情况下，我们考虑了类似于校准设置的设置：在车库内进行校准，棋盘图案安装在所有可用的平面表面上（包括侧壁和底层），如图9所示，由不同颜色表示的来自不同平面的点已经投影到相应的图像上。 在第二种情况下，我们将车辆从车库外面带走，并从福特校园周围的行驶中的车辆中收集了一些数据，在全向相机系统的5个摄像机上的5个摄像机上的360度视场的投影的结果如图10所示。 代码库 https://github.com/SubMishMar/cam_lidar_calib","categories":[{"name":"传感器标定","slug":"传感器标定","permalink":"http://yoursite.com/categories/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/"}],"tags":[]},{"title":"UTC Time and GPS Time Conversion","slug":"utc时间与gps时间","date":"2021-04-21T06:55:30.000Z","updated":"2021-04-21T07:50:30.793Z","comments":true,"path":"2021/04/21/utc时间与gps时间/","link":"","permalink":"http://yoursite.com/2021/04/21/utc%E6%97%B6%E9%97%B4%E4%B8%8Egps%E6%97%B6%E9%97%B4/","excerpt":"","text":"时钟系统的前世今生 最近在完善惯导ros驱动，发现GPGGA语句和GPFPD语句输出的时间不一致，一个是utc时间，另一个是gps时间。为了实现时钟同步，就要完成二者之间的转换。 格林威治标准时间（Greenwich Mean Time，GMT） 格林尼治平均时间（Greenwich Mean Time，GMT）是指位于英国伦敦郊区的皇家格林尼治天文台当地的平太阳时，格林尼治标准时间的正午是指当平太阳横穿格林尼治子午线时（也就是在格林尼治上空最高点时）的时间。由于地球每天的自转是有些不规则的，而且正在缓慢减速，因此格林尼治平时基于天文观测本身的缺陷，已经被原子钟报时的协调世界时（UTC）所取代。 自1924年2月5日开始，格林尼治天文台负责每隔一小时向全世界发放调时信息。 世界时（Universal Time, UT） 后来，由于1925年以前人们在天文观测中，常常把每天的起始（0时）定为正午，而不是通常民用的午夜，给格林尼治平时的意义造成含糊，人们使用世界时（Universal Time, UT）一词来明确表示每天从午夜开始的格林尼治平时。 世界时是以地球自转为基准得到的时间尺度，其精度受到地球自转不均匀变化和极移的影响，为了解决这种影响，1955年国际天文联合会定义了UT0、UT1和UT2三个系统： UT0系统是由一个天文台的天文观测直接测定的世界时，没有考虑极移造成的天文台地理坐标变化。 UT1系统是在UT0的基础上加入了极移改正 Δλ，修正地轴摆动的影响。UT1是目前使用的世界时标准。被作为目前世界民用时间标准UTC在增减闰秒时的参照标准。 UT2系统是UT1的平滑处理版本，在UT1基础上加入了地球自转速率的季节性改正 ΔT。 目前使用的世界时测算标准又称UT1。在UT1之前人们曾使用过UT0，但由于UT0没有考虑极移导致的天文台地理坐标变动的问题，因此测出的世界时不准确，现在已经不再被使用。 在UT1之后，由于人们发现，因为地球自转本身不均匀的问题，UT1定义的时间的流逝仍然不均匀，于是人们又发展了一些对UT1进行平滑处理后的时间标准，包括UT1R和UT2，但它们都未能彻底解决定义的时间的流逝不均匀的问题，这些时间标准现在都不再被使用。 原子时（International Atomic Time, TAI） 为了彻底解决定义的时间的流逝不均匀的问题，开始使用原子钟定义时间。人们首先用全世界的原子钟共同为地球确立了一个均匀流动的时间，称为国际原子时（International Atomic Time, TAI）。 1967年第13届国际计量大会上通过一项决议，定义一秒为铯-133原子基态两个超精细能级间跃迁辐射振荡9,192,631,770周所持续的时间。[2][3]其起点为世界时1958年的开始。 原子时起点定在1958年1月1日0时0分0秒（UT），即规定在这一瞬间原子时时刻与世界时刻重合。但事后发现，在该瞬间原子时与世界时的时刻之差为0.0039秒。这一差值就作为历史事实而保留下来。在确定原子时起点之后，由于地球自转速度的问题，使得原子时钟不能与世界时间保持协调。 协调世界时（Coordinated Universal Time, UTC） 为了使定义的时间与地球自转相配合，人们通过在TAI的基础上不定期增减闰秒的方式，使定义的时间与世界时（UT1）保持差异在0.9秒以内，这样定义的时间就是协调世界时（Coordinated Universal Time, UTC）。 协调世界时是最接近格林威治标准时间（GMT）的几个替代时间系统之一。对于大多数用途来说，UTC时间被认为能与GMT时间互换，但GMT时间已不再被科学界所确定。 UTC基于国际原子时，并通过不规则的加入闰秒来抵消地球自转变慢的影响。闰秒在必要的时候会被插入到UTC中，以保证协调世界时（UTC）与世界时（UT1）相差不超过0.9秒。 这就是所谓的跳秒，由于需要适应地球自转变化，需要在不定时进行跳秒，截止2019年2月，已经18次跳秒。正因为跳秒的存在，才会导致后面介绍的GPS时与UTC时不一致。 GPS时 GPS时是用于卫星定位系统时间，由于卫星系统是连续运行的，其要求时间系统也是连续的，因此采用原子钟的方法。GPS时间系统就是采用基于美国海军观测实验室维持的原子时。 GPS时在1980年1月6日0点0分与世界协调时(UTC)一致，此后就只按原子时来累计，不受外界影响，也不会产生跳秒。因此与UTC时间的差为秒的整数倍，即: \\[ Time_{GPS} = Time_{UTC}+n \\] 特别的，GPS时间的计时方法采用星期数和秒周数来表示，其中周数作为C/A和P码中的十位字段发送，所以\\(2^{10}=1024\\)周(19.6年)后会再次归零。 为了解决这个问题，现代化的GPS导航消息采用了13位的字段，每隔8192周(157年)才归零。","categories":[],"tags":[]},{"title":"LiDAR-Camera 标定-4","slug":"传感器标定/LIDAR_CAMERA标定_4","date":"2021-04-13T20:55:30.000Z","updated":"2022-04-11T15:57:06.370Z","comments":true,"path":"2021/04/14/传感器标定/LIDAR_CAMERA标定_4/","link":"","permalink":"http://yoursite.com/2021/04/14/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/LIDAR_CAMERA%E6%A0%87%E5%AE%9A_4/","excerpt":"","text":"Spatiotemporal Calibration of Camera and 3D Laser Scanner 摘要 我们提出了一种用于相机和3D激光扫描仪的开源时空校准框架。我们的解决方案基于常用的棋盘标记，需要在操作前进行一分钟校准，以提供准确和可重复的结果。该框架基于点对平面约束的批量优化，并且可以通过新颖的最小化来实现时间偏移校准，李代数中平面方程的连续表示以及B样条的使用。在仿真中评估了框架的属性，同时使用Velodyne VLP-16和SICK MRS6124 3D激光扫描仪通过两种不同的感官设置验证了性能。 介绍 提出的标定方法基于棋盘格的运动，以及一系列的来自相机和激光雷达的观测。然后执行批量优化来估计6dof刚体变换矩阵以及时间偏差。 该优化基于独立的激光雷达指向相机的平面约束，该平面约束由连续时间平面表示扩展，使得时间偏差可以得到优化。本文贡献在： 使用通用的棋盘格标记来估计lidar、camera的外参和时间偏移 新颖的李代数形式的连续时间最小化平面表示，使用B样条 对初值不敏感，可以收敛到预期结果 方法 提出的框架专用于刚体连接的具有全局快门相机和3D Lidar，并且假设相机内参已知且已经校正了。此外，假设传感器之间的时间偏移未知，且较小近似于常值。 标定过程需要包含标定板与传感器之间的相对运动，因此应该被激光雷达和相机连续观测得到。录制数据之后，按照下图的过程进行处理： 其中，对于相机，则使用opencv传统检测算法进行检测；对于激光雷达，首先将点投影成range-image，然后通过手动标记或半自动跟踪的方法来提取标定板对应的平面点。 如果不考虑时间偏移，标定可以描述为基于待求解位姿的点-面优化问题： \\[ T^{*} = \\arg \\min \\sum_{i} \\sum_{j} \\pi(t_i)^{T}Tp_{i} \\] 其中， \\(T^{*}\\)是期望得到的从激光雷达坐标系到相机坐标系的变换矩阵 \\(p_i\\)表示标定板上第i个3D点的齐次坐标表示 \\(\\pi(t_i)\\)表示由相机在\\((t_i+\\Delta t)\\)时刻估计得到的标定板平面等式。 提出的方法还注意到时间的校准，即考虑到点云中的每个点都对应一个时间戳，则目标函数变为： \\[ T^{*},\\Delta t^{*} = \\arg \\min \\sum_{i} \\sum_{j} \\pi(t_i+\\Delta t)^{T}Tp_{i} \\] 其中， \\(\\Delta t^{*}\\)是待估计的时间差 要形成上式，需要知道每个3d激光点对应的时间戳以及对应任意时间的平面表示 本文使用LM以及g2o来求解 3D激光雷达时间偏移 对于机械旋转式激光雷达，都有一定的扫描周期，根据扫描起始和扫描结束，可以推断出对应点的时间： vlp16 \\[ t_{i}=t_{\\text {cloud }}+\\frac{\\phi_{i}-\\phi_{s}}{f\\left(\\phi_{e}-\\phi_{s}\\right)} \\] 其中， \\(t_{cloud}\\)表示扫描起始时间 sick-mrs6124 连续时间平面表示 标定板在每一帧图像中都能检测到，由于相机内参、以及标定板物理参数已知，所以可以确定标定板坐标系到相机坐标系的变换。 因此，标定板的平面可以使用4维向量\\((\\bm{n},d)\\)来表示，其中\\(\\bm{n}\\)是平面法向量，\\(d\\)是到坐标系原点的距离。对于所有的图像，可以获取到离散时间下的一组平面方程集合。 为了确定各个时间戳的平面方程，需要对这些方程进行插值，因为4维的平面表示形式并非最小的表示方式，因此可能还需要做归一化处理。为了避免这个问题，提出一种使用类似于SO(3)以及对应的李代数so(3)的思想来表示平面法向量 该思想只需要使用两个参数就可以表示归一化法向量，因此，提出的方法几乎与[21]提出的球面插值法相同。 因此，平面的超参数化是因为法向量\\(\\bm{n}\\)，如果使用两个成分来表示，那么平面可以表示为：\\((\\bm{n},d) \\rightarrow (\\omega_x,\\omega_y,d)_{3\\times 1}\\): \\[ \\begin{aligned} \\theta = acos(\\bm{n}[2]) \\\\ \\omega_{x}=-\\bm{n}[1]*\\frac{\\theta}{\\sin \\theta} \\\\ \\omega_{y}=\\bm{n}[0]*\\frac{\\theta}{\\sin \\theta} \\end{aligned} \\] 这个思想来源于 [20]A. Bartoli, “On the non-linear optimization of projective motion using minimal parameters“ European Conference on Computer Vision (ECCV), Copenhagen, 2002, 340–354. 就是说，在3维欧氏空间中，以点(0,0,1)作为原点，以平行于x轴、y轴的方向作为坐标轴，展开一个超平面，那么3维欧氏空间中的矢量可以通过对数变换投影到该超平面上的一个点。 二维情况 三维情况 因此，选取3维欧氏空间中的单位向量\\(q=[0,0,1]^{T}\\)，然后根据\\(\\cos \\theta = q^{T} n\\)，那么可以得到\\(\\theta = \\arccos (q^{T}n)=\\arccos(\\bm{n}[2])\\)，表示两个向量之间的夹角，特别的又因为球面半径是单位向量，因此，\\(\\theta\\)也表示两个向量之间的球面距离。 特别的，根据下式可构成超平面上的点\\(p=(\\omega_x,\\omega_y)\\)： \\[ \\begin{aligned} \\theta = \\arccos(\\bm{n}[2]) \\\\ \\omega_{x}=-\\bm{n}[1]*\\frac{\\theta}{\\sin \\theta} \\\\ \\omega_{y}=\\bm{n}[0]*\\frac{\\theta}{\\sin \\theta} \\end{aligned} \\] 其中， \\[ \\begin{aligned} \\sqrt{\\omega_x^2 + \\omega_y^2} &amp;= \\sqrt{ \\frac{\\arccos^{2} (n[2])}{\\sin^{2}( \\arccos(n[2])) } (n[0]^{2}+n[1]^{2}) } \\\\ &amp;= \\sqrt{ \\frac{\\arccos^{2} (n[2])}{1- \\cos^{2}(\\arccos(n[2])) } (1-n[2]^{2}) } \\\\ &amp;= \\arccos (n[2]) = \\theta \\end{aligned} \\] 可以发现，在超平面上，点q和点p的距离等于球面上向量q和另一个向量之间的球面距离。 因此，实现了使用两个参数来表示欧氏空间中的向量，需要注意的是，\\(\\theta==0\\)时，取\\(\\frac{\\theta}{\\sin \\theta}=1\\)，特别的，仅适用于\\(\\theta &lt; \\pi\\)的情况下。 平面方程插值 使用最小化的平面表示使得可以进行插值，然后返回到所需时间戳对应的4维的平面方程表示形式。 对于此任务，我们尝试了参数的线性插值，由于缺乏连续的微分导致优化陷入局部最小值。因此，提出了使用三次样条插值，确保最小平面表示具有一阶和二阶的连续微分。如下： \\[ \\mathbf{s}(t)=\\mathbf{s}_{0} B_{0}(t)+\\sum_{i=1}^{n}\\left(\\mathbf{s}_{i}-\\mathbf{s}_{i-1}\\right) B_{i}(t) \\] 其中， \\(s(t)\\)是在时间t插值得到的结果 \\(s_i\\)是根据测量得到的第i个控制点的值 \\(B_i(t)\\)是cumulative basis function的第i个成分 \\(n\\)是B样条的阶数 对于李代数，则有插值方程如下： \\[ \\mathbf{r}(t)=\\log \\left\\{\\exp \\left(\\mathbf{r}_{0} B_{0}(t)\\right) \\prod_{i=1}^{n} \\exp \\left(\\boldsymbol{\\Omega}_{i} B_{i}(t)\\right)\\right\\} \\] 其中， \\(r(t)\\)表示t时刻的李代数插值结果 \\(r_i\\)表示李代数表示的第i个控制点 \\(\\Omega_i=\\log(\\exp(r_{i-1})^{T}\\exp(r_i))\\)表示两个李代数之间的差值 来源于文献[23]：A. Patron-Perez, S. Lovegrove, and G. Sibley, “A spline-based trajec- tory representation for sensor fusion and rolling shutter cameras“, in International Journal of Computer Vision, vol. 113, no. 3, 208–219, 2015. 使用4阶B样条插值，cumulative basis function 如下： \\[ \\mathbf{B}(u) = \\frac{1}{6} \\left[ \\begin{array}{cccc} 6 &amp; 0 &amp; 0 &amp; 0 \\\\ 5 &amp; 3 &amp; -3 &amp; 1 \\\\ 1 &amp; 3 &amp; 3 &amp; -2 \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{array} \\right] \\left[\\begin{array}{c} 1 \\\\ u \\\\ u^{2} \\\\ u^{3} \\end{array} \\right] \\] 其中， \\(u\\)是从t2到t3之间的归一化时间(0~1)，在实践中，我们还检查了检测到的棋盘的时间戳（T1，T2，T3，T4）是否均匀地分布在时间内，如果不满足这种情况，则不会执行插值 重要的是，可以使用[23]的已知方程来导出B样条曲线的jacobians，特别的，本系统使用了[24]所述的更有效的雅可比表示。 [24]C. Sommer, V. Usenko, D. Schubert, N. Demmel, and D. Cremers, “Efficient derivative computation for cumulative B-splines on Lie groups“, arXiv preprint, 1911.08860v1, 2019.","categories":[{"name":"传感器标定","slug":"传感器标定","permalink":"http://yoursite.com/categories/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/"}],"tags":[]},{"title":"LiDAR-Camera 标定-2","slug":"传感器标定/LIDAR_CAMERA标定_2","date":"2021-04-12T13:05:30.000Z","updated":"2022-04-11T15:57:06.233Z","comments":true,"path":"2021/04/12/传感器标定/LIDAR_CAMERA标定_2/","link":"","permalink":"http://yoursite.com/2021/04/12/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/LIDAR_CAMERA%E6%A0%87%E5%AE%9A_2/","excerpt":"","text":"Calibration of RGB Camera With Velodyne LiDAR 适用于32线以上 摘要 本文提出了一种从粗到细的lidar-camera的标定方法，以前的方法用于计算校准参数的已知棋盘标记的多个视图，或者它们仅限于具有小相互位移的传感器的校准。 我们的方法提出了一种用于粗校准的新型3D标记，可以在相机图像和激光扫描中鲁棒地检测到粗略校准。只需要单帧的cam-lidar数据就可以估计比较大的平移外参，后续的refinement步骤将在标定参数子空间中寻找更准确的参数。 本文同样提出了一种基于投影误差的标定准确度度量。 介绍","categories":[{"name":"传感器标定","slug":"传感器标定","permalink":"http://yoursite.com/categories/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/"}],"tags":[]},{"title":"LiDAR-Camera 标定-3","slug":"传感器标定/LIDAR_CAMERA标定_3","date":"2021-04-12T13:05:30.000Z","updated":"2022-04-11T15:57:06.370Z","comments":true,"path":"2021/04/12/传感器标定/LIDAR_CAMERA标定_3/","link":"","permalink":"http://yoursite.com/2021/04/12/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/LIDAR_CAMERA%E6%A0%87%E5%AE%9A_3/","excerpt":"","text":"Automatic Extrinsic Calibration Method for LiDAR and Camera Sensor Setups 摘要 本文提出了一种无需用户干预即可进行激光雷达-立体相机对的外在校准的方法。我们的校准方法旨在解决汽车设置中常见的限制，例如低分辨率和特定的传感器姿态。 介绍 现有的校准方法要么需要复杂的设置，要么缺乏通用性，因此结果的准确性在很大程度上取决于传感器的参数或环境的结构性。 与现有方法不同，没有进行严格的假设，因此允许中等分辨率如16线lidar，以及适用于传感器之间的相对姿势较大的情况。 我们的方法可以使用简单的设置在合理的时间内执行，该设置旨在利用来自两个设备的数据中的对应关系。 标定 一个定制的平面target用于提供两个传感器之间的特征配对关系，如图2所示 图2所示的模式具有几何和视觉特性，可以估计lidar、双目、单目的关键点。一方面，4个圆孔可以利用激光、双目点云的不连续性获取，另一方面，4个ArUco标记放置于4个角点附近，可以使用单目摄像头获取。 这种方法不会对传感器之间的相对姿态有较强的限制，因此适用于平移和旋转较大的情况。实际上，只需要满足两个约束即可： 传感器之间必须有包含校准目标的共视区域 传感器可以良好的观察到校准目标（如圆孔），特别的，当校准中包含距离数据时，每一个圆至少需要3个点来表示。对于多线激光雷达而言，必须要有两根线达到同一个圆上 特别的，对于视觉传感器而言，需要提前知道设备内参 提出的方法如图3所示，分为两个阶段： 第一阶段包括校准目标的分割和每个传感器的参考点定位 第二阶段是求解参考点的转换 目标分割 这第一阶段旨在在每个传感器的数据中对校准目标进行定位，在此阶段中的信息是相对于该传感器坐标系而言的。最终输出一组包含4个3D点数据， 激光雷达数据 在将数据馈送到分割处理之前，通过了三个笛卡尔坐标的pass-through滤波器来提出无关数据的影响，因此必须根据传感器重叠区域的位置和大小来设置pass-through滤波器的限制。 预处理后的点云\\(\\mathcal{P}_{1}^{L}\\)包含校准目标和激通过孔中可见的点。对于\\(\\mathcal{P}_{1}^{L}\\)中的每一个点，按下式计算其深度梯度幅值： \\[ p_{i, \\Delta}=\\max \\left(p_{i-1, r}-p_{i, r}, p_{i+1, r}-p_{i, r}, 0\\right) \\] 其中， \\(p_{i,r}\\)表示关于点\\(p_i\\)的测量 \\(p_{i-1},p_{i+1}\\)是点\\(p_i\\)的同一线束扫描的邻近点 然后，利用一个阈值对所有不连续性较高的点进行提取，得到点云\\(\\mathcal{P}_{2}^{L}\\) 双目/立体摄像头数据 当要校准的传感器之一是立体视觉系统时，首先通过立体声匹配过程将原始图像对转换为3D点云。 在我们的实验中，我们使用OpenCV实现的[28]的半全局块匹配（SGBM）变体，我们发现我们发现合理准确地进行深度估计。注意，当涉及这种模态时，预计校准目标将具有一些纹理（例如，木纹），以便可以成功解决立体声对应问题。但是，在我们的实验中，我们发现由模式边界引起的强度差异通常是足够的，。 与激光雷达数据处理类似，首先通过pass-through滤波器进行过滤。不同的是，对于立体视觉，通过提取点云目标的边缘，具体地，使用sobel算子来对图像提取边缘，然后根据边缘强度对点云进行滤除，得到点云\\(\\mathcal{P}_{2}^{S}\\) 对深度数据提取目标点 这一步主要是对激光雷达/立体视觉预处理后的数据进行下一步处理： （1）平面分割： 首先，使用RANSAC算法对点云\\(\\mathcal{P}_{1}\\)(包括激光雷达/立体视觉)进行平面拟合得到模型\\(\\pi\\)，为了确保模型的准确，使用了较为严格的RANSAC阈值，并且提取的平面必须大概与传感器坐标系成垂直关系，使用一个容限\\(\\alpha_{plane}\\). 然后，根据得到的平面模型\\(\\pi\\)，对点云\\(\\mathcal{P}_{2}\\)中的点进行剔除，然后得到点云\\(\\mathcal{P}_{3}\\) （2）转换到2d空间： 由于所有其余点都属于同一平面，因此在该点执行降维：通过转换x-y平面与模型\\(\\pi\\)重合，可以将点云\\(\\mathcal{P}_{3}\\)转换到平面点\\(\\mathcal{P}_{4}\\) （3）圆形提取 接下来，使用2D圆分割来提取\\(\\mathcal{P}_{4}\\)中存在的图案孔的模型，此步骤是迭代地执行的过程中，在寻找最可能的圆圈，并且在寻找下一个圆之前，剔除掉已经找到的圆。如果找到4个圆，才进入下一步。 为此，将中心分成四个一组，并将它们形成的矩形的尺寸（对角线，高度，宽度和周长）与理论值进行比较，公差δ一致性表示为与中心线的偏差百分比。 期望值。 大概只有一组中心可以满足这些限制， 一旦识别到圆，就可以将其圆心反投影回3d空间，形成点云\\(\\mathcal{P}_{p}\\)，\\(\\mathcal{P}_{p}\\)必须正好是4个中心点。 单目摄像头数据 如果要校准的传感器是单眼相机，则参考点的提取需要检测ARUCO标记，其提供所需的提示来检索目标的几何形状。Aruco标记是由黑色边界和内部二进制矩阵制成的合成方标记，旨在允许其明确识别[27]。 在我们的校准目标中，使用四个ARUCO标记，每个角落都是一个; 由于此位置，它们不会影响其他方式的目标或孔检测。 如果相机内参以及标记的尺寸已知，就可以通过Pnp恢复每个标记相对于相机坐标系的位姿，在我们的实施中，我们将四个标记设置为一个ARUCO板，这个板允许利用4个标记来共同估计校准目标的位姿。 然后通过LM优化来最小化重投影误差来求解ARUCO板的位姿，使用4个标记的位姿均值作为初始值，最后得到了ARUCO板中心的3d位姿。 为了生成与点云\\(\\mathcal{P}_{p}\\)同等的4个点，利用已知的相对位置关系来分别提取4个圆孔中心的3D点，得到点云\\(\\mathcal{P}_{M}\\) 点云聚类 在分割阶段的最后，已经得到了两组点云\\(\\mathcal{P}_{p}\\)，每一组点云都是相对于传感器坐标系的。 这些数据足以找到转换传感器的相对姿势的转换，然而，方法固有的不同噪声源（例如，传感器噪声和诸如Ransac等非确定性程序）可能会影响结果的准确性。为了提高算法的稳健性，我们通过反复应用分割步骤并以两种不同的方式累积结果来增加可用的信息 （1）数据帧累积 由于场景可以是静止的，因此可以通过累积N帧的点云\\(\\mathcal{P}_{p}\\)来得到\\(\\mathcal{P}_{p}^{&#39;}\\)，如果找到的超过4个圆，则不可用 （2）目标板不同位姿的数据累积 本方法可以通过单个目标板的位姿来求解，然而，通过考虑超过四个参考点，可以提高估计的准确性。另一方面，单帧提取得到的4个点有可能不共面，通过多帧可以提高标定效果。 配准 在分割阶段结束后，一共获取到两组\\(\\mathcal{P}_{p}^{&#39;}\\)点云，每组分别对应一个传感器，主要包含每个圆圈中心相对于该传感器坐标系的点。并且，两组点云的点对关系是已知的。 点关联 提出了一种策略，来避免设置两组\\(\\mathcal{P}_{p}^{&#39;}\\)点云的点具有相同的顺序关系。 首先将\\(\\mathcal{P}_{p}^{&#39;}\\)点云中的4个点投影到球面坐标系，然后（only assume that the point that appears highest in the cloud, that is, the one with the lowest inclination angle, belongs to the upper row of the calibration target (i.e., either the top-left or the top-right circle).） 上面步骤首先确定了一个上方的点，然后根据这一点到另外三个的距离确定了正确的排序。因此，可以建立起关联： 求解 排序好的两组点云，记为\\(\\mathcal{P}_{c}^{&#39;X},\\mathcal{P}_{c}^{&#39;Y}\\)，通过使用Umeyama配准[30]，可以寻找两组点云的刚体变换，其中，两组点云中的点具有匹配关系如下： \\[ p_{i, a}^{X}=p_{i, a}^{Y} \\wedge p_{i, m}^{X}=p_{i, m}^{Y} \\] 即目标函数为两组点云之间的距离： \\[ \\frac{1}{4 \\cdot M} \\sum_{i=0}^{4 \\cdot M}\\left\\|\\mathbf{p}_{i}^{X}-\\mathbf{T}_{X Y} \\mathbf{p}_{i}^{Y}\\right\\|^{2} \\] 由于点云配对关系已知，所以使用svd即可求得闭式解。方便的是，Umeyama方法可以处理所有点都在同一平面上的情况，例如使用单个图案位置（M = 1）时，这样可以避免将它们误认为是反射。 实验 除了需要人工放置标记板之外，其他参数使用固定值如下表： 其中，除非另有说明，否则参考点累积超过30帧（n = 30） gazebo仿真 在实验中，将目标放置在后面的墙壁，使得穿过圆孔的LIDAR梁到达表面，在前景和背景点之间产生必要的梯度。 高斯噪声\\(\\epsilon \\sim \\mathcal{N}(0,(K\\sigma_{0})^{2})\\)被施加到传感器的捕获数据，对于像素强度和激光距离，\\(\\sigma_{0}= 0.007\\) m和\\(\\sigma_{0}= 0.008\\)米，其中： K=0表示理想环境 K=1表示真实环境 K=2表示噪声环境 特征提取实验 实际上，该方法无法在一些极端配置中提供结果; 具体为在LIDAR扫描仪的情况下，它们有限的分辨率使得不可能在远距离找到圆圈，而立体声受到深度估计的实质性降级的影响，即这种模块遭受的距离增加。 因此，在典型用例中，应该通过将图案位置限制为相对于传感器的合理距离范围来避免这些情况 求解结果 真实环境实验","categories":[{"name":"传感器标定","slug":"传感器标定","permalink":"http://yoursite.com/categories/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/"}],"tags":[]},{"title":"LiDAR-Camera 标定-1","slug":"传感器标定/LIDAR_CAMERA标定_1","date":"2021-04-12T01:05:30.000Z","updated":"2022-04-11T15:57:06.370Z","comments":true,"path":"2021/04/12/传感器标定/LIDAR_CAMERA标定_1/","link":"","permalink":"http://yoursite.com/2021/04/12/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/LIDAR_CAMERA%E6%A0%87%E5%AE%9A_1/","excerpt":"","text":"LiDAR-Camera Calibration using 3D-3D Point correspondences 摘要 采用多个传感器来提供冗余信息，该信息可以减少具有错误测量的可能性。 在上述情况下，必须相对于单个参考帧从各种传感器获得数据，以便可以融合数据，并且可以利用冗余。 基于标记的[2]以及LIDAR和摄像机的自动校准已经提出，但在这些使用的方法和实验中讨论了高密度，更昂贵的激光雷达，并且当较低密度的LIDAR时，不太适用，例如 使用VLP-16。 我们提出了一种非常准确和可重复的方法来估计相机和激光器之间的6度自由度的外部校准参数 传感器及参数准备 我们提出的方法利用LIDAR和相机的传感器数据。 在启动激光雷达相机校准过程之前应该知道相机的内在参数. 每次收集数据，LIDAR和相机都在3D空间中的任意距离保持,它们之间的转换是手动测量的。虽然，使用卷尺测量是粗糙的，但它用作使用各种算法获得的值的进行检查，测量平移量比旋转量容易的多，在其他情况下，当旋转极小时，我们假定它们为零。如果存在较大的角度，只能用三角板估计一下 。 2D-3D关联 在使用3D-3D点对应关系的方法之前，我们尝试了涉及2D-3D对应关系的方法。我们设计了自己的实验设置，以帮助校准激光器和相机。 实验设置 需要设置的标记：中空矩形纸板。 即使是普通纸板也可以很好地工作，因为我们将在即将到来的讨论中看到，提供更少的对应关系，而不是挖空的矩形纸板 数据提取 首先使用2D-3D方法：这种方法涉及通过匹配2D-3D点对应的方式在相机和激光器之间找到6-DOF变换，可以通过手动在图像中标记具有3-4像素的精度的图像中的特征点来容易地获得2D对应关系。 直接获取对应3d点的方法并不直接，这是因为lidar点云稀疏 平面纸板可以提供4个角点，在3D中，这些点可以通过直线拟合交点得到，在2D中，可以直接从marker的像素坐标获得。 如果空心纸板的外边框也使用，那么就可以提供8个3D-2D点关联，这样的设置允许有足够的数据来运行PNP算法的Ransac版本，并且还将有助于减少嘈杂的数据。 如果纸板的一侧与地面平行，由于激光水平扫描，那么可能只能获取到纸板的竖直边缘，而不能获取到水平边缘。为了克服这一点，我们将板倾斜以在一个边缘和地面平面之间制作大约45度来获取所有四个边缘获得点。 Ransac用于拟合LIDAR的点的直线。 这个节点允许手动绘制多边形，然后自动提取内部直线： 纸板上最突出的特征是角点，它可以在图像上相对容易地标记，并且由于我们对四个边缘具有相当准确的线条方程，因此它们的交叉点在3D中计算，这些空间中的直线实际上可能无法相交，但是非常接近。 我们将角点近似于两行之间最短线段的中点。 实验发现：两个线段之间的距离是\\(10^{-4}\\)米的距离，边缘长度之间的误差平均约为1厘米. 本实验获取到了20个角点：2个空心矩阵（2*8）+ 1个实心纸板（4） 问题求解 Perspective n-Point (PnP)方法用于寻找2D-3D匹配点对之间的刚体变换，其中式（1）展示了3D点投影方程： 式（2）展示了使用的通用cost-function： 首先，使用了PNP和EPNP方法来最小化上述cost-func，然后通过手动剔除外点，进一步降低重投影误差到1.88个像素，但是，并没有求解出接近手动测量值的\\(\\{R,t\\}\\) 在上述实验中，由于激光雷达和相机比较接近，仅相差12厘米，且实验中仅使用了12个点进行EPNP，并没有达到预期效果。在随后的实验中，相机和lidar距离更远，减轻了误差的影响。 在检查数据时，我们发现了一些噪声点，这些噪声点造成了较大的重投影误差，我们运行了一个自定义的EPNP和RanSac算法，理论上可以确保滤除噪声点的影响。 通过实验发现，重投影误差小于1个像素，但是得到的\\(\\{R,t\\}\\)与期望值相差更大，这可能意味着最小化重投影误差可能不是一种整体最优的方法，因此必须使用其他更好的度量。 3D-3D关联 2D-3D对应方法在我们的实验设置中结果似乎不太理想，这可能是由于2D标记点的不准确或者使用含有噪声点进行PnP。尽管重投影误差似乎已经最小化，但是求出来的结果与测量值相差较大。 因此，这部分涉及使用增强 - 现实（AR）标签和LIDAR点云来找到外部校准参数，开源社区[7] [5]已释放多个版本的AR标签。 这里提出的方法使用ARUCO标签[5]。 为了找到相机与Velodyne之间的转换，我们需要两组3D点：一个在相机坐标系中，另一组在Velodyne坐标系中。 一旦发现这些点对应，就可以求解了。 实验设置 矩形纸板可以是任何任意尺寸。 我们执行的实验使用了一个Velodyne VLP-16 [3]，其在单次扫描中仅具有16个环，与较高密度的LIDAR相比（每次扫描的32和64环）相比。 对于低密度的LIDAR，如果板的尺寸很小，并且LIDAR保持比特定距离更远，则击中板的环数变为低（2至3个环，导致边缘仅2至3点） ，使其非常困难地适应边缘（使用Ransac） 实验中使用的纸板的长度/宽度在45.0-55.0厘米之间，保持距离激光雷达2米左右距离，就可以有足够的点来拟合直线和计算交点。 相机坐标系中的3D点 ARUCO标记是特殊编码的模式，其促进标记本身的检测和纠错。 有关如何在这里找到工作的更多详细信息[5] ArcoTag贴在纸板上，如果已知纸板的尺寸和ARUCO标记的位置，则可以容易地计算角落的位置（来自aruco标记的中心）。 ArcoTag提供相机坐标系和标记中心的\\(\\{R,t\\}\\)变换，这个变换可以用来将角点从标记所在的坐标系转换到相机坐标系。 激光雷达坐标系中的3D点 通过检测纸板的边缘可以找到激光雷达中的点，这又可以以类似的方式为拐角又可以解决第3节中描述的类似方式。 使用ArcoTag获取到的转换矩阵（特别是平移量）非常准确，一旦获取到两组3D点集合，就可以使用ICP算法进行求解了。 求解 ICP算法最小化式（3）表示的cost-func： 一般ICP算法认为点云中的最近点作为对应关系（有其他选择最接近点的其他变体,找到正确的对应关系可能是棘手的，可能导致不期望的解决方案. 由于在本方法中，点与点之间的对应关系是已知的，因此icp算法存在闭式解（Kabsch算法[9] [10]找到两点云之间的旋转，并且坐标系对齐后就可以找到平移）： 下面的推导使用与[10]中的相同的参数。 首先，我们假设旋转是已知的，所以先求解平移量： 已知目标函数： 对平移量t求导并等于0： 进一步有： 即： 使用求出来的平移量替换式（4）中的部分，有： 令： 目标函数变成： 解释如下： 令\\(X_{i}^{&#39;}-Y_{i}=[x_i,y_i,z_i]^{T}\\) 对不同的点得到的[x_i,y_i,z_i]进行堆叠，则有： \\[ \\begin{aligned} (X&#39;-Y)^{T}(X&#39;-Y)&amp;= \\begin{bmatrix} x_1 &amp; y_1 &amp; z_1 \\\\ x_2 &amp; y_2 &amp; z_2 \\end{bmatrix} \\begin{bmatrix} x_1 &amp; x_2 \\\\ y_1 &amp; y_2 \\\\ z_1 &amp; z_2 \\\\ \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} x_1^{2}+y_1^{2}+z_1^{2} &amp; m \\\\ n &amp; x_2^{2}+y_2^{2}+z_2^{2} \\end{bmatrix} \\end{aligned} \\] 实际上，我们的目标函数就是对角线元素之和。 进一步的，利用矩阵的迹的性质，可以进一步简化： 又因为旋转矩阵\\(R\\)是正交矩阵，因此有\\(|X_i^{&#39;}|^{2}=|X_i|^{2}\\)，进一步有： 观察可知，前半部分是固定的，只有后半部分与旋转\\(R\\)有关，而且我们的目标是最小化，因此，即最大化后面的部分： 使用旋转\\(R\\)替换回\\(X^{&#39;}\\)，有： 问题转化为，求\\(R\\)使得\\(Tr(XY^{T}R)\\)最大 进一步的，根据定理： 因此，对\\(XY^{T}\\)进行SVD分解，得到\\(XY^{T}=UDV^{T}\\)， 令\\(R=VU^T\\)，则 \\[ Tr(XY^{T}R)=Tr(UDV^{T}VU^{T})=Tr((UD^{\\frac{1}{2}})(UD^{\\frac{1}{2}})^{T}) \\] 因此，旋转\\(R=VU^T\\) 多帧求解 在初步实验中，观察到尽管在封闭空间中，激光雷达点云并非静止，为了减少噪声，采用多次扫描的方法。多帧数据中，保持激光雷达与相机空间关系不变： 对于每一帧数据估计出来的平移量，求均值有： 对于旋转量，先转换到四元数，然后求平均： 然后，还要进行归一化： 结果","categories":[{"name":"传感器标定","slug":"传感器标定","permalink":"http://yoursite.com/categories/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/"}],"tags":[]},{"title":"IMU预积分模型","slug":"IMU预积分模型推导","date":"2021-02-19T07:05:33.000Z","updated":"2022-04-11T15:57:06.354Z","comments":true,"path":"2021/02/19/IMU预积分模型推导/","link":"","permalink":"http://yoursite.com/2021/02/19/IMU%E9%A2%84%E7%A7%AF%E5%88%86%E6%A8%A1%E5%9E%8B%E6%8E%A8%E5%AF%BC/","excerpt":"","text":"什么是预积分 即对两个关键帧之间的imu数据进行整合，得到一个factor，并且该factor基本上不随两个关键帧的状态改变而变化 预积分计算 回顾惯导解算，已知系统位置、速度、姿态的微分方程如下： \\[ \\begin{array}{l} \\dot{\\mathbf{p}}_{w b_{t}}=\\mathbf{v}_{t}^{w} \\\\ \\dot{\\mathbf{v}}_{t}^{w}=\\mathbf{a}_{t}^{w} \\\\ \\dot{\\mathbf{q}}_{w b_{t}}=\\mathbf{q}_{w b_{t}} \\otimes\\left[\\begin{array}{c} 0 \\\\ \\frac{1}{2} \\boldsymbol{\\omega}^{b_{t}} \\end{array}\\right] \\end{array} \\] 基于上述微分方程，可以得到连续时间下的状态传播方程： \\[ \\mathbf{p}_{w b_{j}}= \\mathbf{p}_{w b_{i}}+\\mathbf{v}_{i}^{w} \\Delta t+\\iint_{t \\in[i, j]}\\left(\\mathbf{q}_{w b_{t}} \\mathbf{a}^{b_{t}}-\\mathbf{g}^{w}\\right) \\delta t^{2} \\] \\[ \\mathbf{v}_{j}^{w}= \\mathbf{v}_{i}^{w}+\\int_{t \\in[i, j]}\\left(\\mathbf{q}_{w b_{t}} \\mathbf{a}^{b_{t}}-\\mathbf{g}^{w}\\right) \\delta t \\] \\[ \\mathbf{q}_{w b_{j}}=\\int_{t \\in[i, j]} \\mathbf{q}_{w b_{t}} \\otimes\\left[\\begin{array}{c}0 \\\\ \\frac{1}{2} \\boldsymbol{\\omega}^{b_{t}}\\end{array}\\right] \\delta t \\] 由于上面三个公式都与前一个时刻的状态有关，因此需要进行变换： 根据\\(\\mathbf{q}_{w b_{t}}=\\mathbf{q}_{w b_{i}} \\otimes \\mathbf{q}_{b_{i} b_{t}}\\)，即可将上面三个公式中的前一个时刻的位姿项提取出来： \\[ \\mathbf{p}_{w b_{j}}=\\mathbf{p}_{w b_{i}}+\\mathbf{v}_{i}^{w} \\Delta t-\\frac{1}{2} \\mathbf{g}^{w} \\Delta t^{2}+\\mathbf{q}_{w b_{i}} \\underbrace{\\iint_{t \\in[i, j]}\\left(\\mathbf{q}_{b_{i} b_{t}} \\mathbf{a}^{b_{t}}\\right) \\delta t^{2}}_{\\mathbf{\\alpha}} \\] \\[ \\mathbf{v}_{j}^{w}=\\mathbf{v}_{i}^{w}-\\mathbf{g}^{w} \\Delta t+\\mathbf{q}_{w b_{i}}\\underbrace{\\int_{t \\in[i, j]}\\left(\\mathbf{q}_{b_{i} b_{t}} \\mathbf{a}^{b_{t}}\\right) \\delta t}_{\\mathbf{\\beta}} \\] \\[ \\mathbf{q}_{w b_{j}}=\\mathbf{q}_{w b_{i}}\\underbrace{\\int_{t \\in[i, j]} \\mathbf{q}_{b_{i} b_{t}} \\otimes\\left[\\begin{array}{c}0 \\\\ \\frac{1}{2} \\boldsymbol{\\omega}^{b_{t}}\\end{array}\\right] \\delta t}_{\\mathbf{\\gamma}} \\] 将上式的积分项分别提取出来，有： \\[ \\boldsymbol{\\alpha}_{b_{i} b_{j}}=\\iint_{t \\in[i, j]}\\left(\\mathbf{q}_{b_{i} b_{t}} \\mathbf{a}^{b_{t}}\\right) \\delta t^{2} \\] \\[ \\boldsymbol{\\beta}_{b_{i} b_{j}}=\\int_{t \\in[i, j]}\\left(\\mathbf{q}_{b_{i} b_{t}} \\mathbf{a}^{b_{t}}\\right) \\delta t \\] \\[ \\mathbf{q}_{b_{i} b_{j}}=\\int_{t \\in[i, j]} \\mathbf{q}_{b_{i} b_{t}} \\otimes \\left[ \\begin{array}{c} 0 \\\\ \\frac{1}{2} \\boldsymbol{\\omega}^{b_{t}} \\end{array} \\right] \\delta t \\] 由于上面的推导都是基于连续时间下的，在实际使用中，通常使用离散形式计算，采用中值积分法： \\[ \\boldsymbol{\\omega}=\\frac{1}{2}\\left[\\left(\\boldsymbol{\\omega}^{b_{k}}-\\mathbf{b}_{k}^{g}\\right)+\\left(\\boldsymbol{\\omega}^{b_{k+1}}-\\mathbf{b}_{k}^{g}\\right)\\right] \\] \\[ \\mathbf{a}=\\frac{1}{2}\\left[\\mathbf{q}_{b_{i} b_{k}}\\left(\\mathbf{a}^{b_{k}}-\\mathbf{b}_{k}^{a}\\right)+\\mathbf{q}_{b_{i} b_{k+1}}\\left(\\mathbf{a}^{b_{k+1}}-\\mathbf{b}_{k}^{a}\\right)\\right] \\] 那么预积分量\\(\\boldsymbol{\\alpha}_{b_{i} b_{j}},\\boldsymbol{\\beta}_{b_{i} b_{j}},\\mathbf{q}_{b_{i} b_{j}}\\)可以通过迭代计算得到，当新的一帧imu数据到达时，计算该imu预积分的第k+1次迭代，有： \\[ \\boldsymbol{\\alpha}_{b_{i} b_{k+1}}=\\boldsymbol{\\alpha}_{b_{i} b_{k}}+\\boldsymbol{\\beta}_{b_{i} b_{k}} \\delta t+\\frac{1}{2} \\mathbf{a} \\delta t^{2} \\] \\[ \\boldsymbol{\\beta}_{b_{i} b_{k+1}}=\\boldsymbol{\\beta}_{b_{i} b_{k}}+\\mathbf{a} \\delta t \\] \\[ \\mathbf{q}_{b_{i} b_{k+1}}=\\mathbf{q}_{b_{i} b_{k}} \\otimes \\left[ \\begin{array}{c} 1 \\\\ \\frac{1}{2} \\boldsymbol{\\omega} \\delta t \\end{array} \\right] \\] 预积分量计算完成 基于预积分量的导航状态更新公式为： \\[ \\left[ \\begin{array}{c} \\mathbf{p}_{w b_{j}} \\\\ \\mathbf{v}_{j}^{w} \\\\ \\mathbf{q}_{w b_{j}} \\\\ \\mathbf{b}_{j}^{a} \\\\ \\mathbf{b}_{j}^{g} \\end{array} \\right] = \\left[ \\begin{array}{c} \\mathbf{p}_{w b_{i}}+\\mathbf{v}_{i}^{w} \\Delta t-\\frac{1}{2} \\mathbf{g}^{w} \\Delta t^{2}+\\mathbf{q}_{w b_{i}} \\boldsymbol{\\alpha}_{b_{i} b_{j}} \\\\ \\mathbf{v}_{i}^{w}-\\mathbf{g}^{w} \\Delta t+\\mathbf{q}_{w b_{i}} \\boldsymbol{\\beta}_{b_{i} b_{j}} \\\\ \\mathbf{q}_{w b_{i}} \\mathbf{q}_{b_{i} b_{j}} \\\\ \\mathbf{b}_{i}^{a} \\\\ \\mathbf{b}_{i}^{g} \\end{array} \\right] \\] 此中，陀螺仪和加速度计的零偏不变是认为在这个预积分中，由于时间很短，bias基本没有变化。然而，在整个系统中，其实是认为bias在缓慢变化的，因此，陀螺仪加速度计的模型为： 预积分更新 从上面的推导可以发现，预积分量中包含了bias，而在后续的优化过程中，bias作为待优化状态量会随优化而发生改变，因此，预积分量应该随之更新，为了避免完全重新计算预积分，一个技巧是把预积分结果在bias处进行泰勒展开，通过线性近似得到更新的预积分： \\[ \\boldsymbol{\\alpha}_{b_{i} b_{j}}=\\overline{\\boldsymbol{\\alpha}}_{b_{i} b_{j}}+\\mathbf{J}_{b_{i}^{a}}^{\\alpha} \\boldsymbol{b}_{i}^{a}+\\mathbf{J}_{b_{i}^{g}}^{\\alpha} \\delta \\mathbf{b}_{i}^{g} \\] \\[ \\boldsymbol{\\beta}_{b_{i} b_{j}}=\\overline{\\boldsymbol{\\beta}}_{b_{i} b_{j}}+\\mathbf{J}_{b_{i}^{a}}^{\\beta} \\delta \\mathbf{b}_{i}^{a}+\\mathbf{J}_{b_{i}^{g}}^{\\beta} \\delta \\mathbf{b}_{i}^{g} \\] \\[ \\mathbf{q}_{b_{i} b_{j}}=\\overline{\\mathbf{q}}_{b_{i} b_{j}} \\otimes \\left[ \\begin{array}{c} 1 \\\\ \\frac{1}{2} \\mathbf{J}_{b_{i}^{g}}^{q} \\delta \\mathbf{b}_{i}^{g} \\end{array} \\right] \\] 其中，（详细计算见后续） \\[ \\begin{aligned} \\mathbf{J}_{b_{i}^{a}}^{\\alpha} &amp;=\\frac{\\partial \\boldsymbol{\\alpha}_{b_{i} b_{j}}}{\\partial \\delta \\mathbf{b}_{i}^{a}} \\\\ \\mathbf{J}_{b_{i}^{g}}^{\\alpha} &amp;=\\frac{\\partial \\boldsymbol{\\alpha}_{b_{i} b_{j}}}{\\partial \\delta \\mathbf{b}_{i}^{g}} \\\\ \\mathbf{J}_{b_{i}^{a}}^{\\beta} &amp;=\\frac{\\partial \\boldsymbol{\\beta}_{b_{i} b_{j}}}{\\partial \\delta \\mathbf{b}_{i}^{a}} \\\\ \\mathbf{J}_{b_{i}^{g}}^{\\beta} &amp;=\\frac{\\partial \\beta_{b_{i} b_{j}}}{\\partial \\delta \\mathbf{b}_{i}^{g}} \\\\ \\mathbf{J}_{b_{i}^{g}}^{q} &amp;=\\frac{\\mathbf{q}_{i_{i} b_{j}}}{\\partial \\mathbf{b}_{i}^{g}} \\end{aligned} \\] 预积分(误差)协方差计算 由于预积分量是由imu数据迭代计算得到的，然而imu单次测量包含噪声，时间越长，预积分量越不准确，因此，需要计算对应的协方差来表示其不确定性，方差计算公式如下： \\[ \\boldsymbol{P}_{i, k+1}=\\mathbf{F}_{k} \\boldsymbol{P}_{i, k} \\mathbf{F}_{k}^{\\top}+\\mathbf{G}_{k} \\boldsymbol{Q} \\mathbf{G}_{k}^{\\top} \\] 注意：上式的\\(\\mathbf{F}_{k},\\mathbf{G}_{k}\\)是离散时间下的状态转移矩阵 下面需要求关于预积分误差的微分方程： 已知连续时间下的微分方程形式为： \\[ \\dot{\\boldsymbol{X}}=\\boldsymbol{F}_{t} \\boldsymbol{X}+\\boldsymbol{G}_{t} \\boldsymbol{N} \\] 其中， \\[ \\boldsymbol{X}= \\left[ \\begin{array}{l} \\delta \\boldsymbol{\\alpha}_{t}^{b_{k}} \\\\ \\delta \\boldsymbol{\\theta}_{t}^{b_{k}} \\\\ \\delta \\boldsymbol{\\beta}_{t}^{b_{k}} \\\\ \\delta \\boldsymbol{b}_{a_{t}} \\\\ \\delta \\boldsymbol{b}_{w_{t}} \\end{array} \\right] \\] \\[ \\boldsymbol{N}= \\left[ \\begin{array}{l} \\boldsymbol{n}_{a} \\\\ \\boldsymbol{n}_{w} \\\\ \\boldsymbol{n}_{b_{a}} \\\\ \\boldsymbol{n}_{b_{w}} \\end{array} \\right] \\] \\(\\delta \\dot{\\theta}_t^{b_k}\\)微分方程推导 符号简化：\\(\\delta \\dot{\\theta}_t^{b_k} \\rightarrow \\delta \\dot \\theta\\) 写出不考虑误差的微分方程 \\[ \\dot{\\boldsymbol{q}}_{t}=\\frac{1}{2} \\boldsymbol{q}_{t} \\otimes \\left[ \\begin{array}{c} 0 \\\\ \\boldsymbol{\\omega}_{t}-\\boldsymbol{b}_{\\omega_{t}} \\end{array} \\right] \\] 写出考虑误差的微分方程 \\[ \\dot{\\tilde{\\boldsymbol{q}}}_{t}=\\frac{1}{2} \\tilde{\\boldsymbol{q}}_{t} \\otimes \\left[ \\begin{array}{c} 0 \\\\ \\tilde{\\boldsymbol{\\omega}}_{t}-\\tilde{\\boldsymbol{b}}_{\\omega_{t}} \\end{array} \\right] \\] 写出带有误差的参数与理想真实值之间的关系 \\[ \\tilde{\\boldsymbol{q}}_{t}=\\boldsymbol{q}_{t} \\otimes \\delta \\boldsymbol{q} \\] \\[ \\tilde{\\boldsymbol{\\omega}}_{t}=\\boldsymbol{\\omega}_{t}+\\boldsymbol{n}_{\\omega} \\] \\[ \\tilde{\\boldsymbol{b}}_{\\omega_{t}}=\\boldsymbol{b}_{\\omega_{t}}+\\delta \\boldsymbol{b}_{\\omega_{t}} \\] 其中，\\(\\delta \\theta\\)是计算坐标系与真实导航坐标系的偏差 或者 在body系与计算误差body系之间的偏差 \\[ \\delta \\boldsymbol{q}= \\left[ \\begin{array}{c} \\cos \\left(\\frac{|\\delta \\theta|}{2}\\right) \\\\ \\frac{\\delta \\boldsymbol{\\theta}}{|\\delta \\theta|} \\sin \\left(\\frac{|\\delta \\theta|}{2}\\right) \\end{array} \\right] \\approx \\left[ \\begin{array}{c} 1 \\\\ \\frac{\\delta \\boldsymbol{\\theta}}{2} \\end{array} \\right] \\] 将误差值与理想真实值的关系代入(2) \\[ \\left(\\boldsymbol{q}_{t} \\dot{\\otimes} \\delta \\boldsymbol{q}\\right)= \\frac{1}{2} \\boldsymbol{q}_{t} \\otimes \\delta \\boldsymbol{q} \\otimes \\left[ \\begin{array}{c} 0 \\\\ \\boldsymbol{\\omega}_{t}+\\boldsymbol{n}_{\\omega}-\\boldsymbol{b}_{\\omega_{t}}-\\delta \\boldsymbol{b}_{\\omega_{t}} \\end{array} \\right] \\] 其中， \\[ \\left(\\boldsymbol{q}_{t} \\dot{\\otimes} \\delta \\boldsymbol{q}\\right)=\\dot{\\boldsymbol{q}}_{t} \\otimes \\delta \\boldsymbol{q}+\\boldsymbol{q}_{t} \\otimes \\delta \\dot{\\boldsymbol{q}} \\] 把(1)中的关系代入(4) \\[ \\begin{aligned} \\left(\\boldsymbol{q}_{t} \\dot{\\otimes} \\delta \\boldsymbol{q}\\right) &amp;= \\frac{1}{2} \\boldsymbol{q}_{t} \\otimes \\delta \\boldsymbol{q} \\otimes\\left[\\begin{array}{c}0 \\\\ \\boldsymbol{\\omega}_{t}+\\boldsymbol{n}_{\\omega}-\\boldsymbol{b}_{\\omega_{t}}-\\delta \\boldsymbol{b}_{\\omega_{t}}\\end{array}\\right] \\\\ \\dot{\\boldsymbol{q}}_{t} \\otimes \\delta \\boldsymbol{q}+\\boldsymbol{q}_{t} \\otimes \\delta \\boldsymbol{q} &amp;= \\\\ \\frac{1}{2} \\boldsymbol{q}_{t} \\otimes\\left[\\begin{array}{c}0 \\\\ \\boldsymbol{\\omega}_{t}-\\boldsymbol{b}_{\\omega_{t}}\\end{array}\\right] \\otimes \\delta \\boldsymbol{q}+\\boldsymbol{q}_{t} \\otimes \\dot{\\delta \\boldsymbol{q}} &amp;= \\end{aligned} \\] 化简 (5)两边同时左乘\\((\\boldsymbol{q}_t)^{-1}\\)，然后移项得到： \\[ \\delta \\dot{\\boldsymbol{q}}= \\frac{1}{2} \\delta \\boldsymbol{q} \\otimes \\left[ \\begin{array}{c} 0 \\\\ \\boldsymbol{\\omega}_{t}+\\boldsymbol{n}_{\\omega}-\\boldsymbol{b}_{\\omega_{t}}-\\delta \\boldsymbol{b}_{\\omega_{t}} \\end{array} \\right] -\\frac{1}{2} \\left[ \\begin{array}{c} 0 \\\\ \\boldsymbol{\\omega}_{t}-\\boldsymbol{b}_{\\omega_{t}} \\end{array} \\right] \\otimes \\delta \\boldsymbol{q} \\] 根据四元数乘法性质，可以将四元数乘法转换成矩阵与向量相乘： 因此，可得： \\[ \\begin{aligned} \\delta \\dot{\\boldsymbol{q}} &amp;= \\frac{1}{2} \\left[ \\begin{array}{c}0 \\\\ \\boldsymbol{\\omega}_{1} \\end{array} \\right]_{R} \\delta \\boldsymbol{q} - \\frac{1}{2} \\left[ \\begin{array}{c}0 \\\\ \\boldsymbol{\\omega}_{2} \\end{array} \\right]_{L} \\delta \\boldsymbol{q} \\\\ &amp;= \\frac{1}{2} \\left[ \\begin{array}{cc} 0 &amp; \\left(\\boldsymbol{\\omega}_{2}-\\boldsymbol{\\omega}_{1}\\right)^{T} \\\\ \\left(\\boldsymbol{\\omega}_{1}-\\boldsymbol{\\omega}_{2}\\right) &amp; -\\left[\\boldsymbol{\\omega}_{1}+\\boldsymbol{\\omega}_{2}\\right]_{\\times} \\end{array} \\right] \\delta \\boldsymbol{q} \\end{aligned} \\] 其中, \\[ \\boldsymbol{\\omega}_{1}=\\boldsymbol{\\omega}_{t}+\\boldsymbol{n}_{\\omega}-\\boldsymbol{b}_{\\omega_{t}}-\\delta \\boldsymbol{b}_{\\omega_{t}} \\] \\[\\boldsymbol{\\omega}_{2}=\\boldsymbol{\\omega}_{t}-\\boldsymbol{b}_{\\omega_{t}}\\] 又因为： \\[\\delta \\dot{\\boldsymbol{q}}= \\left[ \\begin{array}{l} 0 \\\\ \\frac{\\delta \\dot{\\theta}}{2} \\end{array} \\right] \\] 可以得到关于\\(\\delta \\dot{\\theta}\\)的方程： \\[ \\begin{aligned} \\delta \\dot{\\boldsymbol{\\theta}} &amp;= -\\left[\\boldsymbol{\\omega}_{1}+\\boldsymbol{\\omega}_{2}\\right] \\times \\frac{\\delta \\boldsymbol{\\theta}}{2}+\\left(\\boldsymbol{\\omega}_{1}-\\boldsymbol{\\omega}_{2}\\right) \\\\ &amp;= -\\left[2 \\boldsymbol{\\omega}_{t}+\\boldsymbol{n}_{\\omega}-2 \\boldsymbol{b}_{\\omega_{t}}-\\delta \\boldsymbol{b}_{\\omega_{t}}\\right]_\\times \\frac{\\delta \\boldsymbol{\\theta}}{2}+\\boldsymbol{n}_{\\omega}-\\delta \\boldsymbol{b}_{\\omega_{t}} \\end{aligned} \\] 忽略上式中的二阶小项，可得\\(\\delta \\dot{\\theta}_t^{b_k}\\)微分方程 \\[ \\delta \\dot{\\boldsymbol{\\theta}}=-\\left[\\boldsymbol{\\omega}_{t}-\\boldsymbol{b}_{\\omega_{t}}\\right]_{\\times} \\delta \\boldsymbol{\\theta}+\\boldsymbol{n}_{\\omega}-\\delta \\boldsymbol{b}_{\\omega_{t}} \\] \\(\\delta \\dot{\\beta}_t^{b_k}\\)微分方程推导 符号简化：\\(\\delta \\dot{\\beta}_t^{b_k} \\rightarrow \\delta \\dot \\beta\\) 写出不考虑误差的微分方程 \\[ \\dot{\\boldsymbol{\\beta}}=\\boldsymbol{R}_{t}\\left(\\boldsymbol{a}_{t}-\\boldsymbol{b}_{a_{t}}\\right) \\] 其中，\\(\\boldsymbol{R}_{t}\\)表示载体姿态 写出考虑误差的微分方程 \\[ \\dot{\\tilde{\\boldsymbol{\\beta}}}=\\tilde{\\boldsymbol{R}}_{t}\\left(\\tilde{\\boldsymbol{a}}_{t}-\\tilde{\\boldsymbol{b}}_{a_{t}}\\right) \\] 写出带有误差的参数与理想真实值之间的关系 \\[\\tilde{\\boldsymbol{\\beta}}=\\boldsymbol{\\beta}+\\delta \\boldsymbol{\\beta}\\] \\[\\tilde{\\boldsymbol{a}}_{t}=\\boldsymbol{a}_{t}+\\boldsymbol{n}_{a}\\] \\[\\tilde{\\boldsymbol{b}}_{a_{t}}=\\boldsymbol{b}_{a_{t}}+\\delta \\boldsymbol{b}_{a_{t}}\\] \\[ \\begin{aligned} \\tilde{\\boldsymbol{R}}_{t} &amp;=\\boldsymbol{R}_{t} \\exp \\left([\\delta \\boldsymbol{\\theta}]_{\\times}\\right) \\\\ &amp;=\\boldsymbol{R}_{t}\\left(\\boldsymbol{I}+[\\delta \\boldsymbol{\\theta}]_{\\times}\\right) \\end{aligned} \\] 关于姿态与理想真实值的关系： 因为 \\(\\delta \\boldsymbol{\\theta}\\)表示的是在载体姿态上的误差，直接右乘即可","categories":[],"tags":[]},{"title":"Zotero导入CNKI文献","slug":"Zotero快速入门","date":"2021-02-11T09:05:33.000Z","updated":"2022-04-11T15:57:06.354Z","comments":true,"path":"2021/02/11/Zotero快速入门/","link":"","permalink":"http://yoursite.com/2021/02/11/Zotero%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","excerpt":"","text":"Why Zotero? 可以一键导入并下载CNKI文献(pdf) 可以抓取硕士论文目录 与Word兼容性良好(安装插件即可实现gb7714等参考文献引用格式) …… Zotero以及浏览器插件安装 参考官网即可： https://www.zotero.org/ 下载地址： https://www.zotero.org/download/ CNKI中文插件安装 参考： https://github.com/l0o0/translators_CN Zotero translator_CN 安装 1 下载网页翻译器(web translator)文件 2 解压下载的压缩包，找到translators目录，将目录中的文件复制到 Zotero 的 translators 目录 如果是macos系统，Zotero的目录就在用户主目录下 3 更新 translator 信息，Firefox 和 Chrome 浏览器操作类似。下面以 Firefox 为例 Chrome 浏览器按照下面信息找到更新按钮 更新时请多点几下，根据我的经验，Chrome 浏览器更新比较快，Firefox 会比较慢 如果你使用学校的 VPN 来登录知网，可以参考这个链接进行设置。设置过程不复杂，就是用特殊符号把网址中的字符替换掉。 🍇 如何在Zotero Connector 中添加中文姓名处理以及保留知网CAJ格式文件的设置 需要特别注意的是，这里在 Zotero Connector 中添加的参数，只是方便控制的网页翻译器的数据抓取行为，限本页面列出的一些翻译器中起作用，并不影响其他翻译器和Zotero的其他功能。 添加的参数有： translators.zhnamesplit，默认为true，抓取过程会拆分姓和名，如果想全并姓名，请设置为false translators.CNKIPDF,默认为true，~下载知网上文章的PDF文件，如果想要下载学位论文的CAJ格式，请设置为false~ (这个方法有点问题，建议直接下载pdf版本即可，后面会有利用插件添加硕士论文目录的部分) 设置方法请参考下面： 为防止设置错误，可以把参数名复制过去。设置完成后，请刷新网页，再重新抓取。如果你参数名写错了也没事，不会有什么问题，放着就好。 使用方法 1 打开知网 2 点击插件，选择需要导入的文献 3 确认即可导入Zotero 4 双击即可打开对应的pdf 由于直接下载的硕士论文pdf版本没有目录，因此下面通过安装插件的方法来解决这个问题 Jasminum - 茉莉花插件安装使用 插件官方地址：https://github.com/l0o0/jasminum 安装步骤 1 Jasminum插件 下载最新的xpi文件进行安装，安装方法：打开 Zotero -&gt; 工具 -&gt; 插件 -&gt; 右上小齿轮图标 -&gt; Install Add-on From File ... -&gt; 选择下载好的xpi文件。 2 PDFtk server插件 PDFtk server，该书签添加工具有 Windows， Linux 和 Mac，请根据自己的系统下载对应的版本进行安装，并在选项中设置好对应的目录。PDFtk server 下载链接 官网：https://www.pdflabs.com/tools/pdftk-server/ After installation, open a Terminal, type pdftk and press Return. Pdftk will respond by displaying brief usage information(注意！安装后请试试这一步，出现使用说明说明安装成功). Access pdftk documenation by running man pdftk. Mac 用户（感谢[@GuokaiLiu](https://github.com/GuokaiLiu)同学在 issue 中的补充） macos(10.15)用户： 下载：https://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/pdftk_server-2.02-mac_osx-10.11-setup.pkg 关于Mac系统的插件路径配置（我没有进行这一步，有需要的再看） 配置方法： 打开Zotero-&gt;首选项-&gt;茉莉花 路径：/opt/pdflabs/pdftk/. （该路径默认对外隐藏无法选取） 选择路径的技巧：shift+command+G: 输入：/opt/pdflabs/pdftk/，选择bin确认 使用方法（同上） 稍微等一会，插件就抓取到目录了","categories":[],"tags":[]},{"title":"Eigen-Operation","slug":"Eigen常用操作","date":"2021-02-01T03:05:32.000Z","updated":"2021-02-02T02:01:54.000Z","comments":true,"path":"2021/02/01/Eigen常用操作/","link":"","permalink":"http://yoursite.com/2021/02/01/Eigen%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","excerpt":"","text":"Eigen常用操作|Eigen Cheatsheet 12&#x2F;&#x2F; A simple quickref for Eigen. Add anything that&#39;s missing.&#x2F;&#x2F; Main author: Keir Mierle 1. 包含头文件 1#include &lt;Eigen/Dense&gt; 2. 矩阵、向量声明 2.1 矩阵声明 12345Matrix&lt;double, 3, 3&gt; A; // Fixed rows and cols. Same as Matrix3d.Matrix&lt;double, 3, Dynamic&gt; B; // Fixed rows, dynamic cols.Matrix&lt;double, Dynamic, Dynamic&gt; C; // Full dynamic. Same as MatrixXd.Matrix&lt;double, 3, 3, RowMajor&gt; E; // Row major; default is column-major.Matrix3f P, Q, R; // 3x3 float matrix. 2.2 向量声明 1234Vector3f x, y, z; // 3x1 float matrix.RowVector3f a, b, c; // 1x3 float matrix.VectorXd v; // Dynamic column vector of doublesdouble s; 3. 基础操作 3.1 计算大小 12345// Basic usage// Eigen // Matlab // commentsx.size() // length(x) // vector sizeC.rows() // size(C,1) // number of rowsC.cols() // size(C,2) // number of columns 3.2 访问元素 12x(i) // x(i+1) // Matlab is 1-basedC(i,j) // C(i+1,j+1) // 3.3 改变大小 1234A.resize(4, 4); // Runtime error if assertions are on.B.resize(4, 9); // Runtime error if assertions are on.A.resize(3, 3); // Ok; size didn't change.B.resize(3, 9); // Ok; only dynamic cols changed. 3.4 矩阵赋值 12345A &lt;&lt; 1, 2, 3, // Initialize A. The elements can also be 4, 5, 6, // matrices, which are stacked along cols 7, 8, 9; // and then the rows are stacked.B &lt;&lt; A, A, A; // B is three horizontally stacked A's.A.fill(10); // Fill A with all 10's. 4. 特殊矩阵 12345678910111213// Eigen // MatlabMatrixXd::Identity(rows,cols) // eye(rows,cols)C.setIdentity(rows,cols) // C = eye(rows,cols)MatrixXd::Zero(rows,cols) // zeros(rows,cols)C.setZero(rows,cols) // C = zeros(rows,cols)MatrixXd::Ones(rows,cols) // ones(rows,cols)C.setOnes(rows,cols) // C = ones(rows,cols)MatrixXd::Random(rows,cols) // rand(rows,cols)*2-1 // MatrixXd::Random returns uniform random numbers in (-1, 1).C.setRandom(rows,cols) // C = rand(rows,cols)*2-1VectorXd::LinSpaced(size,low,high) // linspace(low,high,size)'v.setLinSpaced(size,low,high) // v = linspace(low,high,size)'VectorXi::LinSpaced(((hi-low)/step)+1, // low:step:hi low,low+step*(size-1)) // 5. 矩阵元素提取与替换 123456789101112131415161718192021222324252627282930313233343536373839404142434445// Matrix slicing and blocks. All expressions listed here are read/write.// Templated size versions are faster. Note that Matlab is 1-based (a size N// vector is x(1)...x(N))./******************************************************************************//* PLEASE HELP US IMPROVING THIS SECTION *//* Eigen 3.4 supports a much improved API for sub-matrices, including, *//* slicing and indexing from arrays: *//* http://eigen.tuxfamily.org/dox-devel/group__TutorialSlicingIndexing.html *//******************************************************************************/// Eigen // Matlabx.head(n) // x(1:n)x.head&lt;n&gt;() // x(1:n)x.tail(n) // x(end - n + 1: end)x.tail&lt;n&gt;() // x(end - n + 1: end)x.segment(i, n) // x(i+1 : i+n)x.segment&lt;n&gt;(i) // x(i+1 : i+n)P.block(i, j, rows, cols) // P(i+1 : i+rows, j+1 : j+cols)P.block&lt;rows, cols&gt;(i, j) // P(i+1 : i+rows, j+1 : j+cols)P.row(i) // P(i+1, :)P.col(j) // P(:, j+1)P.leftCols&lt;cols&gt;() // P(:, 1:cols)P.leftCols(cols) // P(:, 1:cols)P.middleCols&lt;cols&gt;(j) // P(:, j+1:j+cols)P.middleCols(j, cols) // P(:, j+1:j+cols)P.rightCols&lt;cols&gt;() // P(:, end-cols+1:end)P.rightCols(cols) // P(:, end-cols+1:end)P.topRows&lt;rows&gt;() // P(1:rows, :)P.topRows(rows) // P(1:rows, :)P.middleRows&lt;rows&gt;(i) // P(i+1:i+rows, :)P.middleRows(i, rows) // P(i+1:i+rows, :)P.bottomRows&lt;rows&gt;() // P(end-rows+1:end, :)P.bottomRows(rows) // P(end-rows+1:end, :)P.topLeftCorner(rows, cols) // P(1:rows, 1:cols)P.topRightCorner(rows, cols) // P(1:rows, end-cols+1:end)P.bottomLeftCorner(rows, cols) // P(end-rows+1:end, 1:cols)P.bottomRightCorner(rows, cols) // P(end-rows+1:end, end-cols+1:end)P.topLeftCorner&lt;rows,cols&gt;() // P(1:rows, 1:cols)P.topRightCorner&lt;rows,cols&gt;() // P(1:rows, end-cols+1:end)P.bottomLeftCorner&lt;rows,cols&gt;() // P(end-rows+1:end, 1:cols)P.bottomRightCorner&lt;rows,cols&gt;() // P(end-rows+1:end, end-cols+1:end)// Of particular note is Eigen's swap function which is highly optimized.// Eigen // MatlabR.row(i) = P.col(j); // R(i, :) = P(:, j)R.col(j1).swap(mat1.col(j2)); // R(:, [j1 j2]) = R(:, [j2, j1]) 6. 矩阵操作 6.1 转置与旋转 123456789101112131415// Views, transpose, etc;/******************************************************************************//* PLEASE HELP US IMPROVING THIS SECTION *//* Eigen 3.4 supports a new API for reshaping: *//* http://eigen.tuxfamily.org/dox-devel/group__TutorialReshape.html *//******************************************************************************/// Eigen // MatlabR.adjoint() // R'R.transpose() // R.' or conj(R') // Read-writeR.diagonal() // diag(R) // Read-writex.asDiagonal() // diag(x)R.transpose().colwise().reverse() // rot90(R) // Read-writeR.rowwise().reverse() // fliplr(R)R.colwise().reverse() // flipud(R)R.replicate(i,j) // repmat(P,i,j) 6.2 矩阵运算 6.2.1 基本算数运算 12345678// All the same as Matlab, but matlab doesn't have *= style operators.// Matrix-vector. Matrix-matrix. Matrix-scalar.y = M*x; R = P*Q; R = P*s;a = b*M; R = P - Q; R = s*P;a *= M; R = P + Q; R = P/s; R *= Q; R = s*P; R += Q; R *= s; R -= Q; R /= s; 6.2.2 点运算 12345678910111213141516171819202122232425262728293031323334// Vectorized operations on each element independently// Eigen // MatlabR = P.cwiseProduct(Q); // R = P .* QR = P.array() * s.array(); // R = P .* sR = P.cwiseQuotient(Q); // R = P ./ QR = P.array() / Q.array(); // R = P ./ QR = P.array() + s.array(); // R = P + sR = P.array() - s.array(); // R = P - sR.array() += s; // R = R + sR.array() -= s; // R = R - sR.array() &lt; Q.array(); // R &lt; QR.array() &lt;= Q.array(); // R &lt;= QR.cwiseInverse(); // 1 ./ PR.array().inverse(); // 1 ./ PR.array().sin() // sin(P)R.array().cos() // cos(P)R.array().pow(s) // P .^ sR.array().square() // P .^ 2R.array().cube() // P .^ 3R.cwiseSqrt() // sqrt(P)R.array().sqrt() // sqrt(P)R.array().exp() // exp(P)R.array().log() // log(P)R.cwiseMax(P) // max(R, P)R.array().max(P.array()) // max(R, P)R.cwiseMin(P) // min(R, P)R.array().min(P.array()) // min(R, P)R.cwiseAbs() // abs(P)R.array().abs() // abs(P)R.cwiseAbs2() // abs(P.^2)R.array().abs2() // abs(P.^2)(R.array() &lt; s).select(P,Q ); // (R &lt; s ? P : Q)R = (Q.array()==0).select(P,R) // R(Q==0) = P(Q==0)R = P.unaryExpr(ptr_fun(func)) // R = arrayfun(func, P) // with: scalar func(const scalar &amp;x); 6.2.3 矩阵函数 123456789101112131415161718192021222324252627// Reductions.int r, c;// Eigen // MatlabR.minCoeff() // min(R(:))R.maxCoeff() // max(R(:))s = R.minCoeff(&amp;r, &amp;c) // [s, i] = min(R(:)); [r, c] = ind2sub(size(R), i);s = R.maxCoeff(&amp;r, &amp;c) // [s, i] = max(R(:)); [r, c] = ind2sub(size(R), i);R.sum() // sum(R(:))R.colwise().sum() // sum(R)R.rowwise().sum() // sum(R, 2) or sum(R')'R.prod() // prod(R(:))R.colwise().prod() // prod(R)R.rowwise().prod() // prod(R, 2) or prod(R')'R.trace() // trace(R)R.all() // all(R(:))R.colwise().all() // all(R)R.rowwise().all() // all(R, 2)R.any() // any(R(:))R.colwise().any() // any(R)R.rowwise().any() // any(R, 2)// Dot products, norms, etc.// Eigen // Matlabx.norm() // norm(x). Note that norm(R) doesn't work in Eigen.x.squaredNorm() // dot(x, x) Note the equivalence is not true for complexx.dot(y) // dot(x, y)x.cross(y) // cross(x, y) Requires #include &lt;Eigen/Geometry&gt; 6.2.4 类型转换 123456789101112131415161718192021//// Type conversion// Eigen // MatlabA.cast&lt;double&gt;(); // double(A)A.cast&lt;float&gt;(); // single(A)A.cast&lt;int&gt;(); // int32(A)A.real(); // real(A)A.imag(); // imag(A)// if the original type equals destination type, no work is done// Note that for most operations Eigen requires all operands to have the same type:MatrixXf F = MatrixXf::Zero(3,3);A += F; // illegal in Eigen. In Matlab A = A+F is allowedA += F.cast&lt;double&gt;(); // F converted to double and then added (generally, conversion happens on-the-fly)// Eigen can map existing memory into Eigen matrices.float array[3];Vector3f::Map(array).fill(10); // create a temporary Map over array and sets entries to 10int data[4] = &#123;1, 2, 3, 4&#125;;Matrix2i mat2x2(data); // copies data into mat2x2Matrix2i::Map(data) = 2*mat2x2; // overwrite elements of data with 2*mat2x2MatrixXi::Map(data, 2, 2) += mat2x2; // adds mat2x2 to elements of data (alternative syntax if size is not know at compile time) 6.2.5 求解线性方程组 1234567891011// Solve Ax = b. Result stored in x. Matlab: x = A \\ b.x = A.ldlt().solve(b); // A sym. p.s.d. #include &lt;Eigen/Cholesky&gt;x = A.llt() .solve(b); // A sym. p.d. #include &lt;Eigen/Cholesky&gt;x = A.lu() .solve(b); // Stable and fast. #include &lt;Eigen/LU&gt;x = A.qr() .solve(b); // No pivoting. #include &lt;Eigen/QR&gt;x = A.svd() .solve(b); // Stable, slowest. #include &lt;Eigen/SVD&gt;// .ldlt() -&gt; .matrixL() and .matrixD()// .llt() -&gt; .matrixL()// .lu() -&gt; .matrixL() and .matrixU()// .qr() -&gt; .matrixQ() and .matrixR()// .svd() -&gt; .matrixU(), .singularValues(), and .matrixV() 6.2.6 求解特征值 1234567// Eigenvalue problems// Eigen // MatlabA.eigenvalues(); // eig(A);EigenSolver&lt;Matrix3d&gt; eig(A); // [vec val] = eig(A)eig.eigenvalues(); // diag(val)eig.eigenvectors(); // vec// For self-adjoint matrices use SelfAdjointEigenSolver&lt;&gt; 参考 Eigen short ASCII referenceeference.txt)","categories":[],"tags":[]},{"title":"占用栅格更新过程","slug":"占用栅格更新过程","date":"2021-01-30T03:05:20.000Z","updated":"2021-05-31T08:38:02.000Z","comments":true,"path":"2021/01/30/占用栅格更新过程/","link":"","permalink":"http://yoursite.com/2021/01/30/%E5%8D%A0%E7%94%A8%E6%A0%85%E6%A0%BC%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/","excerpt":"","text":"占用栅格更新过程 静态二值贝叶斯滤波 机器人技术中的某些问题表达为不随时间变化的二值状态的最优估计间题。这些问题通过二值贝叶斯滤波 (binary Bayes filter) 来阐述。 如果一个机器人从传感器测量的序列中估计环境的一个固定的二值数,此时这类问题就产生了。例如,一个机器人可能想知道门是开着的还是关着的,并认为在检测期间门的状态不改变。 更新算法 当状态静止时,置信度就仅是测量的函数: 这里状态有两种： \\(x\\) \\(\\neg x\\) 具体来说，有 状态 x 不含时间项反映了状态不会改变的事实 自然的,这类二值估计问题可以利用程序 4. 1 的离散贝叶斯滤波来处理。但是,置信度通常由一个概率比的对数 (log odds ratio)来实现。状态 x 的概率比(odds) 定义为此事件的概率除以该事件不发生的概率 概率对数就是这个表达式的对数 逆向公式，即置信度\\({bel}_t(x)\\)可以根据概率比对数\\(l_t\\)通过下面的方程来求得: : 概率对数将(0,1)映射到\\(-\\infty\\) ~ \\(\\infty\\)，用于更新以概率对数表示的置信度的贝叶斯滤波计算很简洁。它避免了概率接近0或1引起的截断间题。 程序 4.2给出了其基本的更新算法。这种算法是加法。 事实上,任何对测量做出反应的变量的递增和递减都可以解释为贝叶斯滤波的概率对数形式。该二值贝叶斯滤波利用一个反向测量模型 (inverse measurement model) \\(p(x|z_t)\\)代替熟 悉的前向模型\\(p(z_i|x)\\) 。反向测量模型将关于(二值)状态变量的一个分布指定为测量\\(z_t\\)的一个函数。 反向模型经常用于测凰比二值状态更复杂的情况。这种情况的一个实例就是: 从相机图像中估计门是否为关的问题。这里状态很简单,但需要进行所有测量的空间却是很大的。通过设计一个函数根据相机图像来计算门为关着的概率, 要比描述所有相机图像中显示门为关着的分布更容易些。换旬话说,实现一个反向传感器模型比前向传感器模型更容易。 具体证明 根据贝叶斯公式及马尔可夫假设: 将贝叶斯准则应用于测量模型\\(p(z_t|x)\\) 将上述两式结合，得到: 对于对立事件\\(\\neg x\\)，可得: 用式 (4. 18)除以式 (4. 17) 可以将各种难以计算的概率抵消: 对上式两边同时取对数，用\\(l_t(x)\\)表示，即为置信度 \\({bel}_t (x)\\)的概率比对数\\(log \\frac{p(x|z_{1:t})}{1-p(x|z_{1:t})}\\)，有: 这里 \\(p(x)\\) 是状态 x 的先验 (prior) 概率。在式 (4. 20)中, 每个测最更新涉及先验(以概率对数形式)的求和。先验也定义为处理传感器测量前的初始置信度的概率对数:","categories":[],"tags":[]},{"title":"ICRA2020_dynamic_object_removing","slug":"ICRA2020_dynamic_object_removing","date":"2021-01-29T03:05:30.000Z","updated":"2021-02-03T01:11:35.000Z","comments":true,"path":"2021/01/29/ICRA2020_dynamic_object_removing/","link":"","permalink":"http://yoursite.com/2021/01/29/ICRA2020_dynamic_object_removing/","excerpt":"","text":"从点云中删除动态对象的稳健方法 摘要 提出了一种从3D点云地图中删除动态对象的可靠方法。给定一组已配准的3D点云，我们构建一个占据栅格地图，其中体素表示扩展时间段内空间量的占用状态。构建占用地图后，我们将其用作过滤器，以在将激光雷达扫描中的动态点添加到地图之前将其删除。此外，我们使用对象检测和新颖的体素遍历方法来加速构建占用地图的过程。一旦构建了占用图，就可以实时运行动态对象移除。我们的方法在交通停滞或移动的宽阔城市道路上效果很好，并且由于包含了来自同一场景的更多激光雷达扫描，因此占用地图变得更好。 介绍 算法的输入是一组已配准的3D点云，通常由3D激光扫描仪获取。首先，我们使用地平面检测和对象检测算法将点云中的点分为三类：对象点，地面点和未知点。接下来，我们对未知点和地面点执行体素遍历，并降低从传感器原点到端点的光线路径上所有体素的占用分数，但增加端点体素的占用分数。类似地，我们在对象点上执行体素遍历，但是不增加端点体素的占用率，而是降低其占用率，因为我们从对象检测中已经知道端点落在移动的对象上。我们还维护了一组与地面点相对应的地面体素，并防止在两个体素遍历步骤中将它们标记为空闲。我们对注册集中的所有点云重复此过程，并构建一个占用图。最后，我们将完整的占用地图覆盖在点云地图上，并删除空闲体素中的点（请参阅图2）。应当注意，随着时间的推移，随着更多点云的集成，占用图将变得更加稳定和准确。 具体贡献为： 提出了一种新的占用概率更新策略，该策略通过考虑体素的占用历史来构建持久的占用图。与我们的方法不同，[3]赞成快速更新体素的占用分数，赞成最新看到的占用状态 提供了一种可选方法，可通过使用对象检测方法对对象点进行分类来加速占用地图的构建过程，并提供一种使用这些点更新占用地图的策略。 提供了一种生成手工端点的独特方法，该终点用于更新体素的占用分数。 相关工作 在检测/移除激光扫描中的动态对象方面已经完成了大量工作，并且已经提出了解决该问题的不同方法。这些方法可以大致分为三类： 基于模型的无变化检测方法，该方法依赖于将当前激光扫描与之前或之前的一组扫描和将来的扫描进行比较[6]，[7]，[8]，[9]，[10]。 基于神经网络模型的方法，将动态对象对应的点分类[11]，并在激光扫描[12]，[13]，[14]中在对象周围生成边界框并将这些边界框内的点分类为动态对象点。 基于地图的方法，其中使用贝叶斯规则[3]通过激光扫描构建全局占用图/体素网格，或者仅将激光扫描标识符存储在体素中[5]，并且占用图用作过滤器以删除在自由空间中的点。本文提出的动态对象去除方法是基于神经网络模型和基于占用图的方法的混合。 算法介绍 在III-A节中，我们描述了为什么我们偏爱八叉树数据结构 在III-B节中，我们描述了如何使用对象检测来加快在地图中插入点云的过程 第III-D，III-E和III-F节讨论了使用自由计数器使占用图更倾向于持久性而不是易于更新的能力，以及如何使用自由计数器值修剪节点 第III-G节介绍了一种独特的过滤策略，以提高我们的入住地图的质量 占据八叉树 Octree是用于存储有关3D空间的信息的分层数据结构，八叉树中的每个节点代表一个空间容量，称为体素。我们使用log odds表格来表示空间的占用信息。另外，我们还记录着每个节点没有被观测到的次数作为free counter，后面会介绍使用free counter来更新体素的占用率 常用来表示3D空间数据结构的有：体素网格，k-d树和八叉树，我们选择octree作为占用地图，因为octree的层次结构可以紧凑有效地表示空间，与体素网格相反，我们只需在当观测到occupancy information时创建一个节点，在本文中，我们使用最大深度为16的八叉树和0.3米的叶节点体素大小 。 目标检测与体素遍历 对象检测可用于加快生成占用图的过程，并提高动态对象去除的精度和召回得分，我们的方法不依赖于任何特定的对象检测方法，但是在我们的实验中，我们使用了AVOD（聚合视图对象检测）[13]网络来获取边界框，目前，该网络已接受训练以检测小型和大型车辆。 但是，许多基于神经网络的对象检测方法有时都无法检测到对象。这些模型只能检测对其进行训练的对象类别。此外，边界框通常不会完全包围检测到的对象，如图（3）所示。因此，使用上述方法构建的点云图仍将具有一些动态点。 为了去除物体检测方法遗漏的动态物体，我们使用上述方法将点云中的点分为两类： 对象点（位于检测到的对象的边界框内的点） 非对象点（位于边界框外的点） 非对象点遍历 对于点云中的每个非对象点，我们执行体素遍历以找到从传感器原点到终点沿激光射线的所有体素，我们降低了除端点体素以外的所有这些体素的占用率，并增加了端点体素的占用率 对象点遍历 接下来，我们按照相同的步骤插入对象点，但是不增加端点体素的占用率外，而是降低其占用率，这是因为从对象检测中我们已经知道对象点对应于动态对象。 如前所述，有时，围绕对象生成的边界框不会完全包围对象。 我们通过在将非对象点插入到占用图中之后插入对象点来部分解决此问题。此顺序可确保在对对象点执行体素遍历时，将删除动态对象未被边界框包围的部分 地面点检测 如[3]中所述，对以浅角度扫过平面的激光进行体素遍历会导致不良的离散化效果，当遍历另一个附近的体素时，在体素遍历期间被测量为占用的体素可能会标记为空闲，这种影响通常发生在平坦的表面（例如地面和平坦的墙壁）上，并且该影响呈现为平坦表面上的孔，如图（4）所示。 就是体素网格大小导致的 此外，通过对象检测生成的边界框可能包括检测到的对象下方的地面点，并且将地面点错误地分类为动态对象点。 因此，某些地面体素可能仍被标记为空闲。 为了解决此问题，我们为每个地面体素维护一个计数器，该计数器指示将体素分类为地面体的次数，我们还将维护所有检测到的地面体素的集合，并为每次激光雷达扫描更新此集合。 只有地面体素集中那些计数器值大于某个阈值的体素才被视为真实地面体素，这些地面体素在射线遍历期间不会被标记为空闲体素。 我们使用[14]，[18]中所述的基于RANSAC的接地平面检测 权重概率 Octomap [3]使用钳制策略允许占用八叉树图的易于更新性和可压缩性，钳位策略可确保节点的log-odds值不低于下限阈值\\(l_{min}\\)，并且不会超出最高值\\(l_{max}\\). 当一个节点的log-odds值达到两个阈值中的任意一个时，就认为该节点是稳定的，并且具有较高的置信度。钳位策略可确保所有稳定的空闲和占用节点具有相同的对数奇数值，从而可以修剪具有相同log-odds值的相邻节点，还确保了节点的占用状态很容易更新 举例：考虑一个机器人已经绘制了某个区域并观测到其前面几个节点是空闲状态的，现在，如果有人走在机器人前面并站在机器人的路径上，则机器人应该能够快速将节点更新为已占用 其中，\\(L()\\)表示计算log-odds值 然而，[3]中的占用率更新策略倾向于体素的最新占用率状态 ，相反的，本文的目标是创建代表环境长期占用状态的区域的占用地图，我们希望占用率更新算法对动态对象不那么敏感。 本文通过维持每个体素的空闲计数器并使用加权概率来实现此目的。每个体素的计数器用于记录该体素被观测为空闲状态的次数，每次在体素遍历期间，当被观测为空闲状态时，将其递增1；如果其值大于1，并且在体素遍历期间观测到体素被占用，则将其减1。 为了理解原理，考虑两个场景： 第一个情况是体素的空闲计数器值&gt;1，并且插入当前帧点云时，观测到这个体素是占用状态，由于空闲计数器值&gt;1，这表明这个体素先前被记录为空闲，因此该体素很有可能被当前帧点云中的动态对象所占用，因此，我们通过将体素的命中值概率除以空闲计数器值来减轻概率更新，如公式（2）所示，这个策略的动机是：其难以增加先前已经被观测为空闲的体素的占用概率。 体素的空闲计数器值越高，则增加体素的占用概率就越难。 第二种情况是由于对象检测方法的错误检测导致体素被错误地标记为已占用，在这种情况下，我们使用原始公式（1）。 这使得属于动态点的体素易于更新状态。","categories":[],"tags":[]},{"title":"LiTAMIN","slug":"LiTAMIN论文阅读","date":"2021-01-29T03:05:30.000Z","updated":"2022-04-11T15:57:06.354Z","comments":true,"path":"2021/01/29/LiTAMIN论文阅读/","link":"","permalink":"http://yoursite.com/2021/01/29/LiTAMIN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"LiTAMIN: LiDAR-based Tracking And MappINg by Stabilized ICP for Geometry Approximation with Normal Distributions 摘要 提出一种3D SLAM方法，采用一种使用正态分布集群来局部近似几何体的icp算法，与基于正太分布的icp，GICP等方法相比，提出的icp方法通过使用\\(Frobenius\\)范数以及正规化的协方差矩阵简单地稳定了cost func的规范形式。 过去的方法使用pca来进行stabilize，其计算成本高于提出的方法，并且，提出的slam方法可以减少错误的闭环带来的影响. 提出的icp 在SLAM系统中，这需要实时处理，ICP方法必须平衡精度和鲁棒性以获得计算效率, 减少3D点的数量是提高计算效率最有效的解决方案之一。任何基于ICP的SLAM系统[9]，[17] - [20]经常使用具有体素网格和正常分布的ICP方法，因为它们可以降低计算成本，同时仍然保持足够的几何信息。 其中，NDT [17]和GICP [9]是最流行的方法 地图表示和点关联 Voxel网格或K-D树用于地图表示和关联搜索,Voxel网格表示具有计算效率的优势，因为体素数量明显低于原始点云中的点数. 关于相应点查找方面，K-D树表示可以找到具有最近邻居（NN）搜索的关联点，而Voxel网格表示没有保证NN搜索 关于计算成本方面，voxel具有优势，计算成本是O(n)；而k-d树是O(n log n ) 提出的LiTAMIN系统结合两种方式，使用voxel 滤波器来减少点数，每个voxel代表一个点，该点表示voxel的质心, 地图也采用voxel来表示，用于减少点数并看起来密度更加均匀。 Cost func 和 退化情况避免 LITAMIN采用了一个由正态分布近似局部几何的ICP，应该应对协方差矩阵的退化关系, 如果局部几何形状是平面，则协方差矩阵的最小特征值为0或极小 ，","categories":[],"tags":[]},{"title":"第二章-相机模型与对极几何","slug":"第二章_相机模型与对极几何","date":"2021-01-24T04:05:29.000Z","updated":"2021-01-24T09:05:27.000Z","comments":true,"path":"2021/01/24/第二章_相机模型与对极几何/","link":"","permalink":"http://yoursite.com/2021/01/24/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E7%9B%B8%E6%9C%BA%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%AF%B9%E6%9E%81%E5%87%A0%E4%BD%95/","excerpt":"","text":"成像原理与图像特征 针孔相机模型 外参矩阵： 世界坐标系与相机坐标系 相机朝向就是外参矩阵中的旋转矩阵第三行 内参矩阵： 小结： 径向畸变 对极几何 八点法求基础矩阵 RANSAC求基础矩阵 ransac拟合直线举例 ransac估计基础矩阵流程 本征矩阵E 本质矩阵E恢复相机运动（四种情况） H矩阵有效的情况： (1) 空间点都在同一平面上 (2) 相机运动只有旋转","categories":[],"tags":[]},{"title":"BaiDu-考虑lio的定位","slug":"文献阅读/BaiDu_LIO_ICRA2020论文阅读","date":"2021-01-20T03:34:33.000Z","updated":"2021-01-21T08:03:35.000Z","comments":true,"path":"2021/01/20/文献阅读/BaiDu_LIO_ICRA2020论文阅读/","link":"","permalink":"http://yoursite.com/2021/01/20/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/BaiDu_LIO_ICRA2020%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"LiDAR Inertial Odometry Aided Robust LiDAR Localization System in Changing City Scenes 摘要 提出一种将激光惯性里程计(LIO)和激光扫描配定位模块进行整合，然后将两种观测融入到pose graph中进行联合优化的框架。基于激光扫描的global matching和 lio是互补的，这使的可以达到鲁棒的定位，以解决环境的短暂变化以及地图的误差问题，如图1所示。 本文贡献： 一种车辆定位的联合框架，可自适应融合激光扫描匹配和局部里程计，从而有效保护定位系统，使其免受城市场景变化的影响 一种LIO方法，并结合了占据栅格和激光强度 每天在拥挤繁忙的城市街道上经过严格测试的强大车辆定位系统，证明了其在充满挑战和动态变化的环境中的强大能力 相关工作 长期定位（Long-term Localization） 建立一个7天24小时的全天候定位系统是一项艰巨的任务，近年来受到了极大的关注。文献[6]表明，可以通过归一化每一帧的LiDAR扫描的亮度和标准偏差来调整由潮湿路面引起的较少反射率。文献[2][3]通过在地图中引入多分辨率高斯混合表示法，展示了一种强大的LiDAR定位系统，该系统可以通过道路翻修和降雪环境下运行。文献[5]，LiDAR定位系统通过结合高度信息成功地通过了具有挑战性的路段，其中包括新建的墙壁和重新铺设的道路。文献[4]通过引入主成分分析（PCA）和边缘轮廓来增强其定位系统的鲁棒性，尤其是在下雨天或下雪天时。 这些工作着重于利用利基技术解决特定问题，但我们力图通过将里程表和全局匹配模块中的补充线索自适应地融合在一起，从而寻求更通用的解决方案。 其他工作如[7,8,9,10,11]解决了类似的长期定位问题，但使用的视觉传感器对时间，光线或天气导致的场景外观变化敏感。 激光惯性里程计（LiDAR Inertial Odometry） 目前有大量关于激光里程计的工作，如[12,13,14,15,16,17,18,19,20,21,22,23,24]。如[14],[18],[17],[17]，惯性测量可通过提供先验估计并补偿运动失真来帮助解决问题。[18]构建更加紧密的局部运动约束，[23],[24]进一步建立紧密耦合的里程表。 在这项工作中，我们遵循Hess的工作[13]，并将基于占用栅格的LiDAR惯性里程表集成到我们的定位框架中，因为它的地图表示与我们的全局匹配模块相似，并且与多个激光扫描仪兼容 融合定位方法 一类重要的是松耦合融合方法[25]，[5]，[26]利用误差状态卡尔曼滤波器并通过不同方法实现了松耦合的位姿估计。类似于[26]，我们的方法不是使用卡尔曼滤波器，而是利用基于图的融合框架，该框架以每单位计算时间的精度更高的性能优于滤波方法[27]，[28]。[29]展示了融合GNSS，LiDAR和惯性测量的紧密耦合导航系统。 系统框架 提出的系统包含四个模块：LiDAR惯性里程计（LIO），LiDAR全局匹配（LGM），基于姿态图的融合（PGF）和环境变化检测（ECD），如图2所示。 我们遵循G. Wan[5]等人的最新LiDAR定位工作来构建系统，并在我们的框架中将其作为子模块LGM。LGM模块是一种global定位方法，可将在线LiDAR扫描与预先构建的地图进行匹配，并进行3 DoF（x，y，yaw）估计，一旦我们成功地水平定位，就可以通过读取IMU重力测量值和数字高程模型（DEM）地图来估算其他3个自由度（侧倾，俯仰，高度）。 其他两个模块是，LIO和PGF，根据解决不同的最大后验概率（MAP）估计问题来实现。 最大后验概率（MAP）估计问题通常是在滑动窗口下定义的非线性优化问题，设\\(\\kappa\\)记为窗口中的所有帧集合 滑动窗口中的状态\\(\\mathcal{X}=\\left\\{\\mathbf{x}_{k}\\right\\}_{k \\in \\mathcal{K}}\\) 观测集合分别记为\\(\\mathcal{Z}=\\left\\{\\mathbf{z}_{k}\\right\\}_{k \\in \\mathcal{K}}\\) 第k帧的状态\\(\\mathbf{x}_{k}=\\left[\\boldsymbol{\\omega}_{k}, \\mathbf{t}_{k}, \\mathbf{v}_{k}, \\mathbf{b}_{k}\\right]\\)分别表示旋转、位置、速度和bias，其中\\(\\omega_k\\)是李代数中的\\(so(3)\\)，即有\\(R_k=\\exp(\\omega_k)\\)。 提出的LIO框架 LiDAR惯性里程计在我们的系统中起着至关重要的作用，可在严峻的环境（例如，由于道路建设或恶劣天气导致的地图过期或环境变化）中提高定位性能。其中，激光里程计估计相邻帧的相对位姿变换，同时构建局部地图，称为子图，该子图始终是最新的，并且随着每个新的LiDAR SCAN不断更新。 我们的LiDAR惯性里程计的实现遵循W. Hess的工作[13] （注：cartographer），但有许多重要的扩展可提高其准确性。 使用了3d占据栅格来代替2d，来实现6自由度的里程计，这种扩展可将系统应用到3维环境中，如停车场结构或立交桥，同时简化了下面提到的imu预积分 重要的惯性测量数据被合并以提供运动预测和帧之间的相对约束，更重要的是，惯性测量的结合使我们能够对由载体运动引起的扭曲的LiDAR扫描进行运动补偿，为了控制计算时间，我们在实现中采用了[30]引入的惯性测量值的预积分 考虑到某些情况下来自车道或者路面标记的丰富信息，在占据栅格配准过程中整合了激光强度信息，用来补充每个网格单元的占用概率，它提供了有价值的环境纹理信息 最后，通过将多分辨率的占据栅格来实现求解非线性优化问题中的从粗到精细化的方法，它不仅有助于网格配准的收敛，而且可以避免计算需求 LIO问题描述：在给定先前的状态\\(x_{k-1}^L\\)、使用k-1帧更新后的子图\\(\\mathcal{S}_{k-1}\\)以及观测\\(z_k\\)，求状态\\(x_{k}^L\\)的最大后验概率。 其中，\\(\\mathbf{z}_{k}=\\left\\{\\mathbf{z}_{k}^{P}, \\mathbf{z}_{k}^{I}\\right\\}\\)，\\(\\mathbf{z}_{k}\\)和\\(\\mathbf{z}_{I}\\)分别是点云和惯性测量的观测，上标\\(L\\)表示由子图和里程计表示的局部帧的状态\\(\\mathbf{x}_{k}^L\\). 在零均值高斯似概率的假设下，观测的似然概率通过构建cost func来定义： 其中，\\(\\|\\mathbf{r}\\|_{\\Lambda}^{2}=\\mathbf{r}^{T} \\Lambda^{-1} \\mathbf{r}\\)，并且有： 其中， 等式(2)根据imu预积分方法计算，可参考文献30 等式(3)中的SSOP （Sum of Squared Occupancy Probability）和SSID（Sum of Squared Intensity Difference）分别代表占用栅格概率和LiDAR强度损失，其定义如下： 给定一个激光点\\(\\mathbf{p}_j \\in \\R^3\\)，一个分辨率为\\(i\\)的子图以及一个位姿状态\\(\\mathbf{x}_{k}^{L}=\\left[\\mathrm{R}_{k}, \\mathbf{t}_{k}\\right]\\)，子图中被击中的单元\\(s\\)可以被找到。\\(P(s)\\)是在分辨率i下击中子图的占用概率，这个占用概率的维持是通过以最大化后验概率\\(P\\left(\\mathbf{x}_{k}^{L} \\mid \\mathbf{z}_{k}, \\mathbf{x}_{k-1}^{L}, \\mathcal{S}_{k-1}\\right)\\)的方法不断的将新的激光雷达扫描插入到子图中。 这个增量式升级问题可以通过使用inverse measurement模型以及[31]中引入的log adds ratio 的二进制贝叶斯滤波器来解决。 \\(I(\\mathbf{p}_j)\\)是点\\(\\mathbf{p}_j\\)的强度，\\(u_s\\)和\\(\\sigma_s\\)是击中单元的激光强度均值和方差，（注：归一化到标准正态分布）。为了更好的确保配准性能，采用了三次插值从子图中获得概率和强度。方差\\(\\sigma_{Oi}\\)和\\(\\sigma_{ri}\\)用于在不同分辨率下对优化中的占据概率和强度项分别进行加权。 MAP估计值与负对数后验的最小值相对应，后者可以写为残差平方的总和，从而产生非线性最小二乘优化问题 位姿图融合 虽然LiDAR惯性里程计可以在局部坐标系中提供良好的相对约束，但我们仍然需要全局约束才能实现全局定位，baidu-LGM模块为我们的系统提供了全局定位信息，我们的LGM遵循[5]. 将此融合问题公式化为MAP估计，并假设先验分布具有统一形式，将后验概率分解为: 分解可以可视化为如图3所示的贝叶斯网络。在零均值高斯似概率的假设下，观测的似然概率如下： 其中，\\(\\mathbf{r}_{k s}^{O}\\)、\\(\\mathbf{r}_{k}^{I}\\)、\\(\\mathbf{r}_{k}^{G}\\)分别代表里程计、惯性测量、全局匹配的残差。 坐标系定义如下： Local Frame: 局部坐标系，如使用utm投影，再划分，以某个位置作为原点 Global Frame: 全局坐标系，utm/wgs-84等 Submap Pose: 子图相对于局部坐标系的位姿 Lidar Local Frame: 激光雷达坐标系相对于局部坐标系的位姿 如果定义如下： 某帧相对于局部坐标系的位姿（待估计位姿）：\\(\\mathbf{x}_{k}^{L}=\\left[\\mathrm{R}_{k}^{L},\\mathbf{t}_{k}^{L}\\right]\\) 局部坐标系到全局坐标系的变换（应该是已知的）：\\(\\mathbf{x}_{L}^{G}=\\left[\\mathrm{R}_{L}^{G}, \\mathbf{t}_{L}^{G}\\right]\\) 由[5]中的LGM模块输出的全局位姿观测\\(\\mathbf{z}_{k}^{G}=\\left[\\mathrm{R}_{k}^{G}, \\mathbf{t}_{k}^{G}\\right]\\) 全局残差可用如下表示： \\(\\left(\\mathbf{r}_{k}^{G}\\right)^{T}=\\left[\\log ^{T}\\left(\\mathrm{R}_{r G}\\right), \\mathbf{t}_{r G}^{T}\\right]\\)，其中： 关于全局残差的协方差\\(\\Lambda_{k}^{G}\\)，我们将其写为： 其中， \\(\\Lambda^{G_\\omega} \\in \\R^{3\\times3}\\)是旋转协方差 \\(\\Lambda^{G_{z}} \\in \\mathbb{R}^{1 \\times 1}\\)是高度方差 上述协方差矩阵是恒定的对角矩阵，因为我们的LGM模块仅使用[5]中讨论的2D直方图滤波器来估计水平定位的不确定性 如[5]中的等式12所示，相应地针对每个帧k计算水平匹配协方差矩阵\\(\\Lambda_{k}^{G_{h}} \\in \\mathbb{R}^{2 \\times 2}\\) 注意，此处介绍的不确定性估计对于定位系统的性能至关重要，从而产生自适应融合 关于里程计的残差问题，将会采用随着激光里程计的运行终结旧的子图更新并且创建新的子图。 由LIO模块输出的载体局部位姿与子图的之间的相对位姿关系约束\\(\\mathbf{z}_{ks}^O\\)被构建并存在于滑动窗口的生命周期中。相似的，如果由如下定义： 某个子图的位姿:\\(\\mathbf{x}_{s}^{S}=\\left[\\mathrm{R}_{s}^{S}, \\mathbf{t}_{s}^{S}\\right]\\) 某帧相对于子图的位姿观测: \\(\\mathbf{z}_{k s}^{O}=\\left[\\mathrm{R}_{k s}^{O}, \\mathbf{t}_{k s}^{O}\\right]\\) 里程计残差可定义为： \\(\\left(\\mathbf{r}_{k s}^{O}\\right)^{T}=\\left[\\log ^{T}\\left(R_{r O}\\right), \\mathbf{t}_{r O}^{T}\\right]\\) 其中， 根据里程残差中的协方差\\(\\Lambda^O\\)，假设估计不确定性在所有帧之间均匀分布，我们在所有帧和子图上使用全局常数对角矩阵 惯性约束的预积分的处理方法与[30]中介绍的相同。 使用Ceres解算器[32]求解非线性最小二乘优化。 实验 传感配置： Velodyne HDL- 64E 360◦LiDAR NovAtel PwrPak7D-E1 GNSS RTK receiver integrated with dual antennas and an Epson EG320N IMU. 基准参考： 没有用rtk，用的啥离线slam方法？ The ground truth poses used in the evaluation are generated using offline LiDAR SLAM methods typically formulated as a large-scale global least-square optimization problem, which are beyond the scope of this work. 运行速度分析 lio、pose graph fuse 运行在CPU上 全局激光匹配运行在FPGA上","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"CUDA编程","slug":"CUDA编程","date":"2020-12-24T14:05:33.000Z","updated":"2021-02-11T10:10:50.713Z","comments":true,"path":"2020/12/24/CUDA编程/","link":"","permalink":"http://yoursite.com/2020/12/24/CUDA%E7%BC%96%E7%A8%8B/","excerpt":"","text":"GPU硬件架构综述 Fermi GPU 相关术语","categories":[],"tags":[]},{"title":"第六章-(1)-基于预积分的建图方法","slug":"多传感器融合定位/第六章-基于优化方法融合_进阶","date":"2020-12-21T00:36:46.000Z","updated":"2020-12-24T14:03:58.000Z","comments":true,"path":"2020/12/21/多传感器融合定位/第六章-基于优化方法融合_进阶/","link":"","permalink":"http://yoursite.com/2020/12/21/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E5%85%AD%E7%AB%A0-%E5%9F%BA%E4%BA%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E8%9E%8D%E5%90%88_%E8%BF%9B%E9%98%B6/","excerpt":"","text":"基于预积分优化的建图方法 预积分模型推导 导航方程 连续时间的预积分计算 离散时间的预积分计算（中值积分） 预积分量的计算 预积分的更新 预积分的方差（传递） 姿态误差微分方程推导 这是定义在local的误差角","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"LiLi-om论文阅读","slug":"文献阅读/Lili-om论文阅读","date":"2020-12-09T03:34:33.000Z","updated":"2020-12-09T14:56:07.000Z","comments":true,"path":"2020/12/09/文献阅读/Lili-om论文阅读/","link":"","permalink":"http://yoursite.com/2020/12/09/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/Lili-om%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Towards High-Performance Solid-State-LiDAR-Inertial Odometry and Mapping IN2LAAMA: Inertial Lidar Localization Autocalibration and Mapping. 用预积分去畸变，可以参考 系统架构 10hz激光雷达 Xsens MTi-670 200Hz imu 首先使用陀螺仪对点云去畸变（旋转） 提取平面、边缘线特征 基于点-线、点-面距离，进行scan-matching，求出相对运动后进一步对点云去畸变（平移） 选择关键帧策略 滑动窗口优化 融合窗口通常包含了几个关键帧，当窗口滑动时，将对窗口内的关键帧状态进行优化， 其中, \\(\\breve{x}_k , \\breve{q}_k\\)表示关键帧位姿 \\(\\breve{v}_k\\)表示速度 \\(\\breve{b}_k = [\\breve{b}_{k,a}^T,\\breve{b}_{k,g}^T]^T\\)表示imu的bias 最终，维护一个全局的位姿图，对所有的lidar关键帧位姿进行整合 特征点提取 这里关于Livox激光雷达的特征提取 提出出来的边缘线特征和平面特征对前端里程计以后后端滑动窗口都有用 为了量化传感器融合过程中每个LiDAR残差的贡献，根据关联质量提出了度量加权函数，如下： 其中， \\(o\\)表示特征（e表示边缘，s表示平面） 对于边缘线特征，\\(\\nu_e, n_e\\)分别表示在\\(p_k^l\\)处的边缘线的方向向量，和最近5个边缘点特征所近似得到的边缘线 对于平面特征，\\(\\nu_s,n_s\\)分别表示在点\\(p_k^l\\)处的平面法向量和由最近5个点形成的 \\(\\gamma(p_k^l),\\gamma_j\\)分别代表特征点\\(p_k^l\\)及其关联的最近5个特征点的关联值 因此，建议的度量加权函数考虑了特征关联的几何和外观一致性 基于关键帧的imu-lidar紧耦合滑动窗口优化 基于关键帧的策略首先应用于视觉slam，LIO-SAM，使用isam2对前端激光前端里程计的关键帧和imu预积分约束进行融合，liom中紧密耦合的LiDAR惯性里程计系统通过滑动窗口优化实现了LiDAR和预集成IMU测量的直接融合，但是实时性不够，因为融合了每一帧lidar扫描 关键帧策略 因此，保持后端直接LiDAR-惯性融合优化方案的稀疏性非常重要，如图5所示，提出的融合方案利用关键帧建立滑动窗口，其中，激光雷达和imu预积分观测使用非线性优化的方法进行融合。 但是关键帧的选取标准会影响前端里程计的准确性，由于imu积分在相邻两关键帧之间存在漂移，因此，提出了两个准则： 当前帧的特征与局部特征地图重叠率&lt;60% 如果最后一个关键帧的时间差大于指定阈值 在窗口优化后向前滑动时，构造一个局部因子图，对两个最旧的关键帧位姿作为约束，而regular-frame帧位姿则通过imu测量作为初始化值。使用一个小规模的因子图优化以获取与激光雷达采样频率一致的regular-frame位姿 滑动窗口 目标是求解式(1)中的滑动窗口内关键帧状态，方法是通过求解激光特征点和imu预积分约束构成的非线性优化问题，使用一个包含三个分量的最大后验(MAP)目标函数： 其中， \\(\\breve{X}=[\\breve{x}_1^T,\\cdots,\\breve{x}_2^T]^T \\in \\R^{15\\times \\tau_w}\\)表示滑动窗口中的关键帧状态，\\(\\tau_w\\)表示滑窗大小 \\(\\mathcal{R}_{p}(\\breve{X})\\)表示由于滑动窗口滑动时进行marginalized得到的关于观测的先验项 \\(\\mathcal{R}_L(\\breve{x}_k^w,\\breve{p}_{k,i}^l,\\breve{\\Mu}^w)\\)表示激光雷达残差项（根据待估计的关键帧位姿\\(\\breve{x}_k^w\\)将观测到的点\\(\\breve{p}_{k,i}^l\\)对齐到局部特征点地图\\(\\breve{\\Mu}^w\\)），m表示特征关联数 局部特征点地图\\(\\breve{\\Mu}^w\\)结合了最近30帧关键帧观察到的特征 \\(\\mathcal{R}_J(\\breve{x}_k,\\hat{z}_{k+1}^k)\\)是第k个关键帧以及imu数据从第k帧到k+1帧的imu预积分约束所构建的残差项 先验因子 为了在不造成实质性信息损失的情况下限制LiDAR惯性融合的计算负担，我们在基于关键帧的窗口中利用边缘化，vins-mono中，使用Schur-complement对最旧的关键帧及其观测进行边缘化，相应的计算得到一个新的先验，并将其添加到一存在的先验因子的顶部。 激光雷达残差 加权的点-线、点-面距离 imu观测残差（预积分误差） 为了避免每次优化窗口滑动时都重新传播IMU状态，所以将两个连续的关键帧k和k+1之间的imu原始数据进行积分，并将预积分看作是两个关键帧之间的相对位姿观测，可以得到预积分误差： 其中， \\(\\Delta \\tau_k\\)表示第k关键帧与k+1帧的时间间隔 \\([\\cdot]_{2:4}\\)表示取四元数向量中的最后3个元素 \\(\\hat{z}_{k+1}^{k}=[\\hat{\\alpha}_{k+1}^{kT},\\hat{\\beta}_{k+1}^{kT},\\hat{\\gamma}_{k+1}^{kT}]\\)表示从第k帧到第k+1帧的imu预积分量 由于篇幅所限，论文不提供IMU预积分的推导和相应的噪声协方差\\(C_{k+1}^{k}\\),具体可参考vins-mono","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"LINS论文阅读","slug":"文献阅读/LINS论文阅读","date":"2020-12-07T12:52:33.000Z","updated":"2020-12-09T03:33:43.000Z","comments":true,"path":"2020/12/07/文献阅读/LINS论文阅读/","link":"","permalink":"http://yoursite.com/2020/12/07/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/LINS%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"LINS: A Lidar-Inertial State Estimator for Robust and Efficient Navigation ESKF模型 坐标系定义： \\(\\mathcal{F}_w\\)表示固定的世界坐标系 \\(\\mathcal{F}_{bk}\\)表示第k个激光雷达时间步的imu坐标系 \\(\\mathcal{F}_{lk}\\)表示第k个激光雷达时间步的lidar坐标系 local frame是指前一个激光雷达时间步的imu坐标系 状态定义 \\(x_w^{bk}\\)表示\\(\\mathcal{F}_{bk}\\)坐标系到\\(\\mathcal{F}_w\\)世界坐标系的变换 \\(x_{bk+1}^{bk}\\)表示从\\(\\mathcal{F}_{bk+1}\\)坐标系到\\(\\mathcal{F}_{bk}\\)坐标系的变换 \\[ x_w^{bk} = [p_w^{bk},q_w^{bk}] \\] \\[ x_{bk+1}^{bk} = [p_{bk+1}^{bk},v_{bk+1}^{bk},q_{bk+1}^{bk},b_a,b_g,g^{bk}] \\] 误差状态定义 \\[ \\delta x=[\\delta p, \\delta v ,\\delta \\theta, \\delta b_a , \\delta b_g ,\\delta g] \\] 根据误差状态卡尔曼，一旦\\(\\delta x\\)被估计出来，我们就可以获得最终的结果\\(x_{bk+1}^{bk}\\)，通过向state nominal的\\(^-x_{bk+1}^{bk}\\)注入误差状态\\(\\delta\\)，即： 状态传播（预测） 这一步进行如下参数的传播 误差状态\\(\\delta x\\) 误差状态协防差矩阵\\(P_k\\) state nominal的\\(^-x_{bk+1}^{bk}\\) 当新的imu测量到达，线性连续时间模型如下： 其中， \\(w=[n_a^T,n_g^G,n_{ba}^T,n_{bg}^T]\\)，分别表示高斯噪声模型，与VINS-Mono一致 \\(F_t\\)是误差状态转移矩阵 \\(G_t\\)是噪声雅克比矩阵 论文公式有误，详细可参考 误差状态卡尔曼P69——The error state Jacobian and perturbation matrices 式(311) 其中， \\([\\cdot]_{\\times} \\in \\R^{3\\times 3}\\)表示将3D向量转换成反对称矩阵 \\(R_t^{bk}\\)表示将k时刻的imu坐标系转换到\\(\\mathcal{F}_{bk}\\)坐标系的旋转 \\(\\hat{a}^t,\\hat{\\omega}_t\\)表示去除bias以及(重力影响?)的加速度计输出和陀螺仪输出 对式(5)进行离散化，得到离散时间的传播方程(预测) 其中, \\(\\Delta_t=t_\\tau-t_{\\tau-1}\\) \\(t_\\tau,t_{\\tau-1}\\)是imu数据时间戳 Q表示噪声w的协方差矩阵，可以由离线的传感器参数标定获取 更新 文章的主要贡献在此 在iekf里面，更新步骤其实可以与优化问题建立关联： 参考文献: A review of point cloud registration algorithms for mobile robotics. Iterated extended kalman filter based visual-inertial odometry using direct photometric feedback. 即以误差状态作为待求解的变量\\(\\delta x\\) 其中， \\(f(\\cdot)\\)是残差函数，其输出是点——线、点——面距离的对叠向量 \\(||\\cdot||\\)是马氏距离 \\(J_k\\)是残差函数\\(f(\\cdot)\\)对观测噪声的雅克比 \\(M_k\\)是观测噪声的协方差矩阵 当给定一个\\(x_{bk+1}^{bk}\\)，\\(f(\\cdot)\\)中关于点\\(p_i^{lk+1}\\)（\\(\\mathcal{F}_{lk+1}\\)坐标系中的第i个点）的误差项可以描述如下: 就是LOAM的距离计算公式 然后有: 其中, \\(\\hat{p}_i^{lk}\\)表示将点\\(p_i^{lk+1}\\)从\\(\\mathcal{F}_{lk+1}\\)坐标系转换到\\(\\mathcal{F}_{lk}\\)坐标系后的点 \\(R_l^b,p_l^b\\)表示激光雷达到imu的外參(可离线标定获取) 关于式(13)的物理解释是：对于一个边缘线上的点，它描述了点\\(\\hat{p}_i^{lk}\\)到与他相关联的边缘线\\(p_a^{lk}p_b^{lk}\\)，对于平面点，同理 (就是LOAM嘛) 然后使用iekf来求解式(12)所描述的优化问题: 其中， \\(\\Delta x_j\\)表示在第j次迭代的矫正，即求解出来的增量 \\(H_{k,j}\\)表示\\(f(^-x_{bk+1}^{bk}\\boxplus\\delta x_j)\\)关于\\(\\delta x_j\\)的雅克比 注意到，在每一次迭代中，将重新关联边缘线特征和平面特征，这样就可以重新计算\\(H_{k,j},J_{k,j}和K_{k,j}\\)，相当于更新线性化点，重新关联特征 当\\(f(x_{bk+1}^{bk})\\)降低到一个特定的阈值，就对协方差\\(P_k\\)进行更新，结束迭代 使用式(4)，即可获取到最终的结果\\(x_{bk+1}^{bk}\\)，然后还可以进行去畸变操作。 最后，可以对下一个状态\\(x_{bk+2}^{bk+1}\\)进行初始化: 其中， \\(q_0\\)表示单位四元数 \\(v_{bk+1}^{bk+1}=R_{bk}^{bk+1}v_{bk+1}^{bk}\\) \\(g^{bk+1}=R_{bk}^{bk+1}g^{bk}\\) 注意到，在协方差矩阵中，速度、bias、重力都保持，而其他关于相对位姿的项都被置零，因为相对于自身坐标系没有不确定性. 状态补偿 每一个更新步完成，需要对全局位姿\\(x_w^{bk}\\)进行更新，如下: 初始化 初始加速度bias，Lidar-imu外參都通过离线标定获取 初始的陀螺仪bias通过求均值获取 初始roll和pitch在运动之前可通过去除bias的加速度计算得到 初始的重力向量使用前面获取的roll和pitch将导航坐标系的重力向量转换到载体坐标系(imu系)获取","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"第四章-(3)-补充内容","slug":"多传感器融合定位/第四章-基于滤波器融合-3","date":"2020-12-07T04:36:46.000Z","updated":"2020-12-07T07:35:06.000Z","comments":true,"path":"2020/12/07/多传感器融合定位/第四章-基于滤波器融合-3/","link":"","permalink":"http://yoursite.com/2020/12/07/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%9F%BA%E4%BA%8E%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%9E%8D%E5%90%88-3/","excerpt":"","text":"","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"IMU噪声模型","slug":"IMU相关/IMU噪声模型","date":"2020-11-27T05:05:29.000Z","updated":"2020-11-27T05:05:01.000Z","comments":true,"path":"2020/11/27/IMU相关/IMU噪声模型/","link":"","permalink":"http://yoursite.com/2020/11/27/IMU%E7%9B%B8%E5%85%B3/IMU%E5%99%AA%E5%A3%B0%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"Kalibr Kalibr使用的IMU观测模型包含两种误差： n，白噪声（波动较快） b，缓慢变化的bias 因此，以陀螺仪为例子，角速度测量可写成： \\[ \\tilde{\\omega}(t) = \\omega(t) + b(t) +n(t) \\] 附加白噪声 连续时间 可以使用零均值、独立、连续时间的高斯白噪声来描述，即 \\[ E[n(t)] =0 \\] \\[ E[n(t_1)n(t_2)]=\\sigma_g^2 \\delta(t_1-t_2) \\] \\(\\sigma_g\\)越大，表明陀螺仪测量越嘈杂 这是连续时间的模型 离散化时间","categories":[{"name":"IMU相关","slug":"IMU相关","permalink":"http://yoursite.com/categories/IMU%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"滤波器分析——状态方程和观测方程","slug":"多传感器融合定位/滤波器融合_2_滤波器分析","date":"2020-11-20T13:36:46.000Z","updated":"2020-11-22T04:17:24.000Z","comments":true,"path":"2020/11/20/多传感器融合定位/滤波器融合_2_滤波器分析/","link":"","permalink":"http://yoursite.com/2020/11/20/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%9E%8D%E5%90%88_2_%E6%BB%A4%E6%B3%A2%E5%99%A8%E5%88%86%E6%9E%90/","excerpt":"","text":"基于误差状态的滤波分析 根据《惯导解算原理——捷联惯导更新算法及误差分析》分析，已经得到了三个误差方程： 姿态误差方程 \\[ \\begin{aligned} \\dot{\\phi} = \\phi \\times \\omega_{in}^n - \\delta \\omega_{ib}^n \\end{aligned} \\] 速度误差方程 \\[ \\begin{aligned} \\delta \\dot{V}^n = \\delta f^n + (f^n \\times)(\\phi) \\end{aligned} \\] 位置误差方程 \\[ \\begin{aligned} \\delta \\dot{P} = \\delta V \\end{aligned} \\] 现在，对上面的方程进行展开 姿态误差方程（矩阵形式） 这里姿态误差取全局误差角\\(\\phi=[\\phi_E , \\phi_N, \\phi_U]\\)，表示的是从 n 系至 n'系的等效旋转矢量，即 n'系到 n系的旋转变换 由于: \\[ \\begin{aligned} \\phi=\\begin{bmatrix} \\phi_E &amp; \\phi_N &amp; \\phi_U \\end{bmatrix}^T \\end{aligned} \\] \\[ \\begin{aligned} \\omega_{ie}^n=\\begin{bmatrix} 0 &amp; \\omega_{ie} \\cos L &amp; \\omega_{ie} \\cos L \\end{bmatrix}^T \\end{aligned} \\] \\[ \\begin{aligned} \\delta \\omega_{ib}^n= C_b^n \\begin{bmatrix} \\epsilon_x \\\\ \\epsilon_y \\\\ \\epsilon_z \\end{bmatrix} \\end{aligned} \\] 其中, \\(\\omega_{ie}\\)为地球自转角速度 \\(\\epsilon\\)为陀螺仪bias 因此，姿态误差方程\\(\\dot{\\phi}=\\phi \\times \\omega_{ie}^n - \\delta \\omega_{ib}^n\\)可写成矩阵形式： \\[ \\begin{aligned} \\begin{bmatrix} \\dot{\\phi}_E \\\\ \\dot{\\phi}_N \\\\ \\dot{\\phi}_U \\end{bmatrix} = \\begin{bmatrix} 0 &amp; -\\phi_U &amp; \\phi_N \\\\ \\phi_U &amp; 0 &amp; -\\phi_E \\\\ -\\phi_N &amp; \\phi_E &amp; 0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ \\omega_{ie} \\cos L \\\\ \\omega_{ie} \\sin L \\end{bmatrix} - C_b^n \\begin{bmatrix} \\epsilon_x \\\\ \\epsilon_y \\\\ \\epsilon_z \\end{bmatrix} \\end{aligned} \\] 速度误差方程（矩阵形式） 由于： \\[ f^n=[f_E,f_N,f_U]^T \\] 且比力误差为加速度计bias \\[ \\begin{aligned} \\delta f^n=C_b^n \\begin{bmatrix} \\triangledown_x \\\\ \\triangledown_y \\\\ \\triangledown_z \\end{bmatrix} \\end{aligned} \\] 其中，\\(\\triangledown\\)为加速度计的bias 因此，速度误差方程\\(\\delta \\dot{V}=f^n \\times \\phi + \\delta f^n\\)可写成矩阵形式如下： \\[ \\begin{aligned} \\begin{bmatrix} \\delta \\dot{V}_E \\\\ \\delta \\dot{V}_N \\\\ \\delta \\dot{V}_U \\end{bmatrix} = \\begin{bmatrix} 0 &amp; -f_U &amp; f_N \\\\ f_U &amp; 0 &amp; -f_E \\\\ -f_N &amp; f_E &amp; 0 \\end{bmatrix} \\begin{bmatrix} \\phi_E \\\\ \\phi_N \\\\ \\phi_U \\end{bmatrix} +C_b^n \\begin{bmatrix} \\triangledown_x \\\\ \\triangledown_y \\\\ \\triangledown_z \\end{bmatrix} \\end{aligned} \\] 位置误差方程（矩阵形式） 直接把位置误差方程\\(\\delta \\dot{P}=\\delta V\\)写成矩阵形式: \\[ \\begin{aligned} \\begin{bmatrix} \\delta \\dot{P}_E \\\\ \\delta \\dot{P}_N \\\\ \\delta \\dot{P}_U \\end{bmatrix} = \\begin{bmatrix} \\delta V_E \\\\ \\delta V_N \\\\ \\delta V_U \\end{bmatrix} \\end{aligned} \\] 状态方程 状态方程基本形式： \\[ \\dot{X}=F_tX+B_tW \\] 对于非线性系统,矩阵\\(F_t\\)是误差状态导数对误差状态向量求偏导 取状态向量: \\[ \\begin{aligned} X= \\begin{bmatrix} \\delta P_{3x1} \\\\ \\delta V_{3x1} \\\\ \\phi_{3x1} \\\\ \\epsilon_{3x1} \\\\ \\triangledown_{3x1} \\end{bmatrix}_{15x1} \\end{aligned} \\] 其中， \\(\\delta P\\)表示enu位置误差量 \\(\\delta V\\)表示enu速度误差量 \\(\\phi\\) 表示导航坐标系n系与计算坐标系n'系的等效旋转矢量偏差 \\(\\epsilon\\)表示陀螺仪bias \\(\\triangledown\\)表示加速度计bias 根据前面推导的误差状态方程，可以得到矩阵\\(F_t\\): $$ \\[\\begin{aligned} F_t &amp;= \\begin{bmatrix} \\frac{\\partial \\delta \\dot{P}}{\\partial \\delta P} &amp; \\frac{\\partial \\delta \\dot{P}}{\\partial \\delta V} &amp; \\frac{\\partial \\delta \\dot{P}}{\\partial \\delta \\phi} &amp; \\frac{\\partial \\delta \\dot{P}}{\\partial \\delta \\epsilon} &amp; \\frac{\\partial \\delta \\dot{}}{\\partial \\delta \\triangledown} \\\\ \\frac{\\partial \\delta \\dot{V}}{\\partial \\delta P} &amp; \\frac{\\partial \\delta \\dot{V}}{\\partial \\delta V} &amp; \\frac{\\partial \\delta \\dot{V}}{\\partial \\delta \\phi} &amp; \\frac{\\partial \\delta \\dot{V}}{\\partial \\delta \\epsilon} &amp; \\frac{\\partial \\delta \\dot{V}}{\\partial \\delta \\triangledown} \\\\ \\frac{\\partial \\delta \\dot{\\phi}}{\\partial \\delta P} &amp; \\frac{\\partial \\delta \\dot{\\phi}}{\\partial \\delta V} &amp; \\frac{\\partial \\delta \\dot{\\phi}}{\\partial \\delta \\phi} &amp; \\frac{\\partial \\delta \\dot{\\phi}}{\\partial \\delta \\epsilon} &amp; \\frac{\\partial \\delta \\dot{\\phi}}{\\partial \\delta \\triangledown} \\\\ \\frac{\\partial \\delta \\dot{\\epsilon}}{\\partial \\delta P} &amp; \\frac{\\partial \\delta \\dot{\\epsilon}}{\\partial \\delta V} &amp; \\frac{\\partial \\delta \\dot{\\epsilon}}{\\partial \\delta \\phi} &amp; \\frac{\\partial \\delta \\dot{\\epsilon}}{\\partial \\delta \\epsilon} &amp; \\frac{\\partial \\delta \\dot{\\epsilon}}{\\partial \\delta \\triangledown} \\\\ \\frac{\\partial \\delta \\dot{\\triangledown}}{\\partial \\delta P} &amp; \\frac{\\partial \\delta \\dot{\\triangledown}}{\\partial \\delta V} &amp; \\frac{\\partial \\delta \\dot{\\triangledown}}{\\partial \\delta \\phi} &amp; \\frac{\\partial \\delta \\dot{\\triangledown}}{\\partial \\delta \\epsilon} &amp; \\frac{\\partial \\delta \\dot{\\triangledown}}{\\partial \\delta \\triangledown} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 0_{3x3} &amp; I_{3x3} &amp; 0_{3x3} &amp; 0_{3x3} &amp; 0_{3x3} \\\\ 0_{3x3} &amp; 0_{3x3} &amp; F_{23} &amp; 0_{3x3} &amp; C_b^n \\\\ 0_{3x3} &amp; 0_{3x3} &amp; F_{33} &amp; -C_b^n &amp; 0_{3x3} \\\\ &amp; &amp; 0_{3x15} &amp; &amp; \\\\ &amp; &amp; 0_{3x15} &amp; &amp; \\end{bmatrix} \\end{aligned}\\] $$ \\[ \\begin{aligned} F_{23}= \\begin{bmatrix} 0 &amp; -f_U &amp; f_N \\\\ f_U &amp; 0 &amp; -f_E \\\\ -f_N &amp; f_E &amp; 0 \\end{bmatrix} \\end{aligned} \\] \\[ \\begin{aligned} F_{33}= \\begin{bmatrix} 0 &amp; \\omega_{ie} \\sin L &amp; -\\omega_{ie} \\cos L \\\\ -\\omega_{ie} \\sin L &amp; 0 &amp; 0 \\\\ \\omega_{ie} \\cos L &amp; 0 &amp; 0 \\end{bmatrix} \\end{aligned} \\] 取噪声向量\\(W\\): \\[ \\begin{aligned} W&amp;= \\begin{bmatrix} W_{gyro} \\\\ W_{acc} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} w_{gx} \\\\ w_{gy} \\\\ w_{gz} \\\\ w_{ax} \\\\ w_{ay} \\\\ w_{az} \\end{bmatrix} \\end{aligned} \\] 其中， \\(W_{gyro}\\)是陀螺仪噪声 \\(W_{acc}\\)是加速度计噪声 由于噪声是跟bias通一个通道引入的，因此矩阵\\(B_t\\)可以直接从\\(F_t\\)矩阵的后两列取，也可以直接算: \\[ \\begin{aligned} B_t= \\begin{bmatrix} 0_{3x3} &amp; 0_{3x3} \\\\ 0_{3x3} &amp; C_b^n \\\\ -C_b^n &amp; 0_{3x3} \\\\ 0_{6x3} &amp; 0_{6x3} \\end{bmatrix} \\end{aligned} \\] 观测方程（基于点云配准获得观测） 观测方程基本形式： 这个方程其实是利用预测的状态向量X来计算出一个预测的Y，后面再根据真实的观测Y与这个预测的Y做差，求得差值 \\[ Y=G_tX+C_tN \\] 由于这是观测，因此\\(G_t\\)矩阵不是偏导 假设观测量有位置和失准角，因此取观测向量\\(Y\\): \\[ \\begin{aligned} Y= \\begin{bmatrix} \\delta P \\\\ \\phi \\end{bmatrix} \\end{aligned} \\] 又由于 \\[ \\begin{aligned} X= \\begin{bmatrix} \\delta P_{3x1} \\\\ \\delta V_{3x1} \\\\ \\phi_{3x1} \\\\ \\epsilon_{3x1} \\\\ \\triangledown_{3x1} \\end{bmatrix}_{15x1} \\end{aligned} \\] 观测方程中的N为观测噪声： \\[ \\begin{aligned} N &amp;= \\begin{bmatrix} n_{P_{3x1}} \\\\ n_{\\phi_{3x1}} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} n_{P_E} \\\\ n_{P_N} \\\\ n_{P_U} \\\\ n_{\\phi_E} \\\\ n_{\\phi_N} \\\\ n_{\\phi_U} \\end{bmatrix} \\end{aligned} \\] 因此有： \\[ \\begin{aligned} G_t = \\begin{bmatrix} I_{3x3} &amp; 0_{3x3} &amp; 0_{3x3} &amp; 0_{3x6} \\\\ 0_{3x3} &amp; 0_{3x3} &amp; I_{3x3} &amp; 0_{3x6} \\end{bmatrix} \\end{aligned} \\] \\[ \\begin{aligned} C_t= \\begin{bmatrix} I_{3x3} &amp; 0_{3x3} \\\\ 0_{3x3} &amp; I_{3x3} \\end{bmatrix} \\end{aligned} \\] 获取真实观测量Y时，需要计算失准角\\(\\phi\\)，具体计算方法如下： 先计算误差矩阵\\(C_n^{n&#39;}\\) \\[ \\begin{aligned} &amp; \\because C_b^n=C_{n&#39;}^n C_b^{n&#39;} \\\\ &amp; \\therefore C_n^{n&#39;} = C_b^{n&#39;}(C_b^n)^T \\end{aligned} \\] 其中， \\(C_b^{n&#39;}\\)为当前时刻位姿的预测值 \\(C_b^n\\)为姿态矩阵的观测值（如点云匹配定位的结果） 根据罗德里格斯公式，获取\\(\\phi\\) \\[ C_n^{n&#39;} \\approx I-(\\phi \\times) \\] 观测方程（基于点云配准+轮速计获得观测） 观测方程基本形式： 这个方程其实是利用预测的状态向量X来计算出一个预测的Y，后面再根据真实的观测Y与这个预测的Y做差，求得差值 \\[ Y=G_tX+C_tN \\] 由于这是观测，因此\\(G_t\\)矩阵不是偏导 假设已知轮速计观测误差方程如下（注意不是状态误差方程，因此跟导数没关系）： 观测误差方程具体推导参见：* \\[ \\delta V_b = C_n^b \\delta V_n - C_n^b (V_n \\times)\\phi \\] 有了观测误差方程后，可以对观测方程进行重写，步骤如下： 确定状态向量 \\[ \\begin{aligned} Y= \\begin{bmatrix} \\delta P \\\\ \\phi \\end{bmatrix} \\end{aligned} \\] 确定观测向量 \\[ \\begin{aligned} Y= \\begin{bmatrix} \\delta P \\\\ \\delta V_b \\\\ \\phi \\end{bmatrix} \\end{aligned} \\] 其中， 相比于之前的观测向量，增加了\\(\\delta V_b\\)，表示根据当前状态预测得到的载体轮速 与 轮速计测量值的差值 误差量\\(\\delta V_b\\)计算公式如下： \\[ \\begin{aligned} \\delta V_b = \\tilde{V_b}-V_b=\\tilde{C}_n^b \\tilde{V}_n - \\begin{bmatrix} 0 \\\\ v_m \\\\ 0 \\end{bmatrix} \\end{aligned} \\] 其中， \\(\\tilde{C}_n^b\\tilde{V}_n\\)表示利用当前的状态值计算得到轮速的预测值 \\(V_b=V_m=[0,v_m,0]^T\\)表示轮速计实际观测值(假设轮速计观测是右x-前y-上z坐标系) 重写观测方程 \\[ Y=G_tX+C_tN \\] 其中，矩阵\\(G_t\\)变成如下形式： \\[ \\begin{aligned} G_t = \\begin{bmatrix} I_{3x3} &amp; 0_{3x3} &amp; 0_{3x3} &amp; 0_{3x6} \\\\ 0_{3x3} &amp; C_n^b &amp; -C_n^b(V_n \\times) &amp; 0_{3x6}\\\\ 0_{3x3} &amp; 0_{3x3} &amp; I_{3x3} &amp; 0_{3x6} \\end{bmatrix} \\end{aligned} \\] 与之前的\\(G_t\\)矩阵相比，增加了中间那行 矩阵\\(C_t\\)变成如下： \\[ \\begin{aligned} C_t= \\begin{bmatrix} I_{3x3} &amp; 0_{3x3} &amp; 0_{3x3}\\\\ 0_{3x3} &amp; I_{3x3} &amp; 0_{3x3} \\\\ 0_{3x3} &amp; 0_{3x3} &amp; I_{3x3} \\end{bmatrix} \\end{aligned} \\] 观测噪声向量变成如下： \\[ \\begin{aligned} N &amp;= \\begin{bmatrix} n_{P_{3x1}} \\\\ n_{Vb_{3x1}} \\\\ n_{\\phi_{3x1}} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} n_{P_E} \\\\ n_{P_N} \\\\ n_{P_U} \\\\ n_{V_{bx}} \\\\ n_{V_{by}} \\\\ n_{V_{bz}} \\\\ n_{\\phi_E} \\\\ n_{\\phi_N} \\\\ n_{\\phi_U} \\end{bmatrix} \\end{aligned} \\] 如果考虑imu安装误差的情况，具体推导参见： * 观测方程（基于GPS获得位置观测） 观测方程基本形式： \\[ Y=G_tX+C_tN \\] 由于这是观测，因此\\(G_t\\)矩阵不是偏导 假设观测量是GPS给出的位置，因此取观测向量\\(Y\\): \\[ \\begin{aligned} Y= \\begin{bmatrix} \\delta P \\\\ \\end{bmatrix} \\end{aligned} \\] 又由于 \\[ \\begin{aligned} X= \\begin{bmatrix} \\delta P_{3x1} \\\\ \\delta V_{3x1} \\\\ \\phi_{3x1} \\\\ \\epsilon_{3x1} \\\\ \\triangledown_{3x1} \\end{bmatrix}_{15x1} \\end{aligned} \\] 观测方程中的N为观测噪声： \\[ \\begin{aligned} N &amp;= \\begin{bmatrix} n_{P_{3x1}} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} n_{P_E} \\\\ n_{P_N} \\\\ n_{P_U} \\end{bmatrix} \\end{aligned} \\] 因此有： \\[ \\begin{aligned} G_t = \\begin{bmatrix} I_{3x3} &amp; 0_{3x3} &amp; 0_{3x3} &amp; 0_{3x6} \\end{bmatrix} \\end{aligned} \\] \\[ \\begin{aligned} C_t&amp;= \\begin{bmatrix} I_{3x3} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\end{aligned} \\]","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"滤波器融合_1_惯导解算原理——捷联惯导更新算法及误差分析","slug":"多传感器融合定位/滤波器融合_1_惯导解算原理","date":"2020-11-20T00:36:46.000Z","updated":"2020-12-07T03:33:14.000Z","comments":true,"path":"2020/11/20/多传感器融合定位/滤波器融合_1_惯导解算原理/","link":"","permalink":"http://yoursite.com/2020/11/20/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%9E%8D%E5%90%88_1_%E6%83%AF%E5%AF%BC%E8%A7%A3%E7%AE%97%E5%8E%9F%E7%90%86/","excerpt":"","text":"捷联惯导更新算法 姿态更新算法 选取“东-北-天”地理坐标系作为惯导系统的导航参考坐标系，后面记为n系，则以n系作为参考系的姿态微分方程为： \\[ \\dot{C}_b^n = C_b^n(\\omega_{nb}^b \\times) \\] 其中，矩阵\\(C_b^n\\)表示载体坐标系（b系）相对于导航坐标系（n系）的姿态矩阵，由于陀螺仪输出的是b系相对于惯性系（i系）的角速度\\(\\omega_{ib}^b\\)，而角速度信息\\(\\omega_{nb}^b\\)不能直接测量获得，因此，进一步分解，有： \\[ \\begin{aligned} \\dot{C}_b^n = C_b^n(\\omega_{nb}^b \\times)&amp;= C_b^n[(\\omega_{ib}^b-\\omega_{in}^b)\\times] \\\\ &amp;= C_b^n(\\omega_{ib}^b\\times)-C_b^n(\\omega_{in}^b\\times) \\\\ &amp;= C_b^n(\\omega_{ib}^b\\times)-C_b^n(\\omega_{in}^b\\times)C_b^bC_b^n \\\\ &amp;= C_b^n(\\omega_{ib}^b\\times)-(\\omega_{in}^n\\times)C_b^n \\end{aligned} \\] 其中， \\(\\omega_{in}^n\\)表示n系相对于i系的旋转，它包含两部分：地球自转引起的导航系旋转、以及惯导系统在地球表明附近运动因地球表面弯曲而引起的n系旋转，因此，有\\(\\omega_{in}^n=\\omega_{ie}^n+\\omega_{en}^n\\) \\[ \\omega_{ie}^n= \\begin{bmatrix} 0 \\\\ \\omega_{ie} \\cos L \\\\ \\omega_{ie} \\sin L \\end{bmatrix} \\] \\[ \\omega_{en}^n= \\begin{bmatrix} -\\frac{v_N}{R_M+h} \\\\ \\frac{v_E}{R_N+h} \\\\ \\frac{v_E}{R_N+h} \\tan L \\end{bmatrix} \\] 其中， \\(\\omega_{ie}\\)为地球自转角速率 \\(L\\)表示地理纬度 \\(h\\)表示高度 与矩阵微分方程\\(\\dot{C}_b^n = C_b^n(\\omega_{nb}^b \\times)\\)相比，上面推导出来的离散化求解更麻烦，一般不会直接求解该方程，而是用如下方法解决姿态矩阵更新问题， 根据矩阵乘法，有: \\[ C_{b(m)}^{n(m)}=C_{i}^{n(m)}C_{b(m)}^{i} \\] 其中， 角标符号m表示\\(t_m\\)时刻 由于i系是不动的惯性参考坐标系，其与时间无关，不需要标注时刻 由: \\[ C_{b(m)}^i=C_{b(m-1)}^iC_{b(m)}^{b(m-1)} \\] \\[ C_{i}^{n(m)}=C_{n(m-1)}^{n(m)}C_{i}^{n(m-1)} \\] 其中， 矩阵\\(C_{b(m)}^{b(m-1)}\\)表示以i系作为参考基准，b系从\\(t_{m-1}\\)时刻到\\(t_{m}\\)时刻的旋转变化，也就是以\\(m-1\\)时刻下的载体坐标系作为基准，\\(t_m\\)时刻下的载体姿态，同时也是载体从\\(t_{m}\\)时刻载体坐标系到\\(t_{m-1}\\)时刻载体坐标系的变换 \\(C_{b(m)}^{b(m-1)}\\)可由陀螺仪角速度确定 \\(C_{n(m-1)}^{n(m)}\\)表示以i系作为参考基准，n系从\\(t_{m}\\)时刻到\\(t_{m-1}\\)时刻的旋转变化 \\(C_{n(m-1)}^{n(m)}\\)可以由计算角速度\\(\\omega_{in}^n\\)确定 结合上面3条等式，有: \\[ \\begin{aligned} C_{b(m)}^{n(m)}&amp;=C_{i}^{n(m)}C_{b(m)}^{i} \\\\ &amp;=C_{n(m-1)}^{n(m)}C_{i}^{n(m-1)} C_{b(m-1)}^iC_{b(m)}^{b(m-1)} \\\\ &amp;=C_{n(m-1)}^{n(m)}C_{b(m-1)}^{n(m-1)}C_{b(m)}^{b(m-1)} \\end{aligned} \\] 其中， \\(C_{b(m-1)}^{n(m-1)}\\)表示\\(t_{m-1}\\)时刻的姿态阵 \\(C_{b(m)}^{n(m)}\\)表示\\(t_m\\)时刻的姿态阵 若陀螺仪在时间段\\([t_{m-1},t_m]\\)内\\((T=t_m-t_{m-1})\\)进行了两次等间隔采样，角增量分别是\\(\\Delta \\theta_{m1}\\)和\\(\\Delta \\theta_{m2}\\)，采用二子样圆锥误差补偿算法，有： \\[ C_{b(m)}^{b(m-1)}=M_{RV}(\\phi_{ib(m)}^b)=\\exp (\\phi_{ib(m)}^b\\times) \\] \\[ \\phi_{ib(m)}^b=(\\Delta \\theta_{m1}+\\Delta \\theta_{m2})+\\frac{2}{3} \\Delta \\theta_{m1} \\times \\Delta \\theta_{m2} \\] 对于单子样，只需要把 \\(\\frac{2}{3}\\) 改成 \\(\\frac{1}{12}\\) 通常，在导航更新期间\\([t_{m-1},t_m]\\)内，可以认为由速度和位置引起的\\(\\omega_{in}^n\\)变化很小，视为常数，记为\\(\\omega_{in(m)}^n\\)，则有： \\[ C_{n(m-1)}^{n(m)}=(C_{n(m)}^{n(m-1)})^T = [M_{RV}(\\phi_{in(m)}^n)]^T \\approx [M_{RV}(T*\\omega_{in(m)}^n)]^T \\] 速度更新算法 比力方程 比力方程是在地球表面附近进行惯性导航解算的基本方程 参见图，假设在地球表面附近有一运载体（惯导系统），其中心为\\(o_g\\)点，以\\(o_g\\)为原点定义当地地理坐标系（g系）,\\(o_g\\)在地球坐标系（e系）下的矢径记为\\(R_{eg}\\) ，则\\(R_{eg}\\)在惯性坐标系（i系）和e系之间的投影变换关系为: \\[ R_{eg}^e = C_{i}^e R_{eg}^i \\] 对上式两边同时微分，可得 \\[ \\dot{R}_{eg}^e =C_i^e \\dot{R}_{eg}^i+\\dot C_{i}^e R_{eg}^i = C_i^e \\dot{R}_{eg}^i + [C_i^e (\\omega_{ei}^i \\times)]R_{eg}^i = C_{i}^e(\\dot{R}_{eg}^i-\\omega_{ie}^i \\times R_{eg}^i) \\] 其中， \\(\\dot{R}_{eg}^e\\)表示g系原点\\(o_g\\)的速度，它是以e系作为参考坐标系的（即在e系观察得到的），即地速，\\(v_{eg}^e=\\dot{R}_{eg}^e\\) 使用变换阵\\(C_e^g\\)同时对上式两边左乘: \\[ \\begin{aligned} C_e^g v_{eg}^e &amp;= C_e^g C_{i}^e(\\dot{R}_{eg}^i-\\omega_{ie}^i \\times R_{eg}^i) \\\\ &amp;= C_i^g (\\dot{R}_{eg}^i-\\omega_{ie}^i \\times R_{eg}^i) \\end{aligned} \\] 其中，上式左侧的\\(C_e^g v_{eg}^e\\)表示地速在g系的投影，记为\\(v_{eg}^g=C_e^g v_{eg}^e\\) 所以，有： \\[ \\begin{aligned} v_{eg}^g = C_i^g (\\dot{R}_{eg}^i-\\omega_{ie}^i \\times R_{eg}^i) \\end{aligned} \\] 用\\(C_{g}^i\\)同时对上式两边左乘后，整理： \\[ C_{g}^i v_{eg}^g = (\\dot{R}_{eg}^i-\\omega_{ie}^i \\times R_{eg}^i) \\] \\[ \\dot{R}_{eg}^i = C_{g}^i v_{eg}^g + \\omega_{ie}^i \\times R_{eg}^i \\] 对上式两边同时微分，可得： \\[ \\begin{aligned} \\dot{v}_{eg}^g &amp;= \\dot{C}_{i}^g(\\dot{R}_{eg}^i-\\omega_{ie}^i \\times R_{eg}^i) + C_i^g (\\ddot{R}_{eg}^i - \\omega_{ie}^i \\times \\dot{R}_{eg}^i) \\\\ &amp;= \\underbrace{C_i^g(\\omega_{gi}^i \\times)C_g^i v_{eg}^g}_{\\dot{C}_{i}^g(\\dot{R}_{eg}^i-\\omega_{ie}^i \\times R_{eg}^i)} + C_i^g[\\ddot{R}_{eg}^i - \\omega_{ie}^i \\times (C_g^i v_{eg}^g + \\omega_{ie}^i \\times R_{eg}^i)] \\\\ &amp;= C_i^g[\\ddot{R}_{eg}^i-(\\omega_{ie}^i \\times)^2R_{eg}^i] + C_i^g[(\\omega_{gi}^i-\\omega_{ie}^i)\\times]C_{g}^i v_{eg}^g \\\\ &amp;= C_i^g[\\ddot{R}_{eg}^i-(\\omega_{ie}^i \\times)^2R_{eg}^i] - (\\omega_{ie}^g+ \\omega_{ig}^g) \\times v_{eg}^g \\\\ &amp;= C_i^g[\\ddot{R}_{eg}^i-(\\omega_{ie}^i \\times)^2R_{eg}^i] - (\\omega_{ie}^g+ \\omega_{ie}^g+ \\omega_{eg}^g ) \\times v_{eg}^g \\\\ &amp;= C_i^g[\\ddot{R}_{eg}^i-(\\omega_{ie}^i \\times)^2R_{eg}^i] - (2\\omega_{ie}^g+ \\omega_{eg}^g) \\times v_{eg}^g \\end{aligned} \\] 由于\\(R_{ig}^i=R_{ie}^i+R_{eg}^i\\)，当选择地心惯性系作为i系时，则i系和e系的坐标原点始终重合，即有\\(R_{ie}^i=0\\)和\\(\\ddot{R}_{eg}^i=\\ddot{R}_{ig}^i\\) 根据牛顿第二定律，有\\(\\ddot{R}_{ig}^i=f_{sf}^i+G^i\\)，其中: \\(f_{sf}^i\\)为比力 \\(G^i\\)为地球引力加速度(注意，不是重力) 再根据地球重力公式\\(g^i=G^i - (\\omega_{ie}^i \\times)^2 R_{eg}^i\\) 可得： \\[ \\begin{aligned} \\dot{v}_{eg}^g &amp;= C_i^g[\\ddot{R}_{eg}^i-(\\omega_{ie}^i \\times)^2R_{eg}^i] - (2\\omega_{ie}^g+ \\omega_{eg}^g) \\times v_{eg}^g \\\\ &amp;= C_i^g(f_{sf}+g^i)-(2\\omega_{ie}^g+ \\omega_{eg}^g) \\times v_{eg}^g \\\\ &amp;= C_b^g f_{sf}^b - (2 \\omega_{ie}^g+\\omega_{eg}^g) \\times v_{eg}^g +g^g \\end{aligned} \\] 将上式的地理过坐标系g系替换成“东-北-天”导航坐标系（n系），即可得到比力方程： \\[ \\dot{v}_{en}^n = C_b^n f_{sf}^b - (2 \\omega_{ie}^n + \\omega_{en}^n )\\times v_{en}^n + g^n \\] 其中， \\(f_{sf}^b\\)为加速度的输出（比力） \\((2 \\omega_{ie}^n ) \\times v_{en}^n\\) 为由载体运动和地球自转引起的哥氏加速度 \\((\\omega_{en}^n) \\times v_{en}^n\\)为载体运动引起的对地向心加速度 \\(g^n\\)为重力加速度 \\(- (2 \\omega_{ie}^n + \\omega_{en}^n )\\times v_{en}^n + g^n\\)统称为有害加速度 以东北天坐标系为导航坐标系，则\\(g^n=[0,0,-9.81]\\) 比力方程表明，加速度计输出中扣除有害加速度后，才能获取载体再导航坐标系的几何运动加速度\\(\\dot{v}_{en}^n\\) 有时，为了计算简便，会把哥氏加速度和向心加速度忽略，即\\(\\dot{v}_{en}^n = C_b^n f_{sf}^b + g^n\\) 综上，可得，速度更新方程: \\[ \\begin{aligned} V_{m}=V_{m-1}+[\\dot{v}_{en}^n]\\Delta T \\end{aligned} \\] 或者由简化形式: \\[ \\begin{aligned} V_{m}=V_{m-1}+\\frac{1}{2}( C_{b(m-1)}^{n(m-1)}f_{sf(m-1)}^b + C_{b(m)}^{n(m)}f_{sf(m)}^b )\\Delta T \\end{aligned} \\] 位置更新算法 由位置微分方程： \\[ \\dot{P} = V \\] 可得，位置更新方程： \\[ \\begin{aligned} P_{m}=P_{m-1}+\\frac{1}{2}(V_m+V_{m-1})\\Delta T \\end{aligned} \\] 捷联惯导误差分析 基本方法——误差分析的思路 误差方程的形式——需要求的是啥？ 假设给定微分方程: \\[ \\begin{aligned} \\dot{z}=x+y \\end{aligned} \\] 且: \\[ \\begin{aligned} \\tilde{z}&amp;=z+\\delta z \\\\ \\tilde{x}&amp;=x+\\delta x \\\\ \\tilde{y}&amp;=y+\\delta y \\end{aligned} \\] 则误差方程的形式为: \\[ \\begin{aligned} \\delta \\dot{z}= ??? \\end{aligned} \\] 写出原微分方程 \\[ \\begin{aligned} \\dot{z}=x+y \\end{aligned} \\tag{1} \\] 写出考虑误差时的微分方程 即把\\(\\dot{z}=x+y\\)使用带有误差的变量代替，得到: \\[ \\begin{aligned} \\tilde{\\dot{z}}=\\tilde{x}+\\tilde{y} \\end{aligned} \\tag{2} \\] 求出误差关系（真实值与理想值的关系） 这一步中，并非所有的关系都是已知的，有些需要自己推 \\[ \\begin{aligned} \\tilde{z}&amp;=z+\\delta z \\\\ \\tilde{x}&amp;=x+\\delta x \\\\ \\tilde{y}&amp;=y+\\delta y \\end{aligned} \\tag{3} \\] 把(3)的误差关系代入到等式(2) \\[ \\begin{aligned} \\dot{z}+\\delta{\\dot{z}}=x+\\delta x+ y+ \\delta y \\end{aligned} \\tag{4} \\] 取原微分方程(1)，代入(4) \\[ \\begin{aligned} \\because \\dot{z}&amp;=x+y \\\\ \\therefore x+y + \\delta \\dot{z}&amp;=x + y+ \\delta x+\\delta y \\end{aligned} \\tag{5} \\] 化简 \\[ \\delta \\dot{z} =\\delta x+ \\delta y \\] 姿态误差方程 写出原微分方程 以“东-北-天(E-N-U)”坐标系为导航坐标系(n系)，“右-前-上”坐标系为(b系)时，姿态微分方程可以表示为 \\[ \\dot{C}_b^n = C_b^n(\\omega_{nb}^b \\times) \\] 当考虑地球自转角速度时，不易直接测量，因此上面的微分方程可以拆解为： \\[ \\begin{aligned} \\dot{C}_b^n = C_b^n(\\omega_{nb}^b \\times)&amp;= C_b^n[(\\omega_{ib}^b-\\omega_{in}^b)\\times] \\\\ &amp;= C_b^n(\\omega_{ib}^b\\times)-C_b^n(\\omega_{in}^b\\times) \\\\ &amp;= C_b^n(\\omega_{ib}^b\\times)-C_b^n(\\omega_{in}^b\\times)C_b^bC_b^n \\\\ &amp;= C_b^n(\\omega_{ib}^b\\times)-(\\omega_{in}^n\\times)C_b^n \\end{aligned} \\tag{1} \\] 其中，\\(\\omega_{in}^n\\)表示导航系(n系)相对于惯性系(i系)的旋转，它包含地球自转和导航系相对于地球的旋转，其表达式为： \\[ \\omega_{in}^n = \\omega_{ie}^n + \\omega_{en}^n \\] 写出考虑误差的微分方程: \\[ \\begin{aligned} \\dot{\\tilde{C}_b^n}= \\tilde{C}_b^n( \\tilde{\\omega}_{ib}^b\\times)-( \\tilde{\\omega}_{in}^n\\times) \\tilde{C}_b^n \\end{aligned} \\tag{2} \\] 求出误差关系（真实值与理想值的关系） 姿态误差关系 imu角速度误差关系 导航系计算误差关系 姿态误差关系 理想情况下，从载体坐标系(b系)到导航坐标系(n系)的变换矩阵为\\(C_b^n\\)，而姿态计算时会有误差，一般假设误差在n系(global)上。 有误差的导航坐标系称为计算导航坐标系，简记为\\(n&#39;\\)系。此时有误差的姿态矩阵\\(\\tilde{C}_b^n\\)表示为 \\[ \\tilde{C}_b^n = C_b^{n&#39;}=C_n^{n&#39;}C_b^n \\] 以n系作为参考坐标系，记从 n' 系到 n 系的旋转矩阵为\\(C_\\phi\\)，n'系在n系中的姿态为\\(C_\\phi\\)，对应的等效旋转矢量为\\(\\phi\\)(其3个元素也被称作失准角)，也就是说，n系绕等效旋转矢量为\\(\\phi\\)旋转之后，得到n' 系 当\\(\\phi\\)为小量时，根据等效旋转矢量与方向余弦阵关系式——罗德里格斯公式： \\[ C_{n&#39;}^{n}=I+\\frac{\\sin \\phi}{\\phi}(\\phi \\times)+ \\frac{1-\\cos \\phi}{ \\phi^2}(\\phi \\times)^2 \\approx I+(\\phi \\times) \\] \\[ C_n^{n&#39;}=I-\\frac{\\sin \\phi}{\\phi}(\\phi \\times)+ \\frac{1-\\cos \\phi}{ \\phi^2}(\\phi \\times)^2 \\approx I-(\\phi \\times) \\] 这个怎么理解，假设n系矩阵\\(C_n\\)等于\\(I\\), 对n系绕z轴逆时针旋转\\(30\\)度，得到n'系，这个等效旋转矢量是\\(\\phi=[0,0,\\frac{1}{6} \\pi]\\)，那么n'系在n系的姿态是\\(I+(\\phi \\times)\\)，n'系到n系的旋转变换为\\(C_{n&#39;}^{n}=I+(\\phi \\times)\\) 因此，带误差的姿态矩阵表示为： \\[ \\begin{aligned} \\tilde{C}_b^{n}=C_b^{n&#39;} = C_n^{n&#39;}C_b^n = [I-(\\phi \\times)] C_b^n \\end{aligned} \\tag{3} \\] IMU角速度误差关系 陀螺仪测量误差关系： \\[ \\tilde{\\omega}_{ib}^b = \\omega_{ib}^b + \\delta \\omega_{ib}^b \\] 一般来说，imu内参的影响会在imu测量的时候先补偿掉，这里就不用考虑了 导航系计算误差 \\[ \\tilde{\\omega}_{in}^n=\\tilde{\\omega}_{ie}^n+\\tilde{\\omega}_{en}^n = \\omega_{ie}^n + \\delta \\omega_{ie}^n + \\omega_{en}^n + \\delta \\omega_{en}^n \\] 在实际使用过程中，对于mems惯导，可以忽略这误差： 在中等精度及以下的惯性导航中，这两项角速度误差相比于器件误差，量级太小，没有考虑的必要; 在组合导航中，速度误差和位置误差一直被修正，会使他们的量级进一步减小。 两项误差的具体推导如下： 将(3)中的误差关系代入(2) 姿态误差关系： \\(\\tilde{C}_b^{n} = [I-(\\phi \\times)] C_b^n\\) imu测量误差关系: \\(\\tilde{\\omega}_{ib}^b = \\omega_{ib}^b + \\delta \\omega_{ib}^b\\) 导航系计算误差关系: \\(\\tilde{\\omega}_{in}^n= \\omega_{ie}^n + \\delta \\omega_{ie}^n + \\omega_{en}^n + \\delta \\omega_{en}^n\\) 对式(2)重新抄写如下： \\[ \\begin{aligned} \\dot{\\tilde{C}_b^n}= \\tilde{C}_b^n( \\tilde{\\omega}_{ib}^b\\times)-( \\tilde{\\omega}_{in}^n\\times) \\tilde{C}_b^n \\end{aligned} \\tag{2} \\] 代入之后，可得： \\[ \\begin{aligned} (-\\dot{\\phi}\\times)C_{b}^n +[I-(\\phi\\times)]\\dot{C}_n^b = [I-(\\phi \\times)]C_b^n[(\\omega_{ib}^b+\\delta \\omega_{ib}^b)\\times]-(\\omega_{in}^n\\times)[I-(\\phi \\times)]C_b^n \\end{aligned} \\tag{4} \\] 将(1)中的原微分方程代入(4) \\[ \\begin{aligned} (-\\dot{\\phi}\\times)C_b^n + [I - (\\phi \\times)][C_b^n (\\omega_{ib}^b\\times)-(\\omega_{in}^n)C_b^n] \\\\ = [I-(\\phi \\times)]C_b^n[(\\omega_{ib}^b+\\delta \\omega_{ib}^b)\\times]-(\\omega_{in}^n\\times)[I-(\\phi \\times)]C_b^n \\end{aligned} \\] 化简 两边同时右乘\\(C_n^b\\) 展开，忽略其中的二阶项 利用定理\\((a\\times)(b\\times)-(b\\times)(a\\times)=[(a\\times b)\\times]\\) 进一步化简 最终，得到: \\[ (\\dot{\\phi}\\times)=[(\\phi \\times \\omega_{in}^n -\\delta \\omega_{ib}^n)\\times] \\] 最后，把两边的反对称符号同时去掉 \\[ \\dot{\\phi} = \\phi \\times \\omega_{in}^n - \\delta \\omega_{ib}^n \\] 速度误差方程 写出原微分方程 \\[ \\begin{aligned} \\dot{V}^n=C_b^n f^b + g^n \\end{aligned} \\tag{1} \\] 写出考虑误差的微分方程 \\[ \\begin{aligned} \\dot{\\tilde{V}}^n = \\tilde{C}_b^n \\tilde{f}^b + \\tilde{g}^n \\end{aligned} \\tag{2} \\] 求出误差关系（真实值与理想值的关系） \\[ \\begin{aligned} &amp; \\tilde{V}^n = V^n +\\delta V^n \\\\ &amp; \\tilde{C}_b^n = [I-\\phi\\times]C_b^n \\\\ &amp; \\tilde{f}^b = f^b +\\delta f^b \\\\ &amp; \\tilde{g}^n = g^n +\\delta g^n \\end{aligned} \\tag{3} \\] 其中： \\(\\delta f^b\\)表示加速度测量误差 \\(g^n\\)表示重力误差，非高精度模型下可忽略 将(3)代入(2) \\[ \\begin{aligned} \\dot{V}^n+\\delta \\dot{V}^n = (I-\\phi \\times)C_b^n(f^b+\\delta f^b)+g^n \\end{aligned} \\tag{4} \\] 将原微分方程代入(4) \\[ \\begin{aligned} C_b^n f^b +g^n + \\delta \\dot{V}^n = (I-\\phi \\times)C_b^n(f^b+\\delta f^b)+g^n \\end{aligned} \\tag{5} \\] 化简 \\[ \\begin{aligned} \\delta \\dot{V}^n &amp;= C_b^n \\delta f^b - (\\phi \\times)C_b^n(f^b +\\delta f^b) \\\\ &amp; \\approx C_b^n \\delta f^b - (\\phi \\times)C_b^n(f^b) \\\\ &amp;= \\delta f^n + (f^n \\times)(\\phi) \\end{aligned} \\tag{6} \\] 位置误差方程 写出原微分方程 \\[ \\begin{aligned} \\dot {P} = V \\end{aligned} \\tag{1} \\] 写出考虑误差的微分方程 \\[ \\begin{aligned} \\dot{\\tilde{P}}=\\tilde{V} \\end{aligned} \\tag{2} \\] 求出误差关系（真实值与理想值的关系） \\[ \\begin{aligned} \\tilde{P} = P + \\delta P \\\\ \\tilde{V} = V + \\delta V \\end{aligned} \\tag{3} \\] 将(3)代入(2) \\[ \\begin{aligned} \\dot{P} + \\delta \\dot{P} = V+ \\delta V \\end{aligned} \\] 将原微分方程代入(4) \\[ \\begin{aligned} V+\\delta \\dot{P} = V+ \\delta V \\end{aligned} \\tag{5} \\] 化简 \\[ \\begin{aligned} \\delta \\dot{P} = \\delta V \\end{aligned} \\tag{6} \\] 整理 姿态误差方程 \\[ \\begin{aligned} \\dot{\\phi} = \\phi \\times \\omega_{in}^n - \\delta \\omega_{ib}^n \\end{aligned} \\] 速度误差方程 \\[ \\begin{aligned} \\delta \\dot{V}^n = \\delta f^n + (f^n \\times)(\\phi) \\end{aligned} \\] 位置误差方程 \\[ \\begin{aligned} \\delta \\dot{P} = \\delta V \\end{aligned} \\]","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"第五章-(2)-组合导航常见现象解释","slug":"多传感器融合定位/第五章-基于滤波器融合_组合导航现象解释","date":"2020-11-16T14:36:46.000Z","updated":"2020-12-07T09:07:07.000Z","comments":true,"path":"2020/11/16/多传感器融合定位/第五章-基于滤波器融合_组合导航现象解释/","link":"","permalink":"http://yoursite.com/2020/11/16/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E4%BA%94%E7%AB%A0-%E5%9F%BA%E4%BA%8E%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%9E%8D%E5%90%88_%E7%BB%84%E5%90%88%E5%AF%BC%E8%88%AA%E7%8E%B0%E8%B1%A1%E8%A7%A3%E9%87%8A/","excerpt":"","text":"组合导航工程经验(重要) 初始对准：航向收敛 公式上理解现象 mems为什么不能做静态初始对准 如果要解方程(3) 待求变量为： \\(\\phi_E\\) \\(\\phi_N\\) \\(\\phi_U\\) 前两个比较好解,解\\(\\phi_U\\)还需要用到方程组(4) 对方程组(3)展开，有： \\[ \\begin{aligned} &amp; \\delta \\dot{V}_E = -g \\phi_N +\\triangledown_E \\\\ &amp; \\delta \\dot{V}_N = g \\phi_E + \\triangledown_N \\\\ &amp; \\delta \\dot{V}_U = \\triangledown_U \\end{aligned} \\] 如果对于高精度惯导，那么\\(\\triangledown_E , \\triangledown_N \\approx (1e-5g_0)\\)可以忽略，所以，可以求得: \\[ \\begin{aligned} &amp; \\phi_E = \\frac{\\delta \\dot{V}_N}{-g} \\\\ &amp; \\phi_N = \\frac{\\delta \\dot{V}_E}{g} \\end{aligned} \\] 对方程组(4)展开，有: \\[ \\begin{aligned} \\dot{\\phi}_E = \\phi_N (\\omega_{ie}\\sin L) - \\phi_U (\\omega_{ie}\\cos L) + \\epsilon_E \\end{aligned} \\] 由于\\(\\phi_E,\\phi_N\\)在前面已经求出来了，并且高精度惯导的\\(\\epsilon_E \\approx 0.01\\deg/h\\)可以忽略 \\[ \\begin{aligned} \\phi_U = \\frac{C-\\epsilon_E}{\\omega_{ie} \\cos L} \\end{aligned} \\] 其中，\\(C\\)是\\(\\phi_E,\\phi_N\\)组成的量 mems初始对准为什么需要绕8字 增加观测，增加矩阵的秩 加减速的收敛速度 mems直线行驶相关现象 从物理意义上理解","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"第五章-(1)-基于滤波器的融合算法-进阶","slug":"多传感器融合定位/第五章-基于滤波器融合_进阶","date":"2020-11-16T14:36:46.000Z","updated":"2020-12-07T09:29:37.000Z","comments":true,"path":"2020/11/16/多传感器融合定位/第五章-基于滤波器融合_进阶/","link":"","permalink":"http://yoursite.com/2020/11/16/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E4%BA%94%E7%AB%A0-%E5%9F%BA%E4%BA%8E%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%9E%8D%E5%90%88_%E8%BF%9B%E9%98%B6/","excerpt":"","text":"基于滤波器的融合算法-进阶 编码器融合 不考虑imu和车体之间的旋转 考虑imu和车体之间的旋转 上述框框来源于：第三章-姿态误差方程的推导 上述框框同样来源于上面的推导，只不过方向相反了而已 从直观来看， - 假设imu与车体有俯仰角偏差，那么，车的前向速度与imu的前向速度就会有偏差，可以反应出来 - 假设imu与车体有航向角偏差，同理 - 假设imu与车体有横滚角误差，但是车体的前向速度与imu的速度仍然一致，所以无法反映出来。 其中， \\(\\tilde{V}_m=\\tilde{C}_b^m\\tilde{C}_n^b\\tilde{V}_n\\) 表示根据当前的状态得到的投影到车体上的速度观测估计 运动约束融合 基于磁力计的融合 LINS融合思路 滤波器方法实现激光里程计，核心是观测怎么做，lins使用了点云的特征做紧耦合 论文中的\\(F_t\\)矩阵可能有错","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"第四章-(2)-基于滤波器的融合算法及可观测性分析","slug":"多传感器融合定位/第四章-基于滤波器融合-2","date":"2020-11-14T04:36:46.000Z","updated":"2020-11-22T04:21:34.000Z","comments":true,"path":"2020/11/14/多传感器融合定位/第四章-基于滤波器融合-2/","link":"","permalink":"http://yoursite.com/2020/11/14/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%9F%BA%E4%BA%8E%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%9E%8D%E5%90%88-2/","excerpt":"","text":"基于滤波的融合方法 基于误差状态的滤波方法(基于角误差) 姿态误差方程 速度误差方程、位置误差方程 状态方程(预测) \\(B_t\\)来源于\\(F_t\\)的后两列，二者等价，因为bias和噪声传入的通道是同一个 观测方程 离散化 因为观测方程不是微分方程，因此不需要离散化 滤波流程 基于四元数状态的滤波 上图中圈中的\\(F_{Vq}\\) 表示的是速度状态对姿态项\\(q\\)的各个分量的求导 另外，\\((f^b+\\triangledown+\\omega_a)\\)实际上就是加速度计的输出值(读数) 滤波流程 基于误差状态的滤波器与普通状态滤波器对比 可观测性分析(待补充)","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"第四章-(1)-概率基础及滤波器原理","slug":"多传感器融合定位/第四章-基于滤波器融合-1","date":"2020-11-12T01:36:46.000Z","updated":"2020-11-14T04:35:37.000Z","comments":true,"path":"2020/11/12/多传感器融合定位/第四章-基于滤波器融合-1/","link":"","permalink":"http://yoursite.com/2020/11/12/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%9F%BA%E4%BA%8E%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%9E%8D%E5%90%88-1/","excerpt":"","text":"基于滤波的融合方法 概率相关基础 贝叶斯公式和贝叶斯推断——核心 高斯概率密度函数——核心 上式说明，如果有(x,y)的联合概率密度函数，同时又有y的分布，那么就可以求出x关于y的条件概率密度，假设y是传感器观测的分布，而x是待求的状态量的话，那么相当于可以求出后验概率 上图专门用来求后面观测量的均值和方差的 滤波器基本原理 滤波器的目的是求最大后验概率 贝叶斯滤波器 详细推导 待估计的后验概率密度： \\[ \\begin{aligned} p(x_k|x_0,v_{1:k},y_{0:k}) \\end{aligned} \\] 意思为，给定 初始状态\\(x_0\\) 1-k时刻的输入\\(v_{1:k}\\) 以及0-k时刻的观测\\(y_{0:k}\\) 发生状态为\\(x_k\\)的概率，我们后面的操作，就是为了求解\\(x_k\\)，使得这个概率最大化 \\[ \\begin{aligned} p(x_k|x_0,v_{1:k},y_{0:k})&amp;= p(x_k|x_0,v_{1:k},y_{0:k-1},y_k) \\\\ &amp;= \\frac{p(x_k,x_0,v_{1:k},y_{0:-1},y_k)}{p(x_0,v_{1:k},y_{0:k-1},y_k)} \\\\ &amp;=\\frac{p(y_k|x_k,x_0,v_{1:k},y_{0:k-1}) p(x_k|x_0,v_{1:k},y_{0:k-1}) p(x_0,v_{1:k},y_{0:k-1})}{p(y_k|x_0,v_{1:k},y_{0:k-1}) p(x_0,v_{1:k},y_{0:k-1})} \\\\ &amp;= \\frac{p(y_k|x_k,x_0,v_{1:k},y_{0:k-1}) p(x_k|x_0,v_{1:k},y_{0:k-1})}{p(y_k|x_0,v_{1:k},y_{0:k-1})} \\\\ &amp;= \\eta p(y_k|x_k,x_0,v_{1:k},y_{0:k-1}) p(x_k|x_0,v_{1:k},y_{0:k-1}) \\end{aligned} \\] 又因为观测方程中，\\(y_k\\)仅和\\(x_k\\)有关，所以进一步简化： \\[ p(x_k|x_0,v_{1:k},y_{0:k})=\\eta p(y_k|x_k) p(x_k|x_0,v_{1:k},y_{0:k-1}) \\] 接下来进一步化简上式右侧一项\\(p(x_k|x_0,v_{1:k},y_{0:k-1})\\) 根据\\(p(x)=\\int p(x|y) p(y) dy\\)可得: \\[ \\begin{aligned} p(x_k|x_0,v_{1:k},y_{0:k-1}) &amp;= \\frac{p(x_k,x_0,v_{1:k},y_{0:k-1})}{p(x_0,v_{1:k},y_{0:k-1})} \\\\ &amp;= \\int \\frac{p(x_k,x_0,v_{1:k},y_{0:k-1}|x_{k-1}) p(x_{k-1})}{p(x_0,v_{1:k},y_{0:k-1})} d x_{k-1} \\\\ &amp;= \\int \\frac{p(x_k,x_{k-1},x_0,v_{1:k},y_{0:k-1})}{p(x_{k-1},x_0,v_{1:k},y_{0:k-1})} \\frac{p(x_{k-1},x_0,v_{1:k},y_{0:k-1})}{p(x_0,v_{1:k},y_{0:k-1})} d x_{k-1} \\\\ &amp;= \\int p(x_k|x_{k-1},x_0,v_{1:k},y_{0:k-1}) p(x_{k-1}|x_0,v_{1:k},y_{0:k-1}) d x_{k-1} \\\\ &amp;= \\int p(x_k| x_{k-1},v_k) p(x_{k-1}|x_0,v_{1:k},y_{0:k-1}) d x_{k-1} \\end{aligned} \\] 最后一步的化简是因为，k时刻的状态仅与k-1时刻的状态\\(x_{k-1}\\)和对应的输入有关 最终后验概率可以写成 其中，先验项就是k-1时刻下的后验概率。 如何使用上面的推导？ ————贝叶斯滤波器 卡尔曼滤波器 回顾： 多元联合高斯概率密度的分解 - 可参考：第四讲(拓展)_高斯过程(边缘化与条件作用)-联合高斯分布的分解 - 舒尔布顺序不一样，得到的结果不一样，但是实际上是等价的 回顾: 这里可用来求观测方程的均值和方差 因此， \\(\\Sigma_{xx}=\\check{P_k}\\) \\(\\Sigma_{xy}=\\Sigma_{xx}G_k^T=\\check{P}_k G_k^T\\) \\(\\Sigma_{yx}=\\Sigma_{xy}^T=G_k\\check{P}_k^T=G_k\\check{P}_k\\) \\(\\Sigma_{yy}=G_k\\check{P}_kG_k^T+C_k R_k C_k^T\\) 所以，最终有: \\(R\\): 观测噪声 \\(Q\\): 输入噪声，IMU噪声 扩展卡尔曼滤波器 \\(\\hat{x}_{k-1}\\) 预测方程线性化点，上一个时刻的更新值 \\(\\check{x}_k\\) 观测方程线性化点，是由预测方程得到的 对运动方程进行线性化之后，输入k-1时刻的更新后的状态\\(\\hat{x_{k-1}}\\)以及控制输入\\(w_k\\)，即可推导出预测值的均值和方差： 对观测方程进行线性化之后，即可得到观测的均值和方差： 推导套路 卡尔曼滤波 写出运动(预测)方程 写出观测方程 写出上一时刻(k-1)的后验分布，即更新后的状态值和方差 求预测值\\(x_k\\)的均值和方差 (利用线性高斯的性质) 求观测值\\(y_k\\)的均值和方差 (利用线性高斯的性质) 联合概率密度函数\\(p(x_k,y_k)\\)分解，得到后验概率\\(p(x_k|y_k)\\)的表示形式 将(4)(5)步求出来的均值和方差，带入(6) 迭代扩展卡尔曼滤波(IEKF) sigmapoint卡尔曼滤波(UKF/SPKF) 基本原理 使用sigmapoint点进行采样，得到一个新的分布，并且计算均值和方差 预测步骤 更新步骤 粒子滤波器(PF) UKF还是依赖高斯分布假设，而蒙特卡洛方法则基于大数定律 预测步骤 更新步骤 几种滤波方法对比","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"BALM论文阅读","slug":"文献阅读/BALM论文阅读","date":"2020-11-03T00:20:46.000Z","updated":"2021-01-20T00:38:44.000Z","comments":true,"path":"2020/11/03/文献阅读/BALM论文阅读/","link":"","permalink":"http://yoursite.com/2020/11/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/BALM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"BALM: Bundle Adjustment for Lidar Mapping 摘要 提出的方法通过最小化协方差矩阵的特征值来使得特征点分布在同一个边缘线或者平面上。为了加速求解，推到了微分，二阶闭式解。此外，还提出了自适应的体素滤波方法用来快速搜索特征关联。 介绍 增量式构建地图会由于环境退化或者较小视场角雷达而导致累计误差快速增大。降低这种漂移的其中一种方法是在激光雷达扫描的滑动窗口上执行局部BA，这使我们能够基于后续扫描中的新信息来重新评估过去的扫描，该方法已广泛用于视觉导航，并被证明是非常有效的。 由于直接进行深度测量，虽然激光雷达BA看起来比视觉BA更简单，但其公式实际上更复杂。因为在视觉BA，观测是高分辨率的图像，即每一个像素都可关联一个空间特征，如下图1，因此目标很明确，即最小化重投影误差。 然而，这个并不适用于激光雷达，因为激光雷达点云非常稀疏，甚至是非重复的，因此无法进行精确的点对点匹配。 文章贡献： 提出了激光雷达BA框架，不像视觉ba那样，而是通过最小化协方差矩阵来约束特征点到边缘线或者平面的距离，还推到了cost func(如特征值)对激光雷达位姿的梯度和Hessian矩阵 提出了自适应体素化方法来快速搜索特征关联 效果： BA推导 问题描述 给定一组稀疏特征点\\(p_{fi}(i=1,\\cdots,N)\\) ——从M帧扫描中提取的，并且都关联到同一个特征上（平面或者边缘线），如图3 假设第i个特征点从第\\(s_i\\)帧提取，其中 \\(i\\in \\{1,\\cdots,N\\}\\) \\(s_i \\in \\{1,\\cdots,M\\}\\) M帧的位姿记为\\(T=(T_1,\\cdots,T_M)\\) 那么，在全局地图上的特征点可以这样表示: 如先前所定义，激光雷达BA的问题是共同确定M扫描的姿势和全局3D点，现在3D地图是一个单一特征（边缘或平面），然后BA问题是联合确定姿态T和该特征的位置位置，这由特征上的点q和单位矢量n表示（n是平面的法线向量或边缘的方向） 对于平面特征 直接BA公式是最小化每个平面特征点到平面的距离，即： \\(p_i\\)：根据待估计位姿投影到全局地图上的特征点 \\(q\\)：某个特征上的点（边缘线内、平面内） \\(\\vec{n}\\): 边缘线的方向向量或者是平面法向量 因此，上式即为最小化投影点到特征的距离 当\\(u_3=\\vec{n}\\)，即当边缘线的方向向量或者是平面法向量是最小的特征向量\\(u_3\\)时，并且\\(q\\)为投影点的质心\\(\\bar{p}\\)时，此时特征值\\(\\lambda_3(A)\\)就表示投影点到特征的距离。 质心\\(\\bar{p}\\)和A如下： 式(3)表明，优化特征点位置以及特征法向量（方向向量）可以写成关于位姿T的函数，因此只需要对位姿T进行优化。 同时，对位姿T的优化简化为最小化(4)中定义的点协方差矩阵A的最小特征值\\(\\lambda_3\\) 对于边缘线特征 类似于平面特征，只是把特征值\\(\\lambda_3(A)\\)变成\\(\\lambda_2(A)\\) 总而言之，激光雷达BA的目标是最小化每个项之和，其中每个项的形式如下： 为了快速优化求解，下面推导对于位姿T的微分的闭式解，最高2阶。 根据链式法则，首先对点\\(p\\)求导 微分 定理一 对于一组点\\(p_i(i=1,\\cdots,N)\\)以及式(4)定义的协方差矩阵\\(A\\)。假设矩阵\\(A\\)有特征值\\(\\lambda_k\\)及其对应的特征向量\\(u_k(k=1,2,3)\\)，则有\\(\\lambda_k\\)对点\\(p_i\\)的偏导： 其中，\\(p\\)是N个点的均值。 定理二 对于一组点\\(p_i(i=1,\\cdots,N)\\)以及式(4)定义的协方差矩阵\\(A\\)。假设矩阵\\(A\\)有特征值\\(\\lambda_k\\)及其对应的特征向量\\(u_k(k=1,2,3)\\)，则有\\(\\lambda_k\\)对点\\(p_j\\)的偏导*\\(\\lambda_k\\)对点\\(p_i\\)的偏导： 当\\(i \\neq k\\)时, \\(\\lambda_i \\neq \\lambda_k\\) 二阶微分 利用上述的一阶导和二阶导，可以使用如下二阶近似来近似式(5)的cost function 其中， \\(J(p)\\) 是雅可比矩阵，第i个元素按式(6)计算 \\(H(p)\\) 是Hessian矩阵，其中第i行第j列元素按式(7)计算 回想一下，点向量p进一步依赖于式(1)中的扫描位姿\\(T\\) 因此，按照链式求导法则，还需要求出 点对位姿的导数，这个可以参考 《14讲》 如果对位姿\\(T_j\\)在其切平面进行扰动\\(\\delta T_j[\\phi_j^T , \\delta t_j^T]^T\\)，使用\\(\\boxplus\\)表示，则有： 和 将式(12)带入式(8)，可得： 也就是说，特征值\\(\\lambda_k\\)对位姿的求导实际上是: \\(JD\\) 最后，就可以使用LM迭代求解增量了","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"第三章-(2)-惯性导航解算原理","slug":"多传感器融合定位/第三章-惯性导航原理及误差分析-2","date":"2020-11-02T12:36:46.000Z","updated":"2020-12-07T03:00:27.000Z","comments":true,"path":"2020/11/02/多传感器融合定位/第三章-惯性导航原理及误差分析-2/","link":"","permalink":"http://yoursite.com/2020/11/02/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E4%B8%89%E7%AB%A0-%E6%83%AF%E6%80%A7%E5%AF%BC%E8%88%AA%E5%8E%9F%E7%90%86%E5%8F%8A%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90-2/","excerpt":"","text":"惯导解算 基础部分 旋转矩阵微分 关于\\(\\dot{r}^{b}=-\\omega_{ib}^{b} \\times r^b\\)的推导 其他求旋转矩阵微分的方法 考虑任意旋转矩阵\\(R^TR=I\\) 对于时变情况，有\\(R^T(t) R(t)=I\\) 对上式两边同时求导: \\[ \\begin{aligned} \\dot{R}^{T}R+R^T\\dot{R}=0 \\end{aligned} \\] 整理，有: \\[ \\begin{aligned} \\dot{R}^{T}R&amp;=-R^T\\dot{R} \\\\ &amp;=-(\\dot{R}^{T}R)^T \\end{aligned} \\] 可以发现，\\(\\dot{R}^{T}R\\)是一个反对称矩阵，因此可以使用一个三维向量的反对称矩阵来表示(实际上就是角速度) \\[ \\dot{R}^{T}(t)R(t)=\\phi(t)^\\wedge \\] 继续整理，有: \\[ \\begin{aligned} \\dot{R}^{T}(t)R(t)=\\phi(t)^\\wedge \\\\ \\rightarrow \\dot{R}^{T}(t)=\\phi(t)^\\wedge R(t)^T \\\\ \\rightarrow \\dot{R}(t)=(\\phi(t)^\\wedge R(t)^T)^T \\\\ \\rightarrow \\dot{R}(t)=R(t)\\phi(t)^\\wedge \\end{aligned} \\] 四元数及其微分 四元数微分-方法一 四元数微分-方法二（推荐） 具体可参见四元数微分 等效旋转矢量 旋转矩阵、四元数、等效旋转矢量之间的关系 姿态更新 基于旋转矩阵的更新 思想：把小周期内的角度增量看作是等效旋转矢量，然后进行姿态更新 基于四元数的更新 推导方法1 补充： \\[ \\begin{aligned} M_{w_{ib}^b}&#39;= q_0 I + (\\phi*)_2 &amp;= \\begin{bmatrix} q_0 &amp; -\\phi_x &amp; -\\phi_y &amp; -\\phi_z \\\\ \\phi_x &amp; q_0 &amp; \\phi_z &amp; -\\phi_y \\\\ \\phi_y &amp; -\\phi_z &amp; q_0 &amp; \\phi_x \\\\ \\phi_z &amp; \\phi_y &amp; -\\phi_x &amp; q_0 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 0 &amp; -\\phi_x &amp; -\\phi_y &amp; -\\phi_z \\\\ \\phi_x &amp; 0 &amp; \\phi_z &amp; -\\phi_y \\\\ \\phi_y &amp; -\\phi_z &amp; 0 &amp; \\phi_x \\\\ \\phi_z &amp; \\phi_y &amp; -\\phi_x &amp; 0 \\end{bmatrix} \\end{aligned} \\] 常系数微分方程求解 推导方法2 等效旋转矢量的计算(关键) 这里探讨的是 等效旋转矢量与角速度(角增量)之间的关系，实际上，等效旋转矢量\\(\\phi\\)一般不等于角增量\\(\\Delta \\theta\\)，当且近当载体做定轴旋转时(即等效旋转矢量与角速度矢量方向平行时)，两者才相等。 解算部分 上图中圈起来的部分： \\(C_{b(m)}^{n(m)}\\) 表示\\(t_m\\)时刻下，载体相对于导航坐标系的姿态 \\(C_i^{n(m-1)}C_{b(m-1)}^i = C_{b(m-1)}^{n(m-1)}\\) 表示\\(t_{m-1}\\)时刻下，载体相对于导航坐标系的姿态 \\(C_{b(m)}^{b(m-1)}=\\exp([\\phi_{ib(m)}^b]\\times)\\) 表示以i系作为参考基准，b系从\\(t_{m-1}\\)到\\(t_m\\)时刻的旋转变化，此量可由载体陀螺仪角速度\\(\\omega_{ib}^b\\)确定 \\(\\phi_{ib(m)}^b=(\\Delta \\theta_1+\\Delta \\theta_2)+\\frac{2}{3}\\Delta \\theta_1 \\times \\Delta \\theta_2\\) 这是误差补偿项，用以补偿 等效旋转矢量与陀螺仪得到的角度增量之间的误差(不可交换误差)，采用二子样圆锥误差补偿算法。(单子样+前一周期的补偿算法见《捷联惯导算法与组合导航原理》-P30) \\(C_{n(m-1)}^{n(m)}=(C_{n(m)}^{n(m-1)})^T=[\\exp(\\phi_{in(m)}^n)]^T=[\\exp(T_{[m-1,m]}\\omega_{in(m)}^n)]^T\\) 通常在导航更新周期\\([t_{m-1},t_m]\\)内，可以认为速度和位置引起的\\(w_{in}^n\\)变化很小，可作为常数，直接乘以周期即可。 误差分析 基本方法——误差分析的思路 误差方程的形式: 假设给定微分方程: \\[ \\begin{aligned} \\dot{z}=x+y \\end{aligned} \\tag{1} \\] 且: \\[ \\begin{aligned} \\tilde{z}&amp;=z+\\delta z \\\\ \\tilde{x}&amp;=x+\\delta x \\\\ \\tilde{y}&amp;=y+\\delta y \\end{aligned} \\tag{2} \\] 则误差方程的形式为: \\[ \\begin{aligned} \\delta \\dot{z}= ??? \\end{aligned} \\] 写出考虑误差时的微分方程 即把\\(\\dot{z}=x+y\\)使用带有误差的变量代替，得到: \\[ \\begin{aligned} \\tilde{\\dot{z}}=\\tilde{x}+\\tilde{y} \\end{aligned} \\tag{3} \\] 把(2)的代入到等式(3) \\[ \\begin{aligned} \\dot{z}+\\delta{\\dot{z}}=x+\\delta x+ y+ \\delta y \\end{aligned} \\tag{4} \\] 取原微分方程(1)，代入(4) \\[ \\begin{aligned} \\because \\dot{z}&amp;=x+y \\\\ \\therefore x+y + \\delta \\dot{z}&amp;=x + y+ \\delta x+\\delta y \\\\ \\therefore \\delta \\dot{z}&amp;=\\delta x+ \\delta y \\end{aligned} \\tag{5} \\] 姿态误差分析 速度误差分析 位置误差分析 总结","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"第三章-(3)-补充内容","slug":"多传感器融合定位/第三章-惯性导航原理及误差分析-3补充","date":"2020-11-02T12:36:46.000Z","updated":"2020-12-07T03:29:28.000Z","comments":true,"path":"2020/11/02/多传感器融合定位/第三章-惯性导航原理及误差分析-3补充/","link":"","permalink":"http://yoursite.com/2020/11/02/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E4%B8%89%E7%AB%A0-%E6%83%AF%E6%80%A7%E5%AF%BC%E8%88%AA%E5%8E%9F%E7%90%86%E5%8F%8A%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90-3%E8%A1%A5%E5%85%85/","excerpt":"","text":"地球模型 概念 坐标系 高精度的惯导解算 指考虑精确的地球模型的导航解算 解算中的体现 误差方程 简化求解 中等精度IMU处理方法 组合导航与基于点云定位的区别","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"imu_tk标定论文阅读","slug":"IMU相关/imu_tk标定论文","date":"2020-10-31T12:05:29.000Z","updated":"2020-11-01T07:45:26.000Z","comments":true,"path":"2020/10/31/IMU相关/imu_tk标定论文/","link":"","permalink":"http://yoursite.com/2020/10/31/IMU%E7%9B%B8%E5%85%B3/imu_tk%E6%A0%87%E5%AE%9A%E8%AE%BA%E6%96%87/","excerpt":"","text":"A Robust and Easy to Implement Method for IMU Calibration without External Equipments 介绍 一个理想的imu，其三轴应该是与三个正交的敏感轴重合的，并且具有确定的尺度因子，但不幸的是，低成本的mems imu通常会受到non accurate scaling,sensor axis misalignments,cross-axis sensitivities以及bias的影响。 IMU标定，其实就是对上述参数的辨识过程。 传感器误差模型 对于理想的imu，加速度计和陀螺仪的三轴是重合、正交的。每个加速度计只测量沿着该轴方向的加速度，而陀螺仪则测量围绕同一轴的角速度。 然而，实际使用中的imu，由于装配等原因，两个三轴坐标系并未对准，从而形成两个非正交的坐标系。 另外，即使是单个传感器(加速度计/陀螺仪)也不是完美的，因为用于转换实际物理量的数字比例因子对于同一传感器的不同实例对象是不同的，厂商仅提供默认的标称比例因子。 其次，还有bias的影响。 下面是一些坐标系的定义： AF：加速度计坐标系（非正交） GF：陀螺仪坐标系（非正交） AOF：与AF坐标系关联的正交坐标系 其中，AOF的x轴与AF的重合 AOF的y轴处于AF坐标系中x轴与y轴所张成的平面中 GOF：类似同理 BF：载体坐标系（正交） 对于小角度导致的非正交的情况，在AF或GF坐标系中的测量值\\(s^{\\mathcal{S}}\\)可以使用如下变换，转换到正交的载体坐标系下： 其中， \\(s^{\\mathcal{B}},s^{\\mathcal{S}}\\)可以是加速度或者角速度，分别在载体坐标系和加速度计(陀螺仪)坐标系的表示 \\(\\beta_{ij}\\)表示加速度计的第i轴绕载体坐标系的第j轴的旋转，如下图2 关于矩阵T的直观解释，这个矩阵按列来看比较清晰，以第一列为例子，\\([1,\\beta_{xz},-\\beta_{xy}]\\)， - 1可以理解成\\(\\beta{xx}\\),其意义是表示加速度计坐标系的x轴由于没对齐，绕载体坐标系x轴旋转所产生的误差对 载体坐标系x轴分量造成的影响，由于没有影响，所以是1 - \\(\\beta_{xz}\\),表示加速度计坐标系的x轴由于没对齐，绕载体坐标系z轴旋转所产生的误差对 载体坐标系y轴分量造成的影响。 - \\(-\\beta_{xy}\\)，表示加速度计坐标系的x轴由于没对齐，绕载体坐标系y轴旋转所产生的误差对 载体坐标系z轴分量造成的影响。（图中绕y轴顺时针转了，而正方向是逆时针，所以加负号） 另外，载体坐标系BF和加速度关联正交坐标系AOF由一个旋转关联起来了。 提出的方法中，假设载体坐标系BF与加速度计关联正交坐标系AOF一致：此时，\\(\\beta_{xz},\\beta_{xy},\\beta_{yx}\\)变成0，因此，等式1变成： 其中，使用\\(\\alpha\\)来替换\\(\\beta\\)以表示更为通用的情况，对于加速度计，则有\\(a^{\\mathcal{O}}\\)和\\(a^{\\mathcal{S}}\\)分别表示在AOF和AF坐标系的表示。 对于陀螺仪，同理有： 其中， \\(\\omega^{\\mathcal{O}}\\)表示在AOF坐标系的角速度 \\(\\omega^{\\mathcal{S}}\\)表示在GF坐标系的角速度 加速度计和陀螺仪的刻度因子矩阵如下： 零偏(Bias)如下： 因此，进行误差补偿之后的输出值(矫正值)如下： 其中， \\(\\nu^{a}\\)表示加速度计测量噪声 \\(\\nu^{g}\\)表示陀螺仪测量噪声 标定Framework 加速度计 为了标定加速度计，需要估计如下参数： 定义补偿模型函数如下： 这里忽略了测量噪声。 定义cost funstion如下： 其中， \\(||g||\\)表示当地重力向量的模（可以查表得到） 与传统的多位置方案一样，我们平稳的旋转imu，一共M个方案。然后提取M个加速度计输出量\\(a_k^{\\mathcal{S}}\\)(即非正交坐标系的测量值)，然后将每个静态间隔时间中的加速度计读数求平均。 陀螺仪 为了标定陀螺仪，这里假设陀螺仪的bias为0，只需在适当的初始静止时间段内对静态陀螺仪信号进行平均即可 此外，由于我们需要使用加速度计作为已知的参考坐标系，因此我们使用上面标定得到的参数\\(\\theta^{acc}\\)并且使用等式(9)来得到补偿输出值。（即矫正之后的imu输出值） 这里定义一个操作符\\(\\Psi\\)，操作为：取n个陀螺仪读数\\(\\omega_i^{\\mathcal{S}}\\) 和 初始第k-1时刻的重力矢量\\(u_{a,k-1}\\)(由上面标定后的加速度计得到) 作为输入，然后返回第k时刻的矫正后的输出值\\(u_{g,k}\\)，使用了从[k-1,k]时间间隔内的gyro测量值进行计算。 \\(\\Psi\\)可以使用任一种积分方法来得到k时刻的姿态。 因此，需要估计的参数如下： cost function如下： 其中， \\(M\\)表示由多少段是静态的 \\(u_{a,k}\\)表示在第k段静态时间内，加速度计补偿输出值的平均值 \\(u_{g,k}\\)表示使用等式(11)在[k-1,k]间隔内进行积分得到载体的姿态，然后把初始重力(即k-1时刻下的加速度计补偿输出值的平均值)进行投影得到的投影值。 标定过程 如前文所述，提出的方法需要把imu移动到不同静态位置进行加速度计和陀螺仪的数据采集，如下图1报告了标定过程示意图。 为了校准加速度计，我们使用静态间隔（单段就可以） 而对于陀螺仪校准，除了两个连续的静态间隔，还包括两个连续的静态间隔之间的运动间隔(用来积分) 为了减少噪声的影响，需要对每个静态时间段的数据求平均， 同时也增加了静态时间段的长度下限（时间太短就不认为是静态的） 静态检测器 根据经验，基于带通滤波器的运算符（如[8]中使用的准静态检测器）在真实数据集上的性能较差：检测到的静态间隔通常包含一小部分运动。 此外，它们需要微调，因为它们取决于三个参数。提出的方法改为使用基于方差的静态检测器算子，该算子利用了上面介绍的静态间隔长度的下限 。。。。具体见原文描述 RK-4积分 式(15)是描述四元数运动学的微分方程： 其中， \\(\\Omega(\\omega)\\)表示把三轴角速度变成反对称矩阵 rk4积分算法如下： Allan方差 最后，使用allan方差来表征陀螺仪的随机bias偏移，该方差用于测量连续区间平均值之间的差异方差 其中 \\(x(t,k)\\)表示第k个静态间隔内平均值，跨度约为t秒 K表示将考虑的总时间分割的间隔数 三个轴的Allan方差收敛到一个小值的时候代表了此时作为初始化周期\\(T_{init}\\)的是一个不错的选择（图4） ？？？？？？？？ 在此初始化期间，我们计算静态陀螺仪信号的平均值，以正确确定校准中使用的陀螺仪偏置 完整过程 为了避免在校准参数估算中产生不可观测性，必须至少收集九种不同的姿态[15]。根据我们的经验，需要更大数量的N的不同姿态才能获得更好的校准结果，同时保持减少每个静态间隔的持续时间，以便保留陀螺仪偏置的时间稳定性假设。 文章选取： 36&lt;=N&lt;=50 1s&lt;=\\(t_{wait}\\)&lt;=4s 初始化周期Tinit的持续时间由Allan方差分析给出 整体算法流程如下：","categories":[{"name":"IMU相关","slug":"IMU相关","permalink":"http://yoursite.com/categories/IMU%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"测试工程师基础知识","slug":"测试工程师基础知识","date":"2020-10-31T02:05:29.000Z","updated":"2020-10-31T03:37:20.000Z","comments":true,"path":"2020/10/31/测试工程师基础知识/","link":"","permalink":"http://yoursite.com/2020/10/31/%E6%B5%8B%E8%AF%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"测试工程师 什么是软件测试? 从广义上说，软件测试是软件生命周期中的所有检查、评审和确认工作，包括在分析、设计阶段，以及完成开发后确认阶段的各类文档、代码的审查和确认。 从狭义上说，是识别软件缺陷的过程 什么是软件测试工程师? 软件测试工程师（Software Testing Engineer）：指理解产品的功能要求，并对其进行测试，检查软件有没有缺陷（Bug），测试软件是否具有稳定性（Robustness）、安全性、易操作性等性能，写出相应的测试规范和测试用例的专门工作人员。 软件测试的目标？ 最终目标是确保软件功能符合用户需求，在产品发布或交付前尽可能多的发现并改正缺陷。 软件测试的原则？ Good-enough原则。一种权衡投入/产出比的原则。 保证测试的覆盖度，但穷举测试是不可能的。 所有测试都应追溯到用户需求。 越早测试越好，测试过程与开发过程应是相互结合的。 测试的规模由小到大，从单元测试到系统测试。 为了尽可能的发现错误，应由独立的第三方进行测试。 不能为了便于测试擅自修改程序。 既应该测试软件应该做什么，也应该测试软件不应该做什么。 测试只是展示缺陷。测试只能表明有缺陷存在，但不能证明没有缺陷，测试能降低未发现缺陷留存的概率，却不能证明软件是绝对正确的。 穷尽测试是不可能的。测试所有的输入和条件组合是不可能的，可以取而代之的是基于风险和优先级的测试。 缺陷簇生。要对缺陷发生率高的模块投入更多的测试。少量的模块往往隐藏了大部分的缺陷。缺陷发生率高的模块往往与需求不清、设计不当、编码复杂度高等内在原因关联，所以从风险的角度来看必然较高。 杀虫剂悖论。相同的测试再重复多次后就无法再找到缺陷了。测试用例要不断评审修改，不断添加新的和不同的测试，就有可能找到更多缺陷。 测试是上下文关联的。测试在不同上下文环境中的执行是不同的。 无错谬论。即使修改了系统中存在的大部分缺陷，但若系统本身背离了用户需求，那么发现和修复缺陷就毫无帮助了。 杀虫剂悖论，在软件测试中用来描述这样一种现象，对软件进行越多的测试，那么该软件对软件测试人员的测试就越具有免疫力。 为了克服“杀虫剂悖论”，测试用例需要经常的评审和修改，不断增加新的不同的测试用例来测试软件或系统的不同部分，保证测试用例永远是最新的，即包含着最后一次程序代码或说明文档的更新信息。这样软件中未被测试过的部分或者先前没有被使用过的输入组合就会重新执行，从而发现更多的缺陷。软件测试人员必须不断地编写新的不同的测试来检验程序的不同部分从而找出更多的bug。让其他的人来测试你的程序将有助于打破”杀虫剂悖论”。 相同的测试人员测试同一个模块（功能），因长时间测试，形成了思维定式，因此也容易产生懈怠，忽视一些缺陷的存在，也容易导致杀虫剂悖论。解决办法就是采用交叉测试，不同的测试人员，有不同的测试思路和技巧，容易发现被忽视的缺陷。 软件测试的基本流程? 需求分析、测试计划、测试设计、测试开发、测试执行、测试评估。 需求分析 阅读需求，理解需求，主要就是对业务的学习，分析需求点，参与需求评审会议 测试计划 主要任务就是编写测试计划，参考软件需求规格说明书，项目总体计划，内容包括测试范围（来自需求文档），进度安排，人力物力的分配，整体测试策略的制定。风险评估与规避措施有一个制定。 测试设计 主要是编写测试用例，会参考需求文档（原型图），概要设计，详细设计等文档，用例编写完成之后会进行评审。 测试执行 搭建环境，执行测试，bug管理直到测试结束 测试评估 出测试报告，确认是否可以上线 软件测试的度量？ 测试覆盖率：有多少需求、代码已经被测试了。 缺陷发现率：缺陷是何时被发现，且有多少缺陷已经被发现，缺陷可以根据严重性来分类，需要记录的数据有：缺陷数量、缺陷的严重等级等。 测试成功率：有多少测试用例已经通过，且有多少运行正常的，需要记录的数据有：通过的测试用例数、未通过的测试用例数、已执行的测试用例数等。 多少测试才足够？ 取决于风险程度（商业风险和技术风险）和项目约束条件（时间和经费）。 调试和测试的区别？ 调试 for 开发人员发现缺陷原因，修复代码并确认缺陷已经被修复； 测试 for 测试人员识别缺陷。 什么是缺陷发现率（DDP）？ DDP=Bugs(tester)/(Bugs(tester)+Bugs(customer)) 测试人员发现的bug/（测试人员发现的bug+用户发现的bug） 什么是单元测试？ 定义：又称模块测试，是针对软件设计的最小单位程序模块进行正确性检查的测试工作；可以从程序的内部结构出发设计测试用例，多个模块测试可以平行地独立进行测试。 目的：发现模块内部可能存在的各种差错。 内容： 模块接口测试（数据的流入流出） 局部数据结构测试 路径测试 错误处理测试 边界测试。 步骤： 利用设计文档设计测试用例； 创建被测试模块的桩模块或驱动模块； 利用被测试模块、驱动模块和桩模块来建立测试环境，进行测试。 什么是集成测试？ 定义：又称组装测试或联合测试，在单元测试基础上，将所有模块按概要设计和详细设计进行组装。 目的：发现模块连接中的接口可能存在的各种差错。 内容： 穿越模块之间的数据是否会丢失； 一个模块组装后是否会对另一个模块或其他模块存在影响； 各个子功能组装在一起是否会达到预期的父功能； 全局数据结构是否有问题。 组装方法：一次性组装、增殖式组装。 完成标志： 成功地执行了测试计划中规定的所有测试用例； 修正了所发现的错误； 测试结果通过专门小组的评审。 什么是系统测试？ 目的：验证和确认系统是否达到其原始目标，而对集成的硬件和软件系统进行的测试。 测试内容：在真实或模拟系统运行环境下，检查完整的程序系统能否和系统（硬件、网络、软件）正确配置、连接，满足用户需求。 什么是静态测试？ 又称为静态分析技术，不执行被测试软件，对需求分析说明书、软件设计说明书、源程序做结构检测、流图分析、符号执行等找出软件的错误。 什么是动态测试？ 通过输入一组预先按照一定的测试准则构造的实例数据动态运行程序，而达到发现程序错误的过程。 什么是自动化测试？ 自动化测试是把以人为驱动的测试行为转化为机器执行的一种过程。 测试的分类 白盒测试 定义 白盒测试也称为结构测试或逻辑驱动测试，是针对被测单元内部是如何进行工作的测试。它根据程序的控制结构设计测试用例，主要用于软件或程序验证。这种方法是把测试对象看做一个打开的盒子，它允许测试人员利用程序内部的逻辑结构及有关信息，设计或选择 测试用例，对程序所有逻辑路径进行测试。 内容 对程序模块的所有独立的执行路径至少测试一遍。 对所有的逻辑判定，取“真”与取“假”的两种情况都能至少测一遍。 在循环的边界和运行的界限内执行循环体。 测试内部数据结构的有效性 方法 代码检查法 逻辑覆盖法（语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、条件组合覆盖和路径覆盖） 基本路径测试法 静态结构分析法 静态质量度量法 符号测试 黑盒测试 定义 软件的黑盒测试意味着测试要在软件的接口处进行。这种方法是把测试对象看做一个黑盒子，测试人员完全不考虑程序内部的逻辑结构和内部特性，只依据程序的需求规格说明书，检查程序的功能是否符合它的功能说明。 内容 是否有不正确或遗漏的功能？ 在接口上，输入是否能正确的接受？能否输出正确的结果？ 是否有数据结构错误或外部信息（例如数据文件）访问错误？ 性能上是否能够满足要求？ 是否有初始化或终止性错误？ 方法 等价类划分（等价类是指某个输入域的集合，它表示对揭露程序中的错误来说，集合中的每个输入条件是等效的） 边值分析法：列出单元功能、输入、状态及控制的合法边界值，设计测试用例，包含全部边界值的方法。 因果图 判定表法 场景法 错误推测法 正交实验法 灰盒测试 灰盒测试，是介于白盒测试与黑盒测试之间的，可以这样理解，灰盒测试关注输出对于输入的正确性，同时也关注内部表现，但这种关注不象白盒那样详细、完整，只是通过一些表征性的现象、事件、标志来判断内部的运行状态，有时候输出是正确的，但内部其实已经错误了，这种情况非常多，如果每次都通过白盒测试来操作， 效率会很低，因此需要采取这样的一种灰盒的方法。 白盒测试中的逻辑覆盖法介绍 六种覆盖标准：语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、条件组合覆盖和路径覆盖发现错误的能力呈由弱至强的变化。语句覆盖每条语句至少执行一次。 判定覆盖每个判定的每个分支至少执行一次。条件覆盖每个判定的每个条件应取到各种可能的值。判定/条件覆盖同时满足判定覆盖条件覆盖。条件组合覆盖每个判定中各条件的每一种组合至少出现一次。路径覆盖使程序中每一条可能的路径至少执行一次。 语句覆盖 语句覆盖就是设计若干个测试用例，运行所测试用例，使得程序里的每条可执行的语句都要至少执行一次，但这种覆盖对检测错误而言并不是完美无缺的，它有时候也不能发现有些错误。 测试用例虽然做到了语句覆盖，但有时候可能发现不了判断中逻辑运算中出现的错误,语句覆盖是最弱的逻辑覆盖 判定覆盖 每个判断的真假分支至少执行一次，就是真要至少取一次，假要至少取一次。 条件覆盖 和判定覆盖思路一样，只是把重点从判定移动到条件上来了，每个判定中的每个条件可能至少满足一次，也就是每个条件至少要取一次真的，再取一次假的。同样它也会遗漏许多路径，条件取真假并不能满足判定也取到真假两次。 判定-条件覆盖 要求判断中的每个条件所有可能至少出现一次,并且每个判定本身的判定结果也要出现一次。判定取真假就覆盖了判定，可是条件取真假两次并不能完全覆盖，因为条件之间还有组合。所以才有了条件组合覆盖 条件组合覆盖 每个判定中条件的各种可能组合至少满足一次。条件各种可能都出现了，必然把判定给覆盖了，它覆盖了上面的4个 路径覆盖 把所有可能路径至少都走一遍，最高阶覆盖 黑盒测试方法介绍 等价类划分法 适用场景： 有数据输入的地方，就可以使用等价类划分法。如：输入框 测试思想： 从大量数据中划分范围（等价类），然后从每个范围中挑选代表数据，这些代表数据要能反应这个范围内数据的测试结果。 有效等价类：对程序来说，有意义的、合理的数据（正确的、有效的数据） 无效等价类：对程序来说，没有意义、不合理的数据（错误的、无效的数据） 例子： 手机号输入框 无效等价类：汉字、表情、符号、空格等 有效等价类：数字 边界值分析法 根据经验法则，大量的错误是发生在输入或输出范围的边界上的，而不是发生在输入输出范围的内部。因此针对各种边界情况涉及测试用例，可以查出更多的错误。而使用边界值的分析方法涉及测试用例，首先应确定边界情况。通常输入和输出等价类的边界，应当选取正好等于，刚刚大于或者刚刚小于边界的值作为测试数据 适用场景：有数据输入的地方，在实际工作中，一般和等价类划分一起使用 测试思想：边界值是程序员在编程时是最容易出错的位置 因果图法 适用场景： 在一个界面中有多个控件，如果控件之间存在组合关系或者限制关系，不同的控件组合会产生不同的输出结果，为了弄清楚不同的输入组合会产生怎样的输出结果，可以使用因果图或判定表。 概念： 因：输入条件 果：输出结果 思想：就是通过画图的方式表达输入条件和输出结果之间的关系 测试步骤： 找出所有的输入条件 找出所有的输出结果 分析，列出输入条件之间所有的组合和限制条件 确定每组输入条件的组合会产生怎样的输出结果，画因果图，填写判定表 编写测试用例 每一列代表一种组合，编写一条测试用例 因果图/判定表的特点： 输入条件的排列顺序无关紧要 输出结果的排列顺序无关紧要 每种组合是独立的 先测哪种组合后测哪种组合无关紧要 判定表格式如下： 场景法 适用场景： 业务比较复杂的软件系统都适合使用场景法，场景法是基于软件业务的测试方法，测试人员把自己当成最终用户，尽可能真实的模拟用户在使用此软件的操作情形 重点模拟两类操作： 用户正确操作的业务过程--验证软件的业务功能是否正确实现 模拟用户错误操作的情形--验证软件的异常处理能力（健壮性） 测试思路： 场景法是模拟用户操作软件时的各种情景，主要用于测试软件的业务逻辑和流程。当拿到一个测试任务是，我们并不先关注某个文本框的等价类等是否满足要求，而是先关注它的主要功能和业务流程是否正确实现，这就需要场景法来完成测试。当业务流程测试没有问题，也就是软件的主要功能没有问题时，我们再去关注控件的等价类、边界值等细节测试。（先整体后细节） 场景划分 基本流（有效流、正确流）: 模拟用户正确的业务操作流程就是基本流 备选流（无效流、错误流）: 模拟用户错误的操作流程就是备选流 错误推测法 错误推测法是基于经验和直觉推测程序中所有可能存在的各种错误, 从而有针对性的设计测试用例的方法。 正交排列法 适用场合 在一个界面中有多个控件，每个控件有多个取值，要考虑不同控件不同取值之间的组合 ，且组合数量较大的话，我们就可以使用正交排列法。 思想 使用最少的抽样数据达到最广的，覆盖率最高的统计结果。 正交表公式如下 L：line 行 n：表示正交表有几行，需要测试的组合的个数。n值是固定的，一旦正交表确定n值就是固定的，不需要测试人员自己计算。 m：表示正交表中允许出现的最大值,根据每个控件的取值个数来确定m值 k：表示正交表有几列 未完待续 https://blog.csdn.net/weixin_30363263/article/details/80110247?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.add_param_isCf&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.add_param_isCf 其他基础 一、网络部分 1、Web页面响应过慢怎么定位问题：从一个浏览器输入url到形成页面经历了什么？ 答案参考：https://github.com/ljianshu/Blog/issues/24 2、“三次握手，四次挥手”？ 答案参考：https://www.cnblogs.com/qcrao-2018/p/10182185.html 3、HTTP常见面试题 参考答案：https://github.com/ZhongFuCheng3y/3 4、HTTP缓存机制及原理 参考答案：http://www.cnblogs.com/chenqf/p/6386163.html 5、GET和POST的区别？ 参考答案：https://segmentfault.com/a/1190000018129846 二、算法与数据结构 面试中需要掌握的8中数据结构 参考答案：https://mp.weixin.qq.com/s/MM6q9-IO0eQtbEQ_D-mLAQ 1、链表算法面试问题。 参考答案：https://mp.weixin.qq.com/s/Kxcld56hjEukti0PwHOKSQ 2、树相关 1）什么是2-3树？ 参考答案：https://mp.weixin.qq.com/s/b_J-Sw9mJ0p-c4t3ey81Xw 2）什么是红黑树？ 参考答案：https://www.jianshu.com/u/1d933ff900e7 3）为什么MySQL数据库要用B+树存储索引？ 参考答案：https://mp.weixin.qq.com/s/9oAc5QgJ7kub2-HISTnW6A 4）AVL树 参考答案：https://www.61mon.com/index.php/archives/218/ 3、十大经典排序算法。 参考答案：https://mp.weixin.qq.com/s/mq2NSG3xMqIs28nU354TjQ 4、什么是堆排序？ 参考答案：https://mp.weixin.qq.com/s/KJldeFePHSTLUaxIj9Czpg 5、栈和队列手写 参考答案：https://mp.weixin.qq.com/s/6CacG5kDmKimTMYpZdSEEA 6、什么是散列表？ 参考答案：https://mp.weixin.qq.com/s/Zks_Du7Qr2T5iDlT61gEXg 7、什么是哈希表？ 参考答案： https://mp.weixin.qq.com/s/1o8TZlyuikaE0mbtqQjg4A 8、程序员面试最常见问题TOP 48 参考答案：https://hackernoon.com/50-data-structure-and-algorithms-interview-questions-for-programmers-b4b1ac61f5b0 三、数据库 1、Redis面试必问题目 参考答案：（1）https://mp.weixin.qq.com/s/XJzu8yyVYZYmcOui_xXnvw （2）https://mp.weixin.qq.com/s/HeHvINDdXiPjgkE8TYdNYQ 2、MySQL面试必问题目 参考答案：https://mp.weixin.qq.com/s/Hj67Ll1jXarGedBQxr2ecw 四、Linux常用命令 参考答案：http://blog.csdn.net/qwe6112071/article/details/50806734 五、测试部分 参考链接：https://www.cnblogs.com/czhang2-12/p/9649835.html","categories":[],"tags":[]},{"title":"GNSS-IMU数据仿真器使用说明","slug":"多传感器融合定位/GNSS-IMU数据仿真器使用说明","date":"2020-10-29T06:57:03.000Z","updated":"2020-10-29T09:24:35.000Z","comments":true,"path":"2020/10/29/多传感器融合定位/GNSS-IMU数据仿真器使用说明/","link":"","permalink":"http://yoursite.com/2020/10/29/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/GNSS-IMU%E6%95%B0%E6%8D%AE%E4%BB%BF%E7%9C%9F%E5%99%A8%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/","excerpt":"","text":"GNSS-INS-SIM GNSS-INS-SIM是GNSS/INS模拟项目，它生成参考轨迹，IMU传感器输出，GPS输出，里程表输出和磁力计输出。用户选择/设置传感器模型，定义航路点并提供算法，gnss-ins- sim可以为算法生成所需的数据，运行算法，布局仿真结果，保存仿真结果并生成摘要。 基本使用方式 import 12345import osimport mathimport numpy as npfrom gnss_ins_sim.sim import imu_modelfrom gnss_ins_sim.sim import ins_sim 选择或定义IMU误差模型 选择现成的模型 内置了三种IMU模型：“低精度”，“中精度”和“高精度”： 1imu = imu_model.IMU(accuracy='mid-accuracy', axis=6, gps=False) 自定义误差模型 123456789101112imu_err = &#123;'gyro_b': np.array([5.0, -5.0, 2.5]) * 3600.0, 'gyro_arw': np.array([0.25, 0.25, 0.25]) * 1.0, 'gyro_b_stability': np.array([3.5, 3.5, 3.5]) * 1.0, 'gyro_b_corr': np.array([100.0, 100.0, 100.0]), 'accel_b': np.array([50.0e-3, 50.0e-3, 50.0e-3]) * 0.0, 'accel_vrw': np.array([0.03119, 0.03009, 0.04779]) * 1.0, 'accel_b_stability': np.array([4.29e-5, 5.72e-5, 8.02e-5]) * 1.0, 'accel_b_corr': np.array([200.0, 200.0, 200.0]), 'mag_std': np.array([0.2, 0.2, 0.2]) * 1.0 &#125;# do not generate GPS and magnetometer dataimu = imu_model.IMU(accuracy=imu_err, axis=6, gps=False) 设置运动轨迹 初始值 初始位置应以LLA（纬度，经度和高度）形式给出。 初始速度在车身框架中指定。 初始姿态由ZYX顺序的欧拉角表示。 Ini lat (deg) ini lon (deg) ini alt (m) ini vx_body (m/s) ini vy_body (m/s) ini vz_body (m/s) ini yaw (deg) ini pitch (deg) ini roll (deg) 32 120 0 0 0 0 0 0 0 初始欧拉角为0度俯仰角，0度侧倾角和0度偏航角，这意味着车辆处于水平状态且其x轴指向北方 运动指令 运动命令定义了车辆如何从其初始状态开始运动。仿真将根据命令生成真实的角速度，加速度，磁场，位置，速度和姿态。结合传感器误差模型，这些真实值将用于生成陀螺仪，加速度计，磁力计和GPS输出。 您可以添加更多的运动命令来指定车辆的姿态和速度。 您还可以为每个命令定义车辆的GPS可见性。 支持五种命令类型: 命令类型 功能 1 直接定义欧拉角变化率(角速度)和速度变化率(加速度)。变化率在第2〜7栏给出。单位是度/秒和米/秒/秒。第8列给出了命令将持续多长时间。如果要完全控制每个命令的执行时间，则应始终将运动类型选择为1 2 定义要达到的绝对姿态和绝对速度。目标姿态和速度由第2〜7列给出。单位是deg和m/s。第8列定义了执行命令的最长时间。如果实际执行时间少于最大时间，则将不使用剩余时间，并且将立即执行下一条命令。如果命令不能在最大时间内完成，则在最大时间后直接执行下一个命令。 3 定义姿态变化和速度变化。姿态和速度变化在第2〜7列中给出。单位是度和m / s。第8列定义了执行命令的最长时间。 4 定义绝对姿态和速度变化。绝对姿态和速度变化由第2〜7列给出。单位是度和m / s。第8列定义了执行命令的最长时间。 5 定义姿态变化和绝对速度。姿态变化和绝对速度由第2〜7列给出。单位是度和m / s。第8列定义了执行命令的最长时间。 例子 创建算法对象 alan 1algo = allan_analysis.Allan() # an Allan analysis demo algorithm 积分 积分接口如下: 12345678910111213class FreeIntegration(object): ''' Integrate gyro to get attitude, double integrate linear acceleration to get position. ''' def __init__(self, ini_pos_vel_att, earth_rot=True): ''' Args: ini_pos_vel_att: 9x1 numpy array containing initial position, velocity and attitude. 3x1 position in the form of LLA, units: [rad, rad, m]; 3x1 velocity in the body frame, units: m/s; 3x1 Euler anels [yaw, pitch, roll], rotation sequency is ZYX, rad. earth_rot: Consider the Earth rotation or not. Only used when ref_frame=0. ''' ini_pos_vel_att: 9x1的numpy数组，包括初始位置(LLA)、速度(body-frame)、姿态(ZYX) earth_rot: 是否考虑地球自转 使用案例: 1234567891011121314151617#### Algorithm# Free integration in a virtual inertial framefrom demo_algorithms import free_integration_odofrom demo_algorithms import free_integrationini_pos_vel_att = np.genfromtxt(motion_def_path+\"//motion_def-long_drive.csv\",\\ delimiter=',', skip_header=1, max_rows=1)ini_pos_vel_att[0] = ini_pos_vel_att[0] * D2Rini_pos_vel_att[1] = ini_pos_vel_att[1] * D2Rini_pos_vel_att[6:9] = ini_pos_vel_att[6:9] * D2R# add initial states error if neededini_vel_err = np.array([0.0, 0.0, 0.0]) # initial velocity error in the body frame, m/sini_att_err = np.array([0.0, 0.0, 0.0]) # initial Euler angles error, degini_pos_vel_att[3:6] += ini_vel_errini_pos_vel_att[6:9] += ini_att_err * D2R# create the algorith objectalgo = free_integration.FreeIntegration(ini_pos_vel_att) Manhony 使用Manhony算法进行姿态解算 1234#### Algorithm# ECF based inclinometerfrom demo_algorithms import inclinometer_mahonyalgo = inclinometer_mahony.MahonyFilter() loosely couple (松耦合) ——算法未完成 1234#### Algorithm# loosely couple INS algorithmfrom demo_algorithms import ins_loosealgo = ins_loose.InsLoose() 创建仿真器对象 12345678# start simulationsim = ins_sim.Sim([fs, fs_gps, fs_mag], motion_def_path+\"//motion_def-90deg_turn.csv\", ref_frame=1, imu=imu, mode=None, env=None, algorithm=None) 具体接口描述如下: fs: [fs_imu, fs_gps, fs_mag] , 包括imu采样频率，也是仿真频率，gps频率 motion_def: 设备日志或者仿真运动规划 ref_frame：参考坐标系 0：表示使用NED坐标系，x轴指向正北(地理北，而不是磁北)，y轴指向东，z轴指向地，位置使用LLA表示 1：虚拟的惯性坐标系? imu: imu误差模型，如果使用的是设备的日志输出来仿真，则把imu误差模型设置为None,即imu=None mode: 使用默认的None即可 env: 振动模型，有三种 algorithm: 算法模型 开始仿真 123sim.run() # run for 1 timesim.run(1) # run for 1 timesim.run(100) # run for 100 times 结果显示 12345678910# generate a simulation summary,# and save the summary and all data in directory './data'.# You can specify the directory.sim.results('./data/')# generate a simulation summary, do not save any filesim.results()# plot interested datasim.plot(['ref_pos', 'gyro'], opt=&#123;'ref_pos': '3d'&#125;) 完整imu数据仿真示例 生成6轴imu数据 1234567891011121314151617181920212223242526272829303132333435363738import osimport mathfrom gnss_ins_sim.sim import imu_modelfrom gnss_ins_sim.sim import ins_sim# globalsD2R = math.pi/180motion_def_path = os.path.abspath('.//demo_motion_def_files//')fs = 100.0 # IMU sample frequencyfs_gps = 10.0 # GPS sample frequencyfs_mag = fs # magnetometer sample frequency, not used for nowdef test_path_gen(): ''' test only path generation in Sim. ''' #### choose a built-in IMU model, typical for IMU381 imu_err = 'mid-accuracy' # generate GPS and magnetometer data imu = imu_model.IMU(accuracy=imu_err, axis=6, gps=False) #### start simulation sim = ins_sim.Sim([fs, fs_gps, fs_mag], motion_def_path+\"//motion_def-3d.csv\", ref_frame=1, imu=imu, mode=None, env=None, algorithm=None) sim.run(1) # save simulation data to files sim.results('') # plot data, 3d plot of reference positoin, 2d plots of gyro and accel sim.plot(['ref_pos', 'gyro', 'gps_visibility'], opt=&#123;'ref_pos': '3d'&#125;)if __name__ == '__main__': test_path_gen() 一些数据成员说明 名称 描述 'ref_frame' 参考坐标系用作导航框架和姿态参考。0：NED（默认），x轴指向地理北部，y轴指向东，z轴指向下。位置将以LLA形式表示，并且车辆相对于ECEF框架的速度将以本地NED框架表示。1：虚拟惯性系，其常数g，x轴指向地理或磁北，z轴指向g，y轴构成右手坐标系。在此帧中，位置和速度都将为[xyz]形式。注意：对于此虚拟惯性框架，位置确实是ecef中的初始位置与病毒性惯性框架中的相对位置之和。实际上，不应添加在不同帧中表达的两个向量。这是在此处以保留所有有用信息以生成.kml文件的方式完成的。如果使用此结果，请记住这一点。 'fs' IMU的采样频率，单位：Hz 'fs_gps' GNSS的采样频率，单位：Hz 'fs_mag' 磁力计的采样频率，单位：Hz '时间' 时间序列对应于IMU样本，单位：秒。 'gps_time' 时间序列对应于GNSS样本，单位：秒。 'algo_time' 对应于算法输出的时间序列，单位：['s']。如果您的算法输出数据速率与输入数据速率不同，则应在算法输出中包含“ algo_time”。 'gps_visibility' 指示GPS是否可用。1表示是，0表示否。 'ref_pos' 导航框中的真实位置。当用户选择NED（ref_frame = 0）作为导航框时，位置将以[纬度，经度，高度]的形式给出，单位为['rad'，'rad'，'m']。当用户选择虚拟惯性框架时，位置（初始位置+相对于框架原点的位置）将以[x，y，z]的形式给出，单位为['m'，'m'，'m ']。 'ref_vel' NED帧中表示的导航/参考帧的真实速度，单位：['m / s'，'m / s'，'m / s']。 'ref_att_euler' 真实姿态（欧拉角，ZYX旋转顺序），单位：['rad'，'rad'，'rad'] 'ref_att_quat' 真实态度（四元数） 'ref_gyro' 车架中的真实角速度，单位：['rad / s'，'rad / s'，'rad / s'] 'ref_accel' 车身框架中的真实加速度，单位：['m / s ^ 2'，'m / s ^ 2'，'m / s ^ 2'] 'ref_mag' 车架中的真实地磁场，单位：['uT'，'uT'，'uT']（仅当IMU对象中的axis = 9时可用） 'ref_gps' NED（LLA）的真实GPS位置/速度，['rad'，'rad'，'m'，'m / s'，'m / s'，'m / s']，['m'，'m '，'m'，'m / s'，'m / s'，'m / s']用于虚拟惯性框架（xyz）（仅当gps = IMU对象中为True时可用） 陀螺仪 陀螺仪测量结果“ ref_gyro”出现错误 '加速' 加速度计测量，“ ref_accel”有错误 'mag' 磁力计测量，“ ref_mag”有错误 '全球定位系统' GPS测量，“ ref_gps”有错误 'ad_gyro' 陀螺仪的Allan std，单位：['rad / s'，'rad / s'，'rad / s'] 'ad_accel' 加速度的Allan std，单位：['m / s2'，'m / s2'，'m / s2'] “ pos” 来自算法的仿真位置，单位：对于NED（LLA）为['rad'，'rad'，'m']，对于虚拟惯性系（xyz）为['m'，'m'，'m']。 'vel' 来自算法的仿真速度，单位：['m / s'，'m / s'，'m / s'] 'att_euler' 来自算法的模拟态度（Euler，ZYX），单位：['rad'，'rad'，'rad'] 'att_quat' 来自算法的模拟态度（四元数） 'wb' 陀螺仪偏差估计，单位：['rad / s'，'rad / s'，'rad / s'] 'ab' 加速度计偏差估计，单位：['m / s ^ 2'，'m / s ^ 2'，'m / s ^ 2'] 'gyro_cal' 校准陀螺仪输出，单位：['rad / s'，'rad / s'，'rad / s'] 'accel_cal' 校准的加速器输出，单位：['m / s ^ 2'，'m / s ^ 2'，'m / s ^ 2'] 'mag_cal' 校准的磁力计输出，单位：['uT'，'uT'，'uT'] '软铁' 3x3软铁校准矩阵 'hard_iron' 硬铁校准，单位：['uT'，'uT'，'uT']","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"第三章-(1)-惯性器件误差分析及内参标定","slug":"多传感器融合定位/第三章-惯性导航原理及误差分析_1","date":"2020-10-25T08:53:13.000Z","updated":"2020-11-02T12:35:59.000Z","comments":true,"path":"2020/10/25/多传感器融合定位/第三章-惯性导航原理及误差分析_1/","link":"","permalink":"http://yoursite.com/2020/10/25/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E4%B8%89%E7%AB%A0-%E6%83%AF%E6%80%A7%E5%AF%BC%E8%88%AA%E5%8E%9F%E7%90%86%E5%8F%8A%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90_1/","excerpt":"","text":"惯性导航基础 惯导误差分析 Allan方差 惯性器件内参标定 内参误差模型 标定方法 分立级标定 加速度计标定 分立级：各个部分分开标定，系统级标定：使用一个模型进行全部参数的标定 其中， \\((a_x,a_y,a_z)\\)为真实值 \\((A_x,A_y,A_z)\\)为imu输出值 陀螺仪标定 补充内容： 角速度定义： - 角速度ω是矢量。按右手螺旋定则，大拇指方向为ω方向。当质点作逆时针旋转时，ω向上；作顺时针旋转时，ω向下。 其中， 上图中的\\(w\\)轴表示地球自转角速度矢量的方向 主要原因：转台旋转的时候，本来就有误差，如果使用信噪比来评价，信：指由零偏积分造成的误差，也就是我们要求解的，噪：指转台的误差，这个时候，信噪比其实并不大。 半系统级标定 惯性器件温差补偿","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"C/C++整理","slug":"Cplusplus整理","date":"2020-10-20T13:48:15.000Z","updated":"2020-11-02T15:37:38.000Z","comments":true,"path":"2020/10/20/Cplusplus整理/","link":"","permalink":"http://yoursite.com/2020/10/20/Cplusplus%E6%95%B4%E7%90%86/","excerpt":"","text":"一、基础知识 static关键字作用 全局静态变量 在全局变量前加上关键字 static,全局变量就定义成一个全局静态变量 存放地址：静态存储区 初始化：未经初始化的全局静态变量会被自动初始化为 0 作用域：全局静态变量在声明他的文件之外是不可见的, 准确地说是从定义之处开始, 到文件结尾。 局部静态变量 在局部变量之前加上关键字 static,局部变量就成为一个局部静态变量。 存放地址：静态存储区 初始化：自动初始化为 0 作用域:作用域仍为局部作用域 静态函数 在函数返回类型前加 static,函数就定义为静态函数。函数的定义和声明在默认情况下都是 extern 的,但静态函数只是在声明他的文件当中可见,不能被其他文件所用(函数的实现使用 static 修饰,那么这个函数只可在本 cpp 内使用) 类的静态成员 在类中, 静态成员可以实现多个对象之间的数据共享, 并且使用静态数据成员还不会破坏隐藏的原则,即保证了安全性。因此,静态成员是类的所有对象中共享的成员,而不是某个对象的成员。对多个对象来说,静态数据成员只存储一处,供所有对象共用 类的静态函数 在静态成员函数的实现中不能直接引用类中说明的非静态成员, 可以引用类中说明的静态成员, 调用静态成员函数使用如下格式:::(); c++中四种 cast 转换 C++中四种类型转换是:static_cast, dynamic_cast, const_cast, reinterpret_cast const_cast: 用于将 const 变量转为非 const static_cast: 用于各种隐式转换,比如非 const 转 const,void*转指针等, static_cast 能用于多态向上转化,如果向下转能成功但是不安全,结果未知; dynamic_cast: 用于动态类型转换。 只能用于含有虚函数的类, 用于类层次间的向上和向下转化。 只能转指针或引用。向下转化时,如果是非法的对于指针返回 NULL reinterpret_cast 为什么不使用 C 的强制转换? C 的强制转换表面上看起来功能强大什么都能转,但是转化不够明确,不能进行错误检查, 容易出错。 C/C++ 中指针和引用的区别? 1.指针有自己的一块空间,而引用只是一个别名; 2.使用 sizeof 看一个指针的大小是 4,而引用则是被引用对象的大小; 3.指针可以被初始化为 NULL,而引用必须被初始化且必须是一个已有对象 的引用; 4.作为参数传递时,指针需要被解引用才可以对对象进行操作,而直接对引 用的修改都会改变引用所指向的对象; 5.可以有 const 指针,但是没有 const 引用; 6.指针在使用中可以指向其它对象,但是引用只能是一个对象的引用,不能 被改变; 7.指针可以有多级指针(**p),而引用至于一级; 8.指针和引用使用++运算符的意义不一样; 9.如果返回动态内存分配的对象或者内存,必须使用指针,引用可能引起内存泄露。 野指针是什么? 野指针就是指向一个已删除的对象或者未申请访问受限内存区域的指针 智能指针有没有内存泄露的情况? 当两个对象相互使用一个 shared_ptr 成员变量指向对方,会造成循环引用,使引用计数失效,从而导致内存泄漏。例如: 上述代码中, parent 有一个 shared_ptr 类型的成员指向孩子, 而 child 也有一个 shared_ptr 类型的成员指向父亲。然后在创建孩子和父亲对象时也使用了智能指针 c 和 p,随后将 c 和 p 分别又赋值给 child 的智能指针成员 parent 和 parent 的智能指针成员 child。 从而形成了一个循环引用 智能指针的内存泄漏如何解决? 为了解决循环引用导致的内存泄漏,引入了 weak_ptr 弱指针,weak_ptr 的构造函数不会修改引用计数的值, 从而不会对对象的内存进行管理, 其类似一个普通指针, 但不指向引用计数的共享内存,但是其可以检测到所管理的对象是否已经被释放,从而避免非法访问。 函数指针 定义：函数指针是指向函数的指针变量。 函数指针本身首先是一个指针变量, 该指针变量指向一个具体的函数。 这正如用指针变量可指向整型变量、字符型、数组一样,这里是指向函数。 C 在编译时,每一个函数都有一个入口地址,该入口地址就是函数指针所指向的地址。有了指向函数的指针变量后, 可用该指针变量调用函数, 就如同用指针变量可引用其他类型变量一样, 在这些概念上是大体一致的。 示例： 为什么析构函数必须是虚函数?为什么 C++默认的析构函数不是虚函数 将可能会被继承的父类的析构函数设置为虚函数, 可以保证当我们 new 一个子类, 然后使用基类指针指向该子类对象,释放基类指针时可以释放掉子类的空间,防止内存泄漏。 C++默认的析构函数不是虚函数是因为虚函数需要额外的虚函数表和虚表指针,占用额外的内存。而对于不会被继承的类来说,其析构函数如果是虚函数,就会浪费内存。因此 C++默认的析构函数不是虚函数,而是只有当需要当作父类时,设置为虚函数。 C++中析构函数的作用 析构函数与构造函数对应, 当对象结束其生命周期, 如对象所在的函数已调用完毕时, 系统会自动执行析构函数。 析构函数名也应与类名相同,只是在函数名前面加一个位取反符,例如stud( ),以区别于构造函数。它不能带任何参数,也没有返回值(包括 void 类型)。只能有一个析构函数,不能重载。 如果用户没有编写析构函数, 编译系统会自动生成一个缺省的析构函数 (即使自定义了析构函数, 编译器也总是会为我们合成一个析构函数, 并且如果自定义了析构函数, 编译器在执行时会先调用自定义的析构函数再调用合成的析构函数) , 它也不进行任何操作。 所以许多简单的类中没有用显式的析构函数。 如果一个类中有指针, 且在使用的过程中动态的申请了内存, 那么最好显示构造析构函数在销毁类之前,释放掉申请的内存空间,避免内存泄漏。 类析构顺序: 1)派生类本身的析构函数; 2)对象成员析构函数; 3)基类析构函数。 静态函数和虚函数的区别 静态函数在编译的时候就已经确定运行时机, 虚函数在运行的时候动态绑定。 虚函数因为用了虚函数表机制,调用的时候会增加一次内存开销 重载和覆盖 重载: 两个函数名相同,但是参数列表不同(个数,类型),返回值类型没有要求,在同一作用域中 重写: 子类继承了父类,父类中的函数是虚函数,在子类中重新定义了这个虚函数,这种情况是重写 虚函数和多态 多态的实现主要分为静态多态和动态多态 静态多态: 主要是重载, 在编译的时候就已经确定; 动态多态: 用虚函数机制实现的, 在运行期间动态绑定。 举个例子: 一个父类类型的指针指向一个子类对象时候, 使用父类的指针去调用子类中重写了的父类中的虚函数的时候, 会调用子类重写过后的函数,在父类中声明为加了 virtual 关键字的函数,在子类中重写时候不需要加 virtual 也是虚函数。 虚函数表具体是怎样实现运行时多态的? 子类若重写父类虚函数,虚函数表中,该函数的地址会被替换 ++i 和 i++的实现 C++里是怎么定义常量的?常量存放在内存的哪个位置? 常量在 C++里的定义就是一个 top-level const 加上对象类型,常量定义必须初始化。 对于局部对象,常量存放在栈区 对于全局对象,常量存放在全局/静态存储区。 对于字面值常量,常量存放在常量存储区。 extern “C” C++调用 C 函数需要 extern C,因为 C 语言没有函数重载。 new/delete 与 malloc/free 的区别是什么 首先, new/delete 是 C++的关键字, 而 malloc/free 是 C 语言的库函数, 后者使用必须指明申请内存空间的大小,对于类类型的对象,后者不会调用构造函数和析构函数 C++中拷贝赋值函数的形参能否进行值传递? 不能。如果是这种情况下,调用拷贝构造函数的时候,首先要将实参传递给形参,这个传递的时候又要调用拷贝构造函数。。如此循环,无法完成拷贝,栈也会满。 STL容器 map 和 set 有什么区别,分别又是怎么实现的? map 和 set 都是 C++的关联容器,其底层实现都是红黑树(RB-Tree)。由于 map 和 set 所开放的各种操作接口,RB-tree 也都提供了,所以几乎所有的 map 和 set 的操作行为,都只是转调 RB-tree 的操作行为。 map 和 set 区别在于: (1)map 中的元素是 key-value(关键字—值)对:关键字起到索引的作用,值则表示与索引相关联的数据;Set 与之相对就是关键字的简单集合,set 中每个元素只包含一个关键字。 (2)set 的迭代器是 const 的,不允许修改元素的值; map 允许修改 value,但不允许修改key。其原因是因为 map 和 set 是根据关键字排序来保证其有序性的,如果允许修改 key的话, 那么首先需要删除该键,然后调节平衡,再插入修改后的键值,调节平衡,如此一来,严重破坏了 map 和 set 的结构,导致 iterator 失效,不知道应该指向改变前的位置,还是指向改变后的位置。所以 STL 中将 set 的迭代器设置成 const,不允许修改迭代器的值;而 map 的迭代器则不允许修改 key 值,允许修改 value 值。 map 支持下标操作, set 不支持下标操作。 map 可以用 key 做下标, map 的下标运算符[ ] 将key作为下标去执行查找,如果key-value不存在,则插入一个具有该关键码和 mapped_type 类型默认值的元素至 map 中,因此下标运算符[ ]在 map 应用中需要慎用,如果 find 能解决需要,尽可能用 find。 STL 迭代器删除元素 1.对于序列容器 vector,deque 来说,使用erase(itertor)后, 后边的每个元素的迭代器都会失效, 但是后边每个元素都会往前移动一个位置,但是 erase 会返回下一个有效的迭代器; 2.对于关联容器 map set 来说,使用了erase(iterator)后,当前元素的迭代器失效,但是其结构是红黑树,删除当前元素的,不会影响到下一个元素的迭代器, 所以在调用 erase 之前, 记录下一个元素的迭代器即可。 3.对于 list 来说,它使用了不连续分配的内存,并且它的 erase 方法也会返回下一个有效的 iterator,因此上面两种正确的方法都可以使用。 vector 和 list 的区别,应用 vector: 连续存储的容器 动态数组: 在堆上分配空间 底层实现: 数组 两倍容量增长: vector 增加(插入)新元素时,如果未超过当时的容量,则还有剩余空间,那么直接添加到最后(插入指定位置),然后调整迭代器。如果没有剩余空间了,则会重新配置原有元素个数的两倍空间,然后将原空间元素通过复制的方式初始化新空间,再向新空间增加元素,最后析构并释放原空间,之前的迭代器会失效。 适用场景: 经常随机访问,且不经常对非尾节点进行插入删除. vector 拥有一段连续的内存空间,因此支持随机访问,如果需要高效的随即访问,而不在乎插入和删除的效率,使用 vector。 性能: list: 动态链表,在堆上分配空间 每插入一个元数都会分配空间,每删除一个元素都会释放空间。 底层: 双向链表 适用场景: 经常插入删除大量数据. list 拥有一段不连续的内存空间,如果需要高效的插入和删除,而不关心随机访问,则应使用 list。 性能： STL 中迭代器的作用,有指针为何还要迭代器 迭代器 Iterator(迭代器)模式又称 Cursor(游标)模式,用于提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示。或者这样说可能更容易理解:Iterator 模式是运用于聚合对象的一种模式, 通过运用该模式, 使得我们可以在不知道对象内部表示的情况下,按照一定顺序(由 iterator 提供的方法)访问聚合对象中的各个元素。 迭代器和指针的区别 迭代器不是指针,是类模板,表现的像指针。他只是模拟了指针的一些功能,通过重载了指针的一些操作符, -&gt;、 *、 ++、 --等。 迭代器封装了指针, 是一个 “可遍历 STL ( Standard Template Library)容器内全部或部分元素”的对象, 本质是封装了原生指针,是指针概念的一种提升(lift),提供了比指针更高级的行为,相当于一种智能指针,他可以根据不同类型的数据结构来实现不同的++,--等操作。 **迭代器返回的是对象引用而不是对象的值,所以 cout 只能输出迭代器使用*取值后的值而不能直接输出其自身。** 迭代器产生原因 Iterator 类的访问方式就是把不同集合类的访问逻辑抽象出来,使得不用暴露集合内部的结构而达到循环遍历集合的效果。 STL 里 resize 和 reserve 的区别 resize(): 改变当前容器内含有元素的数量, eg: vector&lt;int&gt;v; v.resize(len); , v 的 size 变为 len 如果原来 v 的 size() 小于 len, 那么容器新增(len-size)个元素, 元素的值为默认为 0. reserve(): 改变当前容器的最大容量(capacity),它不会生成元素,只是确定这个容器允许放入多少对象, 如果 reserve(len)的值大于当前的 capacity(),那么会重新分配一块能存 len 个对象的空间,然后把之前 v.size() 个对象通过 copy construtor 复制过来,销毁之前的内存; 注意，这个操作并不会创建新的元素对象 类和数据抽象 C++中类成员的访问权限 C++通过 public、 protected、 private 三个关键字来控制成员变量和成员函数的访问权限, 它们分别表示公有的、受保护的、私有的,被称为成员访问限定符。在类的内部(定义类的代码内部),无论成员被声明为 public、protected 还是 private,都是可以互相访问的,没有访问权限的限制。在类的外部(定义类的代码之外),只能通过对象访问成员,并且通过对象只能访问 public 属性的成员,不能访问 private、protected 属性的成员 C++中 struct 和 class 的区别 在 C++中,可以用 struct 和 class 定义类,都可以继承。 区别在于: struct 的默认继承权限和默认访问权限是 public , 而 class 的默认继承权限和默认访问权限是 private。 另外,class 还可以定义模板类形参,比如 template &lt;class T, int i&gt;。 泛型编程 什么是右值引用,跟左值又有什么区别? 右值引用是 C++11 中引入的新特性 , 它实现了转移语义和精确传递。它的主要目的有两个方面: - 消除两个对象交互时不必要的对象拷贝,节省运算存储资源,提高效率。 - 能够更简洁明确地定义泛型函数。 左值和右值的概念: - 左值: 能对表达式取地址、或具名对象/变量。一般指表达式结束后依然存在的持久对象。 - 右值: 不能对表达式取地址,或匿名对象。一般指表达式结束就不再存在的临时对象。 - 举例: 123A a;A&amp; a_ref=a;A&amp;&amp; temp_rref = A(); 右值引用和左值引用的区别: - 左值可以寻址,而右值不可以。 - 左值可以被赋值,右值不可以被赋值,可以用来给左值赋值。 《左右值与右值引用》 编译与底层 C++源文件从文本到可执行文件经历的过程 对于 C++源文件,从文本到可执行文件一般需要四个过程: 1) 预处理阶段: 对源代码文件中文件包含关系(头文件)、预编译语句(宏定义)进行分析和替换,生成预编译文件。 2) 编译阶段: 将经过预处理后的预编译文件转换成特定汇编代码,生成汇编文件 3) 汇编阶段: 将编译阶段生成的汇编文件转化成机器码,生成可重定位目标文件 4) 链接阶段: 将多个目标文件及所需要的库连接成最终的可执行目标文件 include 头文件的顺序以及双引号””和尖括号&lt;&gt;的区别? Include 头文件的顺序: 对于 include 的头文件来说, 如果在文件 a.h 中声明一个在文件 b.h 中定义的变量,而不引用 b.h。那么要在 a.c 文件中引用 b.h 文件,并且要先引用 b.h,后引用a.h,否则汇报变量类型未声明错误。 双引号和尖括号的区别: 编译器预处理阶段查找头文件的路径不一样 1) 对于使用双引号\"\"包含的头文件,查找头文件路径的顺序为: (1) 当前头文件目录 (2) 编译器设置的头文件路径(编译器可使用-I 显式指定搜索路径) (3) 系统变量 CPLUS_INCLUDE_PATH/C_INCLUDE_PATH 指定的头文件路径 2) 对于使用尖括号包含的头文件,查找头文件的路径顺序为: (1) 编译器设置的头文件路径(编译器可使用-I 显式指定搜索路径) (2) 系统变量 CPLUS_INCLUDE_PATH/C_INCLUDE_PATH 指定的头文件路径 malloc 的原理 Malloc 函数用于动态分配内存。为了减少内存碎片和系统调用的开销,malloc 其采用内存池的方式, 先申请大块内存作为堆区, 然后将堆区分为多个内存块, 以块作为内存管理的基本单位。当用户申请内存时,直接从堆区分配一块合适的空闲块。 new 和 malloc 的区别 new 分配内存按照数据类型进行分配, malloc 分配内存按照指定的大小分配; new 返回的是指定对象的指针, 而 malloc 返回的是 void*, 因此 malloc 的返回值一般都需要进行类型转化。 new 不仅分配一段内存,而且会调用构造函数,malloc 不会。 new 分配的内存要用 delete 销毁,malloc 要用 free 来销毁;delete 销毁的时候会调用对象的析构函数,而 free 则不会。 new 是一个操作符可以重载,malloc 是一个库函数。 malloc 分配的内存不够的时候, 可以用 realloc 扩容。 new 如果分配失败了会抛出 bad_malloc 的异常,而 malloc 失败了会返回 NULL。 申请数组时: new[]一次分配所有内存, 多次调用构造函数, 搭配使用 delete[], delete[] 多次调用析构函数,销毁数组中的每个对象。而 malloc 则只能 sizeof(int) * n。 C++的内存管理是怎样的 在 C++中,虚拟内存分为代码段、数据段、BSS 段、堆区、文件映射区以及栈区六部分。 1) 代码段:包括只读存储区和文本区,其中只读存储区存储字符串常量,文本区存储程序的机器代码。 2) 数据段:存储程序中已初始化的全局变量和静态变量 3) bss 段:存储未初始化的全局变量和静态变量(局部+全局),以及所有被初始化为 0 的全局变量和静态变量。 4) 堆区: 调用 new/malloc 函数时在堆区动态分配内存, 同时需要调用 delete/free 来手动释放申请的内存。 5) 映射区:存储动态链接库以及调用 mmap 函数进行的文件映射 6) 栈:使用栈空间存储函数的返回地址、参数、局部变量、返回值 什么是 memory leak,也就是内存泄漏 内存泄漏(memory leak)是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。 内存泄漏并非指内存在物理上的消失, 而是应用程序分配某段内存后, 由于设计错误, 失去了对该段内存的控制,因而造成了内存的浪费。 内存泄漏分类 堆内存泄漏 (Heap leak): 指的是程序运行中根据需要分配通过 malloc,realloc new 等从堆中分配的一块内存,再是完成后必须通过调用对应的 free 或者 delete 删掉。如果程序的设计的错误导致这部分内存没有被释放, 那么此后这块内存将不会被使用, 就会产生 Heap Leak. 系统资源泄露(Resource Leak): 主要指程序使用系统分配的资源比如Bitmap,handle ,SOCKET 等没有使用相应的函数释放掉,导致系统资源的浪费,严重可导致系统效能降低,系统运行不稳定。 没有将基类的析构函数定义为虚函数: 当基类指针指向子类对象时,如果基类的析构函数不是 virtual,那么子类的析构函数将不会被调用,子类的资源没有正确是释放,因此造成内存泄露。 如何判断内存泄漏? 内存泄漏通常是由于调用了 malloc/new 等内存申请的操作, 但是缺少了对应的 free/delete。 为了判断内存是否泄露, 我们一方面可以使用 linux 环境下的内存泄漏检查工具 Valgrind,另一方面我们在写代码时可以添加内存申请和释放的统计功能, 统计当前申请和释放的内存是否一致, 以此来判断内存是否泄露。 C++如何处理内存泄漏? 使用 varglind,mtrace 检测 什么时候会发生段错误 段错误通常发生在访问非法内存地址的时候,具体来说分为以下几种情况: 1) 使用野指针 2) 试图修改字符串常量的内容 如何采用单线程的方式处理高并发 在单线程模型中, 可以采用 I/O 复用来提高单线程处理多个请求的能力, 然后再采用事件驱动模型,基于异步回调来处理事件来 C++11 C++11 有哪些新特性? C++11 最常用的新特性如下： 1) auto 关键字:编译器可以根据初始值自动推导出类型。但是不能用于函数传参以及数组类型的推导 2) nullptr 关键字: nullptr 是一种特殊类型的字面值, 它可以被转换成任意其它的指针类型; 而 NULL 一般被宏定义为 0,在遇到重载时可能会出现问题。 3) 智能指针: C++11 新增了 std::shared_ptr、std::weak_ptr 等类型的智能指针,用于解决内存管理的问题。 4) 初始化列表:使用初始化列表来对类进行初始化 5) 右值引用: 基于右值引用可以实现移动语义和完美转发, 消除两个对象交互时不必要的对象拷贝,节省运算存储资源,提高效率 6) atomic 原子操作用于多线程资源互斥操作 7) 新增 STL 容器 array 以及 tuple 介绍一下 C++11 中的可变参数模板、右值引用和 lambda 这几个新特性 可变参数模板: C++11 的可变参数模板,对参数进行了高度泛化,可以表示任意数目、任意类型的参数,其语法为:在 class 或 typename 后面带上省略号... 省略号作用如下: 1) 声明一个包含 0 到任意个模板参数的参数包 2) 可以将参数包展成一个个独立的参数 12345//T 叫做模板参数包,args 叫做函数参数包Template&lt;class ... T&gt;void func(T ... args)&#123; cout&lt;&lt;\"num is\"&lt;&lt;sizeof ...(args)&lt;&lt;endl;&#125; func();//args 不含任何参数 func(1);//args 包含一个 int 类型的实参 func(1,2.0)//args 包含一个 int 一个 double 类型的实参 C++11 可以使用递归函数的方式展开参数包,获得可变参数的每个值。通过递归函数展开参数包,需要提供一个参数包展开的函数和一个递归终止函数。例如: 12345678910111213//重载最终递归函数void print()&#123; cout&lt;&lt;\"empty\"&lt;&lt;endl;&#125;// 展开函数template void print(T head, Args ... args)&#123; cout&lt;&lt;head&lt;&lt;\",\"; print(args...);&#125;int main()&#123; print(1,2,3,4); return 0;&#125; 参数包 Args ...在展开的过程中递归调用自己,没调用一次参数包中的参数就会少一个, 直到所有参数都展开为止。当没有参数时就会调用非模板函数 printf 终止递归过程。 右值引用 基于右值引用可以实现转移语义和完美转发新特性。 移动语义 对于一个包含指针成员变量的类, 由于编译器默认的拷贝构造函数都是浅拷贝, 所有我们一般需要通过实现深拷贝的拷贝构造函数, 为指针成员分配新的内存并进行内容拷贝, 从而避免悬挂指针的问题。 如下代码所示: 上述代码中，函数GetTemp()返回了一个类型为HasPtrMem的对象，此外，该类定义了深拷贝的拷贝构造函数，因此，main()函数，两次调用拷贝构造函数，第一次是调用GetTemp()函数返回时的临时变量，第二次是将函数返回值拷贝给变量a时。 而在上述过程中, 使用临时变量构造 a 时会调用拷贝构造函数分配对内存, 而临时对象在语句结束后会释放它所使用的堆内存。 这样重复申请和释放内存, 在申请内存较大时会严重影响性能。因此 C++使用移动构造函数,从而保证使用临时对象构造 a 时不分配内存,从而提高性能. 解决方案: 如下列代码所示, 移动构造函数接收一个右值引用作为参数, 使用右值引用的参数初始化其指针成员变量。 其原理就是使用在构造对象 a 时,使用 h.d 来初始化 a,然后将临时对象 h 的成员变量 d 指向 nullptr,从而保证临时变量析构时不会释放对内存。 完美转发 完美转发是指在函数模板中, 完全依照模板的参数的类型, 将参数传递给函数模板中调用的另一个函数, 即传入转发函数的是左值对象, 目标函数就能获得左值对象, 转发函数是右值对象, 目标函数就能获得右值对象,而不产生额外的开销。 因此转发函数和目标函数参数一般采用引用类型, 从而避免拷贝的开销。 其次, 由于目标函数可能需要能够既接受左值引用,又接受右值引用,所以考虑转发也需要兼容这两种类型。 C++11 采用引用折叠的规则,结合新的模板推导规则实现完美转发。其引用折叠规则如下: Lambda 表达式: Lambda 表达式定义一个匿名函数,并且可以捕获一定范围内的变量,其定义如下: [capture](params)mutable-&gt;return-type{statement} 其中, - [capture]:捕获列表,捕获上下文变量以供 lambda 使用。同时[]是 lambda 寅初复,编译器根据该符号来判断接下来代码是否是 lambda 函数。 - (Params):参数列表,与普通函数的参数列表一致,如果不需要传递参数,则可以连通括号一起省略。 - mutable 是修饰符, 默认情况下 lambda 函数总是一个 const 函数, Mutable 可以取消其常量性。在使用该修饰符时,参数列表不可省略。 - -&gt;return-type:返回类型是返回值类型 - {statement}:函数体, 内容与普通函数一样, 除了可以使用参数之外, 还可以使用所捕获的变量。 特点： Lambda 表达式与普通函数最大的区别就是其可以通过捕获列表访问一些上下文中的数据。 操作系统 进程与线程的概念,以及为什么要有进程线程,其中有什么区别? 基本概念 - 进程是对运行时程序的封装, 是系统进行资源调度和分配的的基本单位, 实现了操作系统的并发; - 线程是进程的子任务, 是CPU调度和分派的基本单位, 用于保证程序的实时性, 实现进程内部的并发; 每个线程都独自占用一个虚拟处理器: 独自的寄存器组, 指令计数器和处理器状态。 每个线程完成不同的任务, 但是共享同一地址空间(也就是同样的动态内存,映射文件,目标代码等等), 打开的文件队列和其他内核资源。 区别: 1. 一个线程只能属于一个进程, 而一个进程可以有多个线程, 但至少有一个线程。 线程依赖于进程而存在。 2. 进程在执行过程中拥有独立的内存单元, 而多个线程共享进程的内存。 3. 进程是资源分配的最小单位,线程是 CPU 调度的最小单位; 4. 系统开销: 由于在创建或撤消进程时,系统都要为之分配或回收资源,如内存空间、I/O设备等。因此,操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。进程切换的开销也远大于线程切换的开销。 5. 进程编程调试简单可靠性高,但是创建销毁开销大;线程正相反,开销小,切换速度快, 但是编程调试相对复杂 6. 进程间不会相互影响 ;线程一个线程挂掉将导致整个进程挂掉 进程间的通信方式 进程间通信主要包括管道、系统 IPC(包括消息队列、信号量、信号、共享内存等)、以及套接字 socket。 1.管道 管道主要包括无名管道和命名管道: 管道可用于具有亲缘关系的父子进程间的通信,有名管道除了具有管道所具有的功能外,它还允许无亲缘关系进程间的通信 1.1 普通管道 PIPE: 它是半双工的(即数据只能在一个方向上流动),具有固定的读端和写端 它只能用于具有亲缘关系的进程之间的通信(也是父子进程或者兄弟进程之间) 它可以看成是一种特殊的文件, 对于它的读写也可以使用普通的 read、 write 等函数。 但是它不是普通的文件,并不属于其他任何文件系统,并且只存在于内存中。 1.2 命名管道 FIFO: FIFO 可以在无关的进程之间交换数据 FIFO 有路径名与之相关联,它以一种特殊设备文件形式存在于文件系统中。 2.系统 IPC 2.1 消息队列: 消息队列,是消息的链接表,存放在内核中。 消息队列克服了信号传递信息少, 管道只能承载无格式字节流以及缓冲区大小受限等特点 一个消息队列由一个标识符(即队列 ID)来标记 具有写权限得进程可以按照一定得规则向消息队列中添加新信息; 对消息队列有读权限得进程则可以从消息队列中读取信息; 2.2 信号量 semaphore: 信号量(semaphore)是一个计数器,可以用来控制多个进程对共享资源的访问。 信号量用于实现进程间的互斥与同步, 而不是用于存储进程间通信数据。 信号量用于进程间同步,若要在进程间传递数据需要结合共享内存。 信号量基于操作系统的 PV 操作,程序对信号量的操作都是原子操作。 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1,而且可以加减任意正整数。 支持信号量组。 2.3 信号 signal 信号是一种比较复杂的通信方式,用于通知接收进程某个事件已经发生。 2.4 共享内存(Shared Memory): 它使得多个进程可以访问同一块内存空间, 不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作,如互斥锁和信号量等 共享内存是最快的一种 IPC,因为进程是直接对内存进行存取 因为多个进程可以同时操作,所以需要进行同步 信号量+共享内存通常结合在一起使用,信号量用来同步对共享内存的访问 3.套接字 SOCKET socket 也是一种进程间通信机制,与其他通信机制不同的是,它可用于不同主机之间的进程通信。 线程间通信的方式? 临界区:通过多线程的串行化来访问公共资源或一段代码,速度快,适合控制数据访问; 互斥量 Synchronized/Lock: 采用互斥对象机制, 只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个,所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare: 为控制具有有限数量的用户资源而设计的,它允许多个线程在同一时刻去访问同一个资源,但一般需要限制同一时刻访问此资源的最大线程数目。 事件(信号),Wait/Notify:通过通知操作的方式来保持多线程同步,还可以方便的实现多线程优先级的比较操作 Linux 虚拟地址空间 为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏, 采用了虚拟内存。 虚拟内存技术使得不同进程在运行过程中,它所看到的是自己独自占有了当前系统的 4G 内存。 所有进程共享同一物理内存, 每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上,在每个进程创建加载时,内核只是为进程“创建”了虚拟内存的布局,具体就是初始化进程控制表中内存相关的链表, 实际上并不立即就把虚拟内存对应位置的程序数据和代码(比如.text .data 段)拷贝到物理内存中,只是建立好虚拟内存和磁盘文件之间的映射就好(叫做存储器映射),等到运行到对应的程序时,才会通过缺页异常,来拷贝数据。 还有进程运行过程中,要动态分配内存,比如 malloc 时,也只是分配了虚拟内存,即为这块虚拟内存对应的页表项做相应设置,当进程真正访问到此数据时,才引发缺页异常。 请求分页系统、 请求分段系统和请求段页式系统都是针对虚拟内存的, 通过请求实现内存与外存的信息置换。 虚拟内存的好处: 1. 扩大地址空间; 2. 内存保护: 每个进程运行在各自的虚拟内存地址空间, 互相不能干扰对方。 虚存还对特定的内存地址提供写保护,可以防止代码或数据被恶意篡改。 3. 公平内存分配。采用了虚存之后,每个进程都相当于有同样大小的虚存空间。 4. 当进程通信时,可采用虚存共享的方式实现。 5. 当不同的进程使用同样的代码时, 比如库文件中的代码, 物理内存中可以只存储一份这样的代码,不同的进程只需要把自己的虚拟内存映射过去就可以了,节省内存 6. 虚拟内存很适合在多道程序设计系统中使用, 许多程序的片段同时保存在内存中。 当一个程序等待它的一部分读入内存时, 可以把 CPU 交给另一个进程使用。 在内存中可以保留多个进程, 系统并发度提高 7. 在程序需要分配连续的内存空间的时候, 只需要在虚拟内存空间分配连续空间, 而不需要实际物理内存的连续空间,可以利用碎片 虚拟内存的代价: 1. 虚存的管理需要建立很多数据结构,这些数据结构要占用额外的内存 2. 虚拟地址到物理地址的转换,增加了指令的执行时间。 3. 页面的换入换出需要磁盘 I/O,这是很耗时的 4. 如果一页中只有一部分数据,会浪费内存。 操作系统中的程序的内存结构? 数据段: 存放程序中已初始化的全局变量的一块内存区域。数据段也属于静态内存分配 bss段: (未进行初始化的数据)的内容并不存放在磁盘上的程序文件中。其原因是内核在程序开始运行前将它们设置为 0。需要存放在程序文件中的只有正文段和初始化数据段。 data段: (已经初始化的数据)则为数据分配空间,数据保存到目标文件中 代码段: 存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定, 并且内存区域属于只读。在代码段中,也有可能包含一些只读的常数变量 text 段和 data 段在编译时已经分配了空间,而 BSS 段并不占用可执行文件的大小,它是由链接器来获取内存的。 数据段包含经过初始化的全局变量以及它们的值。 BSS段的大小从可执行文件中得到,然后链接器得到这个大小的内存块, 紧跟在数据段的后面。 当这个内存进入程序的地址空间后全部清零。包含数据段和 BSS 段的整个区段此时通常称为数据区。 可执行程序在运行时又多出两个区域:栈区和堆区 栈区: 由编译器自动释放,存放函数的参数值、局部变量等。每当一个函数被调用时,该函数的返回类型和一些调用的信息被存放到栈中，然后这个被调用的函数再为他的自动变量和临时变量在栈上进行分配空间。每调用一个函数一个新的栈就会被使用。栈区是从高地址位向低地址位增长的,是一块连续的内存区域,最大容量是由系统预先定义好的,申请的栈空间超过这个界限时会提示溢出,用户能从栈中获取的空间较小。 堆区: 用于动态分配内存,位于BSS和栈中间的地址区域。由程序员申请分配和释放。堆是从低地址位向高地址位增长,采用链式存储结构。频繁的 malloc/free 造成内存空间的不连续, 产生碎片。 当申请堆空间时库函数是按照一定的算法搜索可用的足够大的空间。 因此堆的效率比栈要低的多。 操作系统中的缺页中断? malloc()和 mmap()等内存分配函数,在分配时只是建立了进程虚拟地址空间,并没有分配虚拟内存对应的物理内存。 当进程访问这些没有建立映射关系的虚拟内存时, 处理器自动触发一个缺页异常。 缺页中断: 在请求分页系统中, 可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。 每当所要访问的页面不在内存是, 会产生一次缺页中断, 此时操作系统会根据页表中的外存地址在外存中找到所缺的一页,将其调入内存。 缺页中断是由于所要访问的页面不存在于内存时, 由硬件所产生的一种特殊的中断, 因此,与一般的中断存在区别: 缺页中断返回是,执行产生中断的一条指令,而一般的中断返回是,执行下一条指令 操作系统中的页表寻址? 页式内存管理, 内存分成固定长度的一个个页片。 操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构, 叫页表, 页表的内容就是该进程的虚拟地址到物理地址的一个映射。 页表中的每一项都记录了这个页的基地址。 通过页表, 由逻辑地址的高位部分先找到逻辑地址对应的页基地址, 再由页基地址偏移一定长度就得到最后的物理地址, 偏移的长度由逻辑地址的低位部分决定。一般情况下,这个过程都可以由硬件完成,所以效率还是比较高的。 页式内存管理的优点就是比较灵活, 内存管理以较小的页为单位, 方便内存换入换出和扩充地址空间。 并发(concurrency)和并行(parallelism) 并发(concurrency): 指宏观上看起来两个程序在同时运行,比如说在单核 cpu 上的多任务。 但是从微观上看两个程序的指令是交织着运行的, 你的指令之间穿插着我的指令, 我的指令之间穿插着你的, 在单个周期内只运行了一个指令。 这种并发并不能提高计算机的性能, 只能提高效率。 并行(parallelism): 指严格物理意义上的同时运行,比如多核 cpu,两个程序分别运行在两个核上, 两者之间互不影响, 单个周期内每个程序都运行了自己的指令, 也就是运行了两条指令。这样说来并行的确提高了计算机的效率。 各数据库的默认端口 查看端口号: 使用命令 show global variables like 'port' - mysql 的默认端口是 3306 - sqlserver 默认端口号为: 1433 - oracle 默认端口号为: 1521 - DB2 默认端口号为: 5000 - PostgreSQL 默认端口号为:5432","categories":[],"tags":[]},{"title":"第二章_点云地图构建及基于地图的定位","slug":"多传感器融合定位/第二章-点云地图构建及基于地图的定位","date":"2020-10-17T07:12:42.000Z","updated":"2020-10-25T08:51:59.000Z","comments":true,"path":"2020/10/17/多传感器融合定位/第二章-点云地图构建及基于地图的定位/","link":"","permalink":"http://yoursite.com/2020/10/17/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%82%B9%E4%BA%91%E5%9C%B0%E5%9B%BE%E6%9E%84%E5%BB%BA%E5%8F%8A%E5%9F%BA%E4%BA%8E%E5%9C%B0%E5%9B%BE%E7%9A%84%E5%AE%9A%E4%BD%8D/","excerpt":"","text":"回环检测 基于Scan-Context 基于特征直方图 后端优化 基础知识 这里说的是： 假定对某个旋转\\(R\\)，对应李代数为\\(\\phi\\)。我们给它左乘一个微小旋转，记做\\(\\Delta R\\)，对应的李代数为\\(\\Delta \\phi\\)，那么，在李群上，得到的结果是\\(\\Delta R\\cdot R\\)，而在李代数上，根据BCH近似公式，即相加后对应的李代数为\\(J_r{-1}(\\phi)\\Delta \\phi+\\phi\\) \\[ \\exp(\\Delta \\phi^{\\wedge})\\exp(\\phi^{\\wedge})=\\exp((J_r^{-1}(\\phi)\\Delta\\phi+\\phi)^\\wedge) \\] 伴随矩阵通常用于变量顺序转换，用于公式化简 基于回环的修正 下面进行公式推导： 假设如下： 第i帧位姿估计\\(T_i\\) 第j帧位姿估计\\(T_j\\) 某个绝对观测：第j帧到第i帧的变换\\(T_{mij}^{-1}=T_{mji}=T_{mi}^{-1}T_{mj}\\) 现在需要构建残差: 假设位姿采用6维se3描述 第i帧位姿估计\\(T_i=\\exp(\\xi_{i}^{\\wedge}) ===&gt; \\xi_i=\\ln(\\exp(\\xi_i^{\\wedge}))^{\\vee}\\) 第j帧位姿估计\\(T_j=\\exp(\\xi_{j}^{\\wedge}) ===&gt; \\xi_j=\\ln(\\exp(\\xi_j^{\\wedge}))^{\\vee}\\) 即 残差=观测-估计 \\[ \\begin{aligned} e_{ij}&amp;=\\xi_{mea}-\\xi_{ji} \\\\ e_{ij}&amp;=ln(T_{mij}^{-1}T_i^{-1}T_j)^{\\vee} \\end{aligned} \\] 问题来了，优化通常采用迭代法，如高斯牛顿，LM等，均需要求解雅克比矩阵，而李代数求解导需要借助“扰动” 如采用左乘雅克比 \\[ \\begin{aligned} \\widehat{e_{ij}}&amp;=\\ln(T_{mij}^{-1} \\left \\{ \\exp((\\delta\\xi_i)^{\\wedge})T_i \\right \\}^{-1} \\left \\{ \\exp((\\delta\\xi_j)^{\\wedge})T_j \\right \\} )^{\\vee} \\\\ &amp;=\\ln(T_{mij}^{-1} \\left \\{ T_i^{-1}\\exp((-\\delta\\xi_i)^{\\wedge}) \\exp((\\delta\\xi_j)^{\\wedge})T_j \\right \\} )^{\\vee} \\\\ \\end{aligned} \\] 下面的化简用到了上面ppt的近似公式、伴随性质 上述内容跟《视觉SLAM14讲》的位姿图优化是一致的。 基于先验的修正 建图 激光点云畸变 定位 基于地图定位 作业","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"Scan-Context论文阅读","slug":"文献阅读/Scan-Context 论文阅读","date":"2020-10-07T11:48:19.000Z","updated":"2020-10-08T11:39:32.000Z","comments":true,"path":"2020/10/07/文献阅读/Scan-Context 论文阅读/","link":"","permalink":"http://yoursite.com/2020/10/07/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/Scan-Context%20%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Scan Context: Egocentric Spatial Descriptor for Place Recognition within 3D Point Cloud Map 摘要 相比于视觉场景下使用特征描述符，使用结构信息来描述场景的研究相对较少。文章提出了Scan-Context，一种非直方图方法的全局描述符，用于全局定位。该方法直接记录了可见空间的3d结构，而不是依赖于直方图或先验的训练。此外，该方法还可用于计算两帧扫描的上下文之间的距离进行回环检测，其特点在于不受Lidar视点变化的影响，因此可以在反向访问或拐角等位置进行回环检测。 介绍 目前有在Lidar-based的场景识别方法中仍有两个issue尚待解决： 无论视点如何变化，描述符需要有旋转不变性 噪声处理，因为点云的分辨率随距离变化，而且法线受噪声影响 文章贡献： 高效的bin编码函数。与现有的点云描述符[7，10]不同，所提出的方法不需要计算容器中的点数，而是提出了一种更有效的容器编码功能来进行位置识别，此编码对点云密度和法线具有不变性 保存点云内部结构。如图1所示，矩阵的每个元素值仅由属于bin的点云确定，因此，与[9]不同，后者[9]将点的相对几何形状描述为直方图，并且会丢失点的绝对位置信息。我们的方法有意避免使用直方图来保留点云的绝对内部结构。这有利于提高判别能力，当距离得到后，还允许使得查询扫描帧与候选扫描视点对齐（实验中使用6\\(\\degree\\)分辨率），因此本方法可用于检测反向的loop 高效的二阶段匹配算法。为了获得可行的搜索时间，我们为第一个最近邻搜索提供了一个旋转不变子描述符，并将其与成对相似性评分进行分层组合 Scan Context 对于室外环境，提出的描述符为“Scan Context”，主要受 “Shape Context [7]”（把某个keypoint附近的点云几何形状编码到图像中）启发。 他们的方法只是统计点的数量以得到点的分布，Scan Context方法与他们的不同之处在于，在每个bin中使用最大点的高度。使用高度的原因是可以有效地汇总周围结构的垂直形状，而无需进行大量计算即可分析点云的特征，此外，最大高度表示传感器可以看到周围结构的哪一部分。 类似与Shape Context，我们首先将3D扫描在传感器坐标系中按方位角和径向角划分，但以等距的方式如图1（a）所示。 扫描的中心（Lidar）充当全局关键点，因此我们将扫描上下文称为以自我为中心的位置描述符，以下是符号描述： \\(N_s\\) 扇形的数量（图a蓝色块数量） \\(N_r\\) 环的数量 （图a红色块数量） \\(\\frac{L_{max}}{N_r}\\) 放射间隔，其中\\(L_{max}\\)表示激光最远距离 \\(\\frac{2\\pi}{N_s}\\) 扇形中心角 文章采用: \\(N_s=60,N_r=20\\) 因此，进行扫描上下文的第一步是将3D扫描的整个点划分为相互排斥的点云，如图1（a）所示。 其中，\\(\\mathcal{P}_{ij}\\)表示第i个环(跟距离有关)第j个扇形(跟角度有关)中的点集。 由于点云是按固定间隔划分的，因此，距离传感器较远的bin的物理面积要大于附近的bin，但是，两者均被平等地编码为扫描上下文的单个像素。因此，扫描上下文补偿了由远点稀疏性引起的信息量不足，并将附近的动态对象视为稀疏噪声。 点云分区后，通过使用每个bin中的点云为每个bin分配单个实数值: 我们使用最大高度: 其中，z函数返回点p的高度值，对于空的bin，直接赋值为0。 例如，如图1（b）所示，扫描上下文中的蓝色像素表示对应于其bin的空间是空闲的，或者由于遮挡而未观察到 从上述过程中，扫描上下文I最终表示为Nr×Ns的矩阵为: 为了对平移实现鲁棒，我们通过root移位来进行扫描上下文增强，通过这样做，在轻微的运动扰动下从原始扫描获取各种扫描上下文变得可行。因为再次访问的时候，单个扫描上下文可能对平移运动的扫描的中心位置敏感。 为了克服这种情况，我们根据车道级别间隔将原始点云转换为\\(N_{trans}\\)邻居（本文中使用\\(N_{trans} = 8\\)），并将从这些偏移点云获得的扫描上下文存储在一起。 计算Scan Contexts的相似得分 给定一对“Scan Contexts” pair，我们需要一个距离来衡量两个地方的相似度，其中\\(I^q,I^c\\)分别是查询点云和候选点云的上下文。以列为主进行比较：即距离是相同索引处的列进行比较得到的差距。余弦距离用于计算同一索引处两个列向量之间的距离，\\(c_{j}^q,c_{j}^c\\)。 因此，距离函数为: 按列比较对于动态对象特别有效，但是，由于Lidar的视点在不同位置会发生变化，","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"第一章_3D激光里程计","slug":"多传感器融合定位/第一章_3D激光里程计","date":"2020-10-07T11:48:19.000Z","updated":"2020-10-25T08:51:25.000Z","comments":true,"path":"2020/10/07/多传感器融合定位/第一章_3D激光里程计/","link":"","permalink":"http://yoursite.com/2020/10/07/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/%E7%AC%AC%E4%B8%80%E7%AB%A0_3D%E6%BF%80%E5%85%89%E9%87%8C%E7%A8%8B%E8%AE%A1/","excerpt":"","text":"第1节 renqian：前端不要求精度，而对于平滑性要求较高 激光雷达介绍 前端里程计汇总 ICP理论 去质心(\\(u_x,u_y\\))目的：把旋转和平移进行解耦，然后先求解旋转R，再求解平移t 因为\\(x_i&#39;^T R y_i&#39;\\)是一个数，常量，因此，Trace就是它本身 最终求解 ICP汇总 NDT理论 NDT汇总 LOAM系列理论 renqian: 如果按这种思路进行分割，有可能会飞线（16线还好，32、64可能会出现这种问题），最好是激光雷达驱动把每个点对应的线束ID保留下来 scan-to-map: 因为合并地图的时候，把特征点都划分到对应的网格了，优化的时候直接从grid中索引特征，而不是从‘上一帧’点云中索引。 LOAM汇总 ALOAM使用四元数 自动求导：效率较低 FLOAM使用李代数 lego-loam： - 计算点到面的距离的时候，只计算地面特征，而计算点到线距离的时候，不再从地面提取特征 - 对环境中的点做了聚类，去除树冠等影响 - 分两次优化，但代码又回到了6自由度优化 LOAM部分代码 线数分割 计算曲率（粗糙度） 特征点提取 点分成了四类： 曲率特别大的点(从中挑选点) 曲率一般大的点(从中获取边缘线) 曲率特别小的点(从中挑选点) 曲率一般小的点(从中获取平面) Trick：把360度分成6等份，即每60度分别提取，这是为了避免某些特征点聚集在某个角度上，引起后面求解的病态矩阵 计算特征距离(残差) 第k+1帧来了，按照估计的位姿，将k+1帧投影回第k帧，使用最近邻算法，找到投影点最近的一个点，然后再找一个其他线束的最近点，找到两个点可形成直线。 求点到线的距离 还需要求梯度 检验拟合的直线、平面是否正确： 找5个最近邻点 对5个点的方差，求特征值分解 1.线：最大特征值特别大 2.面：前两个特征值特别大 KITTI数据集 evo使用","categories":[{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"}],"tags":[]},{"title":"两轮差速底盘的三种航迹推算模型","slug":"两轮差速底盘的三种航迹推算模型","date":"2020-09-10T11:48:19.000Z","updated":"2020-09-10T13:39:54.000Z","comments":true,"path":"2020/09/10/两轮差速底盘的三种航迹推算模型/","link":"","permalink":"http://yoursite.com/2020/09/10/%E4%B8%A4%E8%BD%AE%E5%B7%AE%E9%80%9F%E5%BA%95%E7%9B%98%E7%9A%84%E4%B8%89%E7%A7%8D%E8%88%AA%E8%BF%B9%E6%8E%A8%E7%AE%97%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"两轮差速底盘的三种航迹推算模型 差速底盘分析 航迹推算 机器人坐标系为 x轴为前进方向，z轴朝上的右手坐标系 (1)直线假设 切线模型最为简单，是ROS中采用的运动模型。它假设机器人在原来的方向上，沿着直线运动，再转角度 假设 机器人沿着当前方向前进 到达后，再执行旋转操作 因此，有: \\[ \\begin{cases}x_{t+\\Delta t}=x_{t}+\\Delta x\\cdot \\cos \\varphi _{t}\\\\ y_{t+\\Delta t}=y_{t}+\\Delta x\\cdot \\sin \\varphi _{t}\\\\ \\varphi _{t+\\Delta t}=\\varphi _{t}+\\Delta \\varphi \\end{cases} \\] (2)割线模型 如图所示的直角坐标系，机器人从\\(A(x,y,\\theta)\\)出发，经过\\(\\Delta t\\)到达\\(A&#39;(x&#39;,y&#39;,\\theta&#39;)\\)，其中，x和y分别为世界坐标系的坐标，\\(\\theta\\)是机器人坐标系x轴与世界坐标系横轴的夹角，逆时针为正。 设: \\((\\Delta x,\\Delta y,\\Delta \\phi)\\)是相对于世界坐标系的增量 \\(\\Delta S\\)表示A点到A'点的弧长 因此，\\(\\Delta x,\\Delta y\\)推导如下: 其中，\\(AA&#39;\\)表示A点到A'点的直线距离 并且， \\[ \\sin(\\frac{\\Delta \\theta}{2})/\\frac{\\Delta \\theta}{2} \\approx 0 \\] 因此，有: 这个模型的关键在于，假设时间间隔\\(\\Delta t\\)很短，那么\\(AA&#39;\\)近似等于\\(\\Delta S\\)，即用圆的割线长度来近似圆弧长度，最终，有： \\[ \\begin{aligned} x&#39; &amp;=x+\\Delta x = x+ AA&#39; \\cos(\\theta + \\frac{\\Delta \\theta}{2}) \\\\ &amp;=x+\\Delta S \\cos(\\theta + \\frac{\\Delta \\theta}{2}) \\end{aligned} \\] \\[ \\begin{aligned} y&#39; &amp;=y+\\Delta y = y+ AA&#39; \\sin(\\theta + \\frac{\\Delta \\theta}{2}) \\\\ &amp;=y+\\Delta S \\sin(\\theta + \\frac{\\Delta \\theta}{2}) \\end{aligned} \\] 割线模型的直观解释 可以理解为：假设机器人先转一半角度\\(\\frac{1}{2}\\Delta \\phi\\)，然后沿着此方向运动，最后再转剩下的一半角度。 (3)圆弧模型 假设走的是真真的弧线，具体表达式是通过积分得到的，如下: \\[ \\begin{aligned} \\Delta x &amp;= v_{t} \\int_{t}^{t+\\Delta t} \\cos[\\theta_{t}+(T-t)\\omega]dT \\\\ &amp;=\\frac{v_t}{\\omega}[\\sin(\\theta_t+\\Delta \\theta)-\\sin \\theta_t] \\\\ &amp;=\\frac{\\Delta S}{\\Delta \\theta}[\\sin(\\theta_t+\\Delta \\theta)-\\sin \\theta_t] \\end{aligned} \\] \\[ \\begin{aligned} \\Delta y &amp;= v_{t} \\int_{t}^{t+\\Delta t} \\sin[\\theta_{t}+(T-t)\\omega]dT \\\\ &amp;=\\frac{v_t}{\\omega}[-\\cos(\\theta_t+\\Delta \\theta)+\\cos \\theta_t] \\\\ &amp;=\\frac{\\Delta S}{\\Delta \\theta}[-\\cos(\\theta_t+\\Delta \\theta)+\\cos \\theta_t] \\end{aligned} \\] \\[ \\begin{cases} x_{t+\\Delta t}=x_t+\\Delta x \\\\ y_{t+\\Delta t}=y_t+\\Delta y \\\\ \\theta_{t+\\Delta t}=\\theta+\\Delta \\theta \\end{cases} \\] 全向轮底盘的航迹推算模型 可以走任意方向，因此：","categories":[],"tags":[]},{"title":"SLAM基础知识点","slug":"SLAM基础知识点","date":"2020-09-06T03:48:19.000Z","updated":"2020-09-07T14:51:33.000Z","comments":true,"path":"2020/09/06/SLAM基础知识点/","link":"","permalink":"http://yoursite.com/2020/09/06/SLAM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"SLAM基础知识点 SIFT和SUFT的区别 构建图像金字塔： SIFT特征利用不同尺寸的图像与高斯差分滤波器卷积；SURF特征利用原图片与不同尺寸的方框滤波器卷积 特征描述子：SIFT特征有4×4×8=128维描述子，SURF特征有4×4×4=64维描述子 特征点检测方法：SIFT特征先进行非极大抑制，再去除低对比度的点，再通过Hessian矩阵去除边缘响应过大的点；SURF特征先利用Hessian矩阵确定候选点，然后进行非极大抑制 特征点主方向： SIFT特征在正方形区域内统计梯度幅值的直方图，直方图最大值对应主方向，可以有多个主方向；SURF特征在圆形区域内计算各个扇形范围内x、y方向的haar小波响应，模最大的扇形方向作为主方向 相似变换、仿射变换、射影变换的区别 等距变换：相当于是平移变换（t）和旋转变换（R）的复合，等距变换前后长度，面积，线线之间的角度都不变。自由度为6（3+3） 相似变换：等距变换和均匀缩放（S）的一个复合，类似相似三角形，体积比不变。自由度为7（6+1） 仿射变换：一个平移变换（t）和一个非均匀变换（A）的复合，A是可逆矩阵，并不要求是正交矩阵，仿射变换的不变量是:平行线，平行线的长度的比例，面积的比例。自由度为12（9+3） 射影变换：当图像中的点的齐次坐标的一般非奇异线性变换，射影变换就是把理想点（平行直线在无穷远处相交）变换到图像上，射影变换的不变量是:重合关系、长度的交比。自由度为15（16-1） 参考：多视图几何总结——等距变换、相似变换、仿射变换和射影变换 Homography、Essential和Fundamental Matrix的区别 Homography Matrix可以将一个二维射影空间的点变换该另一个二维射影空间的点，如下图所示，在不加任何限制的情况下，仅仅考虑二维射影空间中的变换，一个单应矩阵H HH可由9个参数确定，减去scale的一个自由度，自由度为8。 Fundamental Matrix对两幅图像中任何一对对应点x和x′基础矩阵F都满足条件： ，秩只有2，因此F的自由度为7。它自由度比本质矩阵多的原因是多了两个内参矩阵。 Essential matrix：本质矩是归一化图像坐标下的基本矩阵的特殊形式，其参数由运动的位姿决定，与相机内参无关，其自由度为6，考虑scale的话自由度为5。 视差与深度的关系 在相机完成校正后，则有 \\(\\frac{d}{b}=\\frac{f}{z}\\) ,其中d表示视差，b表示基线，f是焦距，z是深度。这个公式其实很好记，在深度和焦距确定的情况下，基线越大，视差也会越大。 描述PnP算法 已知空间点世界坐标系坐标和其像素投影，公式如下: 目前一共有两种解法，直接线性变换方法（一对点能够构造两个线性约束，因此12个自由度一共需要6对匹配点），另外一种就是非线性优化的方法，假设空间坐标点准确，根据最小重投影误差优化相机位姿。 目前有两个主要场景场景， 其一是求解相机相对于某2维图像/3维物体的位姿； 其二就是SLAM算法中估计相机位姿时通常需要PnP给出相机初始位姿。 在场景1中，我们通常输入的是物体在世界坐标系下的3D点以及这些3D点在图像上投影的2D点，因此求得的是相机坐标系相对于世界坐标系(Twc)的位姿 在场景2中，通常输入的是上一帧中的3D点（在上一帧的相机坐标系下表示的点）和这些3D点在当前帧中的投影得到的2D点，所以它求得的是当前帧相对于上一帧的位姿变换 闭环检测常用方法 ORB-SLAM中采用的是词袋模型进行闭环检测筛选出候选帧，再通过求解Sim3来解决尺度漂移问题，最后再判断最合适的关键帧 LSD-SLAM中的闭环检测主要是根据视差、关键帧连接关系，找出候选帧，然后对每个候选帧和测试的关键帧之间进行双向Sim3跟踪，如果求解出的两个李代数满足马氏距离在一定范围内，则认为是闭环成功 给一个二值图，求最大连通域 二值图的连通域应该是用基于图论的深度优先或者广度优先的方法，后来还接触过基于图的分割方法，采用的是并查集的数据结构，之后再作细致对比研究 梯度下降法、牛顿法、高斯-牛顿法的区别 考虑一个简单的最小二乘问题： \\[ argmin \\frac{1}{2} ||f(x)||_2^2 \\] 如果函数f(x)很简单，那么或许这个问题可以使用解析解，令目标函数的导数为0，求解对应的x值即可，即 \\[ \\frac{d(\\frac{1}{2}||f(x)||_2^2)}{dx}=0 \\] 但是在BA优化、PnP、直接法里面，这些维度通常很大，是非线性优化问题，上面几种方法都是针对对非线性优化问题提出的方法。 对目标函数在x附近进行泰勒展开，得到： 我们可以选择保留泰勒展开的一阶项或者二阶项，分别对应一阶梯度法和二阶梯度法(牛顿法) 梯度下降法是一个一阶最优化算法，通常也称为最速下降法。 要使用梯度下降法找到一个函数的局部极小值，必须向函数上当前点对应梯度（或者是近似梯度）的反方向的规定步长距离点进行迭代搜索。因此指保留一阶梯度信息。缺点是过于贪心，容易走出锯齿路线。 保留泰勒展开的一阶项，然后求导等于0，即可求的梯度方向: 牛顿法是一个二阶最优化算法，基本思想是利用迭代点处的一阶导数(梯度)和二阶导数(Hessen矩阵)对目标函数进行二次函数近似。因此保留二阶梯度信息。缺点是需要计算H矩阵，计算量太大。 其常见的表达如下(二者等价，在解附近是二阶收敛的): \\[ \\Delta x = - \\frac{f(x0)}{f(x0)&#39;} \\] 而把非线性问题，先进行一阶展开，然后再作平方处理就可以得到高斯-牛顿法和列文博格方法： 高斯-牛顿法对上式展开并对Δx进行求导即可得高斯牛顿方程，其实其就是使用\\(JJ^T\\)来近似牛顿法的H矩阵，但是\\(JJ^T\\)有可能为奇异矩阵或变态，Δx也会造成结果不稳定，因此稳定性差。 列文博格法就是在高斯-牛顿法的基础上对Δx添加一个信赖区域，保证其只在展开点附近有效，即其优化问题变为带有不等式约束的优化问题，利用Lagrange乘子求解 推导一下卡尔曼滤波、描述下粒子滤波 卡尔曼滤波： 卡尔曼滤波就是通过运动方程获得均值和方差的预测值，然后结合观测方程和预测的方差求得卡尔曼增益，然后在用卡尔曼增益更行均值和方差的预测值而获得估计值。 卡尔曼滤波推导的思路是（其中一种）先假定有这么一个修正公式 根据真实值和估计值之间的协方差矩阵，然后通过对对角线元素求和获得方差表达式，我们的修正公式是需要使得方差最小，因此把方差表达式对\\(K_k\\)求导就可以获得卡尔曼增益的表达式，然后从先验到预测值的方差公式可以通过求预测值和真实值的协方差矩阵获得。 粒子滤波 粒子滤波最常用的是SIR(重要性重采样(Sampling Importance Resampling))，其算法是用运动方程获得粒子的状态采样，然后用观测方程进行权值更新，通过新的粒子加权平均就获得新的估计状态，最后非常重要的一步就是重采样。 粒子滤波的推导中概念有很多，最重要的推导过程是重要性采样过程，其思路就是我原本的采样分布是不知道的，我如何从一个已知的分布中采样，通过加权的方式使得从已知的分布中采样的粒子分布和原本未知的分布中采样的粒子分布结果一致，从而引入SIS粒子滤波，再进一步加入重采样后就引入了SIR粒子滤波。 如何求解Ax=b的问题 ... 什么是极线约束 所谓极线约束就是说同一个点在两幅图像上的映射，已知左图映射点p1，那么右图映射点p2一定在相对于p1的极线上，这样可以减少待匹配的点数量。如下图 单目视觉SLAM中尺寸漂移是怎么产生的 用单目估计出来的位移，与真实世界相差一个比例，叫做尺度。这个比例在单目初始化时通过三角化确定，但单纯靠视觉无法确定这个比例到底有多大。由于SLAM过程中噪声的影响，这个比例还不是固定不变的。修正方式是通过回环检测计算Sim3进行修正。 解释SLAM中的绑架问题 绑架问题就是重定位，是指机器人在缺少之前位置信息的情况下，如何去确定当前位姿。例如当机器人被安置在一个已经构建好地图的环境中，但是并不知道它在地图中的相对位置，或者在移动过程中，由于传感器的暂时性功能故障或相机的快速移动，都导致机器人先前的位置信息的丢失，在这种情况下如何重新确定自己的位置。 初始化绑架可以阐述为一种通常状况初始化问题，可使用蒙特卡洛估计器，即粒子滤波方法，重新分散粒子到三维位形空间里面，被里程信息和随机扰动不断更新，初始化粒子聚集到/收敛到可解释观察结果的区域。追踪丢失状态绑架，即在绑架发生之前，系统已经保存当前状态，则可以使用除视觉传感器之外的其他的传感器作为候补测量设备。 描述特征点法和直接法的优缺点 特征点法: 优点： 没有直接法的强假设，更加精确； 相较与直接法，可以在更快的运动下工作，鲁棒性好 缺点： 特征提取和特征匹配过程耗时长； 特征点少的场景中无法使用； 只能构建稀疏地图 直接法： 优点： 省去了特征提取和特征匹配的时间，速度较快； 可以用在特征缺失的场合； 可以构建半稠密/稠密地图 缺点： 易受光照和模糊影响； 运动必须慢； 非凸性，易陷入局部极小解 EKF和BA的区别 EKF假设了马尔科夫性，认为k时刻的状态只与k-1时刻有关。BA使用所有的历史数据，做全体的SLAM EKF做了线性化处理，在工作点处用一阶泰勒展开式近似整个函数，但在工作点较远处不一定成立。BA每迭代一次，状态估计发生改变，我们会重新对新的估计点做泰勒展开，可以把EKF看做只有一次迭代的BA 边缘检测算子有哪些？ 边缘检测一般分为三步，分别是滤波、增强、检测。基本原理都是用高斯滤波器进行去噪，之后在用卷积内核寻找像素梯度。常用有三种算法：canny算子，sobel算子，laplacian算子 canny算子：一种完善的边缘检测算法，抗噪能力强，用高斯滤波平滑图像，用一阶偏导的有限差分计算梯度的幅值和方向，对梯度幅值进行非极大值抑制，采用双阈值检测和连接边缘。 sobel算子：一阶导数算子，引入局部平均运算，对噪声具有平滑作用，抗噪声能力强，计算量较大，但定位精度不高，得到的边缘比较粗，适用于精度要求不高的场合。 laplacian算子：二阶微分算子，具有旋转不变性，容易受噪声影响，不能检测边缘的方向，一般不直接用于检测边缘，而是判断明暗变化。 简单实现cv::Mat() 10个相机同时看到100个路标点，问BA优化的雅克比矩阵多少维 因为误差对相机姿态的偏导数的维度是2×6,对路标点的偏导数是2×3，又10个相机可以同时看到100个路标点，所以一共有10×100×2行，100×3+10×6个块。 介绍经典的视觉SLAM框架 g2o: 它表示了g2o中的类结构。 我们最终使用的optimizer是一个SparseOptimizer对象，因此我们要维护的就是它(对它进行各种操作)。 一个SparseOptimizer是一个可优化图(OptimizableGraph)，也是一个超图(HyperGraph)。而图中有很多顶点(Vertex)和边(Edge)。顶点继承于BaseVertex，边继承于BaseUnaryEdge(一元边)、BaseBinaryEdge(二元边)或BaseMultiEdge。它们都是抽象的基类，实际有用的顶点和边都是它们的派生类。我们用SparseOptimizer.addVertex和SparseOptimizer.addEdge向一个图中添加顶点和边，最后调用SparseOptimizer.optimize完成优化。 在优化之前还需要制定求解器和迭代算法。一个SparseOptimizer拥有一个OptimizationAlgorithm，它继承自Gauss-Newton, Levernberg-Marquardt, Powell’s dogleg三者之一。同时，这个OptimizationAlgorithm拥有一个Solver，它含有两个部分: 一个是 SparseBlockMatrix，用于计算稀疏的雅可比和海塞矩阵； 一个是线性方程求解器，可从PCG、CSparse、Choldmod三选一，用于求解迭代过程中最关键的一步： 因此理清了g2o的结构，也就知道了其使用流程: （1）选择一个线性方程求解器，PCG、CSparse、Choldmod三选一，来自g2o/solvers文件夹 （2）选择一个BlockSolver，用于求解雅克比和海塞矩阵，来自g2o/core文件夹 （3）选择一个迭代算法，GN、LM、DogLeg三选一，来自g2o/core文件夹 注意到上面的结构图中，节点Basevertex&lt;D,T&gt;，BaseBinaryEdge&lt;D,E,VertexXi,VertexXj&gt;和BlockSolver&lt;&gt;等都是模板类，我们可以根据自己的需要初始化不同类型的节点和边以及求解器，以ORB-SLAM2为例，分析下后端最典型的全局BA所用的边、节点和求解器： （1）边是EdgeSE3ProjectXYZ，它其实就是继承自BaseBinaryEdge&lt;2, Vector2d, VertexSBAPointXYZ, VertexSE3Expmap&gt;，其模板类型里第一个参数是观测值维度，这里的观测值是其实就是我们的像素误差u,v u,vu,v，第二个参数就是我们观测值的类型，第三个第四个就是我们边两头节点的类型； （2）相机节点VertexSE3Expmap，它其实就是继承自BaseVertex&lt;6, SE3Quat&gt;，其模板类第一个参数就是其维度，SE3是六维的这没毛病，第二个就是节点的类型，SE3Quat就是g2o自定义的SE3的类，类里面写了各种SE3的计算法则； （3）空间点节点VertexSBAPointXYZ，它其实就是继承自BaseVertex&lt;3, Vector3d&gt;，其模板类第一个参数是说明咱空间点的维度是三维，第二个参数说明这个点的类型是Vector3d； （4）求解器是BlockSolver_6_3，它其实就是BlockSolver&lt; BlockSolverTraits&lt;6, 3&gt; &gt;，6,3分别指代的就是边两边的维度了。 室内SLAM与自动驾驶SLAM有什么区别？ 什么是紧耦合、松耦合？优缺点。 紧耦合是把图像的特征加到特征向量中去，这样做优点是可以免去中间状态的累计误差，提高精度，缺点是系统状态向量的维数会非常高，需要很高的计算量； 松耦合是把VO处理后获得的变换矩阵和IMU进行融合，这样做优点是计算量小但是会带来累计误差。 下面是对经典的VIO框架进行一个分类: 地图点的构建方法有哪些 （1）三角化: 在ORB SLAM2中是根据三角化的方法确定地图点的，利用匹配好的两个点构建AX=b的方程，然后利用SVD分解取最小奇异值对应的特征向量作为地图点坐标，参考多视图几何总结——三角形法 （2）深度滤波器: 在SVO中是利用深度滤波器进行种子点深度更新，当种子点深度收敛后就加入地图构建地图点。 （在LSD中好像没有维护地图点，不断维护的是关键帧上的深度图） 如果对于一个3D点，我们在连续帧之间形成了2D特征点之间的匹配，但是这个匹配中可能存在错误的匹配。请问你如何去构建3D点？ 先想到的是用RANSAC方法进行连续帧之间的位姿估计，然后用内点三角化恢复地图点，具体一点说使用RANSAC估计基础矩阵F的算法步骤如下： （1）从匹配的点对中选择8个点，使用8点法估算出基础矩阵F （2）计算其余的点对到其对应对极线的距离，如果距离\\(d_n \\leq d\\)，则该点为内点，否则为外点。记下符合该条件的内点的个数为\\(m_i\\) （3）迭代k次，或者某次得到内点的数目占有的比例大于等于95%，则停止。选择最大的基础矩阵F作为最终的结果. 如果是利用非线性优化的方法获得位姿的话，可以在非线性优化代价函数中加入鲁棒核函数来减少无匹配所带来的误差，例如《视觉SLAM十四讲》里面提到的Huber核: 在《机器人的状态估计》一书总将这种方法称为M估计，核函数还包裹Cauchy核: Geman-MeClure核 等。 RANSAC在选择最佳模型的时候用的判断准则是什么? 简单地说一般是选用具有最小残差和的模型作为最佳模型。","categories":[],"tags":[]},{"title":"LIO-SAM论文阅读","slug":"文献阅读/LIO-SAM论文阅读","date":"2020-07-07T03:48:19.000Z","updated":"2020-07-07T08:18:05.000Z","comments":true,"path":"2020/07/07/文献阅读/LIO-SAM论文阅读/","link":"","permalink":"http://yoursite.com/2020/07/07/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/LIO-SAM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping 摘要 提出了基于因子图的紧耦合的Lidar-IMU系统，允许大量的相对或绝对的观测（来自不同传感器的观测如回环检测、GPS等）作为因子添加到系统中。 为了确保实时性能，对位姿优化采用边缘化旧的激光雷达扫描操作，而不是使用激光扫描来匹配全局点云地图。 使用小范围的局部Scan-Matching来代替全局的Scan-Matching明显提高实时性能，其他还有关键帧的选取、滑动窗口方法（将新的关键帧与固定size的先验子关键帧之间进行配准） 对比介绍 LOAM虽然达到了state-of-art的性能，但是也有一些缺点，通过储存数据到全局体素地图中，通常难以进行回环检测以及和其他绝对的观测进行耦合。 Despite its success, LOAM presents some limitations - by saving its data in a global voxel map, it is often difficult to perform loop closure detection and incorporate other absolute measurements, e.g., GPS, for pose correction. 此外，在特征丰富的环境中，体素地图变得稠密，使其在线优化处理过程效率变得less efficient，LOAM对于大环境下，也会产生漂移，毕竟仅仅是scan-matching的方法为核心。 后面主要对LOAM和LIOM进行了简要的对比，可参见原文。。。 LIO-SAM系统 系统概述 \\(W\\)：世界坐标系 \\(B\\)：机器人坐标系 假设：IMU坐标系与机器人坐标系一致 \\(x=[R^T,p^T,v^T,b^T]^T\\) \\(R \\in SO(3)\\)：从机器人坐标系到世界坐标系的旋转变换 \\(p\\)：平移量 \\(T=[R|p]\\in SO(3)\\)：从机器人坐标系到世界坐标系的变换 系统使用因子图来对SLAM问题进行建模，在高斯噪声模型的假设下，我们问题的最大后验概率推理等价于求解一个非线性最小二乘问题，提出的系统也可以整合其他传感器如高度计、电子罗盘等传感器的测量值。 提出的系统使用了4种因子： IMU预积分因子 Lidar里程计因子 GPS因子 回环因子 IMU因子 IMU测量的角速度、加速度如下： 其中， \\(\\hat{w}_t,\\hat{a}_t\\)：表示机体坐标系下的IMU测量值 \\(b_t^w\\)：陀螺仪bias \\(b_t^a\\)：加速度计bias \\(n_t^w,n_t^a\\)：白噪声 \\(R_t^{BW}\\)：从世界坐标系到机体坐标系的旋转矩阵 \\(g\\)：世界坐标系\\(W\\)的重力向量 可推断出\\(\\Delta t\\)时刻后的状态: 其中 \\(R_t=R_t^{WB}=(R_t^{BW})^T\\) 在这里，假设机体坐标系的角速度以及加速度在积分区间是恒定的 IMU预积分 预积分的观测值：\\(\\Delta v_{ij},\\Delta p_{ij},\\Delta R_{ij}\\)，可以理解为：在超级短的时间内，IMU的相邻两个时刻之间的测量值可认为是准确的，可作为观测值。 由于篇幅限制，作者没有给出更加详细的说明，推荐阅读[19]的式7-9 On-Manifold Preintegration for Real-Time Visual-Inertial Odometry,” IEEE Transactions on Robotics, vol. 33(1): 1-21, 2016. IMU预积分除了可以减少运算时间，同时还可以向因子图中提供一种约束 Lidar里程计因子 当新的一帧激光扫描产生，首先进行特征提取，可以通过计算点的粗糙度来进行边缘线以及平面点的提取，粗糙度值较大的会作为边缘线上的点。 \\(F_i^e\\)：在时间i的扫描中的边缘线点 \\(F_i^p\\)：在时间i的扫描中的平面点 \\(\\mathbb{F}_i=\\{F_i^e,F_i^p\\}\\) 以上的特征都是在机体坐标系\\(B\\)下的描述 更加详细的描述，可参见Loam和Lego-Loam J. Zhang and S. Singh, “Low-drift and Real-time Lidar Odometry andMapping,” Autonomous Robots, vol. 41(2): 401-416, 2017. T. Shan and B. Englot, “LeGO-LOAM: Lightweight and Groundoptimized Lidar Odometry and Mapping on Variable Terrain,”IEEE/RSJ International Conference on Intelligent Robots and Systems,pp. 4758-4765, 2018 关键帧阈值设置: 平移1m 旋转10度 假设准备添加新的状态节点\\(x_{i+1}\\)，Lidar关键帧与状态节点\\(x_{i+1}\\)之间的关联使用\\(\\mathbb{F}_{i+1}\\)表示，Lidar里程计因子如下描述： 滑窗关键帧：实现了滑动窗口方法来保持固定数量的最近几帧扫描来创建点云地图，与只优化相邻的两帧的方法来相比，系统采用最近的n帧来优化，称为子关键帧(sub-KeyFrames)，sub-KeyFrames=\\(\\{\\mathbb{F}_{i-n},\\dots,\\mathbb{F}_{i}\\}\\)使用对应的\\(\\{T_{i-n},\\dots,T_{i}\\}\\)来变换到世界坐标系\\(W\\)下，然后合并成体素地图\\(M_i\\)。 由于我们提取了两种特征，因此体素地图\\(M_i\\)由： \\(M_i^e\\)：边缘特征体素地图 \\(M_i^p\\)：平面特征体素地图 来组成，其关系如下: \\(&#39;F_i^e,&#39;F_i^p\\)：变换到世界坐标系\\(W\\)的边缘特征和平面特征 然后，对\\(M_i^e,M_i^p\\)进行降采样，以消除落在同一个体素网格中的重复特征点，在本文中，采用的滑动窗口大小\\(n=25\\)，对\\(M_i^e,M_i^p\\)降采样的分辨率分别是\\(0.2m\\)和\\(0.4m\\) 扫描匹配：对新的LIdar帧\\(\\mathbb{F}_{i+1}\\)，也就是\\(\\{F_i^e,F_i^p\\}\\)匹配到局部体素地图\\(M_i\\)，系统采用的是LOAM的方法。 首先，将第i+1帧雷达扫描的特征数据从机体坐标系\\(B\\)转换到世界坐标系\\(W\\)，得到\\(&#39;F_{i+1}^e,&#39;F_{i+1}^p\\)，需要注意的是：这里的转换需要机体的位姿，这个位姿首先可通过预测(IMU积分)得到，\\(\\tilde{T}_{i+1}\\) 对于变换到世界坐标系中的特征\\(&#39;F_{i+1}^e,&#39;F_{i+1}^p\\)，首先在\\(M_i^e\\)和\\(M_i^p\\)寻找对应的边缘或平面特征，具体的，参考LOAM论文描述。 相对变换 边缘线和平面块的特征距离可表示成如下: 其中，\\(k,u,v,w\\)是对应的特征关联集合 对于\\(&#39;F_{i+1}^e\\)中的特征点\\(p_{i+1,k}^e\\)，\\(p_{i,u}^e\\)和\\(p_{i,v}^e\\)是在\\(M_i^e\\)中与之对应的特征关联边缘线上的点 第i+1帧的特征\\(\\mathbb{F}_{i+1}\\)及其对应的特征之间的几何相对关系可描述为： 最后，通过LM迭代求解得到\\(T_{i+1}\\)，进一步的，可以得到关键帧节点\\(x_i\\)和\\(x_{i+1}\\)之间的相对变换: 另外，作者还发现一种可替换的方法来获取\\(\\Delta T_{i,i+1}\\)，就是变换sub-KeyFrames到\\(x_i\\)节点。换句话说，直接匹配第i+1帧的特征\\(\\mathbb{F}_{i+1}\\)到节点\\(x_i\\)所表示的体素地图。 使用这种方式，可以直接获得\\(\\Delta T_{i,i+1}\\)，因为变换后的特征\\(&#39;F_i^e,&#39;F_i^p\\)可以被重复使用，我们使用这种方法来替换(1)中描述的方法，以提高计算效率。 GPS因子 当接受到GPS测量时，首先将GPS数据转换到局部的笛卡尔坐标系，使用文献[20]中的方法。当新的节点加入到因子图，然后得到对应的GPS测量值，也就是GPS因子。如果GPS信号没有与Lidar进行硬件同步，那么进行插值同步。 A Generalized Extended Kalman Filter Implementation for The Robot Operating System. In Intelligent Autonomous Systems, vol. 13: 335-348, 2016. 作者注意到，当GPS信号可用时，一直加入GPS因子并不是必要的，在实际使用中，只有在估计的位姿协方差大于GPS位置协方差的时候，才加入GPS因子。 回环因子 得益与因子图的使用，回环检测可以无缝地整合到所提出的系统，为了说明的目的，我们描述并实现了一种朴素但有效的基于距离的环闭检测方法。 当新的状态节点\\(x_{i+1}\\)添加到因子图中: 我们首先搜索图，然后寻找在欧几里德空间上与节点\\(x_{i+1}\\)距离相近的先验状态，如图2所示，例如\\(x_3\\)。 然后尝试匹配\\(x_{i+1}\\)时刻的激光扫描特征\\(\\mathbb{F}_{i+1}\\)到附近的关键帧\\(\\{\\mathbb{F}_{3-m},\\dots,\\mathbb{F}_3,\\dots,\\mathbb{F}_{3+m}\\}\\)，（注意：\\(\\mathbb{F}_{i+1}\\)以及附近关键帧sub-KeyFrames需要先转换到世界坐标系\\(W\\)中）。在这一步，可以得到第i+1节点与第3节点之间的变换\\(\\Delta T_{3,i+1}\\) 将\\(\\Delta T_{3,i+1}\\)作为回环因子添加到因子图中 在本系统，选择\\(m=12\\)，回环搜索距离设置为\\(15m\\) 在实际应用中，作者发现添加回环因子对于矫正高度十分有用，当GPS是唯一的绝对观测传感器时。这是因为GPS的高度测量非常不准确——在作者的测试中，在没有环闭的情况下，会出现接近100米的高度误差。 笔者：实际测试，也没有这么大的偏差吧?? 论文展示的效果图","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"MSCKF-1-前端","slug":"SLAM代码课程/MSCKF/MSCKF-1-前端","date":"2020-06-15T03:00:04.000Z","updated":"2020-06-15T03:32:01.000Z","comments":true,"path":"2020/06/15/SLAM代码课程/MSCKF/MSCKF-1-前端/","link":"","permalink":"http://yoursite.com/2020/06/15/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/MSCKF/MSCKF-1-%E5%89%8D%E7%AB%AF/","excerpt":"","text":"MSCKF-1-前端 开源代码： https://github.com/KumarRobotics/msckf_vio 前端解析","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"MSCKF","slug":"SLAM代码课程/MSCKF","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/MSCKF/"}],"tags":[]},{"title":"VLP-16-说明书摘要","slug":"激光SLAM/VLP-16-说明书摘要","date":"2020-06-10T01:02:09.000Z","updated":"2020-06-16T07:59:25.000Z","comments":true,"path":"2020/06/10/激光SLAM/VLP-16-说明书摘要/","link":"","permalink":"http://yoursite.com/2020/06/10/%E6%BF%80%E5%85%89SLAM/VLP-16-%E8%AF%B4%E6%98%8E%E4%B9%A6%E6%91%98%E8%A6%81/","excerpt":"","text":"1. VLP-16-说明书摘要 2. 激光脉冲间隔 3. 数据量计算 4. 旋转速度与水平角分辨率的关系 4.1. 计算公式 因为传感器的发射时间固定在每次发射序列的55.296us，旋转的速度改变了传感器的角度分辨率 5. 激光数据与坐标系等信息 激光点云数据的原点位于激光雷达底座中心轴上方37.7mm 5.1. 线束ID号与垂直角的关系 6. 关于时间戳 当传感器启动时，它开始使用内部时间基准计算微秒。然而，传感器可以与UTC时间异步它的数据，因此您可以确定任何特定数据包中的每一束激光的确切发射时间 UTC同步需要GPS/INS接收器生成一个同步的Pluse Per Second(PPS)信号和一个NMEA GPRMC语句，GPRMC消息提供了UTC中的分钟和秒，直到同步后，传感器从GPRMC语句读取分钟和秒数，然后使用这些信息来设置传感器的时间戳为当前这个小时所过去的毫秒数 6.1. 详细讨论 下面两个选项控制LIdar如何使用GPS数据 第一控制选项确定传感器如何利用PPS信号(PPS) 第二个控制选项决定传感器如何利用(NMEA)语句中提供的时间戳(GPS) 6.2. LIDAR内部计时逻辑 激光雷达内部维护一个计数器，它表示自最高小时(TOH)以来的微秒数。TOH计数基于内部振荡器递增，当传感器被提供一个有效的PPS信号，TOH计数被调整为每个PPS上升边，以将TOH与UTC时间对齐 TOH由两个独立的计数器组成。一个计数器维护从小时的顶部开始的分和秒数，另一个计数器维护次秒计数(图G-2) 6.3. PPS Qualifier 6.3.1. 选项1：Require GPS Receiver Valid 如果设置为ON，那么传感器需要GPS接收器接收到有效的卫星的时候，才认为PPS有效，（此判定通过传感器接收到NMEA语句来决定） 如果设置为OFF，传感器同步其亚秒计数器的上升边缘的PPS信号，而不管GPS接收机卫星状态 6.3.2. 选项2：Require PPS Lock 该设置决定了传感器在调整内部亚秒计数器到该PPS信号的上升边缘之前确认PPS信号的方式 如果设置为ON，传感器利用在（选项3）Delay的值来确定在同步它的内部亚秒计数器到一个PPS信号的上升边缘之前的PPS的有效性 如果设置为OFF，该传感器忽略（选项3）Delay的值，在PPS信号可能被认为有效之前，传感器使用2个周期的滚动窗口，然后被传感器用作时间参考。 关闭此选项相当于将延迟值设置为2 6.3.3. 选项3：Delay 该参数允许用户延长传感器验证PPS所需的时间。单位是整数（秒）。可接受的值范围从0到65535。默认值是5秒 6.4. GPS Qualifier 这个设置决定了TOH计数器的分和秒组件是根据GPS接收器提供的时间戳进行调整，（即使用NMEA语句来调整） 7. 相位锁（用于多激光雷达抗干扰） 当使用多个彼此接近的传感器(例如安装在车辆顶部)时，传感器数据中可能会出现偶尔的干扰模式。Velodyne提供了发射控制，通过控制数据聚集的位置来最小化这种干扰。然后可以将传感器配置为忽略包含干扰的数据。 7.1. Phase Lock 要求有PPS信号并且是Locked状态，传感器使用PPS信号的上升沿作为0度参考时刻，然后传感器调整它的时间，使得它序列起始的锁相偏移由用户指定。 举例 假设用户输入\\(35\\deg(\\alpha)\\)作为相位偏移，如下图红色箭头，红色箭头精确地表示了激光发射方向，此时传感器接收到PPS信号的上升边缘。 7.1.1. Setting the Phase Lock 要启用相位锁定，在下图所示的相位锁定偏移量字段中输入所需的相位偏移量。 例如，如果所需的偏移量是270，则在偏移量字段中输入270。单击按钮上的相位锁定(根据需要)，然后单击右边的设置按钮 7.2. 应用场景 当为两个或更多的传感器设置相位锁定偏移时，Velodyne建议将传感器配置为to fire at each other。这是最小化干扰的最佳配置，因为干扰的位置在用户控制之下。 下图显示两个传感器安装在一辆车上。安装在车辆左侧的传感器将其相位锁偏置设置为90，安装在车辆右侧的传感器锁相偏置设置为270，如红色箭头表示 在这两种情况下，两个传感器在彼此背后创建数据阴影，为了避免来自相反传感器的阻塞或反射造成的任何虚假数据，用户应该忽略在shadowed方位角范围内的任何数据，如下面的图H-5所示。 要做到这一点，你需要知道传感器的直径(见第93页的传感器规格)和传感器中心之间的距离 8. 关于水平扫描角度的设定 默认Y轴正方向为0度，那如果想要从X轴负方向开始扫描，那么设定如下 START： 270度 END： 450度 9. 命令设置激光雷达的参数 这里只列出几个，具体参见VLP-16说明书，第10章 9.1. Set Motor RPM Sets the RPM of the motor. Valid integer values range from 300 to 1200, in increments of 60. (If the RPM setting is not evenly divisible by 60, neither motor speed control nor phase lock functions will function properly.) For values 1 through 299, the sensor defaults back to 300 RPM. If a value of 0 or less is entered, the sensor motor powers down and the lasers are turned off, as leaving them on with the motor stopped would be an unsafe eye state. This has the same effect as setting the value for the Motor RPM in the Web Interface. Command: 1curl --data “rpm=[integer]” http://192.168.1.201/cgi/setting Example: 1curl --data “rpm&#x3D;600” http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;setting 9.2. Set Field of View Sets the field of view (0° to 359°). Numbers outside this range are quietly ignored. This has the same effect as setting the FOV Start and FOV End values on the Web Interface. Command: 1curl --data “[start]|[end]&#x3D;[integer]” http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;setting&#x2F;fov Examples: 12curl --data &quot;start&#x3D;10&quot; http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;setting&#x2F;fovcurl --data &quot;end&#x3D;270&quot; http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;setting&#x2F;fov 9.3. Set Return Type (Strongest, Last, Dual) This command sets the return type (or mode) of the sensor. Choose one: Strongest, Last, and Dual. This has the same effect as selecting the Web Interface Return Type. Command: 1curl --data “returns&#x3D;[Strongest]|[Last]|[Dual]” http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;setting Examples: 123curl --data “returns&#x3D;Strongest” http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;settingcurl --data “returns&#x3D;Last” http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;settingcurl --data &quot;returns&#x3D;Dual&quot; http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;setting 9.4. Save Configuration Saves the configuration so that the settings are persistent across power cycles. This is equivalent to clicking on the Save Configuration button under the Configuration tab in the Web Interface. Command: 1curl --data “submit” http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;save 9.5. Reset System Resets the sensor. This command performs the same operation as pressing the Reset System button under the System tab in the Web Interface, or if you cycled power to the sensor. Command: 1curl --data &quot;reset_system&quot; http:&#x2F;&#x2F;192.168.1.201&#x2F;cgi&#x2F;reset Example Response: 1The system resets. LOAM代码中关于VLP16的细节 12345678910111213//!lidar scan开始点的旋转角,atan2范围[-pi,+pi],计算旋转角时取负号是因为velodyne是顺时针旋转float startOri = -atan2(laserCloudIn.points[0].y, laserCloudIn.points[0].x);//lidar scan结束点的旋转角，加2*pi使点云旋转周期为2*pifloat endOri = -atan2(laserCloudIn.points[cloudSize - 1].y, laserCloudIn.points[cloudSize - 1].x) + 2 * M_PI;//结束方位角与开始方位角差值控制在(PI,3*PI)范围，允许lidar不是一个圆周扫描//正常情况下在这个范围内：pi &lt; endOri - startOri &lt; 3*pi，异常则修正if (endOri - startOri &gt; 3 * M_PI) &#123; endOri -= 2 * M_PI;&#125; else if (endOri - startOri &lt; M_PI) &#123; endOri += 2 * M_PI;&#125; 根据点的仰角，区分所在线束编号 123456789101112131415161718192021//坐标轴交换，velodyne lidar的坐标系也转换到z轴向前，x轴向左的右手坐标系point.x = laserCloudIn.points[i].y;point.y = laserCloudIn.points[i].z;point.z = laserCloudIn.points[i].x;//计算点的仰角(根据lidar文档垂直角计算公式),根据仰角排列激光线号，velodyne每两个scan之间间隔2度float angle = atan(point.y / sqrt(point.x * point.x + point.z * point.z)) * 180 / M_PI;int scanID;//仰角四舍五入(加减0.5截断效果等于四舍五入)int roundedAngle = int(angle + (angle&lt;0.0?-0.5:+0.5));if (roundedAngle &gt; 0)&#123; scanID = roundedAngle;&#125;else &#123; scanID = roundedAngle + (N_SCANS - 1);&#125;//过滤点，只挑选[-15度，+15度]范围内的点,scanID属于[0,15]if (scanID &gt; (N_SCANS - 1) || scanID &lt; 0 )&#123; count--; continue;&#125;","categories":[{"name":"激光SLAM","slug":"激光SLAM","permalink":"http://yoursite.com/categories/%E6%BF%80%E5%85%89SLAM/"}],"tags":[]},{"title":"LOAM-论文阅读","slug":"激光SLAM/LOAM-论文阅读","date":"2020-06-08T15:41:02.000Z","updated":"2020-07-07T01:19:07.000Z","comments":true,"path":"2020/06/08/激光SLAM/LOAM-论文阅读/","link":"","permalink":"http://yoursite.com/2020/06/08/%E6%BF%80%E5%85%89SLAM/LOAM-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"LOAM: Lidar Odometry and Mapping in Real-time 摘要 主要思想，通过两个算法来同时优化大量变量，其中一个是作为高频输出的里程计，另一个是以更低的固定频率运行的后端优化。结合这两种算法，该方法可以实现实时分析。该方法已通过大量的实验和KITTI测程基准进行了评价。结果表明，该方法可以达到最先进的离线批处理方法的水平 由于此方法是为了在测程估计中最小化漂移，所以目前不涉及Loop Closure 去畸变 如果扫描运动相对缓慢（扫描周期长），运动失真会很严重。 文献[13]提出了一种两步法来去除激光雷达的畸变 使用速度来矫正（其他传感器提供速度，或者使用ICP等算法来估计速度） Barfoot等人使用的一种方法是从激光强度返回中创建视觉目标，并在两帧图像之间匹配视觉上不同的特征[17]，以恢复地面车辆的运动[18]～[21]。其中，文献[18,19]把车辆的运动建模为恒速度模型。 [18]～[21]的方法涉及灰度图像的视觉特征，需要密集的点云，本文提出的方法在笛卡尔空间中提取和匹配几何特征，对云密度要求较低 符号约定 作为本文的一个惯例，我们使用右大写字母来表示坐标系统，使用右下标\\(k,k\\in Z^+\\)来表示扫描，其中\\(\\mathcal{P}_k\\)表示在第k次扫描的点云。 定义两个坐标系描述如下 激光雷达坐标系\\(L\\)，原点是激光雷达中心，x轴指向左侧，y轴指向上，z轴指向前方。对于此坐标系下的一个点\\(i,i \\in \\mathcal{P}_k\\)，可以记为\\(X_{(k,i)}^L\\) 世界坐标系\\(W\\)，原点是激光雷达的初始位姿，此坐标系下的点，记为\\(X_{(k,i)}^W\\) 系统概述 硬件 采用180度视野范围，0.25度分辨率，40线的激光雷达UTM-30LX 软件系统 \\(\\hat{\\mathcal{P}}\\)作为一帧扫描所得到的点，在每一次扫描中，\\(\\hat{\\mathcal{P}}\\)被配准到激光雷达坐标系中 然后\\(P_k\\)使用两种算法来处理： 首先是激光里程计，计算两帧扫描来估计激光雷达的相对运动，估计得到的运动反过来矫正\\(\\mathcal{P}_k\\)的畸变，这个算法运行的频率为10Hz。 里程计的输出作为建图模块的输入，以1Hz的频率将去畸变后的点云进行匹配和配准到地图上。最后，将两个算法的结果进行整合，以10Hz输出位姿变换矩阵。 激光里程计 特征提取 选取点云中边缘上的点以及平面上的点。 i： 点云\\(\\mathcal{P}_k\\)中的点 S： 同一帧扫描中与点i连续的点集 定义如下函数来评估某个点的平滑度： 根据计算得到的\\(c\\)值进行排序，具有最大c值的特征点被选中，作为边缘点 具有最小c值的点也选中，作为平面点 为了将特征点均匀地分布在环境中，我们将一次扫描分成四个子区域,每个子区域能最多提供2个边缘点和4个平面点。只有当点i的c值比阈值大或者小的时候，才会被考虑作为边缘点或者平面点，另外还要求选择的特征点不超过子区域最大值。 在选择特征点时，我们希望避免重复选取： 某个已选中的特征点的附近点 与激光束大致平行的平面上的点(如图4(a)) 这些点通常认为是不可靠的，同时，我们要避免在被遮挡的区域边界上的点，如下图4(b)，点A是激光雷达云中的边缘点，因为它连接的表面(虚线段)被另一个物体阻塞了。然而，如果激光雷达移动到另一个视点，被遮挡的区域就会发生变化，成为可观测的。 如何处理： 为了避免前面提到的点被选择，使用点集\\(\\mathcal{S}\\)进行判断： 点集\\(\\mathcal{S}\\)不形成与激光束平行的平面 点集\\(\\mathcal{S}\\)中没有任何点是(由于激光束方向的gap导致)与点i不连续的，并且比点i更加靠近激光雷达的 ！！！则点i才有可能被选中！！！ 小结 综上所述，特征点的选取：以最大c值为起点来选择边缘点，以c值最小值为起点来选择平面点， 选择的边缘点或平面点不超过子区域的最大值 候选点i的附近点没有被选中 候选点i所在的 局部平面 不能与激光束方向平行，或者是被遮挡区域的边界点 如下图5所示 黄色：边缘点 红色：平面点 查找特征点关联 \\(t_k\\)：第k帧扫描的起始时间 \\(\\bar{\\mathcal{P}}_k\\)：第k帧扫描重投影到第k+1帧扫描起始时刻的点云 在每一帧扫描的结束时，在该帧扫描得到的点云\\(\\mathcal{P}_k\\)被重投影到时间戳为\\(t_{k+1}\\)，如图6所示。在接下来的\\(t_{k+1}\\)时刻的扫描中，\\(\\bar{\\mathcal{P}}_k\\)与\\(t_{k+1}\\)新扫描点云\\(\\mathcal{P}_{k+1}\\)一起用来估计激光雷达的运动。 假设\\(\\bar{\\mathcal{P}}_k\\)和\\(\\mathcal{P}_{k+1}\\)都可用，然后开始寻找两帧点云之间的关联。 对于点云\\(\\mathcal{P}_{k+1}\\)，先选出边缘点和平面点。 \\(\\mathcal{E}_{k+1}\\)：边缘点集合 \\(\\mathcal{H}_{k+1}\\)：平面点集合 注意，在扫描\\(k+1\\)开始时，\\(\\mathcal{P}_{k+1}\\)是一个空的点集，在扫描过程中，随着接收到更多的点，该点数会增长。激光里程计连续地估计扫描中的6自由度的运动，同时\\(\\mathcal{P}_{k+1}\\)点数增加。 在每次迭代中，使用当前的里程计位姿估计，将\\(\\mathcal{E}_{k+1}\\)和\\(\\mathcal{H}_{k+1}\\)投影到当前帧的扫描起始时刻，分别得到\\(\\bar{\\mathcal{E}}_{k+1}\\)和\\(\\bar{\\mathcal{H}}_{k+1}\\) 对于\\(\\bar{\\mathcal{E}}_{k+1}\\)和\\(\\bar{\\mathcal{H}}_{k+1}\\)中的每一个点，我们准备从点云\\(\\bar{\\mathcal{P}}_k\\)中选择最近邻的点，注意：为了快速查找，点云\\(\\bar{\\mathcal{P}}_k\\)以3D-KD-tree形式来储存 边缘线点的关联 图7(a)表示了寻找与边缘点对应的边缘线的过程，假设: \\(i\\)是\\(\\bar{\\mathcal{E}}_{k+1}\\)中的点 \\(j\\)是在\\(\\bar{\\mathcal{P}}_k\\)中与点\\(i\\)最近邻的点（图中的橙色线上的点） \\(l\\)是两个连续线束扫描中与点\\(i\\)最近邻的点（图中的上下两条蓝色线束） 那么\\((j,l)\\)表达了一条关于点\\(i\\)的边缘线 边缘线使用两个点来表示： \\((j,l)\\)形成了点i的关联，为了确认点\\(j\\)和\\(l\\)都是边缘点，我们基于平滑度计算公式来对局部平面的平滑度进行检查。在这里，特别要求\\(j\\)和\\(l\\)是来自不同线束的扫描，原因是考虑到一线束的扫描中，对于同一个边缘线不能超过1个点。（只有一个例外，即边缘线在扫描平面上，在这种情况下，边缘线会退化为扫描平面上的一条直线，线上的特征点不应该被首先提取） 平面点的关联 图7(b)展示了查找与平面点\\(i\\)相关联的平面块的过程，假设 \\(i\\)：\\(\\bar{\\mathcal{H}}_{k+1}\\)中的点 \\(j\\)：在\\(\\bar{\\mathcal{P}}_{k}\\)中关于点\\(i\\)的最近邻点 \\(l\\)：在与点\\(j\\)的同一线圈扫描中，另一个与点\\(i\\)的最近邻点 \\(m\\)：在与点\\(j\\)的相邻两线圈扫描中，与点\\(i\\)的最近邻点 平面块(planer patch)使用3个点来表示： 在\\(\\bar{\\mathcal{P}}_{k}\\)中查找关于点\\(i\\)的最近邻点，记为\\(j\\) 在与点\\(j\\)的同一线圈中，另一个与\\(i\\)最近邻的点，记为\\(l\\) 在与点\\(j\\)的相邻两线圈扫描中，找到与点\\(i\\)的最近邻的点，记为\\(m\\) 这样，保证了这3个点\\((j,l,m)\\)不共线，为了确定\\((j,l,m)\\)是否都是平面点，再次使用公式一来检查对应的平滑度。 特征距离表达式 这个特征距离作为目标函数的一部分，通过最小化目标函数，来求解出激光雷达的运动。 根据找到的特征点的对应关系，计算从特征点到对应特征关联的距离： 边缘线特征距离 对于每一个在边缘集合\\(\\bar{\\mathcal{E}}_{k+1}\\)中的点，如果\\((j,l)\\)是对应该点的边缘线，那么就可以计算特征距离： 其中， \\(\\bar{X}_{k+1,i}^L\\)是点\\(i\\)在{L}中的坐标 \\(\\bar{X}_{k,j}^L\\)是点\\(j\\)在{L}中的坐标 \\(\\bar{X}_{k,l}^L\\)是点\\(l\\)在{L}中的坐标 公式原理： 叉乘计算出平行四边形面积 在除以长度，可以得到点到线的垂线距离 平面点特征距离 对于在平面集合\\(\\bar{H}_{k+1}\\)中的点\\(i\\)，如果\\((j,l,m)\\)是对应的平面块，那么那么点\\(i\\)到平面块\\((j,l,m)\\)的距离为： 其中， \\(\\bar{X}_{k,m}^L\\)是点\\(m\\)在{L}中的坐标 运动估计 在扫描过程中，假设激光雷达的运动以恒定的角速度和恒定的线速度进行（匀速模型）。 这种假设允许我们在一帧扫描中(a sweep)对每一个在不同时间接收到的点对应的激光雷达位姿进行线性插值得到。 假设： \\(t\\): 当前时刻时间戳 \\(t_{k+1}\\): 在第k+1帧扫描的起始时刻 \\(T_{k+1}^L\\): 在时间段\\([t_{k+1},t]\\)之间的激光雷达位姿变换\\(T_{k+1}^L=[t_x,t_y,t_z,\\theta_x,\\theta_y,\\theta_z]^T\\)(旋转部分遵循右手系) 给定一个在\\(\\mathcal{P}_{k+1}\\)中的点\\(i\\) \\(t_i\\)为接收到点\\(i\\)的对应时刻\\((t_i \\in [t_{k+1},t])\\) \\(T_{(k+1,i)}^L\\)为时间段\\([t_{k+1},t_i]\\)之间的激光雷达位姿变换 ===&gt; 从\\(t_i\\)时刻激光雷达坐标系转换到\\(t_{k+1}\\)时刻的激光雷达坐标系的变换 那么，\\(T_{(k+1,i)}^L\\)可以通过对\\(T_{k+1}^L\\)进行线性差值得到： 回想一下: \\(\\mathcal{E}_{k+1}\\)和\\(\\mathcal{H}_{k+1}\\)分别是从\\(\\mathcal{P}_{k+1}\\)提取出来的边缘点和平面点集合 \\(\\tilde{\\mathcal{E}}_{k+1}\\)和\\(\\tilde{\\mathcal{H}}_{k+1}\\)是将上面的点集重投影回在第\\(k+1\\)帧扫描的起始时刻的点集 为了求解激光雷达的运动，我们需要建立 \\(\\mathcal{E}_{k+1}\\)和\\(\\tilde{\\mathcal{E}}_{k+1}\\) \\(\\mathcal{P}_{k+1}\\)和\\(\\tilde{\\mathcal{H}}_{k+1}\\) 之间的几何关系。 使用公式(4)的变换，可以推导得到上述关系: 其中， \\(X_{(k+1,i)}^L\\)是点\\(i\\)投影到\\(t_{k+1}\\)时刻下的激光雷达坐标系的坐标 \\(T_{(k+1,i)}^L(1:3)\\)表示从\\(t_i\\)时刻激光雷达坐标系转换到\\(t_{k+1}\\)时刻的激光雷达坐标系的平移量变换 \\(R\\)是使用罗德里格斯公式得到的旋转矩阵 上式中的\\(\\theta\\)为，表示旋转的量: \\(w\\)是单位向量，表示旋转的方向，\\(\\hat{w}\\)是关于向量\\(w\\)的反对称矩阵: 回想一下：公式(2),(3)计算了\\(\\tilde{\\mathcal{E}}_{k+1}\\)和\\(\\tilde{\\mathcal{H}}_{k+1}\\)中的点与其对应的特征关联之间的距离， 结合公式(2)和(4~8)，我们可以推导出集合\\(\\mathcal{E}_{k+1}\\)中的边缘点和其对应的特征关联之间的几何关系: 同样的，结合公式(3)和(4~8)，有： 最后，通过LM算法来求解激光雷达的运动： 对于在\\(\\mathcal{E}_{k+1}\\)和\\(\\mathcal{H}_{k+1}\\)中的每个点，都可生成如同式(9)和(10)的方程，通过遍历，可以得到一个非线性函数： 其中， \\(f()\\)中的每一行与一个特征点相关联 \\(d\\)包含了对应的特征关联距离 然后计算矩阵\\(f()\\)关于\\(T_{k+1}^L\\)的雅克比矩阵，即 \\[ J=\\frac{\\partial f}{\\partial T_{k+1}^L} \\] 然后，式(11)可以通过以最小化\\(d\\)为目标，使用非线性迭代来求解: (QPC: add)那么，每次迭代的增量方程应该是: \\[ (J^TJ+\\lambda)dx=J^Td \\] 其中 \\(\\lambda\\)是LM算法的参数 小结 激光里程计的算法，总结如下图 建图(LIDAR MAPPING) 建图算法以低频率运行，每一圈扫描执行一次。在第k+1圈扫描的结束时刻，里程计模块生成去畸变后的点云\\(\\bar{P}_{k+1}\\)，同时还有激光雷达的相对位姿变换\\(T_{k+1}^L\\)。 建图部分将去畸变后的点云\\(\\bar{P}_{k+1}\\)配准到世界坐标系\\({W}\\)中，如下图8所示 \\(Q_k\\): 地图上的点云，是前k帧扫描的累积形成的 \\(T_k^W\\): 在第k帧扫描结束时刻（也是\\(t_{k+1}\\)），雷达在点云地图上的位姿 未完待续","categories":[{"name":"激光SLAM","slug":"激光SLAM","permalink":"http://yoursite.com/categories/%E6%BF%80%E5%85%89SLAM/"}],"tags":[]},{"title":"Review-3D-Lidar-Localization","slug":"激光SLAM/Review-3D-Lidar-Localization","date":"2020-06-02T03:02:33.000Z","updated":"2020-06-02T07:14:08.000Z","comments":true,"path":"2020/06/02/激光SLAM/Review-3D-Lidar-Localization/","link":"","permalink":"http://yoursite.com/2020/06/02/%E6%BF%80%E5%85%89SLAM/Review-3D-Lidar-Localization/","excerpt":"","text":"1. 3D-激光雷达定位方法汇总 本次调查的目的是回顾和介绍与三维激光雷达定位相关的工作，比较文献中报道的不同结果，并讨论各自的优缺点。 2. 3D Registration Based Methods 通常与离线构建的地图结合使用，这些方法的优越性在于使用点云配准的方法。虽然这些方法非常精确，但当只依赖于激光雷达数据时，它们的速度太慢，无法实现实时处理。 点云配准主要用于两种情况 - 一是将激光扫描与局部地图进行配准 - 二是连续的激光扫描之间的配准，计算相对位姿 2.1. ICP(Iterative Closest Point) 多年来，ICP算法一直是解决点云配准问题的标准。 通过以优化迭代的方式最小化目标点云和源点云之间的误差测量，来获得两组点云之间的相对变换关系。 其变体还有： point-to-line ICP point-to-plane Generalized ICP 在最近的[50]中，提出了一种集成了激光雷达传感器物理知识并改进了ICP算法的测距法，采用了一种新颖的下采样和点匹配抑制方法：激光雷达扫描的下采样是使用一个正常协方差滤波器(NCF)完成的，该滤波器只保留精确正态点。 2.2. NDT 然而，ICP算法最终被3D正态分布变换(NDT)算法所超越[14], [51]。与ICP算法类似，对源点云和目标点云之间的变换矩阵进行迭代优化，不同的是，被最小化的误差不是两个点云的点对距离，而是首先将点云转换为概率密度函数(PDF)，然后基于预先计算的体素中点的平均值和协方差来计算。此PDF可与牛顿迭代法一起使用，以查找它们之间的空间转换。 2.3. IMLS-SLAM 在一个更经典的SLAM方法中，作者在[20]中提出了一个名为IMLS-SLAM的3步算法 首先是动态对象删除，简化为扫描和小簇删除的聚类 第二步是采用基于每个点的可观察性的采样策略，以便对扫描进行降采样 然后最后是匹配步骤，其中使用Implicit移动最小二乘法(IMLS)表示 2.4. CLS-SLAM Collar Line Segments(CLS)结构是一种有用的预处理方法，它可以达到较高的精度：在[38]中，通过从邻近环的邻近点之间采样线段，可以从激光雷达扫描提取线狀点云，然后使用迭代方法对这些线狀点云进行对准： 首先，计算生成的直线的中心点 然后，这些点被用来查找在连续扫描之间的转换，方法是，对目标点云和已有点云的线狀点云进行配准，其中两组线狀点云之间用中心点的距离来关联 2.5. DLO 有时，降低激光雷达数据的维度也可以产生合理的结果，例如在[40]中，激光扫描被投影到带有占据栅格和高度值的2.5D网格地图中。这个网格映射相当于灰度图像，它用于基于图像测量误差来进行配准，就像通常对相机数据所做的那样。 3. 3D Features Based Methods 灵感来源于流行的基于二维特征提取和匹配的方法，这些方法在三维空间中设计相关的特征，然后用于计算相对位移。这些方法的精度和实时性较好，但在处理机动粗糙和高速运动时，效果较差。这些方法可以被看作是稀疏方法，因为他们只使用在部分的激光雷达点云数据 针对非道路环境，[19]提出了并命名为CPFG-SLAM的方法，其灵感来自于ICP和NDT算法，并依赖于3D特征和概率网格地图。利用网格中的最近邻而不是空间最近邻点，可以更有效地将点云匹配并注册到网格地图中。期望最大化(EM)算法用于估计姿态，最终优化问题使用Levenberg-Marquardt算法求解。 其他定位方法尝试利用环境中存在的主要几何形状:在[21]和[22]中，平面提取算法与帧对帧技术相结合，以生成车辆的位姿估计 3.1. LOAM 目前，在KITTI Odom排行榜上居领先位置，在[25]中提出的方法首先基于点的平滑度和遮挡度提取平面和角点特征。这些特征与后续扫描的点的patch匹配，然后使用Levenberg-Marquardt方法求解激光雷达的运动 LOAM系列文献 [25] J. Zhang and S. Singh, “Loam: Lidar odometry and mapping in realtime.” [26] T. Shan and B. Englot, “Lego-loam: Lightweight and groundoptimized lidar odometry and mapping on variable terrain,” in 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2018, pp. 4758–4765. [27] X. Ji, L. Zuo, C. Zhang, and Y. Liu, “Lloam: Lidar odometry and mapping with loop-closure detection based correction,” in 2019 IEEE International Conference on Mechatronics and Automation (ICMA), Aug 2019, pp. 2475–2480. [28] J. Lin and F. Zhang, “A fast, complete, point cloud based loop closure for lidar odometry and mapping,” 09 2019 4. 3D Deep Learning Based Methods 最近，使用Deep Learning解决定位问题的做法越来越流行。二维相机图像首先被用来尝试和预测一对目标[5]、[6]、[7]、[8]之间的里程数，其结果或多或少是可以接受的，但仍然没有超过目前的技术水平。最近，更多的工作已经探索使用激光雷达，而结果似乎更有希望。 深度学习方法： 端到段的深度学习方法使用原始点云作为输入，直接预测车辆的位移作为输出 使用深度学习替换传统配准流程中的某个子模块 4.1. 端到端 [13]的想法是，尝试把这个挑战带回到图像域，而不是试图在3D pointcloud 中直接解决它，为了简化输入到网络中的数据，激光雷达扫描的点云首先投影到2D空间，从而产生全景深图像，然后输入到一个简单的2分支卷积网络，试图恢复出车辆在两个输入帧之间的位移和方向变化。结果表明，与目前的研究水平相比，作者的研究成果低于平均水平 4.1.1. DeepPCO 全景深度图像（Panoramic depth images）、是激光雷达数据的一种常用表示方法，另一种利用到全景深度图像的方法是DeepPCO [17]，投影的激光雷达帧被送入一个2branch的网络，其中第一个分支预测车辆的平移，而第二个分支预测车辆的旋转。 4.1.2. Deeplo 另一种尝试简化投射到二维空间的输入数据的方法是[18]中提出的方法：激光雷达帧投影使用球形坐标系系统生成两个新的二维表示： a vertex map (representing the location (x,y,z) of each point) a normal map (representing the values of the normals of each point) 提出的网络由残差块组成，有两个主要分支： 第一个名为VertexNet，它将顶点map作为输入，并用于预测后续帧之间的平移 第二个分支名为NormalNet，以normal map作为输入，用于预测两个后续帧之间的旋转 为了以端到端的方式训练完整的网络，作者提出了两种不同的训练方案，基于标记数据的可用性，采用两种不同的损失函数： 首先是一个经典的有监督的损失，将标记数据与网络预测进行比较，以优化网络的权重 其次是无监督损失，即不需要标签数据，使用ICP算法引导网络进行正确的运动预测 4.2. 基于3D场景分割 在[32]、[31]、[33]、[34]等一系列最终形成最终的三维分段方法，[35]的论文中，作者探索了如何利用简单的卷积网络从点云中高效提取和编码段，希望能解决定位和建图相关的任务。 该方法的主要特点是：数据驱动的3D Segment 描述符，采用由卷积层和全连通层组成的网络来提取。 这个描述符提取网络使用两部分组成的loss function来训练： 分类损失 重建损失 最后利用k-NN算法找到提取的分段及其对应的候选，这使得解决localization任务成为可能。 注意，3D SegMap描述符是一个通用描述符，也可以用于解决其他任务如对象分类 4.2.1. LO-Net (Remove Dynamic Obj) 当试图还原两帧之间的运动时，前面讨论的大多数方法将不可避免地受到场景中的动态对象(汽车、行人等)的影响，remove这些动态的对象可以提高里程的精度。但是，在有监督下进行检测并从场景中删除动态对象会增加复杂性，从而导致更高的处理时间和不稳定的结果。 为了以无监督的方式解决这一问题，[37]的作者提出了训练一个用于动态mask预测任务的encoder-decoder branch，这是通过优化几何一致性损失函数来实现的。 整个网络(名为LO-Net)可以结合几何一致性损失、里程回归损失和交叉熵损失以端到端的方式进行训练，用于正则化目的 4.3. 模块替换 除了使用直接Lidar Frames直接学习定位车辆的模型，其他的方法尝试学习经典Pipline中的误差模型等。换句话说，可以使用深度学习的方法来纠正里程测量值，从而得到功能强大且灵活的可插拔模块 4.3.1. L3-Net 在[39]的作者提出了学习偏差校正项，旨在改进以激光雷达数据为输入的经典状态估计器的结果。采用高斯过程模型对6个odometry误差进行了相互独立的建模，精心选择的输入参数集中在误差影响最大的3个自由度 在[41],提出了一种更高级的方法叫L3-Net，与bias correction 主题相关，作者提出一个网络，目的是学习传统定位系统与真值之间的残差，而不是直接预测两帧之间的变换矩阵。 相关的特征首先被提取并输入到一个miniPointNet中，以生成它们的相关特征描述符，然后在解空间(x,y,z)构造一个cost volume，并使用3D卷积神经网络进行调整。 此外，一个RNN branch被添加到网络结构，以保证位移预测的平滑性 4.3.2. Deep-ICP(NEW，端到端) 同样的作者在[42]，[43]中提出了L3-Net的一个更完整和更一般的变体，并命名为DeepICP，这里，使用pointnet++提取特征，然后使用权重层过滤，只保留最相关的，与前面的方法类似，特征描述符使用一个miniPointNet结构计算，然后输入到相应的点生成层(point generation layer)，在目标点云中生成相应的关键点。为了恢复出相对变换的最终值，结合两个损失函数，希望对局部相似性和全局几何约束进行编码。 4.3.3. CAE-LO 最近，提出了一种新的解决方案CAE-LO，其中： 使用了一个无监督卷积自动编码器，以多尺度的方式从激光雷达的球形投影中提取特征 一个自动编码器用于生成特征描述符，用来进行基于RANSAC的帧与帧之间的对应点的匹配 如果知道了两组点云之间的点对匹配关系，则可以使用ICP进行解析求解 4.3.4. Locnet（看看） 在[23]中，再次尝试简化输入的数据，提出了一种基于点云环状分布的手工旋转不变表示方法(RIR)。作者称，正是由于这种表示方法，全局定位问题被重新表述为 an identity verification problem。 这个问题通过使用siamese网络称LocNet来解决，它以2个后续的RIR作为输入，目标是优化一个对比损失函数[61]，LocNet的输出是一个降维特征向量，在后续的全SLAM管道中使用，其中使用MCL[62]和ICP算法求解最终的粗到细的变换。 4.3.5. LORAX 在[29]中，提出了LORAX算法，这种方法引入了超点的概念，超点是位于球内的点的子集，它描述了一个局部平面，被投影到2D空间以形成2D深度maps。这些depth maps然后使用一系列的测试进行过滤，只留下相关的超点，然后使用PCA和深度自动编码器对其进行编码。然后根据欧氏距离对特征候选之间进行匹配，然后进行粗配准步骤，其中使用了涉及RANSAC的迭代方法。最后，为了对配准步骤的结果进行微调，采用了ICP算法来提高整个配准过程的精度。 5. 评价和测试 请注意，我们只考虑不涉及任何 loop closure的结果。虽然Loam仍然占据着排行榜的前面，但可以明显看出，涉及深度学习的方法正变得越来越精确。基于深度学习的方法被证明会产生非常有前途的结果，并且似乎代表了正确的路径，以便在未来解决这个挑战，基于三维特征检测与匹配的方法在实际应用中已被证明是最先进的方法。 DeepICP报告的平均结果优于其他的训练方法，然而，由于两个主要原因，我们很难把它们称为最先进的方法： (DeepICP)大约需要2秒钟来配准每一帧 这些方法在测试数据集上的结果尚未见报道，在测试数据集上的良好结果将证明，这些方法不仅适用于深度神经网络已经看到的数据，而且能够用于真实数据","categories":[{"name":"激光SLAM","slug":"激光SLAM","permalink":"http://yoursite.com/categories/%E6%BF%80%E5%85%89SLAM/"}],"tags":[]},{"title":"KAIST-Urban-数据集-论文阅读","slug":"数据集整理/KAIST-Urban-数据集-论文阅读","date":"2020-05-26T02:49:38.000Z","updated":"2020-05-26T08:45:27.000Z","comments":true,"path":"2020/05/26/数据集整理/KAIST-Urban-数据集-论文阅读/","link":"","permalink":"http://yoursite.com/2020/05/26/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%95%B4%E7%90%86/KAIST-Urban-%E6%95%B0%E6%8D%AE%E9%9B%86-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Complex urban dataset with multi-level sensors from highly diverse urban environments 摘要 提供了数据集地址: http://irap.kaist.ac.kr/dataset. 提供多环境多场景的数据，如市区，公寓，或者是地下停车场 提供了以高精度导航传感器和半自动回环处理的SLAM算法的定位基准 提供两个级别准确度的传感器数据（商用和消费级别） 提供3D点云（LAS格式）以及相应的viewer 提供ROS下的开发者工具 介绍 下表展示了最近的一些自动驾驶或3D mapping的数据集 系统概述 传感器坐标系 激光雷达与车体坐标系外参标定 先根据不同激光雷达的外参关系，将不同激光雷达的点云拼接起来 因为标定过程是在一个平面（地面）上进行的，因此，当车体中心在地面上时，点云在地面上的高度应该为0。因此，通过调整拼接后的点云的高度为0，可以计算出两个3D激光雷达在车体参考坐标系下的roll，pitch和z值 首先，使用RANSAC算法通过拟合平面来提取地面上的点 然后，使用SVD分解求出激光雷达相对于车体坐标系的roll，pitch和z值 对于x，y和yaw值，在空地上控制车辆往返运动，然后从两个相反的视点比较场景，在这个过程中，用到了VRS-GPS和光纤陀螺等高精度的设备。这个过程中，车辆的精确位置主要有VRS-GPS提供，通过对3D点云进行对齐来得到待估计的x，y和yaw值","categories":[{"name":"数据集整理","slug":"数据集整理","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%95%B4%E7%90%86/"}],"tags":[]},{"title":"驱动-组合导航-星网宇达M2","slug":"驱动-组合导航-星网宇达M2","date":"2020-05-18T05:39:10.000Z","updated":"2021-06-01T10:04:39.000Z","comments":true,"path":"2020/05/18/驱动-组合导航-星网宇达M2/","link":"","permalink":"http://yoursite.com/2020/05/18/%E9%A9%B1%E5%8A%A8-%E7%BB%84%E5%90%88%E5%AF%BC%E8%88%AA-%E6%98%9F%E7%BD%91%E5%AE%87%E8%BE%BEM2/","excerpt":"","text":"1. ROS驱动-组合导航-星网宇达M2 这里使用的是Apollo D-Kit套件，采用的是星网宇达公司的M2组合导航。第一步先对组合导航进行设置，第二步是修改ROS社区开源Package nmea_navsat_driver驱动 2. 配置M2 2.1. 清空输出 12$cmd,through,usb0,null*ff$cmd,output,usb0,null*ff 2.2. 航向设置 1$cmd,set,headoffset,0*ff 2.3. 检查导航模式 2.3.1. 设置 1234567$cmd,set,navmode,FineAlign,off*ff$cmd,set,navmode,coarsealign,off*ff$cmd,set,navmode,dynamicalign,on*ff$cmd,set,navmode,gnss,double*ff$cmd,set,navmode,carmode,on*ff$cmd,set,navmode,zupt,on*ff$cmd,set,navmode,firmwareindex,0*ff 如果不行则试试这个: 1234567&gt;$cmd,set,navmode,finealign,off*ff (精对准开&#x2F;关 需要设置成 off)&gt;$cmd,set,navmode,corsealign,off*ff (粗对准开&#x2F;关 设置成 off)&gt;$cmd,set,navmode,dynamicalign,on*ff (动态对准开&#x2F;关 设置成 on)&gt;$cmd,set,navmode,gnss,double *ff (设置成双天线 double)&gt;$cmd,set,navmode,carmode,on*ff (车载模式开&#x2F;关 设置成 on)&gt;$cmd,set,navmode,zupt,on*ff (静止模式开&#x2F;关 设置成 on)&gt;$cmd,set,navmode,firmwareindex,0*ff (固件 0&#x2F;1 除 7660-F01 外都设置成 0 2.3.2. 检查 1$cmd,get,navmode*ff 2.4. 设置杆臂值 1设置命令为： $cmd,set,leverarm,gnss,x,y,z*ff。（xyz 单位为米） （如果 PRI 天线安装在 M2 主机的右、前、上， xyz 则为正，反之 xyz 前面需加负号-） 2.5. 设置输出 指令格式: $cmd,output,comX,cmdname,rate*ff 2.5.1. 输出IMU原始数据GTIMU 1$cmd,output,usb0,gtimu,0.01*ff 2.5.2. 输出RTK定位信息GPGGA语句 1$cmd,output,usb0,gpgga,0.2*ff 2.5.3. 输出融合之后的定位信息GPFPD语句 1$cmd,output,usb0,gpfpd,0.01*ff GPFPD状态输出为4B的时候，表明RTK正常 2.5.4. 输出融合之后的标准差（协方差） 1$cmd,output,usb0,nvstd,0.2*ff 2.6. 设置RTK 1234567$cmd,set,localip,192,168,0,123*ff$cmd,set,localmask,255,255,255,0*ff$cmd,set,localgate,192,168,0,1*ff$cmd,set,netipport,203,107,45,154,8002*ff$cmd,set,netuser,username:password*ff$cmd,set,mountpoint,RTCM32_GGB*ff$cmd,set,ntrip,enable,enable*ff 2.6.1. 检查 1$cmd,get,netpara*ff 2.7. 设置PPS授时输出 12ppscontrol enable positive 1.0 10000log com3 gprmc ontime 1 0.25 2.8. 保存设置 1$cmd,save,config*ff ROS驱动代码 已上传至GitHub https://github.com/qpc001/M2_navsat_driver","categories":[],"tags":[]},{"title":"BASALT-2-3D点的参数化表达","slug":"SLAM代码课程/BASALT/BASALT-2-3D点的参数化表达","date":"2020-05-13T06:40:35.000Z","updated":"2020-05-13T07:44:13.000Z","comments":true,"path":"2020/05/13/SLAM代码课程/BASALT/BASALT-2-3D点的参数化表达/","link":"","permalink":"http://yoursite.com/2020/05/13/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/BASALT/BASALT-2-3D%E7%82%B9%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%96%E8%A1%A8%E8%BE%BE/","excerpt":"","text":"BASALT-2-3D点的参数化表达","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"BASALT","slug":"SLAM代码课程/BASALT","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/BASALT/"}],"tags":[]},{"title":"VINS-Mono-3-初始化和闭环","slug":"SLAM代码课程/VINS-MONO/VINS-Mono-3-初始化和闭环","date":"2020-04-30T01:10:56.000Z","updated":"2020-05-04T13:16:16.000Z","comments":true,"path":"2020/04/30/SLAM代码课程/VINS-MONO/VINS-Mono-3-初始化和闭环/","link":"","permalink":"http://yoursite.com/2020/04/30/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/VINS-Mono-3-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%92%8C%E9%97%AD%E7%8E%AF/","excerpt":"","text":"VINS-Mono-3-初始化和闭环 初始化 初始化要解决什么问题？ 总流程 视觉sfm 视觉-IMU对齐 已知条件 估计旋转外參\\(q_{bc}\\) 估计陀螺仪bias 初始化速度、重力向量和尺度因子 重力向量调优 坐标系对齐 开放性问题 闭环检测 闭环检测 取原始图像: 为了重新提取特征点，计算描述子 取特征点 特征恢复 建立数据关联: 闭环帧与新帧的特征点关联 计算约束 将约束加入Pose Graph 闭环节点 Process() 取后端关键帧，创建KeyFrame对象 提取已有的特征点描述子 提取新的Fast特征点和描述子 丢掉原始图像 进行闭环检测 暴力匹配: 使用当前帧所有特征点与闭环帧的所有特征点进行暴力匹配，同时匹配会产生大量外点","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"VINS-MONO","slug":"SLAM代码课程/VINS-MONO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/"}],"tags":[]},{"title":"第五章-线性系统的能控性和能观性","slug":"控制相关/线性系统理论/第五章-线性系统的能控性和能观性","date":"2020-04-29T13:19:53.000Z","updated":"2020-04-29T15:15:23.000Z","comments":true,"path":"2020/04/29/控制相关/线性系统理论/第五章-线性系统的能控性和能观性/","link":"","permalink":"http://yoursite.com/2020/04/29/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%83%BD%E6%8E%A7%E6%80%A7%E5%92%8C%E8%83%BD%E8%A7%82%E6%80%A7/","excerpt":"","text":"1. 线性系统的能控性和能观性 能控性和能观测性是现代控制理论中两个很重要的基础性概念，最优控制和最佳估计都是以它们的存在为条件的，是由 Kalmen（卡尔曼）1960年首先提出的。 可控性和可观测性就是回答“系统的状态是否能控制“和”状态的变化能否由输出测量出来这两个问题。 1.1. 例子 \\(x2=u_c\\)不能控 \\(x_1=i_L\\)不能观 2. 定义 2.1. 状态能控性 2.2. 状态能观性 3. 线性连续时间系统能控性判据 3.1. 线性定常系统能控性判据 假设有线性定常系统 \\[ \\left \\{ \\begin{aligned} &amp;\\dot{x}=Ax+Bu \\\\ &amp;x(0)=x_0 \\end{aligned} \\right. \\] 3.1.1. 格拉姆矩阵判据(Gram) 充要条件 格拉姆矩阵非奇异 3.1.2. 秩判据 3.1.2.1. 例子1 3.1.2.2. 例子2 3.1.3. PBH秩判据(Popov-Belevitch-Hautus) 3.1.3.1. 例子 3.1.4. 约当规范形判据 3.1.4.1. 例子1 3.1.4.2. 例子2 3.2. 线性时变系统能观性判据 设有线性时变系统 3.2.1. 格拉姆矩阵判据(Gram) 3.2.2. 秩判据 3.2.2.1. 例子 4. 线性连续时间系统的能观性判据 4.1. 线性定常系统 设有线性定常系统 4.1.1. 格拉姆矩阵判据(Gram) 4.1.2. 秩判据 4.1.3. PBH秩判据(Popov-Belevitch-Hautus) 4.1.4. 约当规范形判据 4.1.4.1. 例子1 4.1.4.2. 例子2 4.1.4.3. 例子3 4.1.4.4. 例子4 4.1.4.5. 例子5 4.2. 线性时变系统能观性判据 假设有线性时变系统 \\[ \\left \\{ \\begin{aligned} &amp;\\dot{x}=A(t)x , x(t_0)=x_0, t,t_0 \\in J \\\\ &amp;y=C(t)x \\end{aligned} \\right. \\] 4.2.1. 格拉姆矩阵判据(Gram) 4.2.2. 秩判据 5. 线性离散系统的能控性和能观性判据 5.1. 离散系统能控性 5.1.1. 线性时变离散系统——格拉姆矩阵判据 5.1.2. 线性定常离散系统——秩判据 5.2. 离散系统能观性 假设有线性离散系统 \\[ \\left \\{ \\begin{aligned} &amp;x(k+1)=G(k)x(k) \\\\ &amp;y(k)=C(k)x(k) \\end{aligned} \\right. \\] 5.2.1. 线性时变离散系统——格拉姆矩阵判据 5.2.2. 线性定常离散系统——秩判据 5.3. 统离散化后保持能控和能观的条件 5.3.1. 例子1 5.3.2. 例子2 6. 线性系统能控性与能观测性的对偶关系 7. 能控标准形和能观测标准形 7.1. 能控规范型 7.1.1. 例子 7.2. 能观规范型 7.2.1. 例子 8. 系统的能控性、能观测性和传递函数阵的关系 8.1. 系统的结构分解 8.1.1. 按能控性分解 8.1.1.1. 非奇异变换矩阵T的选取 8.1.1.2. 例子 8.1.2. 按能观性分解 8.1.2.1. 非奇异变换矩阵T的选取 8.1.2.2. 例子 8.1.3. 规范分解定理 结论 8.1.3.1. 传递函数矩阵的最小多项式表示形式 例子 8.1.4. 传递函数中零、极点相消定理 8.1.4.1. 例子","categories":[{"name":"控制相关","slug":"控制相关","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/"},{"name":"线性系统理论","slug":"控制相关/线性系统理论","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"}],"tags":[]},{"title":"倒立摆分析","slug":"控制相关/倒立摆分析","date":"2020-04-22T06:23:15.000Z","updated":"2020-05-18T06:42:36.000Z","comments":true,"path":"2020/04/22/控制相关/倒立摆分析/","link":"","permalink":"http://yoursite.com/2020/04/22/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E5%80%92%E7%AB%8B%E6%91%86%E5%88%86%E6%9E%90/","excerpt":"","text":"1. 倒立摆案例 2. 法一 2.1. 已知参数 假设: 摆的重心坐标\\((z+ l\\sin \\theta,l \\cos \\theta)\\) \\(\\theta\\)从垂直向上，向右为正方向 \\(u\\)向右为正方向 2.2. 对摆进行水平受力分析 摆在水平方向，受到接合处向右的力\\(H\\) 根据牛顿第二定律，\\(F=ma\\)，有 \\[ \\begin{aligned} H &amp;=m \\frac{d^2(z+l \\sin \\theta)}{dt^2} \\\\ &amp;=m\\frac{d( \\dot{z}+l \\cos \\theta \\dot{ \\theta })}{dt} \\\\ &amp;=m( \\ddot{z}+l \\cos\\theta \\ddot{ \\theta}-\\sin\\theta \\dot{ \\theta}^2) \\\\ &amp;=m\\ddot{z}+ml\\cos\\theta\\ddot{ \\theta }-ml\\sin\\theta\\dot{ \\theta }^2 \\end{aligned} \\tag{1} \\] 2.3. 对车进行水平受力分析 根据牛顿第二定律，\\(F=ma\\)，有 \\[ \\begin{aligned} u-H=M\\ddot{z} \\tag{2} \\end{aligned} \\] 将(1)带入(2)，得到 \\[ \\Rightarrow u=(M+m)\\ddot{z}++ml\\cos\\theta\\ddot{\\theta}-ml\\sin\\theta\\dot{\\theta}^2 \\tag{3} \\] 2.4. 对摆进行竖直方向受力分析 根据牛顿第二定律，\\(F=ma\\)，有 \\[ \\begin{aligned} v-mg&amp;=m\\frac{d^2(l\\cos\\theta)}{dt^2} \\\\ &amp;=m\\frac{d(l(-\\sin \\theta \\dot{\\theta}))}{dt} \\\\ &amp;=ml(-\\cos \\theta \\dot{\\theta}^2 - \\sin \\theta \\ddot{\\theta}) \\\\ &amp;=ml\\sin \\theta \\ddot{\\theta} - ml \\cos \\theta \\dot{\\theta}^2 \\end{aligned} \\tag{4} \\] 2.5. 对摆进行转矩平衡分析 在这里，将摆视为绕着杆的重心旋转，那么，杆在端点(也就是接合处)受到的力沿杆方向进行分解，可以得到两个作用相反的力，分别为\\(H\\cos \\theta\\)和\\(v \\sin \\theta\\)，不难发现，\\(H\\cos \\theta\\)使的角\\(\\theta\\)减小，而\\(v \\sin \\theta\\)使\\(\\theta\\)增大 根据转矩平衡，和外力转矩 = 转动惯量 * 角加速度，即有\\(M=J\\alpha\\)，得: \\[ vl\\sin \\theta - Hl \\cos \\theta = J \\ddot{\\theta} \\tag{5} \\] 又根据(1)和(4)， \\[ \\left \\{ \\begin{aligned} H=m\\ddot{z}+ml\\cos\\theta\\ddot{\\theta}-ml\\sin\\theta\\dot{\\theta}^2 \\\\ v=mg+ml\\sin \\theta \\ddot{\\theta} - ml \\cos \\theta \\dot{\\theta}^2 \\end{aligned} \\right. \\] 代入式(5)，得到 \\[ \\begin{aligned} -m\\ddot{z}l\\cos \\theta - ml^2(\\cos^2 \\theta-\\sin^2 \\theta)\\ddot{\\theta}+mgl\\theta = J \\ddot{\\theta} \\end{aligned} \\tag{6} \\] 2.6. 近似化简 \\(\\theta\\)很小的时候，近似有 \\[ \\begin{aligned} \\cos \\theta = 1 \\\\ \\sin \\theta =\\theta \\\\ (\\frac{d \\theta}{dt})^2=\\dot{\\theta}^2 \\approx0 \\end{aligned} \\] 因此，将式(3)和式(6)进行化简，有: \\[ \\left \\{ \\begin{aligned} u=(M+m)\\ddot{z}+ml \\ddot{\\theta} \\\\ (J+ml^2)\\ddot{\\theta}=-ml\\ddot{z}+mgl\\theta \\end{aligned} \\right . \\tag{7} \\] 求解方程组(7)，最终，可以得到系统的状态空间描述: \\[ \\begin{aligned} \\dot{X}= \\begin{bmatrix} \\dot{z} \\\\ \\ddot{z} \\\\ \\dot{\\theta} \\\\ \\ddot{\\theta} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{-m^2gl^2}{J(M+m)+Mml^2} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; \\frac{mgl(M+m)}{J(M+m)+Mml^2} &amp; 0 \\end{bmatrix} \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\frac{J+ml^2}{J(M+m)+Mml^2} \\\\ 0 \\\\ \\frac{-ml}{J(M+m)+Mml^2} \\end{bmatrix} u \\end{aligned} \\tag{8} \\] 进一步地，如果杆是均匀质杆，那么有转动惯量\\(J=\\frac{ml^2}{3}\\)， 代入到式(7)的第二个方程，有 \\[ \\begin{aligned} (\\frac{ml^2}{3}+ml^2)\\ddot{\\theta}=-ml\\ddot{z}+mgl\\theta \\end{aligned} \\tag{9} \\] 即可求出\\(\\ddot{\\theta}\\)的表达 \\[ \\ddot{\\theta}=\\frac{3g}{4l}\\theta-\\frac{3}{4l}\\ddot{z} \\] 如果令输入\\(u=\\ddot{z}\\)，那么，状态方程可以写成 \\[ \\begin{aligned} \\dot{X}= \\begin{bmatrix} \\dot{z} \\\\ \\ddot{z} \\\\ \\dot{\\theta} \\\\ \\ddot{\\theta} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; \\frac{3g}{4l} &amp; 0 \\end{bmatrix} \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\frac{-3}{4l} \\end{bmatrix} u \\end{aligned} \\tag{8} \\] 3. 法二 拉格朗日约束法 因此，假设有某个广义坐标\\(q\\)以及拉格朗日算子\\(L\\)，则拉格朗日方程可表示为: \\[ \\frac{d}{dt}(\\frac{d L}{d \\dot{q}})-\\frac{d L}{d q}=f \\] 其中，f为沿着广义坐标轴方向上的外力。 对于上述系统，定义由\\(z,\\theta\\)组成的广义坐标系，T为系统的动能，V为系统的是势能。 3.1. 小车动能 \\[ T_M=\\frac{1}{2}M\\dot{z}^2 \\tag{9} \\] 3.2. 杆动能 \\[ \\begin{aligned} T_m&amp;=\\frac{1}{2}mv^2+\\frac{1}{2}J\\dot{\\theta}^2 \\\\ &amp;=\\frac{1}{2}m\\{\\underbrace{[\\frac{d(z+l\\sin \\theta)}{dt}]^2}_{v_x}+\\underbrace{[\\frac{d(l\\cos \\theta)}{dt}]^2}_{v_y}\\}+\\frac{1}{2}J\\dot{\\theta}^2 \\end{aligned} \\tag{10} \\] 3.3. 系统总动能 \\[ \\begin{aligned} T=T_M+T_m &amp;=\\frac{1}{2}M\\dot{z}^2+\\frac{1}{2}mv^2+\\frac{1}{2}J\\dot{\\theta}^2 \\\\ &amp;=\\frac{1}{2}M\\dot{z}^2+\\frac{1}{2}m\\{\\underbrace{[\\frac{d(z+l\\sin \\theta)}{dt}]^2}_{v_x}+\\underbrace{[\\frac{d(l\\cos \\theta)}{dt}]^2}_{v_y}\\}+\\frac{1}{2}J\\dot{\\theta}^2 \\\\ &amp;=\\frac{1}{2}M\\dot{z}^2+\\frac{1}{2}m\\dot{z}^2+m\\dot{z}\\cos \\theta \\dot{\\theta}+\\frac{2}{3}ml^2\\theta^2 \\end{aligned} \\tag{11} \\] 3.4. 系统总势能 \\[ V=mgl\\cos \\theta \\] 3.5. 构造拉格朗日约束 拉格朗日算子 \\[ \\begin{aligned} L=T-V= \\frac{1}{2}M\\dot{z}^2+\\frac{1}{2}m\\dot{z}^2+m\\dot{z}\\cos \\theta \\dot{\\theta}+\\frac{2}{3}ml^2\\theta^2 - mgl\\cos \\theta \\end{aligned} \\tag{12} \\] 由于在广义坐标轴\\(\\theta\\)上没有外力作用，因此f=0,所以有s拉格朗日方程: \\[ \\frac{d}{dt}(\\frac{d L}{d \\dot{\\theta}})-\\frac{d L}{d \\theta}=0 \\tag{13} \\] 需计算如下 \\[ \\frac{d L}{d \\theta}=-m\\dot{z}l \\sin \\theta \\dot{\\theta}+ mgl \\sin \\theta \\tag{14} \\] \\[ \\frac{d L}{d \\dot{\\theta}}=m\\dot{z}l\\cos\\theta+\\frac{4}{3}ml^2\\dot{\\theta} \\tag{15} \\] \\[ \\frac{d}{dt}(\\frac{d L}{d \\dot{\\theta}}) = m\\ddot{z}\\cos \\theta - m \\dot{z}l\\sin \\theta \\dot{\\theta}+\\frac{4}{3}ml^2\\ddot{\\theta} \\tag{16} \\] 将式(14)(15)(16)代入式(13)，并且使用近似\\(\\cos \\theta=1 , \\sin \\theta=\\theta\\)，因此有 \\[ m\\ddot{z}l+\\frac{4}{3}ml^2\\ddot{\\theta}-mgl\\theta=0 \\tag{17} \\] 3.6. 系统状态空间表达 选取系统状态变量\\(X\\) \\[ \\begin{aligned} X= \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix}~~~ Y= \\begin{bmatrix} z \\\\ \\theta \\end{bmatrix} \\end{aligned} \\] 如果令输入\\(u=\\ddot{z}\\)，那么，根据式(17)，状态方程可以写成 \\[ \\begin{aligned} \\dot{X}= \\begin{bmatrix} \\dot{z} \\\\ \\ddot{z} \\\\ \\dot{\\theta} \\\\ \\ddot{\\theta} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; \\frac{3g}{4l} &amp; 0 \\end{bmatrix} \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\frac{-3}{4l} \\end{bmatrix} u \\end{aligned} \\tag{18} \\] \\[ \\begin{aligned} Y= \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} u \\end{aligned} \\tag{19} \\] 3.7. 能观性能控性分析 已知系统状态方程: \\[ \\begin{aligned} \\dot{X}= \\begin{bmatrix} \\dot{z} \\\\ \\ddot{z} \\\\ \\dot{\\theta} \\\\ \\ddot{\\theta} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; \\frac{3g}{4l} &amp; 0 \\end{bmatrix} \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\frac{-3}{4l} \\end{bmatrix} u \\end{aligned} \\] \\[ \\begin{aligned} Y= \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} u \\end{aligned} \\] 3.7.1. 构造能观性判别矩阵 \\[ \\begin{aligned} \\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ - &amp; - &amp; - &amp; - \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ - &amp; - &amp; - &amp; - \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{3g}{4l} &amp; 0 \\\\ - &amp; - &amp; - &amp; - \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\frac{3g}{4l} \\\\ \\end{bmatrix} \\end{aligned} \\] 可得，(实际上，仅需要算到CA的时候，就可以判断rank=4了) \\[ \\begin{aligned} rank \\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{bmatrix}=4 \\end{aligned} \\] 因此，系统完全能观 3.7.2. 构造能控性判别矩阵 \\[ \\begin{aligned} \\begin{bmatrix} B &amp; AB &amp; A^2b &amp; A^3B \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1-\\frac{3}{4l} &amp; 0 &amp; \\frac{-9g}{16l^2} \\\\ 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; -\\frac{3}{4l} &amp; 0 &amp; \\frac{-9g}{16l^2} \\\\ -\\frac{3}{4l} &amp; 0 &amp; \\frac{-9g}{16l^2} &amp; 0 \\end{bmatrix} \\end{aligned} \\] \\[ \\begin{aligned} rank \\begin{bmatrix} B &amp; AB &amp; A^2b &amp; A^3B \\end{bmatrix}=4 \\end{aligned} \\] 因此，系统完全能控 3.8. 稳定性分析 该一级倒立摆系统的状态空间方程为 \\[ \\left \\{ \\begin{aligned} \\dot{x}(t)=Ax(t)+Bu(t) \\\\ y(t)=Cx(t)+Du(t) \\end{aligned} \\right . \\] 可知，原系统是非线性系统，在平衡点处进行线性化，得到 \\[ \\begin{aligned} \\dot{X}= \\begin{bmatrix} \\dot{z} \\\\ \\ddot{z} \\\\ \\dot{\\theta} \\\\ \\ddot{\\theta} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; \\frac{3g}{4l} &amp; 0 \\end{bmatrix} \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\frac{-3}{4l} \\end{bmatrix} u \\end{aligned} \\] \\[ \\begin{aligned} Y= \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} z \\\\ \\dot{z} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} u \\end{aligned} \\] 取以下参数 \\(g=9.8m/s^2\\) \\(l=0.25m\\) 可以得到系统矩阵A如下 \\[ \\begin{aligned} A= \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 29.4 &amp; 0 \\end{bmatrix} \\end{aligned} \\] 利用特征方程\\(det(\\lambda I-A)=0\\)，可以计算出矩阵A的特征值: \\[ \\lambda_{1,2}=0, \\lambda_{3,4}=\\pm 5.42 \\] 因此，可以看到，系统有两个为0的特征根，另外两个特征根一个在复平面左侧，另外一个具有正的实部，根据Lyapunov第一法稳定判据，可以判断，原系统不稳定。","categories":[{"name":"控制相关","slug":"控制相关","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"Lego-Loam论文阅读","slug":"激光SLAM/Lego-Loam论文阅读","date":"2020-04-21T01:12:05.000Z","updated":"2020-04-21T04:19:43.000Z","comments":true,"path":"2020/04/21/激光SLAM/Lego-Loam论文阅读/","link":"","permalink":"http://yoursite.com/2020/04/21/%E6%BF%80%E5%85%89SLAM/Lego-Loam%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain 摘要 提出了一种轻量级的，地面优化的激光雷达里程计和建图方法——LeGO-LOAM，一种实时的六自由度的地面车辆位姿估计工具。 LeGO-LOAM是轻量级的，可以在低算力的嵌入式设备中达到实时的位姿估计，同时，也是地面优化的，在分割和优化步骤中，利用了地面信息的存在来加以优化。 首先应用点云分割来滤除噪声，然后特征提取，获得平面特征和边缘特征。一个两步的Levenberg-Marquardt优化方法，然后根据平面和边缘的特征，来求解连续扫描帧之间的六个自由度的变换。 我们使用LeGO-LOAM与当前先进的LOAM进行对比，使用从variable-terrain收集的地面车辆数据集，然后展示了LeGO-LOAM达到了相似或更好的准确度，并且减少了计算量。 我们也整合了LeGO-LOAM到SLAM框架中，来消除漂移导致的位姿估计误差。 介绍 第一步中，从地面获取的平面特征用来获得观测\\([t_z,\\theta_{roll},\\theta_{pitch}]\\) 第二步中，剩下的\\([t_x,t_y,\\theta_{yaw}]\\)通过匹配边缘特征(从分割的点云中获取的)来观测得到 我们也整合了回环检测功能来修正运动估计的漂移。 测试系统硬件 VLP-16（测量距离100米，准确度+-3m，垂直视场角+-15度，水平视场角360度），16线雷达提供了垂直的角度分辨率为2度，水平分辨率0.1度到0.4度，基于旋转的速率 HDL-64E（KITTI数据集中），垂直视场角26.9度，水平360度，但是有48线 I7-4710MQ，2.5Ghz TX2——ARM Cortex-A57 CPU 系统概述 全系统概况 提出的框架如图1所示 全系统分为5个部分 (1)分割 取一帧扫描点云，然后投影到range Image用来进行分割(分段)，分割之后的点云被送到特征提取模块 (2)特征提取 对range Image进行特征提取，提取平面和线特征？ (3)lidar Odometry 使用提取得到的特征，寻找连续两帧之间的变换 (4)lidar Mapping 这些特征进一步的交给lidar mapping来处理，对他们进行全局的配准 (5)整合 最后，融合lidar Odometry和lidar Mapping模块的位姿估计，输出最终的位姿估计 提出的框架是为了提高地面车辆的位姿估计的效率和准确度 分割模块 令\\(P_t={p_1,p_2,\\cdots,p_n}\\)为在t时刻获得的点云，其中\\(p_i\\)是点云\\(P_t\\)中的一个点。 \\(P_t\\)首先被投影到range Image上，分辨率是1800×16（360/0.2×16）,因为VLP-16的水平和垂直角分辨率是0.2度和2度。点云中每一个有效点\\(p_i\\)在深度图中使用一个独特的像素点来表示。深度值\\(r_i\\)与点\\(p_i\\)所代表的点\\(p_i\\)到传感器的欧式距离有关。 由于斜坡地形在许多环境中都很常见，所以我们不假定地面是平的。 对距离图像进行按列估计，可看作是对地平面的估计，因此在分割之前，进行地面点提取。 经过这一步处理，可能代表地面的点被标记为ground，然后不参与下一步分割。 然后，将一种基于图像的分割方法[23]应用到深度图中，将点分组成多个簇，同一簇的点被分配得到一个独特的label。注意，地面点是一个特殊的簇。 对点云进行分割，有利于提高后面处理效率和特征提取的准确度。假设机器人在噪声较大的环境下运行，小的物体如树叶，可能会形成一些琐碎且不可靠的特征，因为在连续两次扫描中不太可能看到。 为了对点云进行快速可靠的特征提取，我们忽略小于30个点的簇，分割前后的点云如图2所示 原始的点云包含许多点，这些点是从周围的植被中获得的，这些植被可能产生不可靠的特征。 经过处理之后，仅有图2(b)所示的点云可能包含着大的物体，如卡车和地面点，这些用于进一步的处理，同时，深度图也仅仅保留这部分点的信息。 我们同时有了每个点的3个属性 标签（地面点标签、分割的标签） 深度图中的行和列索引 代表的距离值 特征提取 特征提取与文献[20]相似，不同的是，我们从地面点和点云分割之后点进行特征提取，而不是对原始点云数据进行特征提取。 令\\(\\mathcal{S}\\)作为深度图中与点\\(p_i\\)同一行的连续点集合。 有一半的点是点\\(p_i\\)的另一面（另一个方向）。在本文，设置\\(|S|\\)为10 我们可以计算出S中点\\(p_i\\)的粗糙度 计算每个点\\(p_i\\)的粗糙度，令S作为range image中同一行的连续点\\(p_i\\)的点集 为了从所有方向均匀地提取特征，将range image水平划分为几个相等的sub-image 按每个点的粗糙度值 对sub-image的每一行中的点进行排序 使用阈值\\(c_{th}\\)来区分不同特征的类别，大于阈值的，被认为是边特征，小于阈值的则被认为是平面特征。 从sub-image的每一行中选取不属于地面，且有前\\(n_{\\mathbb{F}_e}\\)个最大c值的边特征 从sub-image的每一行中选取前\\(n_{\\mathbb{F}_p}\\)个最小c的平面特征点（可以标记为地面或分段点） \\(\\mathbb{F}_e\\)和\\(\\mathbb{F}_p\\)为所有sub-image的边缘和平面特征集合，如图2(d) 从子图中的每一行提取具有最大c的\\(n_{Fe}\\)个边缘特征，他们肯定不属于地面 从子图中的每一行提取具有最小c的\\(n_{Fp}\\)个平面特征，他们肯定是地面点 前两步(8,9)产生了绝对的边缘集合\\(F_e\\)和平面集合\\(F_p\\)，特征如图2(c)，其中,\\(F_e \\subset \\mathbb{F}_e，F_p \\subset \\mathbb{F}_p\\) 将360°范围图像分为6个子图像。每个子图像的分辨率为300x16。令\\(n_{Fe}=2,n_{Fp}=4,n_{\\mathbb{F}_e}=40,n_{\\mathbb{F}_p}=80\\) 激光里程计 激光雷达测程模块估计两个连续扫描之间传感器的运动。通过点-边和点-面扫描匹配，实现了连续两帧扫描之间的变换关系. 换句话说，需要从前一帧的\\(\\mathbb{F}_e^{t-1},\\mathbb{F}_{p}^{t-1}\\)找到当前帧的绝对特征\\(F_e^t,F_p^t\\)点的关联 改进点 标签匹配： 因为\\(F_e^t,F_p^t\\)中的每个特征都有标签，我们只从\\(\\mathbb{F}_e^{t-1},\\mathbb{F}_{p}^{t-1}\\)找具有相同标签的关联。 对于\\(F_p^t\\)中的平面特征，只有\\(\\mathbb{F}_{p}^{t-1}\\)中被标记为地面的点才用来寻找关联。 对于\\(F_e^t\\)中的边缘特征，只从\\(\\mathbb{F}_e^{t-1}\\)寻找对应的边缘关联。 这种方式提高匹配准确性，缩小了潜在对应特征的数量。 两步LM优化 将\\(F_p^t\\)中的平面点和\\(\\mathbb{F}_{p}^{t-1}\\)中的特征相匹配，估计得到\\([t_z,\\theta_{roll},\\theta_{pitch}]\\) 将\\(F_e^t\\)中的边缘点与\\(\\mathbb{F}_e^{t-1}\\)中的特征点进行匹配，加上前一步估算的\\([t_z,\\theta_{roll},\\theta_{pitch}]\\)作为附加条件，得到剩下的\\([t_x,t_y,\\theta_{yaw}]\\) 虽然\\([t_x,t_y,\\theta_{yaw}]\\)也可以放在第一步进行，但是这样准确度不高，得到的结果难以在第二步中使用 两个连续扫描之间的6自由度通过对\\([t_z,\\theta_{roll},\\theta_{pitch}]\\)和\\([t_x,t_y,\\theta_{yaw}]\\)融合得到 两步LM优化，可以达到相同的精度，计算时间减少35% 激光建图 建图模块以较低的频率运行，匹配\\(\\{\\mathbb{F}_e^{t},\\mathbb{F}_{p}^{t}\\}\\)中的特征到之前获得的附近的点云地图\\(\\bar{Q}^{t-1}\\)上，来优化位姿估计。然后使用LM迭代，再次进行全局优化 详细的匹配和优化过程，阅读文献[20] LEGO-LOAM一个主要的不同是，如何存储最终点云图：采用的是单独地储存特征集合\\(\\{\\mathbb{F}_e^{t},\\mathbb{F}_{p}^{t}\\}\\)，而不是储存单个完整的点云地图。 例如，\\(M^{t-1}=\\{\\{\\mathbb{F}_e^{1},\\mathbb{F}_{p}^{1}\\}\\cdots,\\{\\mathbb{F}_e^{t-1},\\mathbb{F}_{p}^{t-1}\\} \\}\\)表示以前的所有特征集合的集合，\\(M^{t-1}\\)中的每个特征集合都与该时刻的激光雷达位姿相关联，然后从\\(M^{t-1}\\)获取点云地图\\(\\bar{Q}^{t-1}\\)有两种方法 一，和Zhang Ji论文类似，选择在传感器视野里面的特征点集获得\\(\\bar{Q}^{t-1}\\)，为了简化，我们选择当前传感器位置100米范围内的特征集合，被选择的特征集合经过变换然后融合到一个点云地图\\(\\bar{Q}^{t-1}\\)中 二，在LeGO-LOAM中集成了图优化的方法 1) 图的节点: 每个特征集合对应的传感器位姿 特征集合\\(\\{\\mathbb{F}_e^{t},\\mathbb{F}_{p}^{t}\\}\\)被看作为这个节点上的传感器测量数据 2) 激光雷达建图模型的位姿估计漂移一般比较低，可以假设在短时间内没有位姿漂移(drift)。通过选择一组最近几帧的特征集合来构成点云地图\\(\\bar{Q}^{t-1}\\)，如\\(\\bar{Q}^{t-1}=\\{\\{\\mathbb{F}_e^{t-k},\\mathbb{F}_{p}^{t-k}\\}\\cdots,\\{\\mathbb{F}_e^{t-1},\\mathbb{F}_{p}^{t-1}\\} \\}\\)，其中，k表示选取集合的数量 3) 新的节点(当前帧位姿)和\\(\\bar{Q}^{t-1}\\)中被选择的节点之间加上空间约束，（通过前端LM变换得到的坐标变换） 4) 使用回环检测(loop closure)进一步消除雷达建图的漂移，如果用ICP发现当前特征集和先前特征集之间有匹配，则添加新约束，然后通过将Pose Graph发送到如[24]（iSAM2）的优化系统来更新位姿估计。","categories":[{"name":"激光SLAM","slug":"激光SLAM","permalink":"http://yoursite.com/categories/%E6%BF%80%E5%85%89SLAM/"}],"tags":[]},{"title":"VINS-Mono-2-后端","slug":"SLAM代码课程/VINS-MONO/VINS-Mono-2-后端","date":"2020-04-20T01:25:12.000Z","updated":"2020-04-20T03:32:16.000Z","comments":true,"path":"2020/04/20/SLAM代码课程/VINS-MONO/VINS-Mono-2-后端/","link":"","permalink":"http://yoursite.com/2020/04/20/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/VINS-Mono-2-%E5%90%8E%E7%AB%AF/","excerpt":"","text":"VINS-Mono-后端 class Estimator 对于单目来说，Camera Id始终为0 特征点管理器 因子图 视觉约束 因子图与Hessian矩阵的转换 IMU约束 一个简化的例子 滑窗优化 重投影误差约束 对应代码部分 IMU误差项约束 边缘化 VINS-Mono的边缘化策略 边缘化策略代码部分 边缘化的因子图表示 边缘化管理器 构建边缘化Hessian","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"VINS-MONO","slug":"SLAM代码课程/VINS-MONO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/"}],"tags":[]},{"title":"VINS-Mono-1-前端","slug":"SLAM代码课程/VINS-MONO/VINS-Mono-1-前端","date":"2020-04-18T09:10:21.000Z","updated":"2020-04-20T01:25:19.000Z","comments":true,"path":"2020/04/18/SLAM代码课程/VINS-MONO/VINS-Mono-1-前端/","link":"","permalink":"http://yoursite.com/2020/04/18/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/VINS-Mono-1-%E5%89%8D%E7%AB%AF/","excerpt":"","text":"VINS-Mono整体架构 架构 ROS基础 整体代码流程图 前端 处理图片流程 这里的cur_img实际上是上一帧，只是它在这里是这样定义而已。 假设第一帧跟踪了5个点 第二帧，跟踪到了0,1,2,4号点，另外有新的特征点5 可以看到，特征点0,1,2,4同时被第一帧和第二帧观测到，因此被观测次数是2 ... 直方图均衡化 代码中是直接调用Opencv函数来处理的，用来增强对比度 参数越大，对比度越大，噪点越多 光流跟踪 也是直接调用Opencv函数 异常点剔除——基础矩阵法 也是直接调用Opencv函数 特征点提取 也是直接调用Opencv函数 前端发布消息 根据时间戳挑选观测数据 getMeasuments() 挑选策略 前端视觉+IMU联合优化 简单来说，就是使用IMU数据来给视觉提供初始位姿，来进行跟踪 IMU预积分 根据两帧图像之间的所有IMU数据，来计算IMU约束（预积分） 然后计算IMU预积分误差residual，下图黄色框部分 IMU预积分误差的协方差矩阵 IMU预积分误差协方差更新公式 协方差更新变化过程 第0帧 第1帧 ... 第20帧 IMU预积分误差的雅可比更新变化过程","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"VINS-MONO","slug":"SLAM代码课程/VINS-MONO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/"}],"tags":[]},{"title":"Vins-Mono论文阅读","slug":"SLAM代码课程/VINS-MONO/Vins-Mono论文阅读","date":"2020-04-13T07:36:52.000Z","updated":"2020-04-22T12:51:20.000Z","comments":true,"path":"2020/04/13/SLAM代码课程/VINS-MONO/Vins-Mono论文阅读/","link":"","permalink":"http://yoursite.com/2020/04/13/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/Vins-Mono%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"1. VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator 2. 摘要 单目VI系统，由单目相机和一个低成本IMU组成，形成6自由度的状态估计器。 然而，由于单目相机缺乏直接的距离测量，在IMU处理、估计器初始化、外部校准和非线性优化方面提出了重大的挑战。 在本文，提出了\\(VINS-Mono\\)，一种鲁棒、通用的单目VI状态估计器。 作者提出的方法从一个鲁棒的处理开始，可用于初始化和故障恢复。通过紧耦合的形式和非线性优化的方法，通过融合的IMU数据预积分和特征观测来获得高精度的VI里程计 在回环检测模块，结合了紧耦合的公式，使得重定位部分的计算量得以减小 最后，增加了四个自由度的位姿图优化，以增强全局一致性。 在公共数据集和真实世界的实验中验证了我们的系统的性能，并与其他最先进的算法进行了比较，我们还在MAV平台上进行了机载闭环自主飞行，并将算法移植到基于ios的演示中，作者强调，所提出的工作是一个可靠、完整和通用的系统，适用于需要高精度定位的不同应用 3. 介绍 仅使用单目摄像机的方法因其体积小、成本低和易于硬件设置而引起了社区的极大兴趣，然而，单目视觉系统无法恢复度量尺度，因此限制了它们在现实机器人应用中的使用，近年来，我们发现利用低成本惯性测量单元(IMU)来辅助单目视觉系统的发展趋势。 这种单目视觉惯性系统(VINS)的主要优点是具有可观测的尺度，以及滚转角(roll)和俯仰角(pitch)，这将可以支持需要尺度的状态估计的导航任务 另外，对IMU测量进行积分，可以通过消除视觉轨迹损失之间的差距来显著提高运动跟踪性能，这些视觉轨迹间隙损失来源于：光度变化、纹理缺乏的场景或者是运动模糊，等等。 事实上，单目VINS不仅广泛应用于移动机器人、无人机和移动设备，它也是实现充分自我感知和环境感知的最低传感器设置。 1） 初始化 然而，这些优点同时也带来一些代价，对于单目VINS，加速度激励是使度量尺度可见的必要条件，这意味着单目VINS估计器不能从静止状态出发，而是从未知的运动状态出发(意思是: 初始化过程需要有一定的运动)。同时，我们也认识到视觉惯性系统是高度非线性的，因此在估计初始化方面我们面临着巨大的挑战。另外，由于使用两个传感器，两个传感器的存在也使得相机-IMU的外部标定变得至关重要。 因此，作者提出VINS-Mono，我们的解决方案从动态的评估器初始化开始，对于故障恢复，也使用同样的初始化模块。 2） 核心处理 该方法的核心是一种基于紧耦合滑动窗口非线性优化的VIO方法，单眼VIO模块不仅提供精确的位置、速度和方位估计，它还执行相机-IMU外部校准和IMU偏差的在线标定矫正。 3） 回环、重定位 回环检测部分，使用DBOw2，通过与单目VIO进行特征级融合，在紧密耦合的环境中实现重定位功能。这使得重定位所需的计算开销大大减小 4） 位姿图 最后，几何验证的回环添加到位姿图，得益于单目VIO的可观察的roll和pitch角，可执行一个四自由度(DOF)位姿图，以确保全局的一致性。 5） 小结 与我们之前的工作相比，VINS-Mono的进一步改进包括改进的IMU预集成和偏差校正、紧耦合重定位、全局位姿图优化、广泛的实验评估和健壮的、通用的开源实现 整个系统功能齐全，使用方便。它已成功地应用于小型AR场景、中型无人机导航和大型状态估计任务，优越的性能已显示出与其他先进的方法。为此，我们总结了我们的贡献如下: 一个鲁棒的初始化过程，能够从未知的初始状态引导系统 种紧密耦合的、基于优化的单目视觉惯性测程方法，具有摄像机-IMU外部校准和IMU偏置估计功能 在线回环检测以及紧耦合的重定位 四自由度的位姿图优化 用于无人机导航、大规模定位和移动AR应用的实时性能演示 与ROS完全集成的PC版本和运行在iPhone6s或以上的iOS系统的开源版本 4. Relative Work 。。。 5. 系统概述 提出的VI状态估计器如图2所示 该系统从测量预处理开始，其中包括特征提取和跟踪，IMU测量之间的两个连续帧预积分 初始化过程(V节提供了所有必要的值，包括姿态、速度、重力向量、陀螺仪偏差和3D特征位置)，用于引导后续基于非线性优化的VIO VIO与重定位模块紧密地融合了IMU测量的预积分、特征观测和从回环中重新检测的特征 最后，位姿图优化模块经过采用几何验证的重定位结果，进行全局优化以消除漂移。 下面是一些角标的定义 \\((\\cdot)^w\\)表示世界坐标系(导航坐标系) 重力g的方向与世界坐标系的z轴对齐，\\(g^w=[0,0,g]^T\\)代表了世界坐标系的重力向量 \\((\\cdot)^b\\)是机体坐标系，也定义为IMU的坐标系 \\((\\cdot)^c\\)是相机坐标系 使用旋转矩阵\\(R\\)和哈密顿四元数\\(q\\)来表示旋转(我们主要在状态向量中使用四元数，但旋转矩阵也用于方便地旋转三维向量) \\(q_b^w,p_b^w\\)代表了从body坐标系到world坐标系的旋转和平移变换 \\(b_k\\)是在第k帧图片的机体坐标系 \\(c_k\\)是在第k帧图片的相机坐标系 \\(\\otimes\\)代表了两个四元数之间的乘法运算 \\((\\hat{\\cdot})\\)用来表示噪声观测或者是不确定性的估计 5.1. 测量预处理 本节介绍惯性和单目视觉测量的预处理步骤： 对于视觉测量，我们跟踪连续帧之间的特征，并在最新帧中检测新特征 对于IMU测量，我们预积分两帧之间的数据（注意，我们使用的低成本IMU的测量受到偏差和噪声的影响。因此，我们特别在IMU预积分过程中考虑了bias） 5.1.1. 视觉前端处理 对于每一帧新的图像，使用KLT系数光流法来跟踪已有的特征点，同时，会检测新的角点特征，来保持每帧图片中最小的特征点数目在(100~300)之间，该特征点检测器通过设置两个相邻特征之间的最小像素间隔来实现均匀的特征分布。 首先对二维特征点进行去畸变处理，经过外点去除后将其投影到单位球面上？？ （外点去除采用基础矩阵模型RANSAC处理） 关键帧选取也在这个步骤中进行，主要根据两条准则来选取 一是与前一帧的平均视差 (如果当前帧和最新关键帧 跟踪到的特征点的平均视差超过了阈值范围，就认为当前帧可作为新的关键帧，需要注意的是，这里不仅仅是平移，旋转也可以导致视差的变化)。另外，如果仅有旋转，那么跟踪得到的特征点无法完成三角化过程，为了避免这种情况，在计算视差时，我们使用陀螺测量的短期积分来补偿旋转。 注意：这个旋转补偿仅用于关键帧的选取，不包含在VINS公式的旋转项中，最后，尽管IMU角速度测量包含了较大的噪声或者收到bias的影响，这只会导致次优的关键帧选取结果，并不会直接影响最终估计的质量。 另外一个准则是: 跟踪质量，如果跟踪的特征点数量低于阈值，那么这一帧会作为新的关键帧，这个标准是为了避免完全丧失特征的情况 5.1.2. IMU预积分 IMU预积分首先被[22]提出，使用欧拉角形式对旋转误差进行参数化。 在我们先前的工作中，提出了一种流形空间的IMU预积分，这使得可以利用连续时间IMU误差状态动态方程推导出协方差传播，然而，先前的工作忽略了IMU的bias的影响，在这篇论文中，我们通过加入IMU偏置校正来扩展我们在之前的工作[7]中提出的IMU预积分。 IMU的原始角速度和加速度测量值\\(\\hat{w},\\hat{a}\\)可以表示为如下: IMU测量值，是在body系下的，结合了重力，机体的动态，加速度bias，角速度bias，噪声。我们假设，额外的噪声项是高斯噪声，即\\(n_a \\sim \\mathcal{N}(0,\\sigma_a^2), n_w \\sim \\mathcal{N}(0,\\sigma_w^2)\\)。加速度bias和角速度bias使用随机游走模型，也可以使用高斯分布来表示，即\\(n_{ba}\\sim \\mathcal{N}(0,\\sigma_{ba}^2),n_{bw}\\sim\\mathcal{N}(0,\\sigma_{bw}^2)\\)，并且有: 那么，给定两个图像帧所对应的时刻，可以在时间步\\([t_k,t_{k+1}]\\)内使用IMU测量对世界坐标系下的位置，速度和旋转状态进行传播: 其中，\\(\\Delta t_k\\)是\\([t_k,t_{k+1}]\\)的时间间隔 可以看到，IMU状态传播需要第k帧的的位置，速度和旋转状态。 当起始状态（即第k帧的位置，速度和旋转）发生变化的时候，我们需要对IMU的测量信息重新传播，即需要重新积分。这样一来，特别是在基于优化的算法中，每次我们调整姿态时，都需要在它们之间重新传播IMU测量值，这样的传播策略需要很强的计算能力. 为了避免这样的重传播情况，我们采用预积分算法：把参考坐标系从world frame变为k时刻的机体坐标系\\(b_k\\)，我们可以得到预积分: 上面的 \\(R_{w}^{b_{k}}\\): 将数据从世界坐标系转换到k时刻的机体坐标系的旋转变换 \\(R_{w}^{b_k} p_{b_{k+1}}^{w}\\)指的是将k+1时刻在世界坐标系下的机体位置转换到k时刻的机体坐标系\\(b_k\\)后得到的东西 \\(p_{b_{k+1}}^{w}\\)指的是将k+1时刻在世界坐标系下的机体位置 \\(R_{w}^{b_k} v_{b_{k+1}}^w\\)是k+1时刻在世界坐标系下的机体速度转换到k时刻的机体坐标系\\(b_k\\)后得到的东西 \\(v_{b_{k+1}}^w\\)是k+1时刻在世界坐标系下的机体速度 \\(q_{w}^{b_k}\\)是k时刻世界坐标系下的机体姿态，也就是从世界坐标系转换到k时刻的机体坐标系的旋转变换 \\(R_{t}^{b_k}\\)是指在\\([t_k,t_{k+1}]\\)内的某个时刻t，机体相对于k时刻的机体坐标系的姿态，即表示从时刻 \\(t \\in [t_k,t_{k+1}]\\)到k时刻的机体坐标系的旋转变换 \\(\\alpha_{b_{k+1}}^{b_{k}}\\)指相对于k时刻机体坐标系的位置积分，即这个位置积分量是在k时刻的机体坐标系\\(b_{k}\\)下的 \\(\\beta_{b_{k+1}}^{b_{k}}\\)指相对于k时刻机体坐标系的速度积分，即这个速度积分量是在k时刻的机体坐标系\\(b_{k}\\)下的 可以看到，通过改变参考坐标系为第k帧的机体坐标系\\(b_k\\)，可以使得这些预积分项\\(\\alpha,\\beta,\\gamma\\)基本上只与IMU的测量有关，与第k帧的位置，速度和旋转无关， 即\\(\\alpha_{b_{k+1}}^{b_k},\\beta_{b_{k+1}}^{b_k},\\gamma_{b_{k+1}}^{b_k}\\)与IMU的偏置\\(b_{at},b_{wt}\\)有关，然而这个偏置变化一般较小，如果变化了，我们可以使用一阶近似，然后重新计算预积分，否则，预积分只需计算一次就可以了{这里说的操作，对应于式(12)} 这个预积分策略大大减少了运算量，因为这样使得不需要每次更新完状态之后都重新传播IMU的测量 对于离散时间实现 对于离散时间，有不同的数值积分方法，如欧拉法，中点法，RK4法等等，在这里，选择了欧拉法进行推导，方便理解(实际代码中，使用了中点法积分) 在预积分起始时刻，即\\([t_k,t_{k+1}]\\)中的\\(t_k\\)时刻，\\(\\alpha_{b_k}^{b_k},\\beta_{b_k}^{b_k}\\)都是零，而\\(\\gamma_{b_k}^{b_k}\\)则是单位四元数，因为还没有开始积分 那么，\\(\\alpha,\\beta,\\gamma\\)的均值根据下面的步骤来进行传播，(需要注意的是，噪声项\\(n_a,n_w\\)是未知的，置为0)，这产生了预积分项的估计值，使用\\((\\hat{\\cdot})\\)来表示: 其中， \\(i\\)表示在\\([t_k,t_{k+1}]\\)时间段内的离散化时刻，(即两帧图像之间有很多个时刻的IMU测量值) \\(\\delta t\\)是IMU测量间隔 然后，我们需要处理协方差的传播，因为4自由度的旋转四元数\\(\\gamma_{t}^{b_k}\\)是超参数化的，我们定义其误差项为 在其均值附近的一个小扰动: 其中，\\(\\delta \\theta_t^{b_k}\\)是三维的小扰动 因此，可以推导出连续时间下，关于式(6)的误差项进行线性化之后的动态方程: 这里，有点跟误差状态卡尔曼 类似，具体见里面的式(166) \\(P_{b_{k+1}}^{b_k}\\)可以使用离散时间的一阶近似进行递归计算得到，初始化协方差\\(P_{b_{k}}^{b_k}=0\\): 其中，Q是关于噪声项\\((\\sigma_{\\alpha}^2,\\sigma_{w}^2,\\sigma_{b_a}^2,\\sigma_{b_w}^2)\\)对角型的协方差矩阵 同时，关于预积分误差项\\(\\delta z_{b_{k+1}}^{b_k}\\)分别对于预积分误差项\\(\\delta z_{b_{k}}^{b_k}\\)的一阶雅克比\\(J_{b_{k+1}}\\)，也可以使用初始化的雅克比\\(J_{b_k}=I\\)进行递归计算得到，即: 使用递归公式，我们可以得到协方差矩阵\\(P_{b_{k+1}}^{b_k}\\)，以及雅克比\\(J_{b_{k+1}}\\) \\(\\alpha_{b_{k+1}}^{b_k},\\beta_{b_{k+1}}^{b_k},\\gamma_{b_{k+1}}^{b_k}\\)相对于bias的一阶近似可以写成: 其中， \\(J_{b_a}^\\alpha\\) 是\\(J_{b_{k+1}}\\)的子块，其位置与\\(\\frac{\\delta \\alpha_{b_{k+1}}^{b_k}}{\\delta b_{a_{k}}}\\)相对应 对于\\(J_{b_w}^\\beta,J_{b_a}^\\beta,J_{b_{w}}^\\beta,J_{b_{w}}^\\gamma\\)也同样 当bias的估计发生轻微变化时，我们使用(式12)来矫正预积分的结果，而不是使用重新传播的方式。 现在，我们可以写成IMU测量(预积分)模型以及对应的协方差矩阵\\(P_{b_{k+1}}^{b_k}\\) 实际上，这里就是将(式5)关于预积分项移到等式左侧，其他移到右侧，得到的结果 5.2. 初始化 单目紧耦合的VI里程计是高度非线性系统，因为尺度不能直接从单目相机中获取，因此如果没有很好的初始化值，很难直接对两种测量信息进行融合。 一方面可能会假设一个静止的初始条件来启动VINS估计器，然而，这种假设是不恰当的，由于运动下的初始化是经常遇到的现实世界的情况。当IMU的测量收到大的bias影响的时候，这种情况变得更加复杂。 实际上，对于单目VINS，初始化通常式最脆弱的步骤，系统的可行性需要一个鲁棒的初始化处理。 采用了紧耦合的传感器融合方法来获取初始值，我们发现，仅仅使用视觉的SLAM，或者是Sfm，初始化具有一个好的属性。在大多情况下，visual-only的系统可以通过相对运动关系方法如八点法、五点法或者是估计单应矩阵H，来进行初始化。 通过使用visual-only Sfm的结果来对齐IMU预积分，我们可以粗略的恢复出尺度、重力、速度、甚至是bias，这对于单目VINS的初始化而言已经足够了，如图4所示。 与文献[17]相反，在初始化阶段，其同步估计角速度和加速度的bias。而我们选择在初始化阶段，忽略加速度的bias。加速度的bias与重力耦合在一起，相对于较大的重力向量，小量的平台的动态在这个初始化阶段，这些bias项很难被观测到。 5.2.1. 滑动窗口：Vision-Only SFM 初始化处理的开始阶段：先使用vision sfm来估计相机的pose和特征点的position 为了降低运算的复杂度，我们保持一个有界的滑动窗口。首先，我们检查最新的一帧与之前的所有帧的特征点的相关性。如果我们在最新的一帧与滑动窗口中的任意一帧中，可以找到稳定的特征点跟踪(more than 30 tracked features)同时，视差足够大(大于 20 个 rotation-compensated pixels)。我们使用五点法来恢复出这两帧之间的相对旋转和平移量[文献33]。否则，我们我们保存最新一帧在滑动窗口中，等待其他新的一帧到来。 如果五点法计算成功，我们设置一个任意的尺度，然后对两帧之间的特征点关联进行三角化，然后基于这些三角化得到的特征点(三角化变成了3D点)，对滑动窗口内的其他帧使用PnP算法来估计出滑窗内其他帧的位姿估计。 最后，使用global BA来进行优化，以最小化所有特征点的重投影误差。因为我们没有任何关于世界坐标系的先验知识，因此我们设置第一帧的相机坐标系作为sfm的参考坐标系\\((\\cdot)^{C_0}\\)，所有帧的位姿\\((\\bar{p}_{C_k}^{C_0},q_c^b)\\)以及特征点都是相对于坐标系\\((\\cdot)^{C_0}\\)而言的。假设我们有一个粗略的关于机体坐标系和相机坐标系的外参\\((p_c^b,q_c^b)\\)，我们可以把每一帧的相机坐标系转换为机体坐标系: 其中，\\(s\\)是以米为单位的尺度因子，求解尺度参数是成功初始化的的关键 5.2.2. VI对齐 5.2.2.1. Gyro Bias标定 考虑滑动窗口中连续的两帧的机体坐标系\\(b_k,b_{k+1}\\)，我们从视觉的SFM中可以获得这两帧机体坐标系相对于参考坐标系的旋转\\(q_{b_k}^{c_0},q_{b_{k+1}}^{c_0}\\)，另外，我们可以从IMU预积分数据中获取这两个图像帧之间的预积分约束\\(\\hat{\\gamma}_{b_{k+1}}^{b_k}\\)，我们对IMU预积分项相对于gyro bias参数进行线性化，然后最小化下面的损失函数: 其中 \\(\\mathcal{B}\\)是滑动窗口中所有帧的集合 通过使用前面推导的bias雅克比，我们有\\(\\hat{\\gamma}_{b_{k+1}}^{b_k}\\)关于gyro bias的一阶近似 在这种方式下，我们获得了关于gyro bias的初始标定 然后我们使用新的gyro bias值，对IMU的预积分项\\(\\alpha_{b_{k+1}}^{b_k},\\beta_{b_{k+1}}^{b_k},\\gamma_{b_{k+1}}^{b_k}\\)进行重传播 5.2.2.2. 速度、重力向量、尺度的初始化 在gyro bias初始化完成之后，我们进一步初始化其他状态，定义这些状态为: 其中: \\(v_{b_k}^{b_k}\\)是在机体坐标系\\(b_k\\)的速度 \\(g^{c_0}\\)是在参考坐标系\\(c_0\\)坐标系的重力向量 \\(s\\)是单目sfm的尺度参数，以米为单位 考虑两个连续的坐标系\\(b_k,b_{k+1}\\)，把(式5)中的世界坐标系换成参考坐标系\\((\\cdot)^{c_0}，\\)那么(式5)可以写成如下形式: 我们可以结合(式14)和(式17)到如下线性测量模型: 可以看到， \\(R_{b_{k}}^{c_0},R_{b_{k+1}}^{c_0},\\bar{p}_{c_k}^{c_0},\\bar{p}_{c_{k+1}}^{c_0}\\)都是从单目sfm中获取到的值 \\(\\Delta t\\)是两个连续图像帧之间的时间间隔 通过求解如下线性最小二乘: 我们可以获取每一帧的机体坐标系的速度，以及在参考坐标系\\((\\cdot)^{c_0}\\)的重力向量以及尺度参数 5.2.2.3. 重力对齐 通过量级的约束，可以对原线性初始化步骤(即上面的步骤)得到的重力矢量进行修正。 在大多情况下，重力向量的量级是已知的，这会导致重力向量仅有2自由度，因此，我们对重力向量在其正切空间使用2个变量来重新参数化 我们的参数化使用\\(g\\cdot \\bar{\\hat{g}}+w_1 b_1 +w_2b_2\\)来表示重力向量 其中 \\(g\\)是已知重力的量级 \\(\\bar{\\hat{g}}\\)是代表重力方向的单位向量 \\(b_1,b_2\\)是两个正交基章程的正切平面，如图5所示 \\(w_1,w_2\\)是对应于\\(b_1,b_2\\)两个基的位移 使用下面的算法1进行叉乘，我们可以找到\\(b_1,b_2\\)，然后我们将(式17)中的重力向量\\(g\\)使用\\(|g|\\cdot \\bar{\\hat{g}}+w_1 b_1 +w_2b_2\\)来替换，然后求解\\(w_1,w_2\\)以及其他变量，迭代至收敛 5.2.2.4. 完成初始化 对重力矢量的修正之后，我们可以通过旋转重力向量到z轴来得到世界坐标系和参考坐标系\\(c_0\\)之间的旋转\\(q_{c_0}^{w}\\) 然后我们将参考坐标系\\((\\cdot)^{c_0}\\)中的所有变量旋转到世界坐标系\\((\\cdot)^w\\)中，机体坐标系的速度也被转换到世界坐标系中。 视觉SfM的平移分量将缩放为以米为单位，此时，初始化过程已经完成，所有这些度量值将被提供给一个紧耦合的单目VIO 5.3. 紧耦合VIO 在估计器初始化之后，我们使用基于滑动窗口的紧耦合单目VIO进行高精度和稳健的状态估计，如图3所示 5.3.1. 系统状态 滑动窗口内全部状态向量定义如下: 其中， \\(x_k\\)是IMU在第k帧图像对应的时刻的状态，包含了IMU（机体）在世界坐标系下的位置、速度和姿态，以及在机体坐标系下的IMU加速度bias和角速度bias n表示所有的关键帧数量 m表示滑动窗口内所有的特征点的数量 \\(\\lambda_l\\)表示第l个特征点相对于其第一次观测的逆深度值 我们的目标是最小化关于以下3个部分的和： 先验项 视觉重投影残差项 IMU预积分残差项 即目标函数如下所示: 其中， \\(r_{B}(\\hat{z}_{b_{k+1}}^{b_k},X)\\)表示IMU的测量残差 \\(r_c(\\hat{z}_{l}^{c_j},X)\\)表示视觉测量残差 \\({B}\\)是IMU测量数据的集合 \\({C}\\)是当前滑动窗口中至少被观测到两次或以上的特征点集合 \\({r_p,H_p}\\)是来自边缘化得到的先验信息 我们采用了Google的Ceres优化库来求解这个非线性问题 5.3.2. IMU测量误差 考虑滑动窗口中两个连续的图像帧时刻所对应的机体坐标系\\(b_k,b_{k+1}\\)，根据(式13)定义的IMU测量模型，可以得到IMU的预积分參差如下: 其中, \\([\\cdot]_{xyz}\\)提取四元数中的角度部分，作为误差状态的表达，即\\(\\delta\\theta_{b_{k+1}}^{b_k}\\)是关于四元数的误差状态 \\([\\hat{\\alpha}_{b_{k+1}}^{b_k},\\hat{\\beta}_{b_{k+1}}^{b_k},\\hat{\\gamma}_{b_{k+1}}^{b_k}]^T\\)是关于IMU的在两个图像帧之间的预积分项，这一项仅与包含噪声的加速度和角速度测量有关 加速度计和陀螺仪的bias被包含在參差项中，用以实现在线的矫正 5.3.3. 视觉测量误差 与传统的针孔相机模型(在广义成像平面上定义投影误差)相反，我们在一个单位球面上定义了相机的测量误差，原因是几乎所有类型的照相机，包括广角照相机、鱼眼照相机和全向照相机，其光学特性都可以被模拟成以单位球面为单位的射线。 考虑第l个特征的第一次被第i帧图像观测到，那么在第j帧再次观测到这个特征点时，可以建立如下视觉残差： 其中， \\([u_l^{c_i},v_l^{c_i}]\\)表示第l个特征的第一次被第i帧图像观测所在的像素位置 \\([u_l^{c_j},v_l^{c_j}]\\)表示第l个特征被第j帧图像观测所在的像素位置 \\(\\pi_c^{-1}\\)表示使用相机模型的内参，将像素点坐标反投影成一个单位向量（3D点） \\(P_l^{c_j}\\)用于(式22)，是在正切空间中一个固定长度的标准协方差 \\(\\hat{\\bar{\\mathcal{P}}}_l^{c_j}\\)是将第j帧观测到第l个特征点的像素坐标反投影得到的3D向量 \\(\\mathcal{P}_l^{c_j}\\)是将第i帧观测到第l个特征点的像素坐标 1）先反投影成3D向量(归一化平面上的) 2）再利用逆深度，得到在第i帧相机坐标系下的3D点 3）然后根据IMU和相机的外參，将该3D点变换到IMU坐标系下 4）根据(第i帧)待估计的机体位姿\\(T_{b_i}^{w}\\)，将该点变换到世界坐标系下 5）根据(第j帧)待估计的机体位姿\\([T_{b_j}^{w}]^{-1}\\)，将该点投影到第j帧机体坐标系下 6）然后，再次根据IMU和相机外參，将该点转换到第j帧的相机坐标系下 因为视觉參差的自由度是2,我们将參差向量投影到正切空间。\\(b_1,b_2\\)是在正切平面\\(\\hat{\\bar{\\mathcal{P}}}_l^{c_j}\\)上的两个任意选择的正交基，如图6所示。我们可以使用之前提到的算法1来找到其中的一组\\(b_1,b_2\\) 5.3.4. 边缘化 为了控制基于优化方法的VIO的计算复杂度，采用了边缘化的方法。 我们选择性地对弹出滑动窗口的机体状态\\(x_k\\)和特征点\\(\\lambda_l\\)进行边缘化，然后将它们的测量信息转化为对应的边缘化信息，作为先验 如图7所示，当有新的一帧到来时，首先判断最新的一帧是否为关键帧： 如果是关键帧，那么将其插入到滑动窗口中，同时，弹出滑动窗口中排在最前面（最old的）的那一帧，并且对其视觉和IMU测量信息进行边缘化，转化为先验矩阵\\(H_{prior}\\) 如果不是关键帧，那么对于这个最新的一帧，不插入到滑动窗口中，并且舍弃其视觉信息，保留IMU的测量信息（因为需要其预积分信息来进行向前推算） 关键帧选取+边缘化策略是为了保持滑动窗口中的关键帧保持一定的空间分布，这确保了足够的视差来对特征点进行三角化，并且使得加速度计测量值保持在一个较大的激励下的概率更大。 边缘化的实施采用的是Schur complement，我们基于所有与被移除状态相关的边缘化属性来构建一个新的先验，然后新的先验与旧的先验相加。 Motion-only BA 对于移动终端等计算能力较低的设备，由于非线性优化的计算量较大，紧耦合单目VIO系统无法达到相机帧率的输出。为了达到这个目的，我们使用了一个轻量级的Motion-only的视觉惯性BA来使得状态估计可以达到相机速率(30赫兹) 损失函数与之前定义的单目VIO损失函数一样(式22)，但是，相比与之前对全部状态进行优化，在这里我们只优化了固定数目的IMU（机体）状态的位姿和速度，把特征点深度、IMU和相机外參、bias、以及旧的IMU(机体)状态等这些看作是固定不变的常量。 我们使用所有的视觉和惯性测量来进行这个Motion-only的BA优化，这个结果比直接对最新一帧使用Pnp（前端跟踪）算法更加平滑。 图8给出了该策略的实例 与全状态紧耦合的单目VIO(在最先进的嵌入式计算机上可能需要50ms)相比，Motion-only的视觉-惯性BA优化只需要大约5ms的时间 IMU状态估计的正向传播 虽然我们的VIO的频率受限于图像捕获频率，但我们仍然可以直接使用IMU的测量数据来对最新的VIO状态估计进行传递。 高频状态估计值可用于闭环的状态反馈，后面提出了一种基于这IMU-rate状态估计的自主飞行实验 故障诊断和恢复 尽管提出的VIO对于挑战环境和运动下可以保持一定的鲁棒性。但是由于强烈的光照变化或剧烈的运动等情况下，故障还是不可避免的发生。主动故障检测与恢复策略可以提高系统的实用性，故障检测模块是一个独立于状态估计器的模块，用来检测估计器的异常输出，检测异常有如下准则: 在最新帧中被跟踪的特征数小于某个阈值 估计器的最后两次输出（位置、姿态）有较大的不连续性 bias或外參估计产生了较大的变化 一旦检测出异常，系统将切换回初始化阶段，一旦单目VIO重新初始化完成，将会重新创建新的一段pose Graph 重定位 我们的滑动窗口和边缘化方案控制了计算复杂度，但也为系统引入了累积漂移。更具体地说，漂移发生在全局的3D位置(x, y, z)和绕重力方向(yaw)旋转，VIO（4自由度不可观） 为了消除漂移，提出了一种可以与单目VIO状态估计器无缝整合的紧耦合重定位模块，重定位首先启动回环检测模块，用来检测该环境是否曾经探查过，然后建立回环候选关键帧和（最新）当前帧之间的特征级的关联，这些特征关联被紧密地整合到单目VIO模块中，以此来实现零漂移的状态估计。 多个观测值的多重特征直接用于重定位，获得了更高的精度和更好的状态估计平滑度，重定位的处理过程如图9(a)所示。 回环检测 我们使用DBoW2，一种词袋模型，用于回环检测中。除了单目VIO模块中检测到的角点特征外，还有500个以上的额外角点被检测到，并使用BRIEF描述子进行描述。额外的角特征用于在循环检测时实现更好的召回率。 将描述符作为视觉描述单词来查询视觉数据库，经过时间和几何一致性检查后，DBoW2将返回回环候选帧。我们对所有特征点保留所有BRIEF描述符，但丢弃原始图像以减少内存消耗。 我们注意到我们的单眼VIO能够渲染roll和pitch可观，因此，我们不需要依赖于旋转不变的特性，比如ORB_SLAM中使用的ORB特征点 特征恢复 当检测到一个回环时，通过恢复特征关联，建立起当前滑动窗口和闭环候选帧之间的连接，特征关联采用BRIEF描述符进行匹配来完成。直接的描述符匹配可能会产生大量的外点，为了解决这个问题，我们采用两步骤的外点去除，如图10所示 2D-2D： 使用RANSAC进行基础矩阵F的测试，对当前帧图像的2D观测点与回环候选帧图像（实际上是特征点）进行基础矩阵F测试 3D-2D： 使用RANSAC的PnP测试，基于当前滑动窗口中已知的3D点，以及回环候选帧图像中的2D特征点，进行PnP测试 当两个测试的内点数达到一定阈值的时候，我们认为这个回环候选帧就是正确的回环，然后进行重定位。 紧耦合的重定位 重定位处理可以有效地对齐当前由单目VIO维护的滑动窗口到过去的位姿。重定位过程中，我们把所有闭环关键帧的位姿都作为约束，然后使用所有的IMU测量值、局部视觉测量值和从回环检索到的特征关联来共同优化当前滑动窗口 根据回环检测得到的回环帧\\(v\\)与当前帧的特征关联，我们可以写出视觉误差项，与前面VIO模块中的(式25)一致，唯一不同的是，回环帧的位姿\\((\\hat{q}_v^{w},\\hat{p}_v^w)\\)可以从pose Graph中获取，或者是直接使用过去的里程计输出（如果这是第一次重定位的话），并且回环帧的位姿\\((\\hat{q}_v^{w},\\hat{p}_v^w)\\)作为常数对待，不参与优化，只提供约束。 为了实现紧耦合的重定位，我们可以用附加的闭环约束对式(22)中的非线性目标函数稍作修改，得到: 其中， \\(\\mathcal{L}\\)是从闭环关键帧与当前滑动窗口恢复出来的特征关联的集合 \\((l,v)\\)表示在闭环关键帧中观测到的第l个特征点 需要注意的是，尽管目标函数与(式22)稍有不同，但是待求解的状态量的维度是一样的，这是因为闭环关键帧的位姿作为常数处理 如果当前滑动窗口建立起多个闭环时，我们同时使用全部的闭环帧的特征关联来进行优化。这为重新定位提供了多视图约束，提高了精度和平滑度 注意 这里的优化都是针对于当前滑动窗口的优化，对于过去的位姿、闭环关键帧位姿的全局优化，在下一节进行讨论。 全局Pose Graph优化 重定位后，当前滑动窗口，将与过去的位姿进行对齐，减少漂移。利用重定位的结果，这一步额外的Pose Graph优化步骤是用于确保过去的位姿拥有较好的全局一致性。 因为我们的VI处理中，roll和pitch是可观的（相对于世界坐标系-ENU或其他），那么累积漂移只会发生在其余四个自由度（3D位置、沿重力方向旋转的yaw角）。 为了解决这个问题，我们忽略不产生漂移的roll和pitch状态量，然后只进行一个4自由度的Pose Graph优化 向Pose Graph中添加关键帧 当一个关键帧从滑动窗口中被边缘化掉的时候，它将被插入到Pose Graph里面，这个关键帧在这个Pose Graph里面作为一个顶点，然后它可以使用两种类型的边来连接其他顶点： 序列边：一个关键帧会与之前的几个关键帧建立起一些sequential edge（序列边）。一条序列边代表了两个关键帧的相对变换关系，这个相对变换可以直接从VIO获取，考虑一个较的关键帧i和其前一帧j，那么这个序列边仅仅包含相对位置\\(\\hat{p}_{ij}^i\\)和相对yaw角\\(\\hat{\\psi}_{ij}\\): 回环边：如果这个被边缘化的关键帧与之前的回环帧建立了回环连接，那么这个回环连接同样被加入到Pose Graph中。相似的，回环边也仅仅包含4自由度的相对关系，如上面的(式27)所示，这个回环边的数据来自重定位得到的结果 4自由度的Pose Graph优化 我们定义连接着关键帧i和关键帧j的边所代表的残差如下: 其中， \\(\\hat{\\phi}_i,\\hat{\\theta}_i\\)分别是roll和pitch的估计值，可以直接从单目VIO状态估计器中直接获取 那么，对于Pose Graph中的所有边（序列边、回环边），可以构建出如下损失函数: 其中 \\(\\mathcal{S}\\)代表所有序列边 \\(\\mathcal{L}\\)代表所有回环边 虽然紧耦合重定位模块有助于消除错误的闭环，但是对于回环边，我们仍添加Huber正则项\\(\\rho(\\cdot)\\)进一步减少可能错误的闭环所带来的影响。 相反的是，对于序列边，我们不使用鲁棒性核函数，因为这些边是从紧耦合VIO状态估计模块中来的，已经经过外点去除，满足内点条件了。 位姿图优化和重定位模块在两个单独的线程中异步进行，这使得可以在任何时候使用最优化的位姿图进行重定位。同样，即使当前位姿图优化尚未完成，也可以使用现有的（旧的）位姿图进行重定位，这个过程如图9(b)所示。 Pose Graph管理 当行驶距离增加时，位姿图的大小可能会一直增大，从而限制了系统的长期实时性，为了解决这个问题，我们实现了一个降采样的过程，以保持Pose Graph数据库在限制的大小范围。 所有具有闭环约束的关键帧都将保留，而其他要么太接近要么与它的邻居有相似方向的关键帧则可能被删除，关键帧被移除的概率与它的邻居的空间密度成正比。 实验 作者进行了3个实验以及两个应用来测试所提出的VINS-Mono系统。 在第一个实验中，在公共数据集上进行测试，对比了提出的方法和其他先进方法的性能，然后进行数值分析，展示提出系统的准确性。 然后，在室内环境中测试系统，以评估在重复场景中的性能 最后进行了大规模的实验，验证了系统的长期实用性。 此外，我们将所提出的系统应用于两个应用。对于无人机的应用，我们使用VINS-Mono进行位置反馈，以控制无人机跟随预定的轨迹。然后我们将我们的方法移植到一个iOS移动设备上，并与Google Tango进行比较 公开数据集测试对比 使用EuRoCMAV的视觉-惯性数据集来评估提出的VINS-Mono系统，这个数据集由无人机的板载立体相机(Aptina MT9V034 global shutter, WVGA monochrome, 20FPS)和同步IMU（ADIS16448, 200Hz），以及真值数据组成。在测试的时候，只采用左相机的图像，在这些数据中可以观测到较大的IMU bias以及光照变化。 在这个实验中，我们比较了VINS-Mono和OKVIS（一种支持单目、双目的先进方法）算法，OKVIS也是一种基于滑动窗口优化的算法，本文提出的VINS-Mono和OKVIS在很多细节上不一样，我们的系统完整的，具有鲁棒的初始化和回环检测。 实验使用两个数据序列，分别是: MH_03_median MH_05_difficult 为了方便描述，采用如下符号简化描述 VINS表示仅仅是VIO（视觉-惯性里程计）(没有回环部分) VINS_loop表示带有完整版的重定位和位姿图优化的VINS 为了公平对比，我们采取丢弃头100个输出，然后使用接下来的150个输出来与真值进行对齐，然后比较接下来的输出。 对于MH03序列，其轨迹如图11所示 我们仅仅比较平移误差，因为在这个序列中，旋转运动是微不足道的。 如图所示，VINS_loop的平移误差最小 对于MH05序列，也可以观察到近似的结果， 由于在这个序列中运动平稳，偏航角变化不大，所以基本上只发生位置漂移，显然，具有回环功能的方法消除了大部分的漂移。 在roll和pitch角的估计上，OKVIS的估计更加准确一些，一个可能的原因是VINS-Mono使用的预积分，这是使用一阶近似来进行IMU的传播，以节省计算资源。 对于单纯的VIO, VINS-Mono和OKVIS都有相似的Accuracy，很难区分哪一个更好然而，VINS-Mono在系统级别上优于OKVIS，因为VINS-Mono是一个完整的系统，具有鲁棒的初始化和闭环模块，可以辅助单目VIO 室内环境对比 在室内实验中，我们选择实验室环境作为实验区域，使用的设备如图15所示 我们用手拿着传感器，在实验室里以正常的速度行走，在实验过程中，我们遇到行人，低光照条件，纹理缺乏的区域，玻璃反射区域，如图16所示，在多媒体附件中可以找到该视频。 我们与OKVIS进行了对比，如图17所示 大范围环境测试 实验室外面 我们对VINS-Mono在室内外混合场景下进行了测试，这些传感器套装与图15所示的设备一样。 我们从实验室的一个座位出发，然后我们下了楼梯，绕着大楼外面的操场走，接下来，我们回到大楼，上了楼，最后，我们回到了实验室的同一个座位上。 整个轨迹超过700米，持续接近10分钟，这个实验的视频可以在附件的多媒体中找到。 轨迹如图19所示， 在提出的方法中，可以看到，楼梯的形状是清晰的。最终，将闭环轨迹与Google地图进行比对，验证其准确性，如图18所示 OKVIS的最终漂移是[13.80，-5.26，7.23]米，分别在x、y和z轴上。无回环的VINS-Mono的最终漂移是[-5.47, 2.76,-0.29]米，其占轨迹长度的0.88%，小于OKVIS的2.36%，带有回环功能的VINS-Mono，最终的漂移是[-0.032, 0.09, -0.07]米，对于整条轨迹长度而言，是微不足道的。 虽然我们不知道真值，但我们仍然可以从视觉上判断出优化后的轨迹是平滑的，并且可以精确地与卫星地图对齐。 绕校园环境测试 这个庞大的数据集是用手持型VI-Sensor来记录的，它覆盖了整个科大校园，数据集覆盖的地面长约710m，宽约240m，高约60m，路径总长度是5.62km。数据包含了25Hz的图像和200Hz的IMU数据，持续了1个小时34分钟，这对于测试VINS-Mono的稳定性和耐久性是一项非常有意义。 在这个大规模的测试中，为了提供足够的循环信息和实现实时性能，我们设置关键帧数据库的大小2000帧，然后使用Intel i7-4790在3.6GHz的频率下工作，测试如表格1所示。 应用1：无人机的反馈控制 我们使用VINS-Mono作为无人机的自动反馈控制，如图21所示，我们使用前视全局快门相机(MatrixVision mvBlueFOX-MLC200w)具有752x480的分辨率，并配备了190度鱼眼镜头。然后使用了DJI A3飞行控制器，用于获取IMU测量以及稳定机体姿态。 板载的计算资源是Intel i7-5500U 的CPU，频率为3.00GHz，对于广角相机而言，传统的pinhole相机模型不适用，这里采用了MEI模型[文献42]，然后使用了[文献43]介绍的工具来标定。 在本实验中，我们使用VINS-Mono的状态估计来测试自动轨迹跟踪的性能，在本实验中，关闭回环功能，命令四旋翼飞行器跟踪一个”8”字图形，每个圆的半径为1.0米，如图21所示 在预定义轨迹周围设置四个障碍物，以验证无闭环情况下VINS-Mono的精度。 真值使用OptiTrack来获得，整条轨迹长度61.97米，最终漂移为[0.08,0.09,0.13]米，位置漂移为0.29%，具体的误差如图23所示","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"VINS-MONO","slug":"SLAM代码课程/VINS-MONO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/"}],"tags":[]},{"title":"矩阵相关","slug":"数学基础/矩阵相关","date":"2020-04-07T09:48:25.000Z","updated":"2020-04-07T12:48:28.000Z","comments":true,"path":"2020/04/07/数学基础/矩阵相关/","link":"","permalink":"http://yoursite.com/2020/04/07/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E7%9F%A9%E9%98%B5%E7%9B%B8%E5%85%B3/","excerpt":"","text":"1. 加法 1.1. 加法性质 2. 数乘 2.1. 数乘性质 3. 转置 3.1. 共轭转置 3.2. 转置性质 4. 对称 5. 矩阵乘法 5.1. 矩阵乘法中的某一行或某一列的计算[Important] 举例: \\[ \\begin{aligned} [AB]_{2*} &amp;=A_{2*}B \\\\ &amp;= \\begin{bmatrix} \\begin{bmatrix} a_{21}*b_{11}+ \\\\ a_{22}*b_{21}+ \\\\ a_{23}*b_{31} \\end{bmatrix} &amp; \\begin{bmatrix} a_{21}*b_{12}+ \\\\ a_{22}*b_{22}+ \\\\ a_{23}*b_{32} \\end{bmatrix} &amp; \\begin{bmatrix} a_{21}*b_{13}+ \\\\ a_{22}*b_{23}+ \\\\ a_{23}*b_{33} \\end{bmatrix} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} a_{21}*[b_{11},b_{12},b_{13}]+ \\\\ a_{22}*[b_{21},b_{22},b_{23}]+ \\\\ a_{23}*[b_{31},b_{32},b_{33}] \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} a_{21}B_{1*}+ \\\\ a_{22}B_{2*}+ \\\\ a_{23}B_{3*} \\end{bmatrix}_{1\\times 3} \\end{aligned} \\] 5.2. 矩阵块乘法 5.3. 乘法分配 6. 矩阵的逆 6.1. 矩阵等式 6.2. 如果矩阵的逆存在 则下面几条描述是等价的: 6.3. 计算矩阵的逆 6.4. 逆的性质 7. 线性函数 7.1. 线性组合 7.2. 线性系统","categories":[{"name":"数学基础","slug":"数学基础","permalink":"http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"Gauges-and-Gauge-Transformations","slug":"SLAM代码课程/Gauges-and-Gauge-Transformations","date":"2020-04-07T02:26:01.000Z","updated":"2020-04-07T07:53:59.000Z","comments":true,"path":"2020/04/07/SLAM代码课程/Gauges-and-Gauge-Transformations/","link":"","permalink":"http://yoursite.com/2020/04/07/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/Gauges-and-Gauge-Transformations/","excerpt":"","text":"1. Gauges and Gauge Transformations for Uncertainty Description of Geometric Structure with Indeterminacy 2. 摘要 本文提出了一种一致的理论，用于描述从一系列图像中进行三维重建过程中的确定性和不确定性 首先给出关于gauges和gauge transformations的相关理论，然后讨论了如何评价具有不确定性的解的可靠性，并将克拉美罗下界推广到包含内部不确定性。 另外还介绍了free-gauge approach，然后定义了独立于特定规格的协方差矩阵的标准形式 3. 介绍 从图像中进行3D重建包含了不确定性。 这些不确定性可以通过施加一些normalization的约束来移除，例如: 我们可以将坐标原点固定在对象的特定点上，并将对象的大小标准化为单位长度 而固定参数则定义为没有不确定性，其他所有参数的不确定性均被改变 4. 3D重建问题 在本文中，我们将重点放在基于特征的方法上: 我们追踪图像序列上的可识别特征点(如角点和标记点)的运动，并利用摄像机投影模型的知识计算它们的三维位置 假设我们在M幅图像上跟踪N个刚性移动的特征点，令\\((x_{ka},y_{ka})\\)为第k帧的第a个点的像素坐标 这里，我们采用以相机为中心的描述，假设一个物体在场景中相对于静止的相机移动，但是，如果我们将摄像机看作是移动的，并拍摄静止场景的图像，那么后续的分析基本上是相同的。 4.1. 目标函数 5. Gauges gauge freedom的存在表明了在参数空间\\(\\mathcal{M}\\)中，存在一个光滑流形，对于任意的点\\(\\theta\\)其给出的解都能使目标函数的值一样。 对于在上述的光滑流形中的两点，\\(\\theta\\)和\\(\\theta&#39;\\)是几何等价的，记为\\(\\theta \\sim \\theta&#39;\\)，其中\\(\\theta&#39;=g \\theta\\)，\\(g()\\)代表的是该流形空间(零空间)中的两点的变换关系 这意味着，对于这个等价关系，真正的参数空间不是\\(\\mathcal{M}\\)，而是\\(\\mathcal{M}\\)的商空间\\(\\mathcal{M}/\\mathcal{G}\\)，记为\\(\\mathcal{M}_\\theta\\) 例如：\\(\\mathcal{M}\\)的子集包含了所有关于\\(\\theta\\)的等价 如果gauge的自由度为r，那么\\(\\mathcal{M}_\\theta\\)则是参数空间\\(\\mathcal{M}\\)的r维submanifold，并且称为是与参数\\(\\theta\\)相关的叶子 为了消除解的模糊性，我们定义其他流形空间，它与上面的流形相交于一点。 选取特定的\\(\\theta\\)值的一个自然的想法是，对于上面的\\(\\mathcal{M}_\\theta\\)分配r个等式: 每一个等式去除gauge freedom中的一个自由度，我们称这些等式为gauge condition，如果这些等式满足: 它们在代数上是独立的，共同定义了一个在参数空间\\(\\mathcal{M}\\)中的submanifold \\(\\mathcal{C}\\)，称为gauge manifold gauge manifold \\(\\mathcal{C}\\)与参数空间\\(\\mathcal{M}\\)中的所有叶子，即与\\(\\mathcal{M}_\\theta\\)相交于一点 对于任何\\(\\theta \\in \\mathcal{M}_\\theta\\)和\\(\\theta_C=C \\cap \\mathcal{M}_\\theta\\)，存在一个独特(仅有一个)的变换g()，使得\\(\\theta_C=g\\theta\\) 此后，gauge和gauge manifold都是一个意思，记为\\(\\mathcal{C}\\) 通过引入\\(\\mathcal{C}\\)，我们可以找到一个与叶子\\(\\mathcal{M}_\\theta\\)的独一无二的交点，并且同时满足目标函数最小值 5.1. gauge fix approach 其中， \\(t_k\\)是平移 \\(s_a\\)是尺度 6. 估计的等价性定理 \\(T_{\\theta C}(\\mathcal{M})\\)是参数空间\\(\\mathcal{M}\\)在参数\\(\\theta_C\\)处的正切空间(tangent space)，是一个n维的线性空间 \\(T_{\\theta C}(\\mathcal{C})\\)是gauge manifold \\(\\mathcal{C}\\)在参数\\(\\theta_C\\)处的正切空间，它是\\(T_{\\theta C}(\\mathcal{M})\\)的(n-r)维子空间 n: 参数向量\\(\\theta\\)的维度数 r: gauge freedom的自由度 n-r: 可观测的维度 6.1. 图1的个人理解 已知在\\(M_\\theta\\)轨道上，任意一点都可以满足使得目标函数\\(J()\\)最小化 假定轨道上某一点\\(\\theta_C\\)处，求得了一个增量\\(\\phi_\\theta\\)，显然，这个增量有一部分分量不会改变目标函数\\(J()\\)的能量 在点\\(\\theta_C\\)处，存在一个正切流形空间\\(T_{\\theta_C}(M_\\theta)\\)，增量\\(\\phi_\\theta\\)在这个正切空间上的投影量，只会使得\\(\\theta_C\\)点沿着\\(M_\\theta\\)轨道移动，而不是沿着垂直方向移动，因此，这部分分量并不改变目标函数\\(J()\\)的能量 那么这个在点\\(\\theta_C\\)处的正切流形空间\\(T_{\\theta_C}(M_\\theta)\\)，也就是所说的零空间 6.2. 关于零空间的基 零空间的基，实际上就是正切流形空间\\(T_{\\theta_C}(M_\\theta)\\)的基，可以通过在\\(M_\\theta\\)轨道在\\(\\theta_C\\)处使用小量来进行计算，这跟计算切向量的方法一样的 举例: 求\\(\\theta_C\\)处，关于位姿的平移量x值的零空间基 6.3. 等价性的推导 在这一节中，我们定义了在gauge manifold上的斜投影，并证明所有投影到相同点上的扰动在几何上是等价的 设\\(\\hat{\\theta}_C\\)是参数\\(\\theta\\)对于gauge \\(\\mathcal{C}\\)的估计。 使用一阶近似，那么作差\\(\\Delta \\theta_C=\\hat{\\theta}_C-\\theta_C\\)可以使用\\(T_{\\theta C}(\\mathcal{C})\\)中的一个元素来标识 注意: \\(\\hat{\\theta}_C\\)和\\(\\theta_C\\)都表示状态 \\(\\Delta \\theta_C\\)才表示增量 令\\(\\Delta \\theta \\in T_{\\theta C}(\\mathcal{M})\\)是一个任意的向量(也就是下图中的向量1)，则有: 当且仅当\\(\\Delta \\theta-\\Delta \\theta_C \\in T_{\\theta C}(\\mathcal{M}_\\theta)\\) ，(也就是下图的向量1-向量2，得到向量的\\(Q_{\\theta_C}^C\\))，那么有: \\(\\theta_C+\\Delta \\theta\\)与\\(\\hat{\\theta}_C=\\theta_C+\\Delta \\theta_C\\)是几何等价的 因为\\(\\{D_1(\\theta_C),\\cdots,D_r(\\theta_C)\\}\\)是空间\\(T_{\\theta C}(\\mathcal{M}_\\theta)\\)的基 （零空间的基），那么上面的条件等价于: 存在r个数字\\((x_1,\\cdots,x_r)\\)，使得: \\[ \\Delta \\theta_C=\\Delta \\theta + \\sum_{i=1}^r x_i D_i(\\theta_C) \\] 或者说 \\[ \\Delta \\theta_C=\\Delta \\theta + U_{\\theta_C} x \\tag{36} \\] 其中， \\(x=(x_1,\\cdots,x_r)^T\\) \\(U_{\\theta_C}=(D_1(\\theta_C),\\cdots,D_r(\\theta_C))\\) 如果gauge \\(\\mathcal{C}\\) 由r个等式来定义，即: 那么，正切空间\\(T_{\\theta C}(\\mathcal{C})\\)是 张成的线性空间的正交互补空间 根据\\(\\triangledown_{\\theta C_i}|\\theta_C\\)和\\(\\Delta \\theta_C\\)之间作点乘等于0，对式36两边同时点乘\\(V_{\\theta_C}\\)，可以得到: 其中, 对(式36)和(式38)，消去\\(x\\)，可以得到: 这，就是定义了一个沿着\\(T_{\\theta C}(\\mathcal{M}_\\theta)\\)到\\(T_{\\theta C}(\\mathcal{C})\\)的(斜)投影 因此，得到如下定理: 一个估计\\(\\hat{\\theta}_C\\)与\\(\\theta_C+\\Delta \\theta\\)是几何等价的，当且仅当: 7. 数值优化 问题是给定gauge，如何用数值方法求得最优估计量 牛顿迭代法具有良好的二次收敛性，但同时，解需要满足gauge condiction 目标函数\\(J\\)通过在gauge \\(\\mathcal{C}\\)下的真值\\(\\bar{\\theta}_C\\)附近展开，有: 其中，上面的括号\\((m,n)\\)表示点乘运算 \\(\\triangledown_{\\theta}J，\\triangledown_{\\theta}^2J\\)分别表示目标函数\\(J\\)对参数\\(\\theta\\)的一阶偏导和二阶偏导 表达式中符号上面的横杠，如\\(\\bar{J},\\triangledown_\\theta \\bar{J}, \\triangledown_\\theta^2 \\bar{J}\\)表示的是在真值\\(\\bar{\\theta}_C\\)处进行计算得到的值（也就是线性化点得到值） \\(\\Delta \\theta\\)是使用真值\\(\\bar{\\theta}_C\\)处的正切空间\\(T_{\\bar{\\theta}_C(\\mathcal{M})}\\)的元素来标识的 即\\(\\Delta \\theta\\)是在\\(T_{\\bar{\\theta}_C(\\mathcal{M})}\\)的局部坐标系下的，如 局部扰动向量\\(\\Delta R_{3\\times1}\\) (回想四元数的更新，局部扰动) 忽略掉目标函数(式68)中的其他高阶项如\\(O(\\epsilon^3)\\)，减去在\\(\\bar{\\theta}_C\\)处的真值\\(\\bar{J}\\)，然后令等式为0，可以得到: 因为Hessian矩阵，即\\(\\triangledown_{\\theta}^2J\\)的秩是\\(n-r\\)，这个等式有无穷多个解。 上述(式69)，相当于高斯牛顿中的: \\[ \\begin{aligned} H\\Delta x=b \\\\ J^T J \\Delta x = -J^T r \\end{aligned} \\] 这里有两种选择， 一是通过使用\\(r\\)条等式与(式69)进行结合（这相当于在目标函数中添加约束项(惩罚项)，作为先验）: 来约束\\(\\Delta \\theta\\)在正切空间\\(T_{\\theta}(\\mathcal{C})\\)，（这是相当于添加先验的方法），由此产生的线性方程组可以确定唯一的解\\(\\Delta \\theta\\) 另外一种方法是，首先直接计算(式69)的任意一个解 求解的过程中，需要用到伪逆(Moore-Penrose) 然后，根据定理，我们需要利用gauge \\(\\mathcal{C}\\)，即用\\(Q_{\\theta}^C \\Delta \\theta\\)来代替\\(\\Delta \\theta\\)，最终可以得到: (这个的意思是，先求出一个任意解，然后再减去这个解在零空间上的分量) Free-Gauge Approach过程可以使用图来描述 值得注意的是: Free-Gauge Approach是沿着与\\(\\mathcal{M}_\\theta\\)正交的方向去迭代的，因此，其收敛速度会更快一些。","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"}],"tags":[]},{"title":"VI中的几种自由度处理方法的性能对比","slug":"SLAM代码课程/VI中的几种自由度处理方法的性能对比","date":"2020-04-06T02:01:39.000Z","updated":"2020-04-07T07:55:35.000Z","comments":true,"path":"2020/04/06/SLAM代码课程/VI中的几种自由度处理方法的性能对比/","link":"","permalink":"http://yoursite.com/2020/04/06/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VI%E4%B8%AD%E7%9A%84%E5%87%A0%E7%A7%8D%E8%87%AA%E7%94%B1%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/","excerpt":"","text":"1. On the Comparison of Gauge Freedom Handling in Optimization-based Visual-Inertial State Estimation 2. 摘要 VI系统中有4个不可观测自由度，绕重力方向的旋转和平移(在本文中称为\\(gauge~freedom\\))，以及剩下一些可观的自由度，在求解过程中需要进行特殊的处理。 文章对比了以下3种处理方法: gauge fixation: 设置不可观测的状态为某个固定的值 gauge prior: 为某个状态设置先验 free gauge: 让状态在优化过程中自由演化，优化完成再进行处理 3. VI问题 视觉-惯性状态估计的问题包括对摄像机-惯性组合传感器(IMU)的运动和传感器在场景中运动时摄像机看到的三维地标位置的推断。 通过收集视觉测量方程(图像点)和惯性测量(加速度计和陀螺仪)，问题可写成非线性最小二乘，目标是最小化下面的方程: 其中 \\(||r||_\\Sigma^2=r^T\\Sigma^{-1}r\\)是残差向量\\(r\\)的马氏距离 \\(\\Sigma\\)是测量值的协方差矩阵，作为权重 这个cost func 可以作为 \"full smoothing\"或者\"fixed-lag smooth\"方法 视觉项由图像观测点\\(x_ij\\)的重投影误差组成，惯性项包括惯性测量值与IMU轨迹模型预测值(预积分)之间的误差。 问题求解的状态向量如下: 包括摄像机运动参数(外参和线速度)和3D场景(地标)。 加速度计和陀螺仪的bias通常施加在IMU坐标系中，因此不受坐标系固定的影响，因此，我们排除bias，并假设IMU的测量已经纠正。 3.1. 解的歧义性和几何等价 对于VI系统状态估计问题，很重要的一点是，对参数\\(\\theta\\)(或者说状态)给定特殊的变换\\(g(\\theta)\\)，最终的目标函数(cost func)\\(J(\\theta)\\)不变，即: 特别的，变换\\(g()\\)可以用齐次矩阵的形式表达: 这是一个4自由度的变换，其中: \\(t \\in \\R^3\\)是任意的平移 旋转\\(R_z=\\exp (\\alpha e_z)\\)是绕重力方向轴\\(e_z=(0,0,1)^T\\)的任意yaw角\\(\\alpha \\in (-\\pi,\\pi)\\)所产生的旋转矩阵 为了简化表达，使用\\(Exp(\\theta)=\\exp(\\theta^\\wedge)\\)来表示这个变换 通过对状态应用上面的变换\\(g(\\theta)\\)，将得到新的状态\\(\\theta&#39; \\equiv {p_i&#39;,R_i&#39;,v_i&#39;,X_j&#39;}\\) 对于\\(\\theta\\)和\\(\\theta&#39;\\)，它们是几何等价的，它们产生相同的误差，即，对于目标函数\\(J(\\theta)\\)，它们最终得到的值是一样的。 作为不变性的结果，参数空间\\(\\mathcal{M}\\)可以分解成几何等价重构的不相交集合(即使用基来表示)，这些几何可以称为\\(orbit\\)或者\\(leaf\\) 于是，关于\\(\\theta\\)的\\(orbit\\)可以如下表示: 其中, \\(\\mathcal{G}\\)是\\(g()\\)变换的群，注意到目标函数在每一个\\(orbit\\)上都是常数(意思是存在变换\\(g()\\)，都不会改变目标函数的值) 不变性的主要结果是没有一个特定的解，原因是有无穷多个解可以使得目标函数达到同样的最小值， 如下图2: \\(orbit\\)上的所有状态都可以达到同样的最小值(对于目标函数而言) 因此，VI状态估计问题具有不确定或者说不可观测的状态: 没有足够的方程来完全指定一个唯一解。 上面是三种处理方法关于参数向量维度的对比: 总的参数\\(n=9N+3K\\)，N是相机节点数，K是路标数 3.2. 附加约束:指定一个Gauge 用附加约束完成(1)的处理 这会产生一个独特的解，称为指定一个\\(gauge\\)，C 换句话说，就是上面的(等式7)，选择了一个有代表性的\\(orbit\\)，用来消除等价中的不确定性，在VI系统中，这是通过指定3D的参考坐标系来实现的。 举例: 选择包含第0帧的相机（固定其位姿为position={0,0,0},yaw=0）作为参考坐标系。这些约束指定了一个唯一的转换，因此，这个独特的解就是\\(\\mathcal{C}\\)和参数空间\\(\\mathcal{M}_\\theta\\)的并集，即: \\[ \\theta_C=\\mathcal{C}\\cap \\mathcal{M}_\\theta \\] 那么\\(gauge\\)，C，与轨道\\(orbit\\)也就是\\(\\mathcal{M}_\\theta\\)是横断的，因此，得到的解\\(\\theta_C\\)是唯一的 4. 处理Gauge 从优化的角度来看，使用高斯牛顿来对上面提到的目标函数进行求解会有一些困难，即使我们使用所有元素的最小参数化状态参数向量θ，目标函数中的海森矩阵(用于参数更新的\\(H\\Delta x\\)=b)，由于存在不可观测的自由度，因此是奇异的。 更加具体的说就是，它是一个秩亏矩阵，rank缺了4，恰恰对应了变换\\(g()\\)中的4个自由度。 上面的Table 1 列出了3种常用的处理方法，其中， (gauge fixation approach)是在一个较小的参数空间中进行优化，在这个空间中没有不可观测的状态，因此Hessian是可逆的，这本质上强制了解的硬约束 (gauge prior approach)是通过附加惩罚(来产生一个可逆的Hessian)来增强目标函数，以使解决方案以一种软的方式满足某些约束 (free gauge approach)使用H的伪逆，来隐式地为唯一解决方案提供额外的约束(用最小范数更新参数) 前两种策略需要特定于VI问题的知识(需要约束的状态)，而最后一种策略是通用的 4.1. Rotation Parametrization for Gauge Fixation or Prior 使用gauge fixation和gauge prior方法存在一个问题就是，固定相机位姿的1自由度yaw旋转角并不直接。 在使用求解器(如高斯牛顿、LM)迭代时，标准的更新旋转量的方法是: 其中，q代表第q次迭代 通过设置\\(\\delta \\phi^q\\)中关于\\(z\\)的元素为0，就可以对\\(R^q\\)中的yaw角进行固定，然而，如果连接几次这样的更新，如\\(R^Q=\\prod_{q=0}^{Q-1} Exp(\\delta \\phi ^q)R^0\\)，即相当于经过多次更新之后，并不能把\\(R^Q\\)的yaw角固定成与\\(R^0\\)的一致，测试代码如下: 1234567891011121314151617#include &lt;iostream&gt;#include &lt;eigen3/Eigen/Core&gt;#include &lt;eigen3/Eigen/Dense&gt;#include \"sophus/so3.hpp\"using namespace std;int main() &#123; Eigen::Matrix3d R= Eigen::Matrix3d::Identity(); Sophus::SO3d R_n(R); R_n= Sophus::SO3d::exp(Eigen::Vector3d(0.3,0.1,0))*R_n; cout&lt;&lt;\"First :\"&lt;&lt;R_n.log().transpose()&lt;&lt;endl; R_n= Sophus::SO3d::exp(Eigen::Vector3d(0.1,0.2,0))*R_n; cout&lt;&lt;\"Second :\"&lt;&lt;R_n.log().transpose()&lt;&lt;endl; R_n= Sophus::SO3d::exp(Eigen::Vector3d(0.5,0.1,0))*R_n; cout&lt;&lt;\"Third :\"&lt;&lt;R_n.log().transpose()&lt;&lt;endl; return 0;&#125; 123First : 0.3 0.1 0Second : 0.399579 0.29916 -0.0251046Third : 0.896385 0.404603 0.0308449 尽管使用yaw-fixation或者使用添加先验的方法可以应用于任何相机位姿，这通常用于第一帧。因此，对于其他帧的相机位姿，我们使用标准的迭代更新，对于第一帧，\\(R_0\\)，我们使用更加方便的参数。我们不直接使用R0，而是使用左乘增量: 其中，旋转向量\\(\\Delta \\phi_0\\)被初始化为0，然后进行迭代更新。然而，旋转向量在\\(||\\Delta \\phi_0||=\\pi\\)的时候具有奇异，然而在优化的时候，提供的初值应该比较接近真值，即(\\(||\\Delta \\phi_0||&lt;\\pi\\))，因此可以暂时不过分计较这个问题。 4.2. 处理Gauge Freedom的不同方法 4.2.1. gauge fixation approach 在整个优化过程中，测量固定包括固定第一帧位姿的位置和偏航角，这通过设置如下来实现: 其中\\(p_0^0\\)是第一帧相机的初始位姿，固定这些参数向量相当于将残差所计算的雅克比矩阵的对应的列置为0，即\\(J_{p0}=0\\)，\\(J_{\\Delta 0z}=0\\) 4.2.2. gauge prior approach 通过在目标函数(等式1)加入惩罚项: 关于\\(\\Sigma_{0}^P\\)的选择在后面讨论 4.2.3. free gauge approach 这个处理方法是让参数向量在优化中自由演化。为了求解这个奇异的Hessian矩阵，我们通过使用伪逆或者是添加一些阻尼(如LM算法)使得最小二乘问题可解。 三种方法优化迭代过程中参数空间路径的比较如图2所示 5. 三种处理方式的对比流程 5.1. 数据生成 我们采用6自由度的轨迹，分别是类正弦波，弧状的，矩形的。考虑两种路标配置： 平面的，3D点粗略的分布在几个平面上 随机的，3D点随机沿着轨迹生成 图3展示了仿真: 为了生成imu测量值，我们使用B样条拟合轨迹，然后采样出加速度和角速度。采样值会受到bias和额外添加的高斯白噪声影响，然后作为Imu测量值。 对于数据额测量，我们使用pinhole相机模型，将3D点投影到图像上，得到3D-2D的点对，然后也添加高斯白噪声。 5.2. 优化求解器 为了求解VI系统的状体估计问题，使用gogle的Ceres求解器，采用LM算法。然后实现了上面所述的3种对gauge freedoom的处理方式。对于每条轨迹，我们沿着轨迹采样一些关键帧。我们的参数空间包含了这些关键帧的状态(如位置、旋转、和速度)，以及3D点的位置，而初始状态被随机打乱 5.3. 评估 准确率: 为了评估状态估计值的准确率，我们首先计算了将估计值对齐到真值的变换，这个变换从所有轨迹的第一帧开始计算，这个变换具有4自由度(也就是上面提到的平移和绕重力方向矢量的旋转)。 对齐之后，我们计算所有关键帧的均方差根(RMSE)，特别的，我们对位置和速度误差使用欧几里得距离来计算。 对于旋转估计值，我们首先计算估计值和真值的相对旋转量(轴角形式表示)，然后使用相对旋转的角度作为旋转误差。 计算效率: 为了评估算力消耗，我们记录了求解器的收敛的时间和迭代次数。我们使用每种配置(如轨迹和3D点的结合)，进行50次试验，计算平均时间和精度指标 协方差: 我们同样比较由优化算法产生的协方差，这些协方差对active SLAM等应用有重要意义。 参数估计值的协方差由Hessian矩阵的逆确定。(对于free gauge approach，使用摩尔-彭罗斯伪逆，因为Hessian是奇异的) 6. 对比结果研究 6.1. Gauge Prior: 选择恰当的先验权重 在比较3种方法之前，对于Gauge Prior Apporach，首先需要选择先验协方差\\(\\Sigma_0^P\\)。 一种通用的选择是\\(\\Sigma_0^P=\\sigma_0^PI\\)，也就是(式11)中的先验变成\\(||r_0^P||_{\\Sigma_{0}^P}^2=w^P||r_0^P||^2\\)，其中\\(w^P=\\frac{1}{\\sigma_0^2}\\) 我们测试了大范围的先验权重\\(w^P\\)，最后得到的结果都是相似的。 需要注意的是，\\(w^P=0\\)的本质是第三种方法free gauge approach，而\\(w^P \\rightarrow \\infin\\)对应的是第一种方法gauge fixation approach 6.1.1. Accuracy 图4展示了随着先验权重变化，RMSE的变化。 可以看出，不同先验权值的估计误差非常相似(注意纵轴上的数字)。虽然对于轨迹和三维点的不同配置没有明确的最优先验权值，但当权值增加到一定的阈值以上时，RMSE稳定在一个值上，如图4则是500 6.1.2. Computational Cost 图5展示了不同先验权重的计算代价，与图4相似，当先验权值大于一定值时，迭代次数和收敛时间趋于稳定。 有趣的是，当先前的权重从0增加到稳定的阈值时，在计算时间上有一个峰值，对于所有配置都可以观察到相同的行为。 为了详细研究这一行为，我们在图6中绘制了几个先验权值的每次迭代的平均重投影误差的先验误差， 位置先验误差是第一个位置的当前估计值与其初始值之间的欧氏距离 偏航先验误差是第一个旋转的当前估计相对于其初始值的相对旋转的z分量 平均重投影误差为所有关键帧中观察到的三维点的个数所平均得到的总视觉残差 对于非常大的先验权重(\\(10^8\\))，随着先验误差减少至0，算法同时也减少了重投影误差。 相比之下，对于较小的先验权值(如50-500)，优化算法在前两次迭代中减少了重投影误差，但代价是增加了先验误差，然后，优化算法进行多次迭代，(沿轨道移动)，对先验误差进行微调，同时保持重投影误差较小，因此计算时间增加。 6.1.3. 讨论 对于不同的先验权值，解的精度变化不明显时(如图4)，需要选择适当的先验权重来保持较低的算力消耗(图5). 极大的权值被丢弃，因为它们有时会使优化变得不稳定，对于不同的配置(轨迹和3D点的组合得到各种配置)，我们观察到类似的行为。因此，在接下来的部分，对于gauge prior approach，我们将使用合适的先验权重(如\\(10^5\\))。 6.2. 准确度和计算量 我们比较了三种方法在六种模拟轨迹(正弦、圆弧和矩形)和三维点(平面和随机)组合上的性能。 我们优化了使用不同扰动来初始化的目标函数，然后观察到结果都是相似的。所选取的扰动如下: 真值位置使用5cm的向量进行扰动(对于整条轨迹就是5m) 旋转量使用随机旋转6度进行扰动 速度使用均匀分布随机扰动[-0.05,0.05]m/s ，(速度均值是2m/s) 3D点的位置采用均匀随机变量[-7.5,7.5]cm来进行扰动 表二列出了50次试验的平均RMSE 我们省略了gauge prior approach的结果，因为它们与gauge fixation approach在小数点后8位以内的结果相同。 可以看到，在gauge fixation approach和free gauge approach之间仅有很小的差异。 收敛时间和迭代次数如图7所示 gauge prior approach和gauge fixation approach的计算量大体相同，而第三种方法即free gauge approach比前两者稍微更快一些。 具体来说，除了具有随机三维点的正弦轨迹外，free gauge approach的迭代次数较少，(总体)收敛时间也较短。 有一点需要注意的是: gauge fixation approach由于优化中变量的数量较少，因此每次迭代花费的时间最少 6.3. 小结 这三种方法的精确度几乎相同 gauge prior approach，需要选择合适的先验权重来避免计算量的增大 如果选择合适的先验权重，那么gauge prior approach将会与gauge fixation approach具有几乎一致的性能表现(精确度和计算量) free gauge approach比其他两种方法稍微快一些，因为它只需更少的迭代次数即可收敛 虽然可以对不可观测的DoFs进行固定(即gauge fixation approach)(回想一下，我们使用了一个定制的参数化方法(9)来固定偏航角)，但是free gauge approach有一个额外的优点，那就是它是通用的 7. 真实世界数据集测试 我们使用EuRoC MAV数据集的两个序列进行了与前面仿真环境相同的实验比较: Machine Hall 1 (MH1) 和 Vicon Room 1 (VI1). 我们使用 semi-direct visual odometry algorithm (SVO)来提供优化问题中参数的初始值，并且使用双目配置的SVO来消除尺度模糊性。对于bias，则直接使用数据集中附带的真值。 评估的方法与上面仿真环境下的一样，需要注意的是: 我们并没有在完整的轨迹上运行优化，而是在更短的段上运行，这足以说明三种方法的不同之处 三种不同方法的计算成本如图11所示 准确率由表3展示: 这三种方法都有相似的估计误差","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"}],"tags":[]},{"title":"Apollo_or_ROS","slug":"平台对比/Apollo-or-ROS","date":"2020-04-03T10:09:31.000Z","updated":"2020-04-04T14:29:51.000Z","comments":true,"path":"2020/04/03/平台对比/Apollo-or-ROS/","link":"","permalink":"http://yoursite.com/2020/04/03/%E5%B9%B3%E5%8F%B0%E5%AF%B9%E6%AF%94/Apollo-or-ROS/","excerpt":"","text":"1. 面向对象 1.1. Apollo 低版本: 面向封闭场所的无人驾驶 高版本: 面向城市区域的无人驾驶为主 1.2. AutoWare 1.0 主要面向封闭区域 2. 项目架构 2.1. 基本架构 2.1.1. Apollo(完善但复杂) 2.1.2. AutoWare1.0(简化但Main) 3. 功能实现 3.1. Localization 3.1.1. 技术简介 3.1.1.1. Apollo中的定位技术 RTK模式: 为了方便调试，Apollo自行实现了一套RTK解算，只使用RTK的定位信息。 现在惯导芯片一般都会配一个板卡（NovAtel也卖这样的板卡），直接集成了RTK的定位结果。为什么我们还需要自己开发GNSS-RTK呢？ 从系统的角度考虑，需要每个子模块都是可控的，举一个简单的例子，当给出一个定位结果偏了，但给出的方差很小，也就是置信度很高。我们是没办法知道原因的。 MSF(Multiple Sensor Fusion)模式: 采用Kalman滤波器，对位置、姿态和速度进行融合。 IMU: 惯导解算 LIDAR: NDT匹配算法 GPS: RTK解算 使用松耦合的方式把惯性导航解算、GNSS定位、点云定位三个子模块融合在一起。(松耦合and紧耦合: 松耦合的数据只有位置、速度、姿态，紧耦合会包括GNSS的导航参数、定位中的伪距、距离变化等。) 使用了一个误差卡尔曼滤波器，惯性导航解算的结果用于kalman滤波器的时间更新，也就是预测；而GNSS、点云定位结果用于kalman滤波器的量测更新 3.1.1.2. Autoware(ROS)中的定位技术 基于3D Lidar的定位: 采用NDT点云配准算法进行定位，分别实现了 基于PCL的NDT算法 自行实现的NDT算法 改进的NDT算法:NDT-TKU GNSS: 借助ROS社区，直接使用ROS开源的GNSS驱动，读取GPS-RTK的定位信息 参考文档 Autoware.AI NDT文档 Autoware.AI 定位设计 NDT定位算法原理 3.1.2. 技术成熟度 3.1.2.1. Apollo Apollo实现的RTK解算、MSF传感器融合定位，都有成熟的理论指导，成熟度较高。并且从Apollo最近的几个版本来看，定位模块的改动不大。 3.1.2.2. Autoware Autoware采用的NDT定位算法是2009年的一篇博士论文，目前仍被广泛应用，技术相对成熟，并且名古屋大学教授对此进行了改进，即NDT-TKU算法 3.1.3. 技术前沿性 从定位技术的前沿性来看，Apollo比Autoware领先，并且更加完善 3.1.3.1. Apollo 从目前现有的代码来看，Apollo的RTK、MSF定位都是基于传统技术如: RTK解算 GNSS/IMU解算 NDT点云匹配 ESKF误差卡尔曼 的堆叠，但是实际上Apollo提出了许多新的算法，如基于深度学习的点云匹配，基于深度学习的定位融合，虽然目前没有直接在Apollo代码中实现，不排除后续升级版本对定位模块的改进。 3.1.3.2. Autoware Autoware主要面向封闭环境，因此其认为，使用3D Lidar SLAM足以解决封闭环境的定位问题，而没有像Apollo那样实现GPS/IMU的融合解算，只是使用了EKF来对3D激光点云定位和GPS定位进行了融合，其GPS定位信息转换模块值得学习一下。 3.1.4. 源码开放度 3.1.4.1. Apollo Apollo虽说开源，但是核心部分还是抓的死死的，其中包括 rtk解算gnss_solver 点云定位lidar_locator 惯导解算sins.h 证据如下: 在modules/localization/msf/local_integ/localization_gnss_process.h文件中，引用了 1#include \"include/gnss_solver.h\" 在modules/localization/msf/local_integ/localization_lidar.h文件中，引用了 1#include \"include/lidar_locator.h\" 在modules/localization/msf/local_integ/localization_integ_process.h文件中，引用了 1#include \"include/sins.h\" 当然还有其他一些，上面引用的文件在源码中是找不到其影子的，因为这些头文件打包在Apollo的docker镜像中，至于对应CPP实现，那是不会给你哒，放心好了，早已编译成.so文件了 123liblocalization_msf.so -&gt; liblocalization_msf.so.1liblocalization_msf.so.1 -&gt; liblocalization_msf.so.1.0.2liblocalization_msf.so.1.0.2 关于这部分的内容，更加具体的可参见文档: 【Apollo】【localization】调试与分析 3.1.4.2. Autoware Autoware毕竟是基金组织，也没什么人投钱，基本上实现了的都开了 点云定位: NDT算法，有pcl版本的，也有自行实现版本的，有cpu版本的也有gpu版本的，最后，还有改进版本的 GNSS: 直接使用ROS社区开源驱动 证据如下: 3.1.5. 可移植性 3.1.5.1. Apollo 向内移植 Apollo实现了一整套的底层接口、驱动，向内移植定位算法理论上可行。 前提是: 掌握Apollo的关于Localization协议栈，数据内容以及格式 掌握相关底层设备的消息回调处理流程 你得自己有算法 向外移植 向外移植也不是不可以，但核心技术并不掌握在手中，谁会干这种事呢？ 前提工作: 掌握Apollo的关于Localization协议栈，API接口，数据内容以及格式 关于Localization部分所有输入输出关系全部掌握 3.1.5.2. Autoware 完全基于ROS，移植性不言而喻。 3.1.6. 总结 总结就是，还是要有自己的核心算法呀。 3.2. Perception 3.3. Decision 3.4. Control/Planning 4. 平台 4.1. 解决方案 4.2. 云服务 4.3. 开发套件 4.4. 规范认证","categories":[{"name":"平台对比","slug":"平台对比","permalink":"http://yoursite.com/categories/%E5%B9%B3%E5%8F%B0%E5%AF%B9%E6%AF%94/"}],"tags":[]},{"title":"FEJ-黄国权","slug":"文献阅读/FEJ-黄国权","date":"2020-03-31T13:26:45.000Z","updated":"2020-03-31T17:26:54.000Z","comments":true,"path":"2020/03/31/文献阅读/FEJ-黄国权/","link":"","permalink":"http://yoursite.com/2020/03/31/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/FEJ-%E9%BB%84%E5%9B%BD%E6%9D%83/","excerpt":"","text":"1. First Estimates Jacobian (FEJ)-EKF 2. 标准EKF-SLAM (引用崔老师的论文阅读配图) 如图所示，是以 2D 平面上的小车为例，且假设运动输入\\(u\\)为始终沿车头方向的速度\\(v\\),和角速度\\(\\omega\\)，世界坐标系为W(orld),小车坐标系为R(obot) 取状态向量，由小车的位姿以及路标点的在全局坐标系的位置组成 在时间步k，状态向量如下: 其中，\\(x_{Rk}=[p_{Rk}^T,\\phi_{Rk}]^T\\)，表示了小车的位姿(位置和旋转)，\\(p_L\\)则是路标的坐标(世界坐标系) 2.1. EKF传播 在这一步中，得到两个连续时间步之间的姿态变化估计值，然后利用EKF来传播机器人状态估计。 另一方面，由于路标是静态的，它的估计值不会随着新的里程测量的加入而改变 于是，可以得到EKF传播步骤： 其中， \\(C(\\cdot)\\)表示了2x2的旋转矩阵(基于k时刻更新之后的从机器人坐标系到世界坐标系的旋转变换) \\(^{R_k}\\hat{x}_{R_{k+1}}=[^{R_k}\\hat{p}_{R_{k+1}}^T,^{R_k}\\hat{\\phi}_{R_{k+1}}]\\)是机器人在k到k+1时刻的运动估计，这个估计受到零均值高斯白噪声的影响，白噪声为\\(w_k=^{R_k}x_{R_{k+1}}-^{R_k}\\hat{x}_{R_{k+1}}\\)，其协方差矩阵为Q 除了状态传播，线性化的误差状态传播也是需要的，即: 其中，\\(\\Phi_{R_k}\\)是\\({3\\times 3}\\)矩阵，是上面的预测方程对状态量的雅克比， 于是，\\(\\Phi_{R_k}\\)和\\(G_{R_k}\\)形式如下: 上下标说明 - 下标\\(l|j\\)，是指在时间步长为j的所有测量值处理完毕后，在时间步l处对一个状态量的估计 - \\(\\hat{x}\\)用来表示随机变量x的估计值 - \\(\\tilde{x}=x-\\hat{x}\\)表示估计值的与真值的误差 - \\(s\\phi,c\\phi\\)分别表示\\(\\sin \\phi\\)和\\(\\cos \\phi\\) 需要指出的是，上述传播方程的形式是通用的，适用于任何机器人运动学模型(如独轮车、自行车或Ackerman模型). 2.2. EKF更新 EKF中用于更新的观测是路标相对于机器人的相对位置的函数: 其中,\\(v_k\\)是协方差为\\(R_k\\)的零均值高斯测量噪声，在这里，允许观测函数h为任意的2维观测函数，只要它是可逆的(只要我们能从\\(z_k\\)完全确定机器人相对地标位置的估计值)。 通常，测量函数是非线性的，因此它被线性化，用于EKF，线性化的测量误差方程如下: 其中，\\(H_{Rk}\\)和\\(H_{Lk}\\)是h分别对机器人位姿和路标位置的雅克比，在线性化点\\(\\hat{x}_{k|k-1}\\)处计算得到。使用链式法则，有: 其中， \\(\\bigtriangledown h_k\\)表示观测函数h()对于机器人-路标的相对位置的雅克比 如对\\(^{R_k}p_L=C^T(\\phi_{Rk})(p_L-P_{RK})\\)的雅克比，也就是观测函数h()对路标在机器人坐标系的坐标的雅克比 线性化点在\\(\\hat{x}_{k|k-1}\\) 3. SLAM的非线性可观测性分析 3.1. 先导内容(引自_崔老师_连续非线性系统的可观性) 3.1.1. 非线性系统的可观测性矩阵 3.2. 基于小车实例的可观测性分析 在研究EKF系统模型的可观测特性之前，先对连续时间非线性SLAM系统进行可观测性分析，将实际非线性系统的性质与EKF系统模型的性质进行比较，我们可以确定标准EKF系统中的一个基本缺点，这将会导致滤波器的不一致性。 下面证明SLAM系统不满足可观测性秩条件，因此它既不是局部弱可观测的，也不是局部可观测的 对于连续时间的分析，我们使用了一个上面所述的2D平面小车运动学模型，以及相对位置测量模型。连续时间下的系统模型为: 其中，\\(u\\triangleq [v,w]^T\\)是控制输入量，包含线速度和角速度。 连续时间的相对位置测量模型为(即路标点在机器人坐标系的坐标): \\[ \\begin{aligned} C_{wr} p_{L,inR}=P_{L,in w}-P_{R}(t) \\\\ \\Longrightarrow C_{wr} p_{L,inR}+P_{R}(t)=P_{L,in w} \\end{aligned} \\] 上式就是将机器人坐标系下的路标点转换到世界坐标系的变换，反过来，就是(式16)，可以得到机器人坐标系下的路标点的坐标 对式(15)和式(16)中描述的系统模型进行可观测性分析，首先计算所有k阶Lie 微分\\(L_{f_j}^k h_i (for k \\in \\N,j=1,2,i=1,2)\\)，用\\(\\mathcal{G}\\)来表示。 由\\(\\mathcal{G}\\)各元素的梯度张成的空间\\(d\\mathcal{G}\\)为： 上述矩阵就是非线性SLAM系统的可观测矩阵，显然，这个矩阵的秩是2，因此这个系统是不可观测的。 3.2.1. 补充：引自_崔老师_可观性矩阵的计算 为什么只取到2阶？ 意味着n=3？ 3个自由度(平移xy+旋转)? 3.2.1.1. 观测z对状态X的雅克比\\(\\frac{\\partial z}{\\partial X}\\) 3.2.1.2. {观测值z对时间的导数\\(\\dot{z}\\)}对状态X的雅克比\\(\\frac{\\partial \\dot{z}}{\\partial X}\\) 3.2.1.3. {观测值z对时间的二次偏导\\(\\ddot{z}\\)}对状态X的雅克比\\(\\frac{\\partial \\ddot{x}}{\\partial X}\\) 3.2.1.4. 最终得到可观性矩阵 3.3. 不可观测的意义 直觉上，就是我们无法获得绝对的结果，只是从有效测量中获得的相对的状态信息。 尽管不可观测的子空间的概念不能在这个系统中严格定义，通过对\\(d\\mathcal{G}\\)的正交子空间\\(d\\mathcal{G}\\perp\\)的基进行物理解释，我们可以获得有用的信息。 通过观察，我们可以看到\\(d\\mathcal{G}\\perp\\)空间一种可能的基具有如下形式: 3.3.1. (1) 零空间内平移 从向量n1和n2的结构中我们可以看到状态的变化，即 \\[ \\Delta x=\\alpha n_1 +\\beta n_2 \\] 这对应于在x轴和y轴上的漂移，x轴上漂移\\(\\alpha\\)个单位，y轴上漂移\\(\\beta\\)单位 因此，如果机器人和地标位置移动相等，则根据测量结果，\\(x\\)和\\(x+\\Delta x\\)的状态是相等的，即满足\\(Hx=0\\)和\\(H(x+\\Delta x)=0\\) 3.3.2. (2) 零空间内旋转 为了更好地理解\\(n_3\\)的物理意义，我们考虑一个情况: 即'x-y'平面通过一个小的旋转量\\(\\delta \\phi\\)进行旋转，即受到小扰动。对于平面内所有的点都进行旋转变换，从\\(\\boldsymbol{x}=[x,y]^T\\)变换为\\(\\boldsymbol{x&#39;}=[x&#39; , y&#39;]\\)，变换等式为: 其中，旋转矩阵如下: \\[ \\begin{aligned} \\begin{bmatrix} \\cos \\delta \\phi &amp; -\\sin \\delta \\phi \\\\ \\sin \\delta \\phi &amp; \\cos \\delta \\phi \\end{bmatrix} \\sim \\begin{bmatrix} 1 &amp; -\\delta \\phi \\\\ \\delta \\phi &amp; 1 \\end{bmatrix} \\end{aligned} \\] 利用上面这个结果，我们可以看到，如果机器人和路标点所在平面受到小扰动\\(\\delta \\phi\\)进行旋转，SLAM系统的状态向量变化如下: 这表明，向量\\(n_3\\)与x-y平面的旋转相关，因为\\(n_3 \\in d \\mathcal{G} \\perp\\)，这个结果展示了对于旋转量也是不可观测的，因为旋转不会导致观测量的改变。 3.3.3. 结论 在上面的分析中，对\\(d \\mathcal{G} \\perp\\)空间的基向量意义的分析，与我们的直觉是一致的，即全局坐标下的状态向量不可观测。","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"矩阵的列空间与零空间","slug":"数学基础/矩阵的列空间与零空间","date":"2020-03-31T10:28:33.000Z","updated":"2020-03-31T12:13:46.000Z","comments":true,"path":"2020/03/31/数学基础/矩阵的列空间与零空间/","link":"","permalink":"http://yoursite.com/2020/03/31/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%97%E7%A9%BA%E9%97%B4%E4%B8%8E%E9%9B%B6%E7%A9%BA%E9%97%B4/","excerpt":"","text":"1. 向量空间 向量空间又称线性空间，是线性代数的中心内容和基本概念之一。 1.1. 向量张成的空间 如果几个向量的线性组合在某一个向量空间中，并且该向量空间仅包括这几个向量的线性组合，那么这个向量空间就叫做这几个向量张成的空间。简单地说，N个向量张成的空间就是N个向量的线性组合 2. 子空间 设V是\\(R^n\\)的一个非空子集，若V中的任意N个向量的线性组合依然属于V，则称V是\\(R^n\\)的一个线性子空间，简称子空间。 根据概念，如果V是\\(R^n\\)的线性子空间，则V一定满足三个条件 包含0向量 若x是V中的一个向量，那么x与一个变量的乘积\\(nx\\)也在线性子空间V中——数乘封闭性 若a，b是V中的两个向量，那么a+b也在线性子空间V中——加法封闭性 例子: 下面的V是否是\\(R^2\\)的子空间？ 可以通过分量的取值范围得知，V是直角坐标系的一、四象限： 由于a1+a2 ≥ 0，所以满足加法封闭性。 检验数乘封闭性: 当标量为负数时，得到的结果\\(-x\\)，超越了第一、四象限，不在这个子空间V中，不满足数乘封闭性 因此，V不是\\(R^2\\)的子空间 3. 零空间 A是\\(m\\times n\\)矩阵，x是列向量，如果存在向量集合N，满足 \\[ N=\\{x \\in R^n | Ax =0 \\} \\] 则称N是矩阵A的零空间 3.1. 零空间与\"Ax=0\" 可知，零空间是方程Ax = 0的所有解的集合，也就是说，零空间就是方程Ax=0的解向量所张成的空间 检验零空间是否是\\(R^n\\)的子空间，即检验 加法封闭性 满足 数乘封闭性 满足 所以零空间也是\\(R^n\\)的子空间 3.2. 找出零空间 就是解\\(Ax=0\\)，得到解向量，所张成的空间呗 3.2.1. 例子1 只需求解方程组就可以了，方法之一是将A化为行最简阶梯矩阵: 为了求解方便，我们的目标是让方程组的未知数尽量少，所以还可以进一步化简，让台角上方全为0: 将行最简阶梯矩阵转换为方程组 两个方程，四个未知数，那么解向量的个数为\\(n-r(A)=4-2=2\\)，该零空间是由两个向量张成的空间: x3，x4可以是任意实数，a，b是线性无关的，所以A的零空间就是a和b张成的空间 3.2.2. 例子2 3.3. 零空间与线性无关 3.3.1. 线性相关与线性无关 3.3.2. 线性无关矩阵的零空间只包含零向量 \\(A_{m\\times n}\\)由n个列向量组成，那么Ax即表示了对n个列向量的线性组合，即: 如果A是线性无关的，意味着方程组只有一个全零解，或者说，这个方程的解集是A的零空间，并且这个零空间只包含零向量，即上面列向量的系数(状态)\\(\\{x_1,x_2,x_3\\cdots\\}\\)全为0 结果: 当A是满秩方阵或列满秩的长方矩阵时，A的零空间只有零向量（仅仅是行满秩时就不一定了） 当一个矩阵的零空间只有零向量时，说明该矩阵的列向量线性无关 4. 列空间 如果A是\\(m\\times n\\)的矩阵，那么A的列空间是A中所有列向量张成的空间。A的列空间用C(A)表示 4.1. 列空间与\"Ax=b\" 如果有方程: \\[ Ax=b \\] 如果b在矩阵A的列空间中(即b可以使用Ax来表示(x不全为0))，此时Ax = b有解 b不在A的列空间中，Ax = b无解","categories":[{"name":"数学基础","slug":"数学基础","permalink":"http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"四元数的状态误差卡尔曼-对随机噪声和干扰的积分","slug":"IMU相关/四元数的状态误差卡尔曼-对随机噪声和干扰的积分","date":"2020-03-30T15:49:45.000Z","updated":"2020-04-02T16:11:38.000Z","comments":true,"path":"2020/03/30/IMU相关/四元数的状态误差卡尔曼-对随机噪声和干扰的积分/","link":"","permalink":"http://yoursite.com/2020/03/30/IMU%E7%9B%B8%E5%85%B3/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC-%E5%AF%B9%E9%9A%8F%E6%9C%BA%E5%99%AA%E5%A3%B0%E5%92%8C%E5%B9%B2%E6%89%B0%E7%9A%84%E7%A7%AF%E5%88%86/","excerpt":"","text":"对随机噪声和干扰的积分处理 我们现在的目的在于为动态系统中随机变量的积分提供合适的方法，当然，我们不能对未知的随机值进行积分，但我们可以对其方差和协方差进行积分，用于对不确定性进行传播。 这对于在连续时间系统(被离散化)中的状态估计器建立协方差矩阵是必须的 考虑一个连续时间系统 \\[ \\dot{x}=f(x,u,w) \\] 其中, \\(x\\)是状态向量 \\(u\\)是控制信号，含有噪声\\(\\tilde{u}\\)，因此，对控制量的观测\\(u_m=u+\\tilde{u}\\) \\(w\\)是随机干扰的向量 对于噪声和干扰，都被假设为高斯过程，分别有 \\[ \\tilde{u} \\sim \\mathcal{N}\\{0,U^c\\} \\] \\[ w^c \\sim \\mathcal{N} \\{0, W^c\\} \\] 其中，上标 \\(^c\\)表示连续时间上的不确定性标记，这是我们想要积分的对象 控制信号中的噪声\\(\\tilde{u}\\)和随机干扰\\(w\\)在性质上有明显差异 离散化的时候，控制信号在固定时间\\(n\\Delta t\\)被采样，于是有\\(u_{m,n}\\triangleq u_m(n\\Delta t)=u(n\\Delta t)+\\tilde{u}(n \\Delta t)\\)，测量部分在积分间隔内被看做是固定的常数，如\\(u_m(t)=u_{m,b}\\)，因此，在采样时间\\(n\\Delta t\\)时刻的噪声也被认为是常数，即 \\[ \\tilde{u}(t)=\\tilde{u}(n\\Delta t)=\\tilde{u}_n,~~ n\\Delta t &lt; t &lt;(n+1) \\Delta t \\tag{324} \\] 而扰动项\\(w\\)不能被采样 结果，在积分时间\\(\\Delta t\\)内，对两种对象的处理方式不一样。 标准形式处理噪声和扰动 连续时间误差状态方程(式322)可以线性化为: 然后在给定采样时间间隔\\(\\Delta t\\)内进行积分，得到离散化形式: 会得到3种非常不一样的形式，如下: 状态转移部分: 从附录B，我们知道动态的部分是积分得到的转移矩阵，即: 其中，转移矩阵\\(\\Phi=e^{A\\Delta T}\\)可以使用闭式表达或者使用不同精确度等级的近似 测量噪声部分: 从式(324)，可以得到： 这意味着测量噪声，一旦被采样，就以确定的形式被积分，因为其在积分区间内的behavior是已知的. 随机干扰部分: 从概率论，我们知道在时间间隔\\(\\Delta t\\)内对连续时间的高斯白噪声进行积分，将产生离散的高斯脉冲\\(w_n\\)，如下: 与上面测量噪声部分相反，扰动在积分区间内是不确定的，因此需要随用随机变量来积分。 因此，离散时间下，误差状态方程可以写成: 其中，转移矩阵、控制和扰动矩阵如下: 根据噪声和干扰的强度，有: 总结 EKF的预测阶段，将会传播误差状态的均值和方差，根据如下方程: 在这里，观察积分区间的不同项是很重要和很有说明意义的: 动态误差项是指数函数形式的\\(e^{A \\Delta t}\\) 测量噪声项是二次的 干扰误差项是线性的(一次) 简化形式处理噪声和扰动脉冲 简化形式 我们经常遇到这样的情况(例如，重用现有代码或解释其他作者的文档时)，EKF预测方程的形式比我们这里使用的更简单，即 这相当于一般的离散时间动态系统: 其中，i是服从零均值，方差为Q的高斯分布，是一个随机(白色，高斯)脉冲的向量，将直接添加到\\(t_{n+1}\\)时刻的状态向量上: 矩阵Q被简化的认为是这个脉冲的协方差矩阵，其计算等式如下: (与式337是一致的) 进一步 在脉冲不影响全部状态(full state)的情况下[这是常有的事情]，矩阵Q不是完全对角的，可能包含大量的0，于是可以使用下面的等式(添加了一个系数矩阵\\(F_i\\)而已): (式339)可以变成: 其中，矩阵\\(F_i\\)简单地将每个单独的脉冲映射到它影响到的状态向量的一部分(简单来说，就是想影响那一个状态，就在对应的对角线维度上设置值)。 这样一来，相关的协方差\\(Q_i\\)则较小且呈全对角线，因此(式336,337)可以变成: 显然，无论是上面的式子，还是(式336,337)，都是等价的，因为: 完整版IMU例子 使用标准形式处理噪声和扰动 在前面的四元数的状态误差卡尔曼-Quaternion-kinematics-for-the-error-state-KF，我们研究了IMU的误差状态卡尔曼滤波器的构造，误差状态系统如(式133)所定义，其包含了 nominal state x， error-state \\(\\delta x\\) 控制信号\\(u_m=u+\\tilde{u}\\) 干扰\\(w\\) 分别如下: 在IMU的模型中，就像我们在本文档中所考虑的那样，控制噪声\\(\\tilde{u}\\)对应于IMU测量中的附加噪声(\\(w_n\\))，而扰动会影响IMU的偏置(bias)，因此导致产生随机游走误差 根据(式325)，(式275)，(式133) 得到连续时间下误差状态系统的: 系统矩阵A，控制B和扰动C矩阵 回顾(式325)，(式275)，(式133): 在imu的常规情况下，加速度计和陀螺仪的三个轴是一致的，因此，噪声和干扰是各向同性的(等方性的)，他们的标准差(标量)如下： 然后他们的协方差是完全对角的，如下: 系统以间隔时间\\(\\Delta t\\)的采样，并且按照(式332-335)进行演化====&gt; 即有离散时间下的误差状态系统，离散时间下，误差状态方程可以写成: 其中，转移矩阵、控制和扰动矩阵如下: 根据噪声和干扰的强度，有: 使用简化形式处理噪声和扰动(常见) 使用简化形式，则有误差状态方程: 状态转移矩阵\\(\\Phi\\)和扰动矩阵如下: 脉冲的方差分别是:","categories":[{"name":"IMU相关","slug":"IMU相关","permalink":"http://yoursite.com/categories/IMU%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"四元数的状态误差卡尔曼-对随机噪声和干扰的积分","slug":"四元数的状态误差卡尔曼/四元数的状态误差卡尔曼-对随机噪声和干扰的积分","date":"2020-03-30T15:49:45.000Z","updated":"2020-04-02T16:11:38.000Z","comments":true,"path":"2020/03/30/四元数的状态误差卡尔曼/四元数的状态误差卡尔曼-对随机噪声和干扰的积分/","link":"","permalink":"http://yoursite.com/2020/03/30/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC-%E5%AF%B9%E9%9A%8F%E6%9C%BA%E5%99%AA%E5%A3%B0%E5%92%8C%E5%B9%B2%E6%89%B0%E7%9A%84%E7%A7%AF%E5%88%86/","excerpt":"","text":"对随机噪声和干扰的积分处理 我们现在的目的在于为动态系统中随机变量的积分提供合适的方法，当然，我们不能对未知的随机值进行积分，但我们可以对其方差和协方差进行积分，用于对不确定性进行传播。 这对于在连续时间系统(被离散化)中的状态估计器建立协方差矩阵是必须的 考虑一个连续时间系统 \\[ \\dot{x}=f(x,u,w) \\] 其中, \\(x\\)是状态向量 \\(u\\)是控制信号，含有噪声\\(\\tilde{u}\\)，因此，对控制量的观测\\(u_m=u+\\tilde{u}\\) \\(w\\)是随机干扰的向量 对于噪声和干扰，都被假设为高斯过程，分别有 \\[ \\tilde{u} \\sim \\mathcal{N}\\{0,U^c\\} \\] \\[ w^c \\sim \\mathcal{N} \\{0, W^c\\} \\] 其中，上标 \\(^c\\)表示连续时间上的不确定性标记，这是我们想要积分的对象 控制信号中的噪声\\(\\tilde{u}\\)和随机干扰\\(w\\)在性质上有明显差异 离散化的时候，控制信号在固定时间\\(n\\Delta t\\)被采样，于是有\\(u_{m,n}\\triangleq u_m(n\\Delta t)=u(n\\Delta t)+\\tilde{u}(n \\Delta t)\\)，测量部分在积分间隔内被看做是固定的常数，如\\(u_m(t)=u_{m,b}\\)，因此，在采样时间\\(n\\Delta t\\)时刻的噪声也被认为是常数，即 \\[ \\tilde{u}(t)=\\tilde{u}(n\\Delta t)=\\tilde{u}_n,~~ n\\Delta t &lt; t &lt;(n+1) \\Delta t \\tag{324} \\] 而扰动项\\(w\\)不能被采样 结果，在积分时间\\(\\Delta t\\)内，对两种对象的处理方式不一样。 标准形式处理噪声和扰动 连续时间误差状态方程(式322)可以线性化为: 然后在给定采样时间间隔\\(\\Delta t\\)内进行积分，得到离散化形式: 会得到3种非常不一样的形式，如下: 状态转移部分: 从附录B，我们知道动态的部分是积分得到的转移矩阵，即: 其中，转移矩阵\\(\\Phi=e^{A\\Delta T}\\)可以使用闭式表达或者使用不同精确度等级的近似 测量噪声部分: 从式(324)，可以得到： 这意味着测量噪声，一旦被采样，就以确定的形式被积分，因为其在积分区间内的behavior是已知的. 随机干扰部分: 从概率论，我们知道在时间间隔\\(\\Delta t\\)内对连续时间的高斯白噪声进行积分，将产生离散的高斯脉冲\\(w_n\\)，如下: 与上面测量噪声部分相反，扰动在积分区间内是不确定的，因此需要随用随机变量来积分。 因此，离散时间下，误差状态方程可以写成: 其中，转移矩阵、控制和扰动矩阵如下: 根据噪声和干扰的强度，有: 总结 EKF的预测阶段，将会传播误差状态的均值和方差，根据如下方程: 在这里，观察积分区间的不同项是很重要和很有说明意义的: 动态误差项是指数函数形式的\\(e^{A \\Delta t}\\) 测量噪声项是二次的 干扰误差项是线性的(一次) 简化形式处理噪声和扰动脉冲 简化形式 我们经常遇到这样的情况(例如，重用现有代码或解释其他作者的文档时)，EKF预测方程的形式比我们这里使用的更简单，即 这相当于一般的离散时间动态系统: 其中，i是服从零均值，方差为Q的高斯分布，是一个随机(白色，高斯)脉冲的向量，将直接添加到\\(t_{n+1}\\)时刻的状态向量上: 矩阵Q被简化的认为是这个脉冲的协方差矩阵，其计算等式如下: (与式337是一致的) 进一步 在脉冲不影响全部状态(full state)的情况下[这是常有的事情]，矩阵Q不是完全对角的，可能包含大量的0，于是可以使用下面的等式(添加了一个系数矩阵\\(F_i\\)而已): (式339)可以变成: 其中，矩阵\\(F_i\\)简单地将每个单独的脉冲映射到它影响到的状态向量的一部分(简单来说，就是想影响那一个状态，就在对应的对角线维度上设置值)。 这样一来，相关的协方差\\(Q_i\\)则较小且呈全对角线，因此(式336,337)可以变成: 显然，无论是上面的式子，还是(式336,337)，都是等价的，因为: 完整版IMU例子 使用标准形式处理噪声和扰动 在前面的四元数的状态误差卡尔曼-Quaternion-kinematics-for-the-error-state-KF，我们研究了IMU的误差状态卡尔曼滤波器的构造，误差状态系统如(式133)所定义，其包含了 nominal state x， error-state \\(\\delta x\\) 控制信号\\(u_m=u+\\tilde{u}\\) 干扰\\(w\\) 分别如下: 在IMU的模型中，就像我们在本文档中所考虑的那样，控制噪声\\(\\tilde{u}\\)对应于IMU测量中的附加噪声(\\(w_n\\))，而扰动会影响IMU的偏置(bias)，因此导致产生随机游走误差 根据(式325)，(式275)，(式133) 得到连续时间下误差状态系统的: 系统矩阵A，控制B和扰动C矩阵 回顾(式325)，(式275)，(式133): 在imu的常规情况下，加速度计和陀螺仪的三个轴是一致的，因此，噪声和干扰是各向同性的(等方性的)，他们的标准差(标量)如下： 然后他们的协方差是完全对角的，如下: 系统以间隔时间\\(\\Delta t\\)的采样，并且按照(式332-335)进行演化====&gt; 即有离散时间下的误差状态系统，离散时间下，误差状态方程可以写成: 其中，转移矩阵、控制和扰动矩阵如下: 根据噪声和干扰的强度，有: 使用简化形式处理噪声和扰动(常见) 使用简化形式，则有误差状态方程: 状态转移矩阵\\(\\Phi\\)和扰动矩阵如下: 脉冲的方差分别是:","categories":[{"name":"四元数的状态误差卡尔曼","slug":"四元数的状态误差卡尔曼","permalink":"http://yoursite.com/categories/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC/"}],"tags":[]},{"title":"第四章-控制系统的李雅普诺夫稳定性分析","slug":"控制相关/线性系统理论/第四章-控制系统的李雅普诺夫稳定性分析","date":"2020-03-30T10:33:41.000Z","updated":"2020-04-02T03:24:04.000Z","comments":true,"path":"2020/03/30/控制相关/线性系统理论/第四章-控制系统的李雅普诺夫稳定性分析/","link":"","permalink":"http://yoursite.com/2020/03/30/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9D%8E%E9%9B%85%E6%99%AE%E8%AF%BA%E5%A4%AB%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%88%86%E6%9E%90/","excerpt":"","text":"1. 控制系统的李雅普诺夫稳定性分析 1.1. 对自动控制系统的要求 稳定：系统工作的前提 准确：稳态误差最小或者无差调节 快速：快速、平稳响应 1.2. 两种经典稳定性判据 1.2.1. 奈奎斯特稳定判据 1.2.2. 劳斯判据 稳定的条件：系统传递函数的极点全部位于复平面左侧 必要条件：闭环传递函数特征方程的所有系数全部为正（不允许为0或负数） 充要条件：劳斯表的第一列元素全部为正 稳定判据： 2. 李雅普诺夫(Lyapunov)稳定性分析方法 2.1. 间接法——第一法 通过解系统微分方程，利用解的性质判断，特征根全是负实数根 基本处理思路： 将非线性状态方程线性化 解线性化定长系统的特征值========&gt;判定是否稳定 2.1.1. 推导 设有系统\\(\\dot{x}=f(x,t)\\) 其中， R(x)是包含对x的二次以及二次以上的高阶导数项，Ax为线性化之后的一次近似 所以，有 \\[ \\dot{x}=Ax \\] 关于稳定性的判断 如果矩阵A的所有特征值都具有负实部，则\\(x_e\\)总是渐近稳定的，而且系统的稳定性与高阶导数项R(x)无关 如果矩阵A的特征值中，至少有一个具有正的实部，则无论高阶项R(x)如何，\\(x_e\\)总是不稳定的 如果矩阵A的特征值中，至少有一个的实部为0，则\\(x_e\\)具有局部稳定特性，此时原方程不能使用其一次近似\\(Ax\\)来表征，此时属于临界状况，此时局部稳定性取决于高阶导数项R(x) 2.1.2. 例子 2.2. 直接法——第二法 2.2.1. 先导知识——二次型及其定号性 2.2.1.1. 二次型 2.2.1.2. 正定二次型 设有如下二次型： \\[ f(x_1,x_2,\\cdots,x_n)=X^T A X \\] 其中，矩阵A是对称矩阵(\\(A=A^T,X=(x_1,x_2,\\cdots,x_n)\\)) 如果 \\[ \\begin{aligned} \\forall x \\in R^n, X \\neq 0 \\end{aligned} \\] 都有: \\[ f(x_1,x_2,\\cdots,x_n)&gt;0 \\] 则称\\(f(x_1,x_2,\\cdots,x_n)\\)是正定二次型，并且矩阵A正定 2.2.1.3. 二次型标量函数 二次型标量函数具有如下形式： 其中，矩阵P为实对称矩阵，即\\(p_{ij}=p_{ji}\\) 2.2.1.4. 定号性 二次型最基本的特性就是其定号性，即\\(V(x)\\)在坐标原点附近的特性。 2.2.1.5. Sylvester(塞尔维斯特)准则 二次型函数的正定性可以由S准则来判定，即 2.2.1.6. 矩阵A正定 充要条件 正惯性指数(即正值的特征值个数)等于n 矩阵A与单位矩阵合同 矩阵A的顺序主子式大于0 (见后面补充) 矩阵A的特征值大于0 必要条件 矩阵A的行列式大于0 (但是行列式大于0的矩阵不一定正定) 补充 (1)顺序主子式 取n阶方阵的部分元素化为行列式形式。方阵的第k阶行列式是由该方阵的前k行和k列元素组成 例子: 2.2.2. 一致渐近稳定判定 2.2.2.1. 大范围内渐近稳定 如果当\\(||x|| \\rightarrow \\infin\\) 时，有\\(V(x,t) \\rightarrow \\infin\\)，则系统在坐标原点的平衡状态是大范围内渐近稳定的。 2.2.2.2. 李氏函数V(x,t) 2.2.2.3. 形象描述 2.2.3. 渐进稳定判定 2.2.4. 一致稳定(等幅震荡)(非渐近稳定) 2.2.5. 不稳定 2.2.6. 例子1(大范围渐近稳定) 2.2.7. 例子2 2.2.8. 例子3(一致稳定)(等幅震荡) 2.2.9. 例子4(不稳定) 3. 线性系统的李雅普诺夫稳定性分析 3.1. 线性定常系统(连续) 设有线性定常系统\\(\\dot{x}=Ax\\) 则有： 假设矩阵A为非奇异矩阵，则系统唯一平衡状态在原点\\(x_e=0\\)处 如果它在状态空间中的某域内(包括\\(x_e=0\\))是渐近稳定的，则它一定是大范围渐近稳定的。 对线性系统\\(\\dot{x}=Ax\\)，其李氏函数\\(V(x)\\)一定可以取为二次型\\(x^TPx\\)的形式。 3.1.1. 线性定常系统李氏函数的求法 3.1.2. 根据求法得到的推论 推论：如果系统在\\(x_e=0\\)处是渐近稳定的(即矩阵A为稳定矩阵)，那么李雅普诺夫方程\\(A^TP+PA=-Q\\)，对于给定的任意一个正定对称矩阵Q，都有唯一解P 3.1.3. 例子 3.2. 线性时变系统(连续) 设有线性时变系统\\(\\dot{x}=A(t)x(t)\\) 3.2.1. 线性时变系统李氏函数的求法 3.3. 线性定常系统(离散) 设有线性定常离散系统: \\[ x(k+1)=Gx(k),~~~ x_e=0 \\] 3.3.1. 线性定常(离散)系统李氏函数的求法 3.3.2. 例子 3.4. 线性时变系统(离散) 设有线性时变离散系统: \\[ x(k+1)=G(k+1,k)x(k) ,~~~~ x_e=0 \\] 3.4.1. 线性时变(离散)系统李氏函数的求法 4. 问答 4.1. 稳定性的一般定义 4.1.1. BIBO稳定 对与经典的传递函数描述的系统，一般我们讲的稳定指的是BIBO稳定，即有界输入有界输出稳定。 4.1.2. 直观感受 4.2. 线性定常系统稳定的充要条件 4.2.1. 稳定性判据 4.2.1.1. 直接解法 4.2.1.2. 赫尔维茨稳定判据 4.2.1.3. 劳斯判据 特殊情况: 某一行第一项为0 劳斯表出现全零行 4.2.1.4. 奈奎斯特(Nyquist)准则 5. 参考 自动控制原理 系统稳定性 奈氏判据","categories":[{"name":"控制相关","slug":"控制相关","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/"},{"name":"线性系统理论","slug":"控制相关/线性系统理论","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"}],"tags":[]},{"title":"DSO-3-滑窗优化","slug":"SLAM代码课程/DSO/DSO-3-滑窗优化","date":"2020-03-30T01:20:20.000Z","updated":"2020-04-03T10:03:23.000Z","comments":true,"path":"2020/03/30/SLAM代码课程/DSO/DSO-3-滑窗优化/","link":"","permalink":"http://yoursite.com/2020/03/30/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/DSO-3-%E6%BB%91%E7%AA%97%E4%BC%98%E5%8C%96/","excerpt":"","text":"1. 滑窗优化 1.1. 一些状态估计方法 1.2. 高斯牛顿收敛性问题 可以看到，高斯牛顿方法在高次近似项中，缺了一些项，如在2阶项中缺了一项\\(S(x^{*})\\) 1.3. 滑窗优化中的雅克比 这里对光度参数求导(是相对的光度参数\\(e^{a_{ji}},b_{ji}\\))，后面会有操作，将这个变成绝对的光度参数导数？ \\(p_j\\)是投影点在target帧的像素坐标(\\(p_j=x_j\\)) 需要注意的是，虽然相机模型写成了函数的形式，但是实际上是相机内参矩阵K乘以归一化平面点的一个过程 因此，像素坐标对相机内参K的偏导是对\\(KP_j&#39;\\)进行求导，即\\(\\frac{\\partial x_j}{\\partial \\delta c}=\\frac{\\partial KP_j&#39;}{\\partial \\delta c}=\\dot{K}P_j&#39;+K\\dot{P_j&#39;}\\) 另外，PPT中的\\(u_j,v_j\\)是归一化平面坐标，不是像素坐标值(扯) \\(P_j&#39;\\)是投影点在target帧相机坐标系归一化平面上的点 其中，像素坐标对相机内参K的偏导推导过程如下 (1)下面是关于\\(part_1 \\Longrightarrow \\dot{K}P_j&#39;\\)这一部分 \\[ \\begin{aligned} \\dot{K}P_j&#39;&amp;=\\frac{\\partial K}{\\partial \\delta c}P_j&#39; \\\\ &amp;=\\begin{bmatrix} 1 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} P_j&#39;[0] \\\\ P_j&#39;[1] \\\\ 1 \\end{bmatrix} \\end{aligned} \\] 上面的\\((P_j&#39;[0],P_j&#39;[1],1)\\)是投影点在target帧的相机坐标系归一化平面上的坐标 需要写成求导的形式 \\[ \\begin{aligned} \\frac{\\partial part_1}{\\partial \\delta c}= J_{part1} \\begin{bmatrix} \\delta fx \\\\ \\delta fy \\\\ \\delta cx \\\\ \\delta cy \\end{bmatrix} \\end{aligned} \\] \\[ \\begin{aligned} \\dot{K}P_j&#39; \\triangleq \\begin{bmatrix} P_j&#39;[0] &amp; 0 &amp; 1 &amp; 0\\\\ 0 &amp; P_j&#39;[1] &amp; 0 &amp; 1 \\end{bmatrix} \\end{aligned} \\] (2)下面是关于\\(part_2 \\Longrightarrow K\\dot{P_j&#39;}\\)这一部分 主要先关注\\(\\dot{P_j&#39;}\\) \\[ \\begin{aligned} \\dot{P_j&#39;}= \\frac{\\partial P_j&#39;}{\\partial \\delta c}= \\underbrace{ \\frac{\\partial P_j&#39;}{\\partial P_j} \\frac{\\partial P_j}{\\partial P_i} \\frac{\\partial P_i}{\\partial P_i&#39;}}_{part_{21}} \\underbrace{ \\frac{\\partial P_i&#39;}{\\partial \\delta c}}_{part_{22}} \\end{aligned} \\] \\[ \\begin{aligned} &amp; x_j=KP_j&#39; \\\\ &amp; P_j&#39;=\\frac{P_j}{P_j[2]} \\\\ &amp; P_j=R_{ji}P_i&#39;+t\\cdot d_{pi} \\\\ &amp; P_i&#39;= K^{-1} x_i = \\begin{bmatrix} \\frac{1}{f_x} &amp; 0 &amp; -\\frac{c_x}{f_x} \\\\ 0 &amp; \\frac{1}{fy} &amp; -\\frac{c_y}{f_y} \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} x_i = \\begin{bmatrix} \\frac{x_i[0]-c_x}{f_x} \\\\ \\frac{x_i[1]-cy}{f_y} \\\\ 1 \\end{bmatrix} \\end{aligned} \\] 再次强调 \\(p_j=x_j\\)是投影点在target图像上的像素坐标 \\(P_j\\)是投影点在target帧相机坐标系的坐标 \\(P_j&#39;\\)是投影点在target帧相机坐标系的归一化平面坐标 \\(P_i&#39;\\)是点在参考帧的相机坐标系归一化平面坐标 \\(x_i\\)是点在参考帧图像上的像素坐标(即相当于ppt中的\\(p_i\\)(小写)) 现在处理\\(part_{21}\\) \\[ \\begin{aligned} part_{21}&amp;= \\frac{\\partial P_j&#39;}{\\partial P_j} \\frac{\\partial P_j}{\\partial P_i} \\frac{\\partial P_i}{\\partial P_i&#39;} \\\\ &amp;= \\frac{\\partial P_j&#39;}{\\partial P_j} \\frac{\\partial P_j}{\\partial P_i&#39;} \\end{aligned} \\] 其中, \\[ \\begin{aligned} \\frac{\\partial P_j&#39;}{\\partial P_j} &amp;= \\frac { \\partial \\begin{bmatrix} P_j[0]/P_j[2] \\\\ P_j[1]/P_j[2] \\\\ 1 \\end{bmatrix} } { \\partial P_j } \\\\ &amp;= \\begin{bmatrix} \\frac{\\partial P_j[0]/P_j[2]} { \\partial \\begin{bmatrix} P_j[0] &amp; P_j[1] &amp; P_j[2] \\end{bmatrix} } \\\\ \\frac{\\partial P_j[1]/P_j[2]} { \\partial \\begin{bmatrix} P_j[0] &amp; P_j[1] &amp; P_j[2] \\end{bmatrix} } \\\\ \\frac{\\partial 1} { \\partial \\begin{bmatrix} P_j[0] &amp; P_j[1] &amp; P_j[2] \\end{bmatrix} } \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial \\frac{P_j[0]}{P_j[2]}}{\\partial P_j[0]} &amp; \\frac{\\partial \\frac{P_j[0]}{P_j[2]}}{\\partial P_j[1]} &amp; \\frac{\\partial \\frac{P_j[0]}{P_j[2]}}{\\partial P_j[2]} \\\\ \\frac{\\partial \\frac{P_j[1]}{P_j[2]}}{\\partial P_j[0]} &amp; \\frac{\\partial \\frac{P_j[1]}{P_j[2]}}{\\partial P_j[1]} &amp; \\frac{\\partial \\frac{P_j[1]}{P_j[2]}}{\\partial P_j[2]} \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} \\frac{1}{P_j[2]} &amp; 0 &amp; -\\frac{P_j[0]}{P_j[2]^2} \\\\ 0 &amp; \\frac{1}{P_j[2]} &amp; -\\frac{P_j[1]}{P_j[2]^2} \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix} \\\\ &amp;= \\frac{1}{P_j[2]} \\begin{bmatrix} 1 &amp; 0 &amp; -\\frac{P_j[0]}{P_j[2]} \\\\ 0 &amp; 1 &amp; -\\frac{P_j[1]}{P_j[2]} \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix} \\end{aligned} \\] \\[ \\frac{\\partial P_j}{\\partial P_i&#39;}=R_{ji} \\] 接下来处理\\(part_{22}\\) \\[ \\begin{aligned} part_{22} &amp;= \\frac{\\partial P_i&#39;}{\\partial \\delta_c} = \\frac {\\partial \\begin{bmatrix} P_i&#39;[0] &amp; P_i&#39;[1] &amp; 1 \\end{bmatrix}^T} {\\partial \\delta c} \\\\ &amp;=\\frac{\\partial K^{-1}x_i }{\\partial \\delta c} = \\frac {\\partial \\begin{bmatrix} \\frac{x_i[0]-c_x}{f_x} \\\\ \\frac{x_i[1]-cy}{f_y} \\\\ 1 \\end{bmatrix}} { \\partial \\delta c } \\\\ &amp;= \\begin{bmatrix} -\\frac{x_i[0]-c_x}{f_x^2} &amp; 0 &amp; -\\frac{1}{f_x} &amp; 0 \\\\ 0 &amp; -\\frac{x_i[1]-c_y}{f_y^2} &amp; 0 &amp; -\\frac{1}{f_y} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} -\\frac{P_i&#39;[0]}{f_x} &amp; 0 &amp; -\\frac{1}{f_x} &amp; 0 \\\\ 0 &amp; -\\frac{P_i&#39;[1]}{f_y} &amp; 0 &amp; -\\frac{1}{f_y} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\end{aligned} \\] 对\\(\\dot{P_j&#39;}\\)的两个子部分进行结合 \\[ \\begin{aligned} \\dot{P_j&#39;}&amp;= \\frac{\\partial P_j&#39;}{\\partial \\delta c}= \\underbrace{ \\frac{\\partial P_j&#39;}{\\partial P_j} \\frac{\\partial P_j}{\\partial P_i} \\frac{\\partial P_i}{\\partial P_i&#39;}}_{part_{21}} \\underbrace{ \\frac{\\partial P_i&#39;}{\\partial x_i} \\frac{\\partial x_i}{\\partial K} \\frac{\\partial K}{\\partial \\delta c}}_{part_{22}} \\\\ &amp;= \\frac{1}{P_j[2]} \\begin{bmatrix} 1 &amp; 0 &amp; -\\frac{P_j[0]}{P_j[2]} \\\\ 0 &amp; 1 &amp; -\\frac{P_j[1]}{P_j[2]} \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix}R_{ji} \\begin{bmatrix} -\\frac{P_i&#39;[0]}{f_x} &amp; 0 &amp; -\\frac{1}{f_x} &amp; 0 \\\\ 0 &amp; -\\frac{P_i&#39;[1]}{f_y} &amp; 0 &amp; -\\frac{1}{f_y} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\end{aligned} \\] 即可得到如下: 结合part1和part2两部分，最终得到对内参的总体导数: 1.4. 伴随性质(From 14讲) 1.4.1. SO3伴随 \\[ R \\exp(\\phi^\\wedge)R^T= \\exp ((R\\phi)^\\wedge) \\] 1.4.2. SE3伴随 \\[ T \\exp(\\xi^\\wedge)T^{-1}=\\exp([Ad(T)\\xi]^\\wedge) \\] 其中，伴随Ad(T)形式如下: \\[ \\begin{aligned} Ad(T)= \\begin{bmatrix} R &amp; t^\\wedge R \\\\ 0 &amp; R \\end{bmatrix} \\end{aligned} \\] 1.5. 零空间 1.5.1. 零空间的定义 单目 7个自由度不可观 旋转量 平移量 尺度 可观的理解： 不同视角观测某个状态，状态都一样，则是可观的，如GPS得到的绝对位置 1.5.2. 如何求零空间 上面描述了如何将一个global的扰动转换到local(相机坐标系)的扰动，即 \\[ \\delta \\xi_c = Ad_{T_{cw}} \\delta \\xi_w \\] 这样，就可以得到零空间上在每一个local(相机坐标系)的扰动 1.5.3. 零空间的处理 上面的意思是，我们通过增量方程\\(H\\Delta x=b\\)求解出来的增量\\(\\Delta x=\\Delta x_{true}+\\Delta x_{nullspace}\\)，其中零空间增量\\(\\Delta x_{nullspace}\\)满足\\(H \\Delta x_{nullspace}=0\\) 为了求解出真正的增量，需要在求解出来的\\(\\Delta x\\)中减去关于零空间的漂移部分 上图中的向量\\(v\\)就相当于我们求解出来的\\(\\Delta x\\) 利用零空间的一组基向量，就可以把这个向量\\(v\\)投影到零空间上，得到零空间部分\\(\\Delta x_{nullspace}\\) 那么再对两个向量相减，得到垂直部分，垂直部分就是我们想要的真正的增量\\(\\Delta x_{true}=\\vec{v}-\\vec{v}_{in P_M}=\\Delta x-\\Delta x_{nullspace}\\) 1.6. DSO中的边缘化 1.6.1. 点——边缘化 对路标点进行marg之后，会在左上角的相机位姿参数块中进行FIll-IN 1.6.2. 帧——边缘化 1.6.3. SSE加速 1.7. FEJ 滑动窗口边缘化会带来一些问题，其中一种解决方法是使用FEJ 1.7.1. 举例 滑动窗口边缘化会带来问题 假设有能量函数 \\[ E=E_1+E_2 \\] \\[ E_1=E_2=(xy-1)^2 \\] 根据泰勒公式: 对能量函数进行线性化，即分别对E1和E2进行线性化，即对\\((xy-1)\\)进行泰勒一阶展开，有: \\[ (xy-1)&#39;=(x_0y_0-1)+y_0(x-x_0)+x_0(y-y_0) \\] 那么E1和E2的线性化为: \\[ E_1&#39;=E_2&#39;=[(xy-1)&#39;]^2=[(x_0y_0-1)+y_0(x-x_0)+x_0(y-y_0)]^2 \\] 取两个状态\\(X_0=(0.5,1.4)\\)和\\(X_1=(1.2,0.5)\\)，将这两个状态分别代入E1'和E2'，即相当于在这两个点处进行线性化， \\[ \\begin{aligned} E_1&#39;=(1.4x+0.5y-1.7)^2 \\\\ E_2&#39;=(0.5x+1.2y-1.6)^2 \\end{aligned} \\] 然后叠加，最终得到使用两个线性化点之后的能量函数\\(E_{X_0X_1}\\) \\[ \\begin{aligned} E_{X_0X_1} &amp;=E_1&#39;+E_2&#39; \\\\ &amp;=(1.4x+0.5y-1.7)^2+(0.5x+1.2y-1.6)^2 \\end{aligned} \\] 对于这样一个使用两个线性化点之后的能量函数，其可行解从一条(xy-1)的双曲线变成了一个椭圆区域，这就是滑动窗口边缘化带来的问题，使得原有的零空间减小了 1.8. DSO的其他trick 1.8.1. 利用伴随 利用伴随性质得到基于线性化点处滑窗内的相对位姿与绝对位姿的关系 1.8.2. 一些说明 1.8.3. 一些solver 1.9. DSO的后端流程 1.10. FEJ+边缘化的一些例子","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"DSO","slug":"SLAM代码课程/DSO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/"}],"tags":[]},{"title":"DSO-资料集合","slug":"SLAM代码课程/DSO/DSO-资料集合","date":"2020-03-29T18:00:31.000Z","updated":"2020-04-30T03:42:48.000Z","comments":true,"path":"2020/03/30/SLAM代码课程/DSO/DSO-资料集合/","link":"","permalink":"http://yoursite.com/2020/03/30/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/DSO-%E8%B5%84%E6%96%99%E9%9B%86%E5%90%88/","excerpt":"","text":"资料下载 点击下载","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"DSO","slug":"SLAM代码课程/DSO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/"}],"tags":[]},{"title":"线性系统的近似线性化","slug":"控制相关/线性系统的近似线性化","date":"2020-03-26T11:56:18.000Z","updated":"2020-03-27T18:19:28.000Z","comments":true,"path":"2020/03/26/控制相关/线性系统的近似线性化/","link":"","permalink":"http://yoursite.com/2020/03/26/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%91%E4%BC%BC%E7%BA%BF%E6%80%A7%E5%8C%96/","excerpt":"","text":"1. 线性系统的近似线性化 严格来说，大多物理系统都是非线性的，难以求解，即 \\[ \\left \\{ \\begin{aligned} \\dot{x}=f(x,u) \\\\ y=g(x,u) \\end{aligned} \\right. \\] 在误差允许范围内，可以使用线性系统来近似，有： 确定线性化点 对非线性函数在线性化点处进行泰勒展开，有： 其中，两式的最后一项\\(\\alpha\\)和\\(\\beta\\)是关于\\((\\delta x,\\delta u)\\)的高次项，在这里暂时忽略 并且引入了下面的符号: 求解线性化处的雅可比 线性化后的状态空间表达式为 \\[ \\dot{\\hat{x}}=A\\hat{x}+B\\hat{u} \\] \\[ \\hat{y}=C\\hat{x}+D\\hat{u} \\] 1.1. 例子1 对下面的系统在\\(x_0=0\\)处线性化 \\[ \\left \\{ \\begin{aligned} \\dot{x}_1 &amp;= x_2 \\\\ \\dot{x}_2 &amp;=x_1+x_2+x_2^3+2u \\\\ y &amp;=x_1+x_2^2 \\end{aligned} \\right . \\] 由系统状态方程，有 \\[ \\left \\{ \\begin{aligned} f_1 &amp;= x_2 \\\\ f_2 &amp;=x_1+x_2+x_2^3+2u \\\\ g &amp;=x_1+x_2^2 \\end{aligned} \\right . \\] 根据下面的雅克比求解规则，有: 1.2. 例子2 解: 写出微分方程有: \\[ \\begin{aligned} L\\frac{d i}{d t} + iR = u \\\\ M\\frac{d y^2}{d^2t} = Mg-\\frac{i^2}{y} \\end{aligned} \\] 对微分方程进行拉氏变换 \\[ \\left \\{ \\begin{aligned} s L I(s) + I(s) R = U(s) \\\\ s^2 M Y(s) = Mg -\\frac{I^2(s)}{Y(s)} \\end{aligned} \\right . \\] 选取状态变量 \\[ \\begin{aligned} x= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} i \\\\ y \\\\ \\frac{d y}{d t} \\end{bmatrix} \\end{aligned} \\] 写出状态方程 \\[ \\left \\{ \\begin{aligned} sI(s) = -\\frac{R}{L}I(s)+U(s) &amp;\\longleftrightarrow \\dot{x}_1=\\dot{i} = -\\frac{R}{L} i + u = -\\frac{R}{L} x_1 + u\\\\ &amp;\\longleftrightarrow \\dot{x}_2=\\dot{y}=\\frac{dy}{dt}=x_3 \\\\ s^2 Y(s) = g -\\frac{I^2(s)}{MY(s)} &amp;\\longleftrightarrow \\dot{x}_3=\\dot{\\frac{dy}{dt}}=\\frac{dy^2}{d^2t}=g -\\frac{i^2}{My} = g -\\frac{x_1^2}{Mx_2} \\end{aligned} \\right . \\] 在\\(x_0\\)处进行线性化 注意到\\(\\dot{x}_3\\)状态方程是非线性的，因此需要进行线性化 将系统在平衡点\\(y_0=x_{20}=\\)常数 处进行线性化，于是，进一步推出: \\[ \\dot{x}_{20}=\\frac{dy}{dt} |_{y=y_0}=x_{30}=0 \\] \\[ \\dot{x}_{30}=\\dot{\\frac{dy}{dt}}=\\frac{dy^2}{d^2t}|_{y=y_0}=0 \\] 将上式代入等式: \\[ M\\frac{d y^2}{d^2t} = Mg-\\frac{i^2}{y} \\] 可得\\(x_{10}=i_0=\\sqrt{Mgx_{20}}\\) 求\\(\\dot{x}_3\\)状态方程\\(f_3\\)的雅克比\\(j_3\\) \\[ \\frac{d f_3}{ d x^T}= \\begin{bmatrix} -\\frac{2 i_0}{M y_0} &amp; \\frac{i_0^2}{y_0^2} &amp; 0 \\end{bmatrix} \\] 写出矩阵A，B \\[ \\begin{aligned} A= \\begin{bmatrix} -\\frac{R}{L} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ -\\frac{2 i_0}{M y_0} &amp; \\frac{i_0^2}{y_0^2} &amp; 0 \\end{bmatrix} = \\begin{bmatrix} -\\frac{R}{L} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ -2\\sqrt{\\frac{g}{M x_{10}}} &amp; \\frac{g}{x_{10}} &amp; 0 \\end{bmatrix} \\end{aligned} \\] \\[ \\begin{aligned} B= \\begin{bmatrix} \\frac{1}{L} \\\\ 0 \\\\ 0 \\end{bmatrix} \\end{aligned} \\] 最后有: \\[ \\Delta \\dot{x}=A\\Delta x + B\\Delta u \\] 其中，\\(\\Delta x= x-x_0\\)","categories":[{"name":"控制相关","slug":"控制相关","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"第三章-线性系统的运动分析","slug":"控制相关/线性系统理论/第三章-线性系统的运动分析","date":"2020-03-23T07:04:38.000Z","updated":"2020-03-23T15:29:00.000Z","comments":true,"path":"2020/03/23/控制相关/线性系统理论/第三章-线性系统的运动分析/","link":"","permalink":"http://yoursite.com/2020/03/23/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%90%E5%8A%A8%E5%88%86%E6%9E%90/","excerpt":"","text":"1. 运动分析的数学实质 线性系统的状态方程为: 数学实质是: 相对于给定的初始状态\\(x_0\\)和外部输入\\(u\\)，求解出状态方程的解\\(x(t)\\)，即由初始状态和外输入作用所引起的状态响应。 2. 零输入响应和零初态响应的定义 利用线性系统的叠加原理，可以把系统在初始状态和输入控制向量作用下的运动分解为: (1) 由初始状态引起的自由运动 (2) 输入作用引起的强迫运动 2.1. 零输入响应 2.2. 零初态响应 2.3. 系统总的运动响应 3. 连续时间线性时不变系统的运动分析 3.1. 前提内容——矩阵指数函数的计算 关于nxn的矩阵A的矩阵指数函数定义如下: 上面的三角等于号应该是等于号 3.1.1. 方法一:定义法 直接利用矩阵指数函数的定义式计算,即 3.1.1.1. 矩阵A为对角线矩阵 3.1.1.2. 矩阵A为零幂矩阵 零幂矩阵： 即自乘若干次后化成零矩阵 推广到N阶方阵 3.1.1.3. 矩阵A具有类似反对称形式 举例: 3.1.2. 方法二:特征值法 3.1.2.1. 矩阵A特征值两两互异 对矩阵A进行特征值分解，得到\\(A=P\\Lambda P^{-1}\\)，其中\\(P=[v_1 , v_2 ,\\cdots , v_n]\\)是由特征向量(列向量)组合得到的. 因此，关于矩阵A的矩阵指数为: 举例: 3.1.2.2. 矩阵A的特征值有重根时 回顾约旦规范型\\(J=Q^{-1}AQ \\Longrightarrow A=QJQ^{-1}\\)，因此，矩阵A的矩阵指数为: 例子: 3.1.3. 方法三:有限项展开法 利用凯莱哈密顿定理(Cayley—Hamilton)化\\(e^{At}\\)为A的有限项 关于凯莱哈密顿定理的使用: 对\\(e^{At}\\)使用凯莱哈密顿定理，可得: \\[ e^{At}=\\alpha_0(t)I+\\alpha_1(t)A+\\cdots+\\alpha_{n-1}(t)A^{n-1} \\] 即问题转换为求解这些\\(\\alpha\\)的值 3.1.3.1. 情况1: 矩阵A的特征值互异 \\(\\alpha\\)求解结果如下: 3.1.3.2. 情况2: 矩阵A有重根(n重特征值\\(\\lambda_1\\)) \\(\\alpha\\)求解结果如下: 3.1.4. 方法四:预解矩阵法(拉氏反变换法)[好用] 对于给定的nxn常矩阵A，其指数函数满足: 例子: 3.1.5. 矩阵指数函数性质 \\(\\lim_{t \\rightarrow 0} e^{At}=I\\) \\((e^{At})^T=e^{A^Tt}\\) 令\\(t\\)和\\(\\tau\\)为两个自变量，则\\(e^{A(t+\\tau)}=e^{At}\\cdot e^{A\\tau}=e^{A\\tau}\\cdot e^{At}\\) \\((e^{At})^{-1}=e^{-At}\\) 设有\\(n\\times n\\)常矩阵A和F，如果A和F是可交换的(即\\(AF=FA\\))，则有:\\(e^{(A+F)t}=e^{At}\\cdot e^{Ft}=e^{Ft}\\cdot e^{At}\\) \\(\\frac{d}{dt}e^{At}=Ae^{At}=e^{At}A\\) \\((e^{At})^m=e^{A(mt)}\\) 3.2. 求解系统状态的零输入响应 输入u = 0时,线性定常系统的状态方程: 称为齐次状态方程。求线性定常系统的零输入响应,其实就是求该齐次状态方程的解 对上述微分方程进行求解，可得: 由状态方程\\(\\dot{x}=Ax\\) 且 \\(x(0)=x_0\\)，当\\(t\\geq0\\)时，零输入响应为: 由状态方程\\(\\dot{x}=Ax\\) 且 \\(x(t_0)=x_0\\)，当$tt_0 , t_0 $时，零输入响应为: 零输入响应的形态 在给定初态下,系统的零输入响应即系统在自由运动下的轨迹仅由矩阵指数函数\\(e^{At}\\)决定 矩阵指数函数即系统矩阵A包含了零输入响应即自由运动形态的全部信息 零输入响应的几何特征 \\(x(t)=e^{At}x_0\\)说明系统在t时刻的状态点几何上可由初始状态点x0经过线性变换\\(e^{At}\\)得到 零输入响应随时间t演化过程,几何上即为状态空间中由初始状态x0出发,经过各个时刻变换点x(ti)所构成的一条轨迹 零输入响应趋向平衡态x=0属性 在没有外部输入下,系统的响应应该最终趋向平衡态x=0 系统的零输入响应即自由运动轨迹趋于x=0的条件为: \\(\\lim_{t \\rightarrow \\infty} e^{At}=0\\) 3.3. 求解系统状态的零初态响应 由状态方程\\(\\dot{x}=Ax+Bu\\) 且 \\(x(0)=x_0\\)，\\(t\\geq0\\)时，所描述的线性定常系统的零状态响应为: 由状态方程\\(\\dot{x}=Ax+Bu\\) 且 \\(x(t_0)=x_0\\)，$tt_0 , t_0 $时，所描述的线性定常系统的零状态响应为: 例子: 3.4. 系统总的运动响应 4. 连续时间线性时不变系统的状态转移矩阵 4.1. 基本解阵 4.1.1. 基本解阵的一种形式 对于方程\\(\\dot{x}=Ax+Bu,~~ x(t_0)=x_0 ,~~ t\\geq t_0\\)，，一个可能的基本解阵的形式如下: 4.2. 状态转移矩阵 对于给定的线性定常系统 写出矩阵微分方程: 状态转移矩阵即为上面这个矩阵微分方程的\\(n\\times n\\)解阵 即状态转移矩阵是\\(\\Phi(t-t_0)\\) 状态转移矩阵\\(\\Phi(t-t_0)\\) 与\\(t_0\\)到\\(t\\)的时间间隔相关，与具体时刻大小无关 状态转移矩阵\\(\\Phi(0)=I\\)，说明在初始\\(t_0\\)时刻，没有任何的状态转移 4.2.1. 状态转移矩阵和基本解阵的关系() 4.2.2. 状态转移矩阵的形式 对于线性定常系统来说,它的状态转移矩阵就是矩阵指数函数，即 需要注意的是\\(\\Phi(t-t_0)\\)是唯一确定的，尽管基础解阵\\(\\Psi\\)不是唯一的，即: 4.2.3. 状态转移矩阵用于零输入、零响应、全响应 根据上面状态转移矩阵的形式的讨论，可以得到状态转移矩阵用于零输入、零响应、全响应的关系 对于线性定常系统: \\[ \\dot{x}=Ax+Bu,~~~x(t_0)=x_0,~~~t\\geq t_0 \\] (1)零输入响应 (2)零状态响应 (3)全响应 4.2.4. 求解状态响应 4.2.4.1. 积分法 先求出状态转移矩阵\\(\\Phi(t)=e^{At}\\) 在利用定义计算 4.2.4.2. 拉氏变换法 不需要单独求状态转移矩阵\\(\\Phi(t)=e^{At}\\) 一步到位 结果: 来由: 4.2.5. 求解输出响应 4.2.5.1. 例子 (1)使用积分法先求状态响应\\(x(t)\\)，再求输出响应 (2)使用拉氏变换法先求状态响应\\(x(t)\\)，再求输出响应 4.2.6. 状态转移矩阵的性质 4.2.6.1. \\(\\Phi(0)=I\\) 4.2.6.2. \\(\\dot{\\Phi}(t)=A\\Phi(t)=\\Phi(t)A\\) 4.2.6.3. \\(\\Phi(t_1+t_2)=\\Phi(t_1)\\Phi(t_2)=\\Phi(t_2)\\Phi(t_1)\\) 4.2.6.4. \\(\\Phi^{-1}(t)=\\Phi(-t),\\Phi^{-1}(-t)=\\Phi(t)\\) 4.2.6.5. \\(\\Phi(t_2-t_0)=\\Phi(t_2-t_1)\\Phi(t_1-t_0)\\) 4.2.6.6. \\(\\Phi(kt)=[\\Phi(t)]^{k}\\) 4.2.6.7. \\(A=\\Phi(0)\\) 4.2.6.8. 其他 \\(\\frac{d}{dt}\\Phi(t-t_0)=A\\Phi(t-t_0)=\\Phi(t-t_0)A\\) \\(\\frac{d}{dt}\\Phi^{-1}(t-t_0)=-A\\Phi(t-t_0)=-\\Phi(t-t_0)A\\) 5. 连续时间线性时不变系统的脉冲响应矩阵 5.1. 脉冲函数 5.1.1. 脉冲函数的定义 5.1.2. 脉冲函数的性质 5.1.3. 脉冲信号的意义 5.2. 脉冲响应矩阵 5.2.1. 单输入单输出系统 对单输入单输出的连续时间线性时不变系统，在初始状态为零的条件下，在任意输入u作用下，系统的输出y(t)可表示为: 其中，\\(h(t-\\tau)\\)为对应与\\(\\delta(t-\\tau)\\)的脉冲响应 也就是信号与系统里面的: 零状态响应=脉冲函数\\(\\otimes\\)输入 5.2.2. 多输入多输出系统 对多输入多输出的连续时间线性时不变系统，在初始状态为零的条件下，在任意输入u作用下，系统的输出y(t)可表示为: 5.3. 脉冲响应矩阵和状态空间描述 对连续时间线性时不变系统: 在初始状态为0的条件下，系统脉冲响应矩阵表达式为: 推导如下: 5.3.1. 一些结论 (1)输出零输入响应: (1)输出零状态响应: 注意与状态的零状态\\(x_{0u}\\)、零输入响应\\(x_{0x}\\)的区分 5.4. 脉冲响应矩阵和传递函数矩阵 6. 连续时间线性[时变]系统的状态转移矩阵 6.1. 状态转移矩阵 对于连续时间线性时变系统: 其状态转移矩阵为: 的\\(n\\times n\\)解阵，即\\(\\Phi(t,t_0)\\) 6.2. 基本解阵 6.3. 状态转移矩阵和基本解阵的关系 6.4. 状态转移矩阵\\(\\Phi(t,t_0)\\)的形式 对于连续时间线性时变系统: 其状态转移矩阵为: 6.5. 状态转移矩阵\\(\\Phi(t,t_0)\\)的性质 6.6. 连续时间线性[时变]系统的响应 6.6.1. 状态响应 线性时变系统的系统状态方程: 方程的解即为状态响应 6.6.2. 输出响应 线性时变系统的状态空间描述和初始状态为: 并且有状态响应的表达式: 可得系统的输出响应: 7. 连续时间线性[时变]系统的离散化形式 7.1. 采样约定 7.2. 基本结论 给定连续时间线性时变系统: 则其在基本约定下的时间离散化描述为: 其中， 7.3. 状态转移矩阵\\(\\Phi\\) 对离散时间线性时变系统: 8. 连续时间线性[时不变]系统的离散化形式 对于线性时不变系统，可以看做是时变系统的特例: \\[ \\begin{aligned} \\dot{x}=Ax+Bu \\\\ y=Cx+Du \\end{aligned} \\] 系统矩阵G可以写成如下形式: 8.1. 例子 8.2. 状态转移矩阵\\(\\Phi\\) 对离散时间线性时不变系统: 状态转移矩阵\\(\\Phi\\)具有如下形式: 为什么是\\(G^{k}\\)? 可参见下面的补充内容 \"由于时不变系统的系统矩阵G是常数，那么每迭代一次，就对初始状态\\(x(0)\\)乘一次G，那么最终的状态转移矩阵就是\\(G^{k}\\)\" 补充:","categories":[{"name":"控制相关","slug":"控制相关","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/"},{"name":"线性系统理论","slug":"控制相关/线性系统理论","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"}],"tags":[]},{"title":"DSO-2-跟踪与建图","slug":"SLAM代码课程/DSO/DSO-2-跟踪与建图","date":"2020-03-23T00:11:59.000Z","updated":"2020-03-23T01:55:09.000Z","comments":true,"path":"2020/03/23/SLAM代码课程/DSO/DSO-2-跟踪与建图/","link":"","permalink":"http://yoursite.com/2020/03/23/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/DSO-2-%E8%B7%9F%E8%B8%AA%E4%B8%8E%E5%BB%BA%E5%9B%BE/","excerpt":"","text":"DSO-2-跟踪与建图 跟踪 运动假设 上面说的旋转运动各有3种: 绕x轴: 逆时针转，顺时针转，不转 (3种) 绕y轴: 逆时针转，顺时针转，不转 (3种) 绕z轴: 逆时针转，顺时针转，不转 (3种) 最终，有 3x3x3-1=26种 ，因为3个轴都不做旋转的时候，就相当于匀速模型了。 激活点跟踪 从顶层开始，向底层遍历： 如果某一层的大于能量阈值的点&gt;60%，(有用的点太少了)，则放大外点阈值，然后使用LM来优化，该层再进行优化一次，一共2次 如果某一层能量值&gt;1.5倍能量最小值，认为跟踪失败 直到遍历到第0层(原图) 第0层的优化结果&lt;小于阈值的时候，就停止优化，把目前最好的优化结果作为下一次跟踪的阈值？(相当于使用动态阈值，提高鲁棒性) 需要注意的是: 在第一节-初始化的时候，对光度参数求导，由于参考帧的光度参数\\(t_i e^{a_i},b_i\\)和当前帧的光度参数\\(t_j e^{a_j},b_j\\)都是不知道的，于是在初始化的时候把两帧的光度参数看做是一个整体来进行求导 初始化时对光度参数的求导(最终求得的是相对的光度参数的导数): 在跟踪的时候，参考关键帧的光度参数\\(t_i e^{a_i},b_i\\)是已知的(通过初始化进行固定，然后通过初始化得到的相对光度参数计算得到?)，我们只希望得到关于当前帧j的光度参数的导数，而不是作为一个整体的相对光度参数导数，于是有: 关键帧筛选 建图 候选点跟踪 如果新的一帧被认为是关键帧，并且在这一帧提取了一些点出来，但是这些点的逆深度是不知道的，这些点都被作为Immatture未成熟点，一般的做法是使用后面的帧如(t+1)帧来对这些点进行跟踪优化，得到这些Immatture未成熟点的逆深度。 上面的步骤得到了Immatture未成熟点在后一帧(t+1)帧的匹配点的像素坐标，现在需要反求出逆深度 下面是极线筛选的原理 候选点激活 上面是距离地图 为了控制激活候选点的密度和均匀性，如果某个候选点所在的距离地图的值很小(表明与某个激活点很近了)，就不激活这个候选点了 上面的极线搜索、激活都只是得到了候选点逆深度的范围\\([d_{min},d_{max}]\\) 下面需要使用LM算法来得到具体的逆深度值 DSO的加速方法","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"DSO","slug":"SLAM代码课程/DSO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/"}],"tags":[]},{"title":"四元数的状态误差卡尔曼-[附录]-几种积分方法","slug":"IMU相关/四元数的状态误差卡尔曼-附录-几种积分方法","date":"2020-03-21T14:25:44.000Z","updated":"2020-03-22T15:44:00.000Z","comments":true,"path":"2020/03/21/IMU相关/四元数的状态误差卡尔曼-附录-几种积分方法/","link":"","permalink":"http://yoursite.com/2020/03/21/IMU%E7%9B%B8%E5%85%B3/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC-%E9%99%84%E5%BD%95-%E5%87%A0%E7%A7%8D%E7%A7%AF%E5%88%86%E6%96%B9%E6%B3%95/","excerpt":"","text":"1. [附录]-几种积分方法 2. 龙格库塔数值积分法 我们的目的是对如下形式的非线性微分方程在给定一个时间间隔\\(\\Delta t\\)进行积分， 从而将微分方程转化为差分方程 或者是这种形式(假设\\(t_n=n\\Delta t\\)和\\(x_n \\triangleq x(t_n)\\)) 龙格-库塔(RK)方法是最常用的方法之一，这些方法使用几个迭代来估计区间上的导数，然后利用这个导数在时间步\\(\\Delta t\\)上进行积分。 在接下来的小节中，将介绍几种RK方法，从最简单的方法到最通用的方法，并根据它们最常用的名称进行命名。 2.1. 欧拉方法(The Euler method) 欧拉方法假设导数\\(f(\\cdot)\\)是常数，因此有: 作为一般的RK方法，这对应于一个单阶段方法，它可以描述如下: 计算在初始点处的导数 使用它来计算积分，到结束点 2.2. 中点法(The midpoint method) 中点法假设导数是区间中点处的导数，然后进行一次迭代来计算x在这个中点的值，如 中点法可以解释为以下两步法 使用欧拉方法积分，直到中点 (使用前面定义的k1) 然后使用这个值来计算中间点k2的导数，然后对后半段进行积分 2.3. 4阶龙格库塔法(The RK4 method) 这通常被简单地称为龙格-库塔方法，它用四个阶段或迭代来计算积分，有四个导数，\\(k1 \\cdots k4\\)，是按顺序得到的。然后将这些导数(或斜率)加权平均，得到区间内导数的4阶估计值。 RK4方法比上面两种方法的更好，其积分计算步骤是: 也就是说，增量是通过假设一个斜率来计算的这个斜率是k1 k2 k3 k4的加权平均值，其中k1 k2 k3 k4按下面计算: 不同的斜率有如下的解释: k1是区间开始时的斜率，使用\\(x_n\\)来计算. (欧拉方法) k2是区间中点处的斜率，使用\\(x_n+\\frac{1}{2}\\Delta t k_1\\)来计算。(中点法) k3还是中点的斜率，不过使用\\(x_n+\\frac{1}{2}\\Delta t k_2\\)计算 k4是区间最后的斜率，使用\\(x_n+\\Delta t k_3\\)计算 2.4. 通用龙格库塔法(General Runge-Kutta method) 更详细的RK方法是可能的，它们的目标是减少误差和/或增加稳定性，它们具有通用的形式为: 也就是说，迭代的次数(方法的顺序)是s，平均权值由bi定义，评价时间瞬间由ci定义，斜率ki是用aij值确定的，根据aij的结构，可以使用显式或隐式RK方法。 3. 闭式积分方法(Closed-form integration methods) 在许多情况下，可以得到一个封闭形式的积分步骤表达式，我们现在考虑一阶线性微分方程的情况 也就是说，这个关系是线性的，在区间内是常数，在这种情况下，积分区间[tn, tn + t]，可以得到: 其中，\\(\\Phi\\)就是常说的状态转移矩阵，这个状态转移矩阵的泰勒展开如下: 当写出这串由已知常数矩阵A构成的序列时，有时有可能可以写成闭式的解，一些例子如下 3.1. 角度误差的积分 例如，考虑无偏差和噪声的角度误差(纯净版的式133) 它的转移矩阵可以写成泰勒级数 现在，定义\\(\\boldsymbol{w}\\Delta t \\triangleq \\boldsymbol{u} \\Delta \\theta\\)，旋转轴和旋转的角度，然后应用式53，可以得到 这个解对应于一个旋转矩阵,(根据式51，可以进一步化为转置)，即 \\[ \\Phi=R\\{-\\boldsymbol{u} \\Delta \\theta \\}=R\\{-\\boldsymbol{w} \\Delta t\\}=R\\{\\boldsymbol{w} \\Delta t\\}^T \\] 根据罗德里格斯公式，可以得到闭式解: 3.2. 简化版IMU例子 考虑简化版的IMU系统，其误差状态方程为: 其中，\\((a,w)\\)是已经去除了重力和传感器的偏差的IMU的测量，这个系统的状态向量和矩阵如下: 其在一个时间步\\(\\Delta t\\)的积分为\\(\\boldsymbol{x}_{n+1}=e^{\\boldsymbol{A}\\Delta t}\\cdot \\boldsymbol{x}_n\\)。 状态转移矩阵\\(\\Phi=e^{\\boldsymbol{A\\Delta t}}\\)，泰勒展开如下: 我们可以写出矩阵A的几次幂来说明它们的一般形式 从这里可以看出，对于k&gt;1，有如下一般形式: 我们可以观察这些A的次方项，有固定的部分以及会增长的次方项\\(\\Theta_\\Theta\\) 下面，对状态转移矩阵\\(\\Phi\\)进行分块讨论: 让我们一步一步推进,探索矩阵\\(\\Phi\\)的所有非零块 Trivial diagonal terms (对角线前2个) 没什么好说，就是单位阵I Rotational diagonal term (对角线第3项) 接下来是对角的旋转项\\(\\Phi_{\\theta \\theta}\\)，将新的角误差与旧的角误差联系起来，写出这一项的泰勒级数 正如我们在前一节中看到的，它对应于我们熟知的旋转矩阵 Position-vs-velocity term (第一行第二列) 这是最简单的非对角项 Velocity-vs-angle term (第二行第三列) 根据上面的推导，写出状态转移矩阵\\(\\Phi\\)的第二行第三列\\(\\Phi_{v,\\theta}\\)的叠加形式: 在这里，有两种选择: (1)我们可以把级数的第一个有效项截断，即只保留\\(\\Phi_{v,\\theta}=V_{\\theta}\\Delta t\\) ，但是这样就不是闭式解了。(有关使用这种简化方法的结果，请参见下一节) (2)第二种方法，把因式\\(V_{\\theta}\\)提取出来，如下 可以看到，\\(\\Sigma_1\\)项与我们之前写的\\(\\Phi_{\\theta \\theta}\\)很像，但是有两处例外: \\(\\Sigma_1\\)中的\\(\\Theta_\\theta\\)次方项与系数\\(\\frac{1}{k!}\\)以及\\(\\Delta t\\)次方项都不匹配。实际上，我们在这里\\(\\Sigma_1\\)的标记1表明\\(\\Theta_\\theta\\)次方项少了1次 还有一个问题是，在这个多项式的开头，少了一些内容。实际上，在这里\\(\\Sigma_1\\)的标记1表明少了1些项 关于第一个问题，可以采用式53的办法来解决，(会产生一个单位阵) 式53中的\\(u\\)是单位向量 这个表达式允许我们增加\\(\\Theta_\\theta\\)指数，然后可重写式262如下: 现在，次方项和其他系数都匹配了，但是整个式子还少了一些项，也就是第二个问题。第二个问题可以通过添加和减去缺少的项来解决，用它的封闭形式代替整个级数，即: 于是，最终，可以得到整一个比式解的形式: Position-vs-angle term (第一行第三列) 对\\(\\Phi\\)矩阵的第一行第三列\\(\\Phi_{p\\theta}\\)展开: 提取常数项公因式，写成如下形式: 其中，我们标记下标2在\\(\\Sigma_2\\)中: 对于上面多项式的每一项，都少了\\(\\Theta_\\theta\\)的2次 对于上面的多项式，缺少了开头两项 同样的处理，使用式263所用的方法，可以得到: 进一步地: 最终得到: 以上，就实现了简化版的IMU误差状态的状态转移矩阵\\(\\Phi\\)的推导. 3.3. 完整版IMU例子 为了进一步对上述“简化版IMU”进行推广，我们需要更仔细地研究完整的IMU案例。 考虑一个完整的IMU系统，(式133)所示，可以表示成: 其中，动态矩阵A是块稀疏的，它的各个子块可以由(式133)确定: 其中， \\(P_v=I\\) \\(V_\\theta=-R[a_m-a_b]_\\times\\) \\(V_a=-R\\) \\(V_g=I\\) \\(\\Theta_{\\theta}=-[w_m-w_b]_\\times\\) \\(\\Theta_w=-I\\) 同样的，写出矩阵A的次幂: 可以观察到: A的对角线上的唯一一项，旋转项\\(\\Theta_\\theta\\)，在\\(A^k\\)的次方序列中向右和向上传播。所有不受传播影响的项都将消失，这个传播在以下3个方面影响了\\(\\{A^k \\}\\)序列的结构: 三次幂后，A的稀疏性趋于稳定，也就是说，对于大于3的幂，不再出现或消失非零块。 左上角3x3的子块，与前面例子中的简化IMU模型相对应，在这个例子里面仍然没有改变，因此，这个子块的闭式解就是前面得到的结果。 与角速度偏置(gyrometer bias)误差的相关项(在第5列中的项)，产生了与\\(\\Theta_\\theta\\)次方序列相似的项，可以采用上面“简化版IMU”所使用的技巧进行求解。 我们对寻找构造闭式子块的状态转移矩阵\\(\\Phi\\)的通用方法感兴趣，这与我们在“简化版IMU”所提到的\\(\\Sigma_1,\\Sigma_2\\)有关: 下标表示了序列中每个元素缺失的\\(\\Theta_\\theta\\)的次方数 下标表示了序列开头的项的数目 考虑到这个定义，现在定义一个序列\\(\\Sigma_n(X,y)\\): 这个序列从第n项开始，并且每个元素都缺少了\\(\\Theta_\\theta\\)的n次方，即类似与\\(\\Sigma_1,\\Sigma_2\\): 特别的，当n=0时，有\\(\\Sigma_0=R\\{w\\Delta t\\}^T\\) 现在，我们可以使用这个定义来写出状态转移矩阵\\(\\Phi\\): 现在，我们的问题已经变成了寻找一个关于\\(\\Sigma_n\\)的通用的，闭式的表达，下面再来看一眼之前推导出来的\\(\\Sigma\\) 为了在\\(\\Sigma_3\\)上得到推广，我们需要应用(式263)两次，因为一次只增加\\(\\Theta_\\theta\\)的2次幂，于是得到: 写成闭式解形式: 通过对上面\\(\\Sigma_0,\\Sigma_1,\\Sigma_2,\\Sigma_3\\)的观察，可以推导出关于\\(\\Sigma_n\\)的闭式表达: 状态转移矩阵\\(\\Phi\\)最后的闭式结果使用这个\\(\\Sigma_n\\)来进行表达，即填充到(式278)。 可能需要注意的是，序列拥有了具有有限项的\\(\\Sigma_n\\)表达，因此可以被高效的计算。也就是说，只要\\(n &lt; \\infty\\)，那么\\(\\Sigma_n\\)就可以有闭式表达，这是很常见的情况(\\(n &lt; \\infty\\))。对于当前这个例子来说，\\(n \\leq 3\\)(式278) 4. 使用截断序列的近似方法(重点) 在前面的内容中，我们推导了复杂的状态转移矩阵\\(\\Phi\\)的闭式表达，IMU驱动系统可以写成线性化的形式，即状态误差方程\\(\\dot{\\delta x}=A\\delta x\\) 封闭形式的表达式可能总是令人感兴趣的，但是在什么程度上我们应该担心高阶误差及其对实际算法性能的影响还不清楚，这特别适用于IMU积分误差以相对较高的速率被观察到(并因此需要补偿)的系统，例如视觉-惯性或GPS-惯性融合方案 在这一部分，我们推导关于状态转移矩阵的近似，从相同的假设开始，状态转移矩阵被表达为泰勒展开序列，然后只对影响较大的项进行截断，截断可以使用system-wise和block-wise的方法。 4.1. system-wise截断 4.1.1. 一阶截断: 有限差分法 一种适用于以下系统的典型的、广泛的积分方法: 是基于有限差分法来计算导数的: 这产生: 这与欧拉方法的精度相当，对函数f()在积分的起点处进行线性化，然后得到: 其中，\\(A \\triangleq \\frac{\\partial f}{\\partial x}(t_n,x_n)\\)是雅克比矩阵。这与线性化微分方程的指数解是完全等价的，然后在线性化的项进行截断，从而得到近似: 这说明了，上面提到的欧拉方法，是有限差分方法，是泰勒展开的一阶system-wise截断，也就是说，得到了如下的状态转移矩阵近似: 对于前面所提到的\"简化版IMU\"系统，对其状态转移矩阵应用一阶system-wise截断，得到近似矩阵: 然而，在角度误差的积分一节中，我们已经讨论过了旋转项有一个紧凑的、封闭的表达，即\\(\\Phi_{\\theta \\theta}=R\\cdot (w \\Delta t)^T\\)，对上面的一阶system-wise截断的旋转项进行替换，最终得到: 4.1.2. N阶截断 高阶截断将提高近似状态转移矩阵的精度，截断的一个特别有趣的顺序是最大限度地利用结果的稀疏性，换句话说，没有新的非零项出现的顺序。 对于简化版IMU的例子 回顾一下其系统矩阵A的次幂: 可以发现，在2阶之后，就没有非零项消失和产生，因此，取2阶进行截断，得到: 对于完整版IMU的例子 从系统矩阵A的次幂来看，在3阶之后，就没有非零项消失和产生，因此，取3阶进行截断，得到: 具体的矩阵展开，可往前面翻. 4.2. Block-wise截断(这个好用) 这是一种与前面所推导的闭式结果相当接近的近似方法是: 对状态转移矩阵\\(\\Phi\\)的每个块的泰勒级数展开的第一个有效项上进行截断 就是说，我们单独检查转移矩阵的每个非零子块，而不是对整个状态转移矩阵的泰勒展开序列进行截断。因此，需要在每个块的基础上分析截断 下面使用两个例子来讨论: 4.2.1. 简化版IMU例子 对于\\(\\Phi_{v,\\theta},\\Phi_{p,\\theta}\\)项，分别有序列\\(\\Sigma_1\\)和\\(\\Sigma_2\\) 对上述序列\\(\\Sigma_1\\)和\\(\\Sigma_2\\)进行1阶截断，得到: 于是，简化版IMU系统的状态转移矩阵\\(\\Phi\\)可近似如下: 这种截断方法比上面的全系统(system-wide)一阶截断法更精确，同时，特别是与封闭形式相比，又很容易获得和计算。 对于右下角(3,3)项，由于其闭式已经计算出来了，而且比较好计算，所以直接使用闭式形式即可。 4.2.2. 完整版IMU例子 对于完整的IMU系统，将前面所推导的\\(\\Sigma_n\\)代入到状态转移矩阵\\(\\Phi\\)中，然后进行截断，可以得到转移矩阵的近似: (1)标准的状态转移矩阵\\(\\Phi\\): \\(P_v=I\\) \\(V_\\theta=-R[a_m-a_b]_\\times\\) \\(V_a=-R\\) \\(V_g=I\\) \\(\\Theta_{\\theta}=-[w_m-w_b]_\\times\\) \\(\\Theta_w=-I\\) (2)\\(\\Sigma_n\\)的闭式表达: (3)根据上面的推导进行截断，得到 其中， (4)如果还想要进一步简化，一个直接的方法是限制每个子块的最高阶数n 当n=1(也就是欧拉法)，我们得到: 当n=2，我们得到: 当n=3，也就是最上面的(式297)了 5. 使用龙格库塔积分法得到状态转移矩阵(时变) 其他方法来近似得到状态转移矩阵就是使用龙格库塔积分法，当动态矩阵(系统矩阵)A在积分区间内不能被认为是常数的情况下(即系统矩阵是时变的矩阵\\(A(t)\\))，这是可能可以使用。 假设有连续时间系统: 让我们重写以下两个关系，它们在连续时间和离散时间中定义了同一个系统，这分别包含了时变的系统矩阵\\(A(t)\\)和状态转移矩阵\\(\\Phi\\): 上面两个等式可以分别以两种方式推导\\(\\dot{x}(t_n+\\tau)\\) 其中，需要注意的是\\(\\dot{x}(t_n)=\\dot{x}_n=0\\)，因为这是采样得到的值。 于是，得到: 得到了一个与(式303)一样的常微分方程[即自变量只有1个的微分方程]，只不过是使用转移矩阵\\(\\Phi\\)替换掉了(式303)里面的状态向量。 注意到，因为在起始时系统满足\\(x(t_n)=\\Phi_{t_n|t_n}x(t_n)\\)，所以有: 对非线性函数\\(f(t,\\Phi(t))\\)使用RK4积分，我们得到: 5.1. 举例: 误差状态方程 现在，考虑一个对于一个非线性，时变的系统使用误差状态卡尔曼滤波器(eskf): 其中，\\(x_t\\)代表了状态真值，\\(u\\)代表控制输入，真值是由nominal状态\\(x\\)和误差状态\\(\\delta\\)的组合: 误差状态方程使用线性表达形式，该系统矩阵A由时变的向量(nominal状态\\(x\\)和输入控制量\\(u\\))来决定: 那么，根据(式304)的推导，对应的状态转移矩阵形式可写成如下: 为了对此等式使用RK积分，我们需要计算\\(x(t)\\)和\\(u(t)\\)在RK积分处的值，如果使用RK4来积分，那么就是\\(\\{t_n,t_n+\\frac{\\Delta t}{2},t_n+\\Delta t\\}\\)这几个时间点 从简单的开始，积分点处的控制输入\\(u(t)\\)可以通过当前\\(u_n\\)和最后一次测量值\\(u_{n+1}\\)进行线性插值得到，即: Nominal state方程应采用最优的方法进行积分，例如，使用RK4: 这里的函数\\(f()\\)指的是\\(x_t(t)\\)的导数，是时变的，即(式311) 通过计算加权得到的\\(k\\)，我们可以得到积分处点的状态值的积分估计: 我们注意到: \\(x(t_n+\\frac{\\Delta t}{2})=\\frac{x_n+x_{n+1}}{2}\\)，这和我们在输入控制\\(u_t\\)的计算中所使用的线性插值是一样的，考虑到RK更新的线性特性，这应该不足为奇。 无论我们以何种方式获得Nominal state状态值，我们现在都可以计算RK4矩阵来进行转移矩阵\\(\\Phi\\)的积分:","categories":[{"name":"IMU相关","slug":"IMU相关","permalink":"http://yoursite.com/categories/IMU%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"四元数的状态误差卡尔曼-[附录]-几种积分方法","slug":"四元数的状态误差卡尔曼/四元数的状态误差卡尔曼-附录-几种积分方法","date":"2020-03-21T14:25:44.000Z","updated":"2020-03-22T15:44:00.000Z","comments":true,"path":"2020/03/21/四元数的状态误差卡尔曼/四元数的状态误差卡尔曼-附录-几种积分方法/","link":"","permalink":"http://yoursite.com/2020/03/21/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC-%E9%99%84%E5%BD%95-%E5%87%A0%E7%A7%8D%E7%A7%AF%E5%88%86%E6%96%B9%E6%B3%95/","excerpt":"","text":"1. [附录]-几种积分方法 2. 龙格库塔数值积分法 我们的目的是对如下形式的非线性微分方程在给定一个时间间隔\\(\\Delta t\\)进行积分， 从而将微分方程转化为差分方程 或者是这种形式(假设\\(t_n=n\\Delta t\\)和\\(x_n \\triangleq x(t_n)\\)) 龙格-库塔(RK)方法是最常用的方法之一，这些方法使用几个迭代来估计区间上的导数，然后利用这个导数在时间步\\(\\Delta t\\)上进行积分。 在接下来的小节中，将介绍几种RK方法，从最简单的方法到最通用的方法，并根据它们最常用的名称进行命名。 2.1. 欧拉方法(The Euler method) 欧拉方法假设导数\\(f(\\cdot)\\)是常数，因此有: 作为一般的RK方法，这对应于一个单阶段方法，它可以描述如下: 计算在初始点处的导数 使用它来计算积分，到结束点 2.2. 中点法(The midpoint method) 中点法假设导数是区间中点处的导数，然后进行一次迭代来计算x在这个中点的值，如 中点法可以解释为以下两步法 使用欧拉方法积分，直到中点 (使用前面定义的k1) 然后使用这个值来计算中间点k2的导数，然后对后半段进行积分 2.3. 4阶龙格库塔法(The RK4 method) 这通常被简单地称为龙格-库塔方法，它用四个阶段或迭代来计算积分，有四个导数，\\(k1 \\cdots k4\\)，是按顺序得到的。然后将这些导数(或斜率)加权平均，得到区间内导数的4阶估计值。 RK4方法比上面两种方法的更好，其积分计算步骤是: 也就是说，增量是通过假设一个斜率来计算的这个斜率是k1 k2 k3 k4的加权平均值，其中k1 k2 k3 k4按下面计算: 不同的斜率有如下的解释: k1是区间开始时的斜率，使用\\(x_n\\)来计算. (欧拉方法) k2是区间中点处的斜率，使用\\(x_n+\\frac{1}{2}\\Delta t k_1\\)来计算。(中点法) k3还是中点的斜率，不过使用\\(x_n+\\frac{1}{2}\\Delta t k_2\\)计算 k4是区间最后的斜率，使用\\(x_n+\\Delta t k_3\\)计算 2.4. 通用龙格库塔法(General Runge-Kutta method) 更详细的RK方法是可能的，它们的目标是减少误差和/或增加稳定性，它们具有通用的形式为: 也就是说，迭代的次数(方法的顺序)是s，平均权值由bi定义，评价时间瞬间由ci定义，斜率ki是用aij值确定的，根据aij的结构，可以使用显式或隐式RK方法。 3. 闭式积分方法(Closed-form integration methods) 在许多情况下，可以得到一个封闭形式的积分步骤表达式，我们现在考虑一阶线性微分方程的情况 也就是说，这个关系是线性的，在区间内是常数，在这种情况下，积分区间[tn, tn + t]，可以得到: 其中，\\(\\Phi\\)就是常说的状态转移矩阵，这个状态转移矩阵的泰勒展开如下: 当写出这串由已知常数矩阵A构成的序列时，有时有可能可以写成闭式的解，一些例子如下 3.1. 角度误差的积分 例如，考虑无偏差和噪声的角度误差(纯净版的式133) 它的转移矩阵可以写成泰勒级数 现在，定义\\(\\boldsymbol{w}\\Delta t \\triangleq \\boldsymbol{u} \\Delta \\theta\\)，旋转轴和旋转的角度，然后应用式53，可以得到 这个解对应于一个旋转矩阵,(根据式51，可以进一步化为转置)，即 \\[ \\Phi=R\\{-\\boldsymbol{u} \\Delta \\theta \\}=R\\{-\\boldsymbol{w} \\Delta t\\}=R\\{\\boldsymbol{w} \\Delta t\\}^T \\] 根据罗德里格斯公式，可以得到闭式解: 3.2. 简化版IMU例子 考虑简化版的IMU系统，其误差状态方程为: 其中，\\((a,w)\\)是已经去除了重力和传感器的偏差的IMU的测量，这个系统的状态向量和矩阵如下: 其在一个时间步\\(\\Delta t\\)的积分为\\(\\boldsymbol{x}_{n+1}=e^{\\boldsymbol{A}\\Delta t}\\cdot \\boldsymbol{x}_n\\)。 状态转移矩阵\\(\\Phi=e^{\\boldsymbol{A\\Delta t}}\\)，泰勒展开如下: 我们可以写出矩阵A的几次幂来说明它们的一般形式 从这里可以看出，对于k&gt;1，有如下一般形式: 我们可以观察这些A的次方项，有固定的部分以及会增长的次方项\\(\\Theta_\\Theta\\) 下面，对状态转移矩阵\\(\\Phi\\)进行分块讨论: 让我们一步一步推进,探索矩阵\\(\\Phi\\)的所有非零块 Trivial diagonal terms (对角线前2个) 没什么好说，就是单位阵I Rotational diagonal term (对角线第3项) 接下来是对角的旋转项\\(\\Phi_{\\theta \\theta}\\)，将新的角误差与旧的角误差联系起来，写出这一项的泰勒级数 正如我们在前一节中看到的，它对应于我们熟知的旋转矩阵 Position-vs-velocity term (第一行第二列) 这是最简单的非对角项 Velocity-vs-angle term (第二行第三列) 根据上面的推导，写出状态转移矩阵\\(\\Phi\\)的第二行第三列\\(\\Phi_{v,\\theta}\\)的叠加形式: 在这里，有两种选择: (1)我们可以把级数的第一个有效项截断，即只保留\\(\\Phi_{v,\\theta}=V_{\\theta}\\Delta t\\) ，但是这样就不是闭式解了。(有关使用这种简化方法的结果，请参见下一节) (2)第二种方法，把因式\\(V_{\\theta}\\)提取出来，如下 可以看到，\\(\\Sigma_1\\)项与我们之前写的\\(\\Phi_{\\theta \\theta}\\)很像，但是有两处例外: \\(\\Sigma_1\\)中的\\(\\Theta_\\theta\\)次方项与系数\\(\\frac{1}{k!}\\)以及\\(\\Delta t\\)次方项都不匹配。实际上，我们在这里\\(\\Sigma_1\\)的标记1表明\\(\\Theta_\\theta\\)次方项少了1次 还有一个问题是，在这个多项式的开头，少了一些内容。实际上，在这里\\(\\Sigma_1\\)的标记1表明少了1些项 关于第一个问题，可以采用式53的办法来解决，(会产生一个单位阵) 式53中的\\(u\\)是单位向量 这个表达式允许我们增加\\(\\Theta_\\theta\\)指数，然后可重写式262如下: 现在，次方项和其他系数都匹配了，但是整个式子还少了一些项，也就是第二个问题。第二个问题可以通过添加和减去缺少的项来解决，用它的封闭形式代替整个级数，即: 于是，最终，可以得到整一个比式解的形式: Position-vs-angle term (第一行第三列) 对\\(\\Phi\\)矩阵的第一行第三列\\(\\Phi_{p\\theta}\\)展开: 提取常数项公因式，写成如下形式: 其中，我们标记下标2在\\(\\Sigma_2\\)中: 对于上面多项式的每一项，都少了\\(\\Theta_\\theta\\)的2次 对于上面的多项式，缺少了开头两项 同样的处理，使用式263所用的方法，可以得到: 进一步地: 最终得到: 以上，就实现了简化版的IMU误差状态的状态转移矩阵\\(\\Phi\\)的推导. 3.3. 完整版IMU例子 为了进一步对上述“简化版IMU”进行推广，我们需要更仔细地研究完整的IMU案例。 考虑一个完整的IMU系统，(式133)所示，可以表示成: 其中，动态矩阵A是块稀疏的，它的各个子块可以由(式133)确定: 其中， \\(P_v=I\\) \\(V_\\theta=-R[a_m-a_b]_\\times\\) \\(V_a=-R\\) \\(V_g=I\\) \\(\\Theta_{\\theta}=-[w_m-w_b]_\\times\\) \\(\\Theta_w=-I\\) 同样的，写出矩阵A的次幂: 可以观察到: A的对角线上的唯一一项，旋转项\\(\\Theta_\\theta\\)，在\\(A^k\\)的次方序列中向右和向上传播。所有不受传播影响的项都将消失，这个传播在以下3个方面影响了\\(\\{A^k \\}\\)序列的结构: 三次幂后，A的稀疏性趋于稳定，也就是说，对于大于3的幂，不再出现或消失非零块。 左上角3x3的子块，与前面例子中的简化IMU模型相对应，在这个例子里面仍然没有改变，因此，这个子块的闭式解就是前面得到的结果。 与角速度偏置(gyrometer bias)误差的相关项(在第5列中的项)，产生了与\\(\\Theta_\\theta\\)次方序列相似的项，可以采用上面“简化版IMU”所使用的技巧进行求解。 我们对寻找构造闭式子块的状态转移矩阵\\(\\Phi\\)的通用方法感兴趣，这与我们在“简化版IMU”所提到的\\(\\Sigma_1,\\Sigma_2\\)有关: 下标表示了序列中每个元素缺失的\\(\\Theta_\\theta\\)的次方数 下标表示了序列开头的项的数目 考虑到这个定义，现在定义一个序列\\(\\Sigma_n(X,y)\\): 这个序列从第n项开始，并且每个元素都缺少了\\(\\Theta_\\theta\\)的n次方，即类似与\\(\\Sigma_1,\\Sigma_2\\): 特别的，当n=0时，有\\(\\Sigma_0=R\\{w\\Delta t\\}^T\\) 现在，我们可以使用这个定义来写出状态转移矩阵\\(\\Phi\\): 现在，我们的问题已经变成了寻找一个关于\\(\\Sigma_n\\)的通用的，闭式的表达，下面再来看一眼之前推导出来的\\(\\Sigma\\) 为了在\\(\\Sigma_3\\)上得到推广，我们需要应用(式263)两次，因为一次只增加\\(\\Theta_\\theta\\)的2次幂，于是得到: 写成闭式解形式: 通过对上面\\(\\Sigma_0,\\Sigma_1,\\Sigma_2,\\Sigma_3\\)的观察，可以推导出关于\\(\\Sigma_n\\)的闭式表达: 状态转移矩阵\\(\\Phi\\)最后的闭式结果使用这个\\(\\Sigma_n\\)来进行表达，即填充到(式278)。 可能需要注意的是，序列拥有了具有有限项的\\(\\Sigma_n\\)表达，因此可以被高效的计算。也就是说，只要\\(n &lt; \\infty\\)，那么\\(\\Sigma_n\\)就可以有闭式表达，这是很常见的情况(\\(n &lt; \\infty\\))。对于当前这个例子来说，\\(n \\leq 3\\)(式278) 4. 使用截断序列的近似方法(重点) 在前面的内容中，我们推导了复杂的状态转移矩阵\\(\\Phi\\)的闭式表达，IMU驱动系统可以写成线性化的形式，即状态误差方程\\(\\dot{\\delta x}=A\\delta x\\) 封闭形式的表达式可能总是令人感兴趣的，但是在什么程度上我们应该担心高阶误差及其对实际算法性能的影响还不清楚，这特别适用于IMU积分误差以相对较高的速率被观察到(并因此需要补偿)的系统，例如视觉-惯性或GPS-惯性融合方案 在这一部分，我们推导关于状态转移矩阵的近似，从相同的假设开始，状态转移矩阵被表达为泰勒展开序列，然后只对影响较大的项进行截断，截断可以使用system-wise和block-wise的方法。 4.1. system-wise截断 4.1.1. 一阶截断: 有限差分法 一种适用于以下系统的典型的、广泛的积分方法: 是基于有限差分法来计算导数的: 这产生: 这与欧拉方法的精度相当，对函数f()在积分的起点处进行线性化，然后得到: 其中，\\(A \\triangleq \\frac{\\partial f}{\\partial x}(t_n,x_n)\\)是雅克比矩阵。这与线性化微分方程的指数解是完全等价的，然后在线性化的项进行截断，从而得到近似: 这说明了，上面提到的欧拉方法，是有限差分方法，是泰勒展开的一阶system-wise截断，也就是说，得到了如下的状态转移矩阵近似: 对于前面所提到的\"简化版IMU\"系统，对其状态转移矩阵应用一阶system-wise截断，得到近似矩阵: 然而，在角度误差的积分一节中，我们已经讨论过了旋转项有一个紧凑的、封闭的表达，即\\(\\Phi_{\\theta \\theta}=R\\cdot (w \\Delta t)^T\\)，对上面的一阶system-wise截断的旋转项进行替换，最终得到: 4.1.2. N阶截断 高阶截断将提高近似状态转移矩阵的精度，截断的一个特别有趣的顺序是最大限度地利用结果的稀疏性，换句话说，没有新的非零项出现的顺序。 对于简化版IMU的例子 回顾一下其系统矩阵A的次幂: 可以发现，在2阶之后，就没有非零项消失和产生，因此，取2阶进行截断，得到: 对于完整版IMU的例子 从系统矩阵A的次幂来看，在3阶之后，就没有非零项消失和产生，因此，取3阶进行截断，得到: 具体的矩阵展开，可往前面翻. 4.2. Block-wise截断(这个好用) 这是一种与前面所推导的闭式结果相当接近的近似方法是: 对状态转移矩阵\\(\\Phi\\)的每个块的泰勒级数展开的第一个有效项上进行截断 就是说，我们单独检查转移矩阵的每个非零子块，而不是对整个状态转移矩阵的泰勒展开序列进行截断。因此，需要在每个块的基础上分析截断 下面使用两个例子来讨论: 4.2.1. 简化版IMU例子 对于\\(\\Phi_{v,\\theta},\\Phi_{p,\\theta}\\)项，分别有序列\\(\\Sigma_1\\)和\\(\\Sigma_2\\) 对上述序列\\(\\Sigma_1\\)和\\(\\Sigma_2\\)进行1阶截断，得到: 于是，简化版IMU系统的状态转移矩阵\\(\\Phi\\)可近似如下: 这种截断方法比上面的全系统(system-wide)一阶截断法更精确，同时，特别是与封闭形式相比，又很容易获得和计算。 对于右下角(3,3)项，由于其闭式已经计算出来了，而且比较好计算，所以直接使用闭式形式即可。 4.2.2. 完整版IMU例子 对于完整的IMU系统，将前面所推导的\\(\\Sigma_n\\)代入到状态转移矩阵\\(\\Phi\\)中，然后进行截断，可以得到转移矩阵的近似: (1)标准的状态转移矩阵\\(\\Phi\\): \\(P_v=I\\) \\(V_\\theta=-R[a_m-a_b]_\\times\\) \\(V_a=-R\\) \\(V_g=I\\) \\(\\Theta_{\\theta}=-[w_m-w_b]_\\times\\) \\(\\Theta_w=-I\\) (2)\\(\\Sigma_n\\)的闭式表达: (3)根据上面的推导进行截断，得到 其中， (4)如果还想要进一步简化，一个直接的方法是限制每个子块的最高阶数n 当n=1(也就是欧拉法)，我们得到: 当n=2，我们得到: 当n=3，也就是最上面的(式297)了 5. 使用龙格库塔积分法得到状态转移矩阵(时变) 其他方法来近似得到状态转移矩阵就是使用龙格库塔积分法，当动态矩阵(系统矩阵)A在积分区间内不能被认为是常数的情况下(即系统矩阵是时变的矩阵\\(A(t)\\))，这是可能可以使用。 假设有连续时间系统: 让我们重写以下两个关系，它们在连续时间和离散时间中定义了同一个系统，这分别包含了时变的系统矩阵\\(A(t)\\)和状态转移矩阵\\(\\Phi\\): 上面两个等式可以分别以两种方式推导\\(\\dot{x}(t_n+\\tau)\\) 其中，需要注意的是\\(\\dot{x}(t_n)=\\dot{x}_n=0\\)，因为这是采样得到的值。 于是，得到: 得到了一个与(式303)一样的常微分方程[即自变量只有1个的微分方程]，只不过是使用转移矩阵\\(\\Phi\\)替换掉了(式303)里面的状态向量。 注意到，因为在起始时系统满足\\(x(t_n)=\\Phi_{t_n|t_n}x(t_n)\\)，所以有: 对非线性函数\\(f(t,\\Phi(t))\\)使用RK4积分，我们得到: 5.1. 举例: 误差状态方程 现在，考虑一个对于一个非线性，时变的系统使用误差状态卡尔曼滤波器(eskf): 其中，\\(x_t\\)代表了状态真值，\\(u\\)代表控制输入，真值是由nominal状态\\(x\\)和误差状态\\(\\delta\\)的组合: 误差状态方程使用线性表达形式，该系统矩阵A由时变的向量(nominal状态\\(x\\)和输入控制量\\(u\\))来决定: 那么，根据(式304)的推导，对应的状态转移矩阵形式可写成如下: 为了对此等式使用RK积分，我们需要计算\\(x(t)\\)和\\(u(t)\\)在RK积分处的值，如果使用RK4来积分，那么就是\\(\\{t_n,t_n+\\frac{\\Delta t}{2},t_n+\\Delta t\\}\\)这几个时间点 从简单的开始，积分点处的控制输入\\(u(t)\\)可以通过当前\\(u_n\\)和最后一次测量值\\(u_{n+1}\\)进行线性插值得到，即: Nominal state方程应采用最优的方法进行积分，例如，使用RK4: 这里的函数\\(f()\\)指的是\\(x_t(t)\\)的导数，是时变的，即(式311) 通过计算加权得到的\\(k\\)，我们可以得到积分处点的状态值的积分估计: 我们注意到: \\(x(t_n+\\frac{\\Delta t}{2})=\\frac{x_n+x_{n+1}}{2}\\)，这和我们在输入控制\\(u_t\\)的计算中所使用的线性插值是一样的，考虑到RK更新的线性特性，这应该不足为奇。 无论我们以何种方式获得Nominal state状态值，我们现在都可以计算RK4矩阵来进行转移矩阵\\(\\Phi\\)的积分:","categories":[{"name":"四元数的状态误差卡尔曼","slug":"四元数的状态误差卡尔曼","permalink":"http://yoursite.com/categories/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC/"}],"tags":[]},{"title":"四元数的状态误差卡尔曼-Quaternion-kinematics-for-the-error-state-KF","slug":"IMU相关/四元数的状态误差卡尔曼-Quaternion-kinematics-for-the-error-state-KF","date":"2020-03-21T08:56:18.000Z","updated":"2020-03-24T13:17:15.000Z","comments":true,"path":"2020/03/21/IMU相关/四元数的状态误差卡尔曼-Quaternion-kinematics-for-the-error-state-KF/","link":"","permalink":"http://yoursite.com/2020/03/21/IMU%E7%9B%B8%E5%85%B3/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC-Quaternion-kinematics-for-the-error-state-KF/","excerpt":"","text":"1. 第一章 四元数 2. 第二章 IMU驱动系统的误差状态运动学 2.1. 动机 我们希望写出带有偏置和噪声的加速度计和陀螺仪读数中惯性系统运动学的误差位置方程，用哈密尔顿四元数表示空间方向或姿态。 误差状态卡尔曼滤波器 error-state Kalman filter (ESKF): 姿态误差最小(它有与自由度相同数量的参数)，避免与过度参数化(或冗余)相关的问题以及所涉及的协方差矩阵的奇异性风险 误差状态系统总是在接近原点的地方运行，因此远离可能的参数奇异点， gimbal lock等问题，提供任何时候都有效保证的线性化 误差状态总是很小，意味着所有二阶项的影响都很小，这使得雅可比矩阵的计算非常简单和快速，一些雅可比矩阵甚至可以是常数，或者等于可用状态的大小。 误差动力学是缓慢的，因为所有大的信号都被整合成nominal-state。这意味着我们可以以比预测操作更低的速度进行更新(这是观察误差的唯一方法) 2.2. ESKF的解释 在eskf公式中，分为真值(true-)，nominal-，和误差状态值(error-state values)。真实状态被表示为nominal-和误差状态值(error-state values)合适的组合(线性叠加，四元数乘积，矩阵乘法等)。这个思路是把nominal-state考虑为大信号(以非线性方式可积)以及把误差状态值作为小信号(因此线性可积，适用于线性高斯滤波)。 因此，eskf可以解释为如下：一方面，高频率的IMU数据\\(u_m\\)被整合(积分)成nominal-状态值\\(x\\)，这个nominal-state不考虑噪声项\\(w\\)以及其他可能影响的模型参数。因此，这个norminal值会累积误差。这些errors被误差状态\\(\\delta x\\)所收集，然后使用eskf来估计，此时这次加入了所有的噪音和干扰。误差状态由小信号组成，它的传递函数是由(时变)线性的[带有动态、控制和测量矩阵]的动态系统正确定义的。与nominal-state的积分平行，ESKF预测的是误差状态的高斯估计，而更新过程是由其他观测信号(IMU以外的如GPS，视觉路标)到达之后进行的。这种更新修正提供了误差状态的后验高斯估计，之后误差状态的均值被注入到nominal-state，然后将误差状态重置为0，然后更新误差状态的协方差矩阵。 2.3. 连续时间系统运动学 下面是一些定义: 角速度\\(\\omega\\)被定义为相对于nominal-state是local的(The angular rates ω are defined locally with respect to the nominal quaternion)，这允许我们直接使用角速度测量值\\(\\omega_m\\)，它提供了body系的角速度。 角度误差\\(\\delta \\theta\\)被定义为相对于nominal-state是local的，这未必是最佳的方式，但这与大多数imu积分过程中的选择是一致的(经典方法)。 \\(a_t\\)是全局坐标系下的加速度真值 \\(a_m\\)是测量得到的载体坐标系下加速度测量值(含有噪声和偏置) 2.3.1. 状态真值 运动学方程 body坐标系下的加速度\\(a_m\\)和角速度\\(w_m\\)可以使用加速度真值\\(a_t\\)和角速度真值\\(w_t\\)以及噪声来表达: 写成逆的形式 对上面这些式子进行整合，得到完整的运动系统 可以定义这个系统为\\(\\dot{x}_t=f_t(x_t,u,w)\\)，系统可以写成如下形式: 需要注意的是： 在上面的公式中，重力向量\\(g_t\\)将由滤波器来估计,它有一个恒定的演化方程(130f), 相当于一个已知的常数大小。系统从一个固定的和任意已知的初始方向开始\\(q_t(t=0)=q_0\\)，(由于一般不在水平面上，使得初始重力矢量一般未知)。为了简单起见，通常采用以下这种方法: $q_0 = (1, 0, 0, 0) \\(，因此有\\)R_0=R{q_0}=I\\(，然后我们估计重力向量\\)g_t\\(在\\)q_0\\(下的表示，而不是\\)q_t$在水平坐标系中表达，因此，初始的方向不确定度转化为重力方向的初始不确定度。 我们这样做是为了提高线性度，现在式(130b)是关于\\(g\\)线性化的，携带所有的不确定性，而初始方向\\(q_0\\)是已知的(没有不确定性的)，因此\\(q\\)的开始是不带有不确定性的。 一旦估计出重力矢量，就可以恢复水平面，恢复的运动轨迹可以重新定向，以反映估计的水平。 2.3.2. nominal-state kinematics 即没有噪声和扰动的模型 2.3.3. 误差状态 我们的目标是: 确定误差状态的线性化动力学，对于每个状态方程，在表格2中写出了它们的组合，求解误差状态，简化所有二阶无穷小，下面给出完整的误差状态动态系统，并在此基础上进行了讨论和证明。 上面的等式(133a), (133d), (133e) and (133f),分别代表了位置，偏置和重力误差，是从线性方程推导出来的(即使用式130-式132得到的)，它们的错误状态动态是微不足道的。 举例：考虑真值和nominal位置等式(130a) and (132a)，它们的组合是\\(p_t=p+\\delta p\\)，然后计算出来的\\(\\delta \\dot{p}\\)就是式(133a)所示。 等式 (133b) and (133c)，速度和方向误差，要求对非线性方程进行一些特别的处理(等式 (130b) and (130c) )，来获得线性化的方程。他们的证明将在以下两节中展开 Equation (133b): The linear velocity error的推导 我们希望确定\\(\\delta \\dot{v}\\)(速度的误差)，从下面的等式开始 式(134)是对\\(R_t\\)的欧拉角近似，在式(135)中，我们重写\\((132b)\\)，但是引入了\\(a_{\\mathcal{B}}\\)和\\(\\delta a_{\\mathcal{B}}\\)来进行简写，其中 于是，我们可以写出在惯性坐标系i系的加速度真值: 接下来，通过对式(130b)中\\(\\dot{v}_t\\)写成两种形式，其中\\(O(||\\delta \\theta||^2)\\)被忽略: 因为\\(\\dot{v}_t=R_t a_t +g_t\\)，所以有下列等式的右侧 同时，又有\\(\\dot{v}+\\dot{\\delta v}=\\dot{v}_t\\)，所以有下列等式左侧 去掉等式两边的\\(Ra_{\\mathcal{B}}+g\\)，得到了: 消去二阶项\\(R[\\delta \\theta]_{\\times}\\delta a_{\\mathcal{B}}\\)以及对叉乘进行变换，得到: 然后，把上面定义的变量\\(a_{\\mathcal{B}}\\)，\\(\\delta a_{\\mathcal{B}}\\)重新使用(136,137)使用原来定义的变量 这就是最前面的(式133b)的推导: 为了进一步简化这个表达，我们通常假设加速度噪声是白噪声，独立的，(也就是看做是均值为0的高斯分布) 协方差椭球是一个以原点为中心的球体，这意味着它的均值和协方差矩阵在旋转时不变，证明如下: 然后我们可以重新定义加速度计的噪声矢量，绝对没有任何后果 Equation (133c): The orientation error. 姿态误差的推导 我们希望确定角度误差\\(\\delta \\dot{\\theta}\\)的表达式，从下面的两个关系式开始： 跟前面加速度的处理一样，先对角速度进行简化表达: 那么，角速度真值\\(w_t\\)可以写成 然后使用两种不同的表达来表示\\(\\dot{q}_t\\) 因为\\(q_t=q \\otimes \\delta q\\)，于是有\\(\\dot{q}_t = \\dot{(q \\otimes \\delta q)}\\) 所以: 接着: (1)去掉q(即对上式两边同时乘以2，然后把\\(\\frac{1}{2}q\\otimes w \\otimes \\delta q\\)移到左侧，然后再把q去掉) (2)并且对\\(\\dot{\\delta q}\\)进行分离(使用四元数乘法的两种算法(左乘和右乘)) ，然后得到: 结果得到一个标量和一个向量的等式 第二个等式，进一步去除2阶项之后，得到 最终，把中间变量\\(w\\)和\\(\\delta w\\)换回原来的变量，得到: 2.4. 离散时间的系统 上述微分方程需要集成(积分)到差分方程中，以考虑离散时间间隔t &gt; 0，积分的方法有很多，在某些情况下，可以使用完全封闭的解，在其他情况下，可以采用不同精度的数值积分。 需要对以下子系统进行积分: nominal state error-state (1)确定性部分:状态动力学和控制 (2)不确定部分:噪声和扰动 2.4.1. nominal state 方程 差分形式如下 其中，\\(R \\triangleq R\\{q\\}\\)是与当前nominal state的q相关的旋转矩阵，\\(q\\{v\\}\\)是与旋转向量v相关的四元数，如下 当然，上面的差分形式中的积分部分可以使用其他更加精确的积分，具体见附录。 2.4.2. 误差状态方程 回顾连续时间下的误差状态方程: 对连续时间下使用时间步\\(\\Delta t\\)进行积分，得到离散时间下的误差状态方程 转换规则: 对于确定性的部分，可以使用积分法(也就是附录 C.2 ) 对于不确定性的部分，使用产生随机脉冲 (见附录 E) (式157c)的\\(\\delta \\theta\\)的怎么推导的？ 推导如下: (1)暂时忽略掉一些误差项，只保留\\(\\dot{\\delta \\theta}=-[w]_\\times \\delta \\theta\\) (2)对这个微分方程进行求解，可以得到: \\[ \\begin{aligned} \\delta \\theta_{k+1}= \\Phi \\delta \\theta_{k} = e^{-[w]_\\times \\Delta t} \\delta \\theta_{k} \\end{aligned} \\] (3)将转移矩阵\\(\\Phi\\)进行泰勒级数展开: (4)根据式53，可以写成罗德里格斯公式，最终状态转移矩阵\\(\\Phi\\)化简为关于\\(-w\\Delta t\\)的旋转矩阵，即: \\[ \\Phi=R\\{-\\boldsymbol{u} \\Delta \\theta \\}=R\\{-\\boldsymbol{w} \\Delta t\\}=R\\{\\boldsymbol{w} \\Delta t\\}^T \\] 所以，得到 最后再补上误差和扰动项，就得到了(式157c)的结果 上面的离散时间下的误差状态方程中，\\(v_i,\\theta_i,a_i,w_i\\)都是应用于速度，角度，偏置估计的随机脉冲，使用高斯白噪声模型，它们的均值都是0，协方差矩阵是通过对\\(a_n,w_n,a_w,w_w\\)在一个时间步(即\\(\\Delta t\\))内的积分(见附录 E)，即: 其中，\\(\\sigma_{\\tilde{a}_n}[m/s^2],\\sigma_{\\tilde{w}_n}[rad/s],\\sigma_{\\tilde{a}_w}[m/s^2 \\sqrt{s}],\\sigma_{\\tilde{w}_w}[rad/s \\sqrt{s}]\\)可以通过IMU的出厂数据或者通过标定实验得到。 2.4.3. 误差状态的雅克比和扰动矩阵 通过对前一节中误差状态差分方程的简单检验，得到了雅可比矩阵 为了把这些方程写成紧凑的形式，我们考虑使用 nominal-state向量\\(x\\)，误差状态向量\\(\\delta x\\)，输入向量\\(u_m\\)和扰动脉冲向量\\(i\\)(see App. E.1 for details and justifications)，这些向量展开如下: 此时，误差状态系统可以写成: ESKF预测等式可以写成: 其中， \\(\\delta x \\sim \\mathcal{N}\\{\\hat{\\delta x},P\\}\\); \\(F_x\\)和\\(F_i\\)是f()分别对误差和扰动的雅克比; \\(Q\\)是扰动脉冲的协方差矩阵 下面详细介绍上面的雅可比矩阵和协方差矩阵的表达式，这里出现的所有与状态相关的值都是直接从normal-state中提取的: 特别需要注意的是: \\(F_x\\)是系统的转移矩阵，可以使用多种方法来近似到不同级别的精确度。在这里使用了比较简单的欧拉法进行近似(Euler form) 另外，还需要注意的是，如果误差\\(\\delta x\\)被初始化为0，于是线性化等式(164)一直返回0，当然，您应该跳过代码中的关于(164)，我建议你把它写下来，但是你要把它注释掉，这样你就可以确定你没有忘记任何东西。 请注意，最后，你不应该跳过协方差预测(165)，实际上，\\(F_iQ_i F_i^T\\)不是空的，因此它的协方差应该是一直增长的——在任何预测步骤中都是如此。 3. 使用互补的传感器数据融合IMU 当其他类型的传感器数据(GPS,Vison)到达，我们使用ESKF进行处理。在一个设计好的系统中，这将使IMU的偏差变得明显，然后允许ESKF来正确的估计这个误差。 最常见的有GPS+IMU，单目+IMU，双目+IMU，近年来，使用IMU和视觉传感器融合领域引人注目，使用视觉+IMU对于在不能使用GPS的环境中十分有趣，可以在移动设备(手机)、无人机等其他平台上使用。 在上面的讨论中，IMU信息到目前为止一直用于对ESKF进行预测，而其他的传感器信息用于矫正滤波器，矫正分为3个步骤: 通过滤波器校正对误差状态的观测 注入观测误差到 nominal state 重置误差状态 3.1. 第一步: 通过滤波器校正对误差状态的观测 假设像往常一样，我们有一个传感器，它所传输出来的信息依赖状态真值: 其中，h()是关于状态真值的非线性函数的一般形式，\\(v\\)是协方差为\\(V\\)的高斯白噪声: 我们的滤波器是先估计误差状态，然后有滤波器校正方程: 其中，需要: 状态误差\\(\\delta x\\)的雅克比矩阵\\(H\\)， 使用校正之后的状态误差最优估计\\(\\hat{\\delta x}\\)，对状态真值估计进行更新，即\\(\\hat{x_t}=x \\oplus \\hat{\\delta x}\\)。 由于此时的误差状态均值为零(我们尚未观测到)，因此，我们此时只能得到\\(\\hat{x_t}=x\\)，我们可以使用nominal error x作为线性化点，得到雅克比矩阵\\(H\\): 上面给出了协方差更新的最简单的形式:\\(P\\leftarrow (I-KH)P\\)，但是这种形式的数值稳定性很差，因为它的结果不一定是对称的，也不一定是正定的。一般可以使用更稳定的形式，如 the symmetric form: \\(P\\leftarrow P-K(HPH^T+V)K^T\\) the symmetric and positive Joseph form: \\(P\\leftarrow (I-KH)P(I-KH)^T+KVK^T\\) 3.1.1. 计算观测矩阵H 上面的观测矩阵可以用多种方法计算，最常用连式法则: 其中，\\(H_x \\triangleq \\frac{\\partial h}{\\partial x_t}|_x\\)是关于函数h()的分别对其参数的雅克比 第一部分\\(\\frac{\\partial h}{\\partial x_t}|_x\\)由传感器的测量函数决定，这里不具体展开 第二部分\\(X_{\\delta x}\\triangleq \\frac{\\partial x_t}{\\partial \\delta x}|_x\\)是状态真值对于误差状态的雅克比，这部分可以在这里导出，因为它只依赖于状态的ESKF组合，因此，有: 对上面进行分块，简化，得到: 其中，\\(Q_{\\delta \\theta}=\\frac{q\\otimes \\delta q}{\\delta \\delta \\theta}\\)是\\(4\\times 3\\)的矩阵块，使用(式14/15)以及一阶近似(\\(\\delta q \\rightarrow [1 , \\frac{1}{2}\\delta \\theta]^T\\) ， 见下方补充)，那么\\(Q_{\\delta \\theta}\\)可以写成: 补充: 上面的意思是: 当给定旋转向量\\(\\delta \\theta\\)，其四元数为: \\[ \\begin{aligned} \\begin{bmatrix} \\cos(\\frac{\\delta \\theta}{2}) \\\\ I_{3\\times 1}\\sin(\\frac{\\delta \\theta}{2}) \\end{bmatrix} \\end{aligned} \\] 当\\(\\theta\\)很小时，有\\(\\frac{\\delta \\theta}{2}=\\sin(\\frac{\\delta \\theta}{2})\\)和\\(\\cos(\\frac{\\delta \\theta}{2})=1\\) 所以有: \\[ \\begin{aligned} \\delta \\leftarrow \\begin{bmatrix} 1 \\\\ \\frac{1}{2}\\delta \\theta \\end{bmatrix} \\end{aligned} \\] 或者使用泰勒展开，取一阶近似，也是可以得到相同的结果 3.2. 第二步: 注入观测误差到 nominal state 经过ESKF更新校正之后，可以使用校正之后的误差状态\\(\\hat{\\delta x}\\)与nominal state组合，得到状态真值的估计: 3.3. 第三步: ESKF重置 (为什么需要重置？ 你都观测到接近真值了，并且进行了校正，误差状态当然要重置啊) 当所有误差状态注入到nominal state之后，误差状态均值\\(\\hat{\\delta x}\\)需要被重置，尤其是旋转的部分，因为新的旋转姿态误差是相对于新的nominal state的姿态坐标系而言的。 为了ESKF完整更新，误差状态的协方差也需要被更新 下面称误差重置函数为\\(g()\\)，即: 其中，\\(\\ominus\\)表示与\\(\\oplus\\)相反的操作，因此，ESKF重置操作可表示为: 其中，矩阵G为: 与在第一步中的雅克比矩阵类似，这个矩阵对角线上的子块，除了与旋转部分有关，其他都是单位矩阵I 3.3.1. 关于旋转部分子块的推导(略)","categories":[{"name":"IMU相关","slug":"IMU相关","permalink":"http://yoursite.com/categories/IMU%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"四元数的状态误差卡尔曼-Quaternion-kinematics-for-the-error-state-KF","slug":"四元数的状态误差卡尔曼/四元数的状态误差卡尔曼-Quaternion-kinematics-for-the-error-state-KF","date":"2020-03-21T08:56:18.000Z","updated":"2020-03-24T13:17:15.000Z","comments":true,"path":"2020/03/21/四元数的状态误差卡尔曼/四元数的状态误差卡尔曼-Quaternion-kinematics-for-the-error-state-KF/","link":"","permalink":"http://yoursite.com/2020/03/21/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC-Quaternion-kinematics-for-the-error-state-KF/","excerpt":"","text":"1. 第一章 四元数 2. 第二章 IMU驱动系统的误差状态运动学 2.1. 动机 我们希望写出带有偏置和噪声的加速度计和陀螺仪读数中惯性系统运动学的误差位置方程，用哈密尔顿四元数表示空间方向或姿态。 误差状态卡尔曼滤波器 error-state Kalman filter (ESKF): 姿态误差最小(它有与自由度相同数量的参数)，避免与过度参数化(或冗余)相关的问题以及所涉及的协方差矩阵的奇异性风险 误差状态系统总是在接近原点的地方运行，因此远离可能的参数奇异点， gimbal lock等问题，提供任何时候都有效保证的线性化 误差状态总是很小，意味着所有二阶项的影响都很小，这使得雅可比矩阵的计算非常简单和快速，一些雅可比矩阵甚至可以是常数，或者等于可用状态的大小。 误差动力学是缓慢的，因为所有大的信号都被整合成nominal-state。这意味着我们可以以比预测操作更低的速度进行更新(这是观察误差的唯一方法) 2.2. ESKF的解释 在eskf公式中，分为真值(true-)，nominal-，和误差状态值(error-state values)。真实状态被表示为nominal-和误差状态值(error-state values)合适的组合(线性叠加，四元数乘积，矩阵乘法等)。这个思路是把nominal-state考虑为大信号(以非线性方式可积)以及把误差状态值作为小信号(因此线性可积，适用于线性高斯滤波)。 因此，eskf可以解释为如下：一方面，高频率的IMU数据\\(u_m\\)被整合(积分)成nominal-状态值\\(x\\)，这个nominal-state不考虑噪声项\\(w\\)以及其他可能影响的模型参数。因此，这个norminal值会累积误差。这些errors被误差状态\\(\\delta x\\)所收集，然后使用eskf来估计，此时这次加入了所有的噪音和干扰。误差状态由小信号组成，它的传递函数是由(时变)线性的[带有动态、控制和测量矩阵]的动态系统正确定义的。与nominal-state的积分平行，ESKF预测的是误差状态的高斯估计，而更新过程是由其他观测信号(IMU以外的如GPS，视觉路标)到达之后进行的。这种更新修正提供了误差状态的后验高斯估计，之后误差状态的均值被注入到nominal-state，然后将误差状态重置为0，然后更新误差状态的协方差矩阵。 2.3. 连续时间系统运动学 下面是一些定义: 角速度\\(\\omega\\)被定义为相对于nominal-state是local的(The angular rates ω are defined locally with respect to the nominal quaternion)，这允许我们直接使用角速度测量值\\(\\omega_m\\)，它提供了body系的角速度。 角度误差\\(\\delta \\theta\\)被定义为相对于nominal-state是local的，这未必是最佳的方式，但这与大多数imu积分过程中的选择是一致的(经典方法)。 \\(a_t\\)是全局坐标系下的加速度真值 \\(a_m\\)是测量得到的载体坐标系下加速度测量值(含有噪声和偏置) 2.3.1. 状态真值 运动学方程 body坐标系下的加速度\\(a_m\\)和角速度\\(w_m\\)可以使用加速度真值\\(a_t\\)和角速度真值\\(w_t\\)以及噪声来表达: 写成逆的形式 对上面这些式子进行整合，得到完整的运动系统 可以定义这个系统为\\(\\dot{x}_t=f_t(x_t,u,w)\\)，系统可以写成如下形式: 需要注意的是： 在上面的公式中，重力向量\\(g_t\\)将由滤波器来估计,它有一个恒定的演化方程(130f), 相当于一个已知的常数大小。系统从一个固定的和任意已知的初始方向开始\\(q_t(t=0)=q_0\\)，(由于一般不在水平面上，使得初始重力矢量一般未知)。为了简单起见，通常采用以下这种方法: $q_0 = (1, 0, 0, 0) \\(，因此有\\)R_0=R{q_0}=I\\(，然后我们估计重力向量\\)g_t\\(在\\)q_0\\(下的表示，而不是\\)q_t$在水平坐标系中表达，因此，初始的方向不确定度转化为重力方向的初始不确定度。 我们这样做是为了提高线性度，现在式(130b)是关于\\(g\\)线性化的，携带所有的不确定性，而初始方向\\(q_0\\)是已知的(没有不确定性的)，因此\\(q\\)的开始是不带有不确定性的。 一旦估计出重力矢量，就可以恢复水平面，恢复的运动轨迹可以重新定向，以反映估计的水平。 2.3.2. nominal-state kinematics 即没有噪声和扰动的模型 2.3.3. 误差状态 我们的目标是: 确定误差状态的线性化动力学，对于每个状态方程，在表格2中写出了它们的组合，求解误差状态，简化所有二阶无穷小，下面给出完整的误差状态动态系统，并在此基础上进行了讨论和证明。 上面的等式(133a), (133d), (133e) and (133f),分别代表了位置，偏置和重力误差，是从线性方程推导出来的(即使用式130-式132得到的)，它们的错误状态动态是微不足道的。 举例：考虑真值和nominal位置等式(130a) and (132a)，它们的组合是\\(p_t=p+\\delta p\\)，然后计算出来的\\(\\delta \\dot{p}\\)就是式(133a)所示。 等式 (133b) and (133c)，速度和方向误差，要求对非线性方程进行一些特别的处理(等式 (130b) and (130c) )，来获得线性化的方程。他们的证明将在以下两节中展开 Equation (133b): The linear velocity error的推导 我们希望确定\\(\\delta \\dot{v}\\)(速度的误差)，从下面的等式开始 式(134)是对\\(R_t\\)的欧拉角近似，在式(135)中，我们重写\\((132b)\\)，但是引入了\\(a_{\\mathcal{B}}\\)和\\(\\delta a_{\\mathcal{B}}\\)来进行简写，其中 于是，我们可以写出在惯性坐标系i系的加速度真值: 接下来，通过对式(130b)中\\(\\dot{v}_t\\)写成两种形式，其中\\(O(||\\delta \\theta||^2)\\)被忽略: 因为\\(\\dot{v}_t=R_t a_t +g_t\\)，所以有下列等式的右侧 同时，又有\\(\\dot{v}+\\dot{\\delta v}=\\dot{v}_t\\)，所以有下列等式左侧 去掉等式两边的\\(Ra_{\\mathcal{B}}+g\\)，得到了: 消去二阶项\\(R[\\delta \\theta]_{\\times}\\delta a_{\\mathcal{B}}\\)以及对叉乘进行变换，得到: 然后，把上面定义的变量\\(a_{\\mathcal{B}}\\)，\\(\\delta a_{\\mathcal{B}}\\)重新使用(136,137)使用原来定义的变量 这就是最前面的(式133b)的推导: 为了进一步简化这个表达，我们通常假设加速度噪声是白噪声，独立的，(也就是看做是均值为0的高斯分布) 协方差椭球是一个以原点为中心的球体，这意味着它的均值和协方差矩阵在旋转时不变，证明如下: 然后我们可以重新定义加速度计的噪声矢量，绝对没有任何后果 Equation (133c): The orientation error. 姿态误差的推导 我们希望确定角度误差\\(\\delta \\dot{\\theta}\\)的表达式，从下面的两个关系式开始： 跟前面加速度的处理一样，先对角速度进行简化表达: 那么，角速度真值\\(w_t\\)可以写成 然后使用两种不同的表达来表示\\(\\dot{q}_t\\) 因为\\(q_t=q \\otimes \\delta q\\)，于是有\\(\\dot{q}_t = \\dot{(q \\otimes \\delta q)}\\) 所以: 接着: (1)去掉q(即对上式两边同时乘以2，然后把\\(\\frac{1}{2}q\\otimes w \\otimes \\delta q\\)移到左侧，然后再把q去掉) (2)并且对\\(\\dot{\\delta q}\\)进行分离(使用四元数乘法的两种算法(左乘和右乘)) ，然后得到: 结果得到一个标量和一个向量的等式 第二个等式，进一步去除2阶项之后，得到 最终，把中间变量\\(w\\)和\\(\\delta w\\)换回原来的变量，得到: 2.4. 离散时间的系统 上述微分方程需要集成(积分)到差分方程中，以考虑离散时间间隔t &gt; 0，积分的方法有很多，在某些情况下，可以使用完全封闭的解，在其他情况下，可以采用不同精度的数值积分。 需要对以下子系统进行积分: nominal state error-state (1)确定性部分:状态动力学和控制 (2)不确定部分:噪声和扰动 2.4.1. nominal state 方程 差分形式如下 其中，\\(R \\triangleq R\\{q\\}\\)是与当前nominal state的q相关的旋转矩阵，\\(q\\{v\\}\\)是与旋转向量v相关的四元数，如下 当然，上面的差分形式中的积分部分可以使用其他更加精确的积分，具体见附录。 2.4.2. 误差状态方程 回顾连续时间下的误差状态方程: 对连续时间下使用时间步\\(\\Delta t\\)进行积分，得到离散时间下的误差状态方程 转换规则: 对于确定性的部分，可以使用积分法(也就是附录 C.2 ) 对于不确定性的部分，使用产生随机脉冲 (见附录 E) (式157c)的\\(\\delta \\theta\\)的怎么推导的？ 推导如下: (1)暂时忽略掉一些误差项，只保留\\(\\dot{\\delta \\theta}=-[w]_\\times \\delta \\theta\\) (2)对这个微分方程进行求解，可以得到: \\[ \\begin{aligned} \\delta \\theta_{k+1}= \\Phi \\delta \\theta_{k} = e^{-[w]_\\times \\Delta t} \\delta \\theta_{k} \\end{aligned} \\] (3)将转移矩阵\\(\\Phi\\)进行泰勒级数展开: (4)根据式53，可以写成罗德里格斯公式，最终状态转移矩阵\\(\\Phi\\)化简为关于\\(-w\\Delta t\\)的旋转矩阵，即: \\[ \\Phi=R\\{-\\boldsymbol{u} \\Delta \\theta \\}=R\\{-\\boldsymbol{w} \\Delta t\\}=R\\{\\boldsymbol{w} \\Delta t\\}^T \\] 所以，得到 最后再补上误差和扰动项，就得到了(式157c)的结果 上面的离散时间下的误差状态方程中，\\(v_i,\\theta_i,a_i,w_i\\)都是应用于速度，角度，偏置估计的随机脉冲，使用高斯白噪声模型，它们的均值都是0，协方差矩阵是通过对\\(a_n,w_n,a_w,w_w\\)在一个时间步(即\\(\\Delta t\\))内的积分(见附录 E)，即: 其中，\\(\\sigma_{\\tilde{a}_n}[m/s^2],\\sigma_{\\tilde{w}_n}[rad/s],\\sigma_{\\tilde{a}_w}[m/s^2 \\sqrt{s}],\\sigma_{\\tilde{w}_w}[rad/s \\sqrt{s}]\\)可以通过IMU的出厂数据或者通过标定实验得到。 2.4.3. 误差状态的雅克比和扰动矩阵 通过对前一节中误差状态差分方程的简单检验，得到了雅可比矩阵 为了把这些方程写成紧凑的形式，我们考虑使用 nominal-state向量\\(x\\)，误差状态向量\\(\\delta x\\)，输入向量\\(u_m\\)和扰动脉冲向量\\(i\\)(see App. E.1 for details and justifications)，这些向量展开如下: 此时，误差状态系统可以写成: ESKF预测等式可以写成: 其中， \\(\\delta x \\sim \\mathcal{N}\\{\\hat{\\delta x},P\\}\\); \\(F_x\\)和\\(F_i\\)是f()分别对误差和扰动的雅克比; \\(Q\\)是扰动脉冲的协方差矩阵 下面详细介绍上面的雅可比矩阵和协方差矩阵的表达式，这里出现的所有与状态相关的值都是直接从normal-state中提取的: 特别需要注意的是: \\(F_x\\)是系统的转移矩阵，可以使用多种方法来近似到不同级别的精确度。在这里使用了比较简单的欧拉法进行近似(Euler form) 另外，还需要注意的是，如果误差\\(\\delta x\\)被初始化为0，于是线性化等式(164)一直返回0，当然，您应该跳过代码中的关于(164)，我建议你把它写下来，但是你要把它注释掉，这样你就可以确定你没有忘记任何东西。 请注意，最后，你不应该跳过协方差预测(165)，实际上，\\(F_iQ_i F_i^T\\)不是空的，因此它的协方差应该是一直增长的——在任何预测步骤中都是如此。 3. 使用互补的传感器数据融合IMU 当其他类型的传感器数据(GPS,Vison)到达，我们使用ESKF进行处理。在一个设计好的系统中，这将使IMU的偏差变得明显，然后允许ESKF来正确的估计这个误差。 最常见的有GPS+IMU，单目+IMU，双目+IMU，近年来，使用IMU和视觉传感器融合领域引人注目，使用视觉+IMU对于在不能使用GPS的环境中十分有趣，可以在移动设备(手机)、无人机等其他平台上使用。 在上面的讨论中，IMU信息到目前为止一直用于对ESKF进行预测，而其他的传感器信息用于矫正滤波器，矫正分为3个步骤: 通过滤波器校正对误差状态的观测 注入观测误差到 nominal state 重置误差状态 3.1. 第一步: 通过滤波器校正对误差状态的观测 假设像往常一样，我们有一个传感器，它所传输出来的信息依赖状态真值: 其中，h()是关于状态真值的非线性函数的一般形式，\\(v\\)是协方差为\\(V\\)的高斯白噪声: 我们的滤波器是先估计误差状态，然后有滤波器校正方程: 其中，需要: 状态误差\\(\\delta x\\)的雅克比矩阵\\(H\\)， 使用校正之后的状态误差最优估计\\(\\hat{\\delta x}\\)，对状态真值估计进行更新，即\\(\\hat{x_t}=x \\oplus \\hat{\\delta x}\\)。 由于此时的误差状态均值为零(我们尚未观测到)，因此，我们此时只能得到\\(\\hat{x_t}=x\\)，我们可以使用nominal error x作为线性化点，得到雅克比矩阵\\(H\\): 上面给出了协方差更新的最简单的形式:\\(P\\leftarrow (I-KH)P\\)，但是这种形式的数值稳定性很差，因为它的结果不一定是对称的，也不一定是正定的。一般可以使用更稳定的形式，如 the symmetric form: \\(P\\leftarrow P-K(HPH^T+V)K^T\\) the symmetric and positive Joseph form: \\(P\\leftarrow (I-KH)P(I-KH)^T+KVK^T\\) 3.1.1. 计算观测矩阵H 上面的观测矩阵可以用多种方法计算，最常用连式法则: 其中，\\(H_x \\triangleq \\frac{\\partial h}{\\partial x_t}|_x\\)是关于函数h()的分别对其参数的雅克比 第一部分\\(\\frac{\\partial h}{\\partial x_t}|_x\\)由传感器的测量函数决定，这里不具体展开 第二部分\\(X_{\\delta x}\\triangleq \\frac{\\partial x_t}{\\partial \\delta x}|_x\\)是状态真值对于误差状态的雅克比，这部分可以在这里导出，因为它只依赖于状态的ESKF组合，因此，有: 对上面进行分块，简化，得到: 其中，\\(Q_{\\delta \\theta}=\\frac{q\\otimes \\delta q}{\\delta \\delta \\theta}\\)是\\(4\\times 3\\)的矩阵块，使用(式14/15)以及一阶近似(\\(\\delta q \\rightarrow [1 , \\frac{1}{2}\\delta \\theta]^T\\) ， 见下方补充)，那么\\(Q_{\\delta \\theta}\\)可以写成: 补充: 上面的意思是: 当给定旋转向量\\(\\delta \\theta\\)，其四元数为: \\[ \\begin{aligned} \\begin{bmatrix} \\cos(\\frac{\\delta \\theta}{2}) \\\\ I_{3\\times 1}\\sin(\\frac{\\delta \\theta}{2}) \\end{bmatrix} \\end{aligned} \\] 当\\(\\theta\\)很小时，有\\(\\frac{\\delta \\theta}{2}=\\sin(\\frac{\\delta \\theta}{2})\\)和\\(\\cos(\\frac{\\delta \\theta}{2})=1\\) 所以有: \\[ \\begin{aligned} \\delta \\leftarrow \\begin{bmatrix} 1 \\\\ \\frac{1}{2}\\delta \\theta \\end{bmatrix} \\end{aligned} \\] 或者使用泰勒展开，取一阶近似，也是可以得到相同的结果 3.2. 第二步: 注入观测误差到 nominal state 经过ESKF更新校正之后，可以使用校正之后的误差状态\\(\\hat{\\delta x}\\)与nominal state组合，得到状态真值的估计: 3.3. 第三步: ESKF重置 (为什么需要重置？ 你都观测到接近真值了，并且进行了校正，误差状态当然要重置啊) 当所有误差状态注入到nominal state之后，误差状态均值\\(\\hat{\\delta x}\\)需要被重置，尤其是旋转的部分，因为新的旋转姿态误差是相对于新的nominal state的姿态坐标系而言的。 为了ESKF完整更新，误差状态的协方差也需要被更新 下面称误差重置函数为\\(g()\\)，即: 其中，\\(\\ominus\\)表示与\\(\\oplus\\)相反的操作，因此，ESKF重置操作可表示为: 其中，矩阵G为: 与在第一步中的雅克比矩阵类似，这个矩阵对角线上的子块，除了与旋转部分有关，其他都是单位矩阵I 3.3.1. 关于旋转部分子块的推导(略)","categories":[{"name":"四元数的状态误差卡尔曼","slug":"四元数的状态误差卡尔曼","permalink":"http://yoursite.com/categories/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC/"}],"tags":[]},{"title":"Aruco-2-增强型aruco---aruco板","slug":"Marker_SLAM/Aruco-2-增强型aruco-aruco板","date":"2020-03-20T03:13:39.000Z","updated":"2020-03-20T09:46:41.000Z","comments":true,"path":"2020/03/20/Marker_SLAM/Aruco-2-增强型aruco-aruco板/","link":"","permalink":"http://yoursite.com/2020/03/20/Marker_SLAM/Aruco-2-%E5%A2%9E%E5%BC%BA%E5%9E%8Baruco-aruco%E6%9D%BF/","excerpt":"","text":"1. Aruco Board ArUco板是一组marker，在计算相机位姿时，如同对单个marker计算相机位姿一样，但是更加鲁棒。 板不限于这种布置，并且可以表示任何2d或3d布局 ArUco板与一组独立的marker之间的区别在于，板中Marker之间的相对位置是先验的，这样可以将所有Marker的角点用于估计摄像机相对于整个ArUco板的姿态 使用ArUco板的好处是: 姿势估计更加通用，因为只需要一些Marker，所以即使存在遮挡或局部视图，也可以计算出姿势(相对于整个板的) 由于采用了大量的点对应关系（Marker角），因此获得的姿态通常更准确 1.1. 主要的类 123456class Board &#123;public: std::vector&lt;std::vector&lt;cv::Point3f&gt; &gt; objPoints; cv::Ptr&lt;cv::aruco::Dictionary&gt; dictionary; std::vector&lt;int&gt; ids;&#125;; 第一个参数objPoints: 这个板上面的角点在这个板的3D坐标系下的坐标的集合，对于每个marker，它的4个角以标准顺序存储，即顺时针顺序，从左上角开始 第二个参数: 指示棋盘Marker属于哪个marker字典 第三个参数ids: 表明了在objPoints里面每一个marker在字典中的索引 2. Aruco Board 标定相机 2.1. 使用函数calibrateCameraAruco() 无data，暂时没有进行 3. Aruco Board进行相机位姿估计 在进行相机位姿估计之前，同样需要先进行marker的检测detectMarkers() 3.1. estimatePoseBoard()函数 1cv::aruco::estimatePoseBoard(markerCorners, markerIds, board, cameraMatrix, distCoeffs, rvec, tvec); 第一、二个参数markerCorners，markerIds: marker检测得到的角点和id 第三个参数: 上面提到的Board类对象 第四、五个参数: 相机参数cameraMatrix和distCoeffs 最后两个参数: 平移和旋转(相对于整个Aruco板的)，如果作为数据传入，数据不为空的时候，作为初始位姿估计，然后计算，再作为输出 3.2. 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111#include &lt;iostream&gt;#include &lt;eigen3/Eigen/Core&gt;#include &lt;eigen3/Eigen/Dense&gt;#include &lt;opencv2/aruco/charuco.hpp&gt;#include &lt;opencv2/aruco.hpp&gt;#include &lt;opencv2/aruco/dictionary.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/imgproc/types_c.h&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/core/eigen.hpp&gt;#include &lt;opencv2/calib3d.hpp&gt;using namespace std;int main()&#123; // 内参不知道哪个老哥整出来的 double fx, fy, cx, cy, k1, k2, k3, p1, p2; fx = 955.8925; fy = 955.4439; cx = 296.9006; cy = 215.9074; k1 = -0.1523; k2 = 0.7722; k3 = 0; p1 = 0; p2 = 0; // 内参矩阵 cv::Mat cameraMatrix = (cv::Mat_&lt;float&gt;(3, 3) &lt;&lt; fx, 0.0, cx, 0.0, fy, cy, 0.0, 0.0, 1.0); // 畸变矩阵 cv::Mat distCoeffs = (cv::Mat_&lt;float&gt;(5, 1) &lt;&lt; k1, k2, p1, p2, k3); // 字典读取 cv::Ptr&lt;cv::aruco::Dictionary&gt; dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250); // 读取图片 cv::Mat image, imageCopy; image = cv::imread(\"../../../board.png\"); image.copyTo(imageCopy); // board对象指针，在后面有create函数来实际创建 // 下面这些参数需要用来计算相机位姿 cv::Ptr&lt;cv::aruco::GridBoard&gt; board = cv::aruco::GridBoard::create(5, //每行多少个Marker 7, //每列多少个Marker 0.04, //marker长度 0.01, //marker之间的间隔 dictionary); //字典 std::vector&lt;int&gt; ids; std::vector&lt;std::vector&lt;cv::Point2f&gt; &gt; corners; std::vector&lt;std::vector&lt;cv::Point2f&gt; &gt; corners_out; // 检测Marker cv::aruco::detectMarkers(image, dictionary, corners, ids,cv::aruco::DetectorParameters::create(),corners_out); // 显示检测到的但是由于字典对不上被拒绝的Marker if (corners_out.size()&gt;0)&#123; cout&lt;&lt;\"一共有 \"&lt;&lt;corners_out.size()&lt;&lt;\" 个被拒绝的 Marker \"&lt;&lt;endl; for (int idx_rej=0;idx_rej&lt;corners_out.size();idx_rej++) &#123; for (int i=0;i&lt;4;i++) &#123; cv::circle(imageCopy,cv::Point(corners_out[idx_rej][i].x,corners_out[idx_rej][i].y),6,cv::Scalar(0,0,255)); &#125; &#125; &#125; // 显示正确的Marker if (ids.size() &gt; 0) &#123; cout&lt;&lt;\"track thing\"&lt;&lt;endl; // 绘制检测边框 cv::aruco::drawDetectedMarkers(imageCopy, corners, ids); //board-&gt;create(corners,dictionary,ids);// // 估计相机位姿(相对于每一个marker)// std::vector&lt;cv::Vec3d&gt; rvecs, tvecs;// cv::aruco::estimatePoseSingleMarkers(corners, 0.055, cameraMatrix, distCoeffs, rvecs, tvecs); // 估计相机位姿(相对于 aruco 板) cv::Vec3d rvec, tvec; int valid = cv::aruco::estimatePoseBoard(corners, ids, board, cameraMatrix, distCoeffs, rvec, tvec); // draw axis for each marker if(valid) &#123; /// 得到的位姿估计是：从board坐标系到相机坐标系的 cv::Mat R; cv::Rodrigues(rvec,R); cout &lt;&lt; \"R_&#123;camera&lt;---marker&#125; :\" &lt;&lt; R &lt;&lt; endl; cout &lt;&lt; \"t_&#123;camera&lt;---marker&#125; :\" &lt;&lt; tvec &lt;&lt; endl; cout &lt;&lt; endl; cv::aruco::drawAxis(imageCopy, cameraMatrix, distCoeffs, rvec, tvec, 0.1); Eigen::Matrix3d R_eigen; cv::cv2eigen(R,R_eigen); Eigen::Vector3d zyx_Euler_fromR=R_eigen.eulerAngles(0,1,2);//Eigen中使用右乘的顺序,因此ZYX对应的是012,实际上这个编号跟乘法的顺序一致就可以了(从左向又右看的顺序) cout&lt;&lt; \"zyx euler from Rotation \\n[输出顺序为:x,y,z]:\\n\"&lt;&lt;(180)/(M_PI)*zyx_Euler_fromR.transpose()&lt;&lt;endl; &#125; &#125; cv::imshow(\"out\", imageCopy); cv::waitKey(0); return 0;&#125; 运行效果： 这是我个人运行的结果，可能由于图片中的Marker是旧版本的字典，现在已经识别不了了，通过函数返回的reject判断 这是官方自己给出的运行效果 4. Aruco Board 的生成 创建 Aruco Board 对象需要指定环境中每个Marker的角位置。 然而，在许多情况下， Aruco Board 对象只是在同一个平面和网格布局中的一组Marker，所以它可以很容易地打印和使用。 将会使用一个GridBoard类，是继承自 Board 类的一个特殊类，它表示一个在同一个平面中具有所有标记并且在一个网格布局中的 Board。 GridBoard类的坐标系定位在板面上，坐标系原点在板的左下角，z 轴指向外面，如下图所示。轴色对应为 x: 红色 y: 绿色 z: 蓝色 GridBoard类两个函数说明 12345678static Ptr&lt;GridBoard&gt; cv::aruco::GridBoard::create( int markersX, // X方向marker数量，即下图NumberXint markersY, // Y方向marker数量，即下图NumberYfloat markerLength, // marker长度，即下图MarkerLengthfloat markerSeparation, // marker之间的间隔，即下图MarkerSeperationconst Ptr&lt; Dictionary &gt; &amp; dictionary, // 字典int firstMarker = 0 //grid board上第一个marker的ID) 123456void cv::aruco::GridBoard::draw( Size outSize, // 输出图像大小OutputArray img, // 输出图像int marginSize = 0, // 即上图Margin，即最外面的marker与图像边界之间的距离int borderBits = 1 // 即上图BoderBits,代表每个marker边框大小) 4.1. 生成并输出一个Aruco Board 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;eigen3/Eigen/Core&gt;#include &lt;eigen3/Eigen/Dense&gt;#include &lt;opencv2/aruco/charuco.hpp&gt;#include &lt;opencv2/aruco.hpp&gt;#include &lt;opencv2/aruco/dictionary.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/imgproc/types_c.h&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/core/eigen.hpp&gt;#include &lt;opencv2/calib3d.hpp&gt;using namespace std;int main()&#123; int markersX = 5; //X轴上标记的数量 int markersY = 7; //Y轴上标记的数量 本例生成5x5的棋盘 int markerLength = 100; //标记的长度，单位是像素 int markerSeparation = 20; //每个标记之间的间隔，单位像素 int dictionaryId = cv::aruco::DICT_6X6_250;//生成标记的字典ID int margins = markerSeparation;//标记与边界之间的间隔 int borderBits = 1; //标记的边界所占的bit位数 int firstMarker= 0; //板的第一个Marker id (后面的直接按顺序生成) bool showImage = true; // 计算输出图像大小 cv::Size imageSize; imageSize.width = markersX * (markerLength + markerSeparation) - markerSeparation + 2 * margins; imageSize.height = markersY * (markerLength + markerSeparation) - markerSeparation + 2 * margins; cv::Ptr&lt;cv::aruco::Dictionary&gt; dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::PREDEFINED_DICTIONARY_NAME(dictionaryId)); cv::Ptr&lt;cv::aruco::GridBoard&gt; board = cv::aruco::GridBoard::create(markersX, markersY, float(markerLength), float(markerSeparation), dictionary, firstMarker); // show created board cv::Mat boardImage; board-&gt;draw(imageSize, boardImage, margins, borderBits); if (showImage) &#123; imshow(\"board\", boardImage); cv::waitKey(0); &#125; // save return 0;&#125; 运行效果","categories":[{"name":"Marker_SLAM","slug":"Marker-SLAM","permalink":"http://yoursite.com/categories/Marker-SLAM/"}],"tags":[]},{"title":"Aruco-1-基本介绍","slug":"Marker_SLAM/Aruco-1-基本介绍","date":"2020-03-20T01:02:57.000Z","updated":"2020-03-20T07:45:29.000Z","comments":true,"path":"2020/03/20/Marker_SLAM/Aruco-1-基本介绍/","link":"","permalink":"http://yoursite.com/2020/03/20/Marker_SLAM/Aruco-1-%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"1. Aruco Aruco是一个开源的相机姿态估计库，已经嵌入到Opencv的Contribute包中。 简单来说，这是类似于二维码的Marker，长这样: 结构: 黑色的邊界有利於快速檢測到圖像，同时，黑色边界的旁边需要有白色的space(用于检测) 二進制編碼可以驗證id，並且允許錯誤檢測和矯正技術的應用。 marker的大小決定了內部矩陣的大小。例如，一個4x4的marker由16bits組成 功能： 检测这些Marker 标定相机参数 相机位姿估计(Oroku用于计算相机相对于某个Marker的位姿，Haruko用于多相机的定位) 1.1. 字典 markers的字典是在一個特殊應用中使用到的marker的集合 字典的大小就是组成字典所用到的Marker的数量 marker的大小就是这些Marker的尺寸(bits) 2. Marker的创建 3. Marker的检测 输入一张有Marker的图像，检测所有Marker，并返回Marker信息： Marker的四个角点 Marker的ID 检测过程主要分为两步 预检测Marker 根据内部编码筛选是否Marker 下面是需要检测Marker的图片 3.1. 检测的函数cv::aruco::detectMarkers及参数 1234567cv::Mat inputImage;...std::vector&lt;int&gt; markerIds;std::vector&lt;std::vector&lt;cv::Point2f&gt;&gt; markerCorners, rejectedCandidates;cv::Ptr&lt;cv::aruco::DetectorParameters&gt; parameters = cv::aruco::DetectorParameters::create();cv::Ptr&lt;cv::aruco::Dictionary&gt; dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250);cv::aruco::detectMarkers(inputImage, dictionary, markerCorners, markerIds, parameters, rejectedCandidates); 第一个参数是将要检测Marker的图像 第二个参数是字典对象，在这种情况下是一个预定义的字典（ DICT_6X6_250 ） 检测到的Marker存储在markerCorners和markerIds结构中 markerCorners是检测到的Marker的角点列表。 对于每个Marker，其四个角以其原始顺序返回（从左上角开始顺时针）。 因此，第一个角是左上角，然后是右上角，右下角和左下角 markerIds是markerIds中每个检测到的Marker的id列表。 请注意，返回的markerCorners和markerIds向量具有相同的大小 第四个参数是DetectionParameters类型的对象。 此对象包括可在检测过程中自定义的所有参数 最终参数rejectedCandidates是一个返回的Marker候选列表，即已找到的那些方格，但它们不提供有效的编码。 每个候选者也由其四个角定义，其格式与markerCorners参数相同。 此参数可以省略 3.2. 代码 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;opencv2/aruco/charuco.hpp&gt;#include &lt;opencv2/aruco.hpp&gt;#include &lt;opencv2/aruco/dictionary.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/imgproc/types_c.h&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;using namespace std;int main()&#123; cv::Ptr&lt;cv::aruco::Dictionary&gt; dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250); cv::Mat img=cv::imread(\"../../../marker.jpg\"); cv::Mat imageCopy; img.copyTo(imageCopy); std::vector&lt;int&gt; ids; std::vector&lt;std::vector&lt;cv::Point2f&gt; &gt; corners; cv::aruco::detectMarkers(img, dictionary, corners, ids); // if at least one marker detected if (ids.size() &gt; 0) cv::aruco::drawDetectedMarkers(imageCopy, corners, ids); cv::imshow(\"out\", imageCopy); cv::waitKey(0); return 0;&#125; 检测结果 4. 位姿估计 在检测到这些Marker之后，下一件你可能要做的事情就是从它们那里获得相机的姿势。 为了进行摄像机的姿态估计，你需要知道你的摄像机的校准参数。 这些是相机矩阵和畸变系数。 如果您不知道如何校准您的相机，您可以查看 calibrateCamera ()函数和 OpenCV 的校准教程。 您还可以使用 ArUco 模块校准相机，如 ArUco 和 ChArUco。 最后，校准后得到的是相机矩阵\\(K\\): 一个由3x3元素组成的矩阵，其中包括焦距和相机中心坐标(又称内参数) ，以及畸变系数: 一个由5个或更多元素组成的矢量，用于模拟相机产生的畸变 当你用 ArUco Marker估计姿势时，你可以单独估计每个Marker的姿势。 如果你想从一组Marker中估计一个姿势，使用 ArUco Boards (参见 ArUco Boards 的检测教程)。 使用 ArUco 板代替单一Marker允许一些Marker被遮挡。 4.1. 原理 相机的姿势是指从Marker坐标系到相机坐标系的3d转换。它是通过旋转和平移向量指定的(主要使用solvePnP()函数)。 4.2. 核心函数cv::aruco::estimatePoseSingleMarkers() 1234cv::Mat cameraMatrix, distCoeffs;...std::vector&lt;cv::Vec3d&gt; rvecs, tvecs;cv::aruco::estimatePoseSingleMarkers(markerCorners, 0.05, cameraMatrix, distCoeffs, rvecs, tvecs); 第一个参数markerCorners是由detectMarkers()函数返回的marker的4个角点的坐标vector 第二个参数是marker的尺寸，单位是米或其他，估计出来的姿态的平移量将会与这个尺度保持一致，如果size使用(米)，那么估计出来的平移量也是(米) 第三个参数是相机的内参矩阵 第四个参数是相机的畸变参数 rvecs,tvecs是输出的位姿估计(旋转量，平移量)，需要注意的是，旋转量是轴角表示的旋转，需要使用罗德里格斯公式转换为旋转矩阵R 这个函数所假定的Marker坐标系原点是Marker的中心，z 轴指向外面，如下图所示。轴色对应为 x: 红色 y: 绿色 z: 蓝色 模块提供了一个绘制轴的功能，如上图所示，因此可以检查位姿估计，可视化代码如下: 123456inputImage.copyTo(outputImage);for (int i = 0; i &lt; rvecs.size(); ++i) &#123; auto rvec = rvecs[i]; auto tvec = tvecs[i]; cv::aruco::drawAxis(outputImage, cameraMatrix, distCoeffs, rvec, tvec, 0.1);&#125; 函数的最后一个参数: (这里填了0.1) 指的是绘制的坐标轴的长度，与上面位姿估计的尺度保持一致 4.3. 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include &lt;iostream&gt;#include &lt;eigen3/Eigen/Core&gt;#include &lt;eigen3/Eigen/Dense&gt;#include &lt;opencv2/aruco/charuco.hpp&gt;#include &lt;opencv2/aruco.hpp&gt;#include &lt;opencv2/aruco/dictionary.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/imgproc/types_c.h&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/core/eigen.hpp&gt;#include &lt;opencv2/calib3d.hpp&gt;using namespace std;int main()&#123; // 内参不知道哪个老哥整出来的 double fx, fy, cx, cy, k1, k2, k3, p1, p2; fx = 955.8925; fy = 955.4439; cx = 296.9006; cy = 215.9074; k1 = -0.1523; k2 = 0.7722; k3 = 0; p1 = 0; p2 = 0; // 内参矩阵 cv::Mat cameraMatrix = (cv::Mat_&lt;float&gt;(3, 3) &lt;&lt; fx, 0.0, cx, 0.0, fy, cy, 0.0, 0.0, 1.0); // 畸变矩阵 cv::Mat distCoeffs = (cv::Mat_&lt;float&gt;(5, 1) &lt;&lt; k1, k2, p1, p2, k3); // 字典读取 cv::Ptr&lt;cv::aruco::Dictionary&gt; dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250); cv::Mat image, imageCopy; image = cv::imread(\"../../../marker.jpg\"); image.copyTo(imageCopy); vector&lt;int&gt; ids; vector&lt;vector&lt;cv::Point2f&gt;&gt; corners; // 检测Marker cv::aruco::detectMarkers(image, dictionary, corners, ids); if (ids.size() &gt; 0) &#123; // 绘制检测边框 //cv::aruco::drawDetectedMarkers(imageCopy, corners, ids); // 估计相机位姿(相对于每一个marker) std::vector&lt;cv::Vec3d&gt; rvecs, tvecs; cv::aruco::estimatePoseSingleMarkers(corners, 0.055, cameraMatrix, distCoeffs, rvecs, tvecs); // draw axis for each marker for (int i = 0; i &lt; ids.size(); i++) &#123; if(ids[i]!=23) continue; /// 得到的位姿估计是：从Marker坐标系到相机坐标系的 cv::Mat R; cv::Rodrigues(rvecs[i],R); cout &lt;&lt; \"ID :\" &lt;&lt; ids[i] &lt;&lt; endl; cout &lt;&lt; \"R_&#123;camera&lt;---marker&#125; :\" &lt;&lt; R &lt;&lt; endl; cout &lt;&lt; \"t_&#123;camera&lt;---marker&#125; :\" &lt;&lt; tvecs[i] &lt;&lt; endl; cout &lt;&lt; endl; cv::aruco::drawAxis(imageCopy, cameraMatrix, distCoeffs, rvecs[i], tvecs[i], 0.1); Eigen::Matrix3d R_eigen; cv::cv2eigen(R,R_eigen); Eigen::Vector3d zyx_Euler_fromR=R_eigen.eulerAngles(0,1,2);//Eigen中使用右乘的顺序,因此ZYX对应的是012,实际上这个编号跟乘法的顺序一致就可以了(从左向又右看的顺序) cout&lt;&lt; \"zyx euler from Rotation \\n[输出顺序为:x,y,z]:\\n\"&lt;&lt;(180)/(M_PI)*zyx_Euler_fromR.transpose()&lt;&lt;endl; &#125; &#125; cv::imshow(\"out\", imageCopy); cv::waitKey(0); return 0;&#125; 实际运行效果 5. 流程","categories":[{"name":"Marker_SLAM","slug":"Marker-SLAM","permalink":"http://yoursite.com/categories/Marker-SLAM/"}],"tags":[]},{"title":"强化学习-基础","slug":"深度学习/强化学习-基础","date":"2020-03-19T14:41:15.000Z","updated":"2020-03-20T00:53:50.000Z","comments":true,"path":"2020/03/19/深度学习/强化学习-基础/","link":"","permalink":"http://yoursite.com/2020/03/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%9F%BA%E7%A1%80/","excerpt":"","text":"value-base 期望的计算 如果agent的策略\\(\\pi\\)是确定的(即在给定状态下，agent只会执行一个策略)，那么方程是: 如果agent的策略\\(\\pi\\)是概率的(即，给定状态s，agent选择动作a的概率是\\(\\pi(a|s)\\))，那么方程是: 最优策略的定义 两种value计算 区别","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"DSO-1-系统框架与初始化","slug":"SLAM代码课程/DSO/DSO-1-系统框架与初始化","date":"2020-03-16T06:42:47.000Z","updated":"2020-03-19T12:57:10.000Z","comments":true,"path":"2020/03/16/SLAM代码课程/DSO/DSO-1-系统框架与初始化/","link":"","permalink":"http://yoursite.com/2020/03/16/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/DSO-1-%E7%B3%BB%E7%BB%9F%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96/","excerpt":"","text":"1. DSO-1-系统框架与初始化 2. 直接&amp;稀疏 非直接法: ORB_SLAM2 直接法: DSO 3. 相机几何模型与光度模型&amp;雅克比推导 DSO中的几种畸变模型: FOV: (\\(f_x,f_y,c_x,c_y,\\omega\\) 一共5个参数) RadTan: 考虑径向和切向两种畸变(视觉SLAM14讲第二版P102) KB: \\(f_x,f_y,c_x,c_y,k_1,k_2,k_3,k_4\\) 一共8个参数 3.1. 计算去畸变后的新内参 (1)已知相机内参和畸变模型, 给定一个超大范围的归一化平面[x_min-&gt;x_max],[y_min-&gt;y_max], 遍历这个归一化平面上的点 遍历归一化平面上的点，将每个点应用畸变模型+相机模型，得到畸变的像素点(也就是相机输出图像上的点) 不断裁剪这个超大范围的归一化平面，直到这个归一化平面[x_min-&gt;x_max],[y_min-&gt;y_max]的边界范围内所有(任意)点所对应的畸变像素点都在畸变图像(相机输出图像)的范围内 (2)取归一化平面上的边界，4个点(\\(X_{min},X_{max},Y_{min},Y_{max}\\)组合得到)，即可计算出新的(无畸变的)相机内参 (虽然新的参数还不知道，但是这里这是先用符号表示) \\[ \\left \\{ \\begin{aligned} u_{min}=f_x&#39; X_{min}+c_x&#39; \\\\ u_{max}=f_x&#39; X_{max}+c_x&#39; \\end{aligned} \\Longrightarrow \\underbrace{u_{max}-u_{min}}_{known}=f_x&#39; \\underbrace{(X_{max}-X_{min})}_{known} \\right . \\] 因此，可得 \\[ f_x&#39;=\\frac{u_{max}-u_{min}}{X_{max}-X_{min}} \\] 令\\(u_{min}=0\\)，代入\\(u_{min}=f_x&#39; X_{min}+c_x&#39;\\)，可得 \\[ c_x&#39;= - f_x&#39; X_{min} \\] (3)对于y方向的新内参，同理 根据这些新的(无畸变的)相机内参,如何从畸变图像得到无畸变图像? 畸变图像-----&gt;旧相机内参------&gt;归一化平面 归一化平面----&gt;新相机内参------&gt;无畸变图像 3.2. 光度模型 3.2.1. 辐射(与方向有关)，\\(B_i(x)\\) 辐射率(Radiance)是指一个表面在单位立体角和单位投影面积上所发射、反射、透射或接收的辐射通量 3.2.2. 辐照(与方向无关)，IR(x) 在辐射测量学中，辐照度是指一个表面单位面积所接受的辐射通量(功率)，和方向无关。比如，用来描述传感器像元的入射光强（来自于不同方向的环境光的累加）。 3.2.3. 渐晕，V(x) 光学晕影是由一个或多个透镜的实际尺寸造成的，后方的元件遮蔽了前方的，导致前端透镜离轴的有效入射光减少，结果是光的强度由图像中心向周围逐渐减弱。 也就是说，假如拍摄一个亮度非常均匀的物体，图像中心和边缘的亮度值并不一致。 3.2.4. 三者关系 \\[ IR(x)=V(x)B_i(x) \\] 3.2.5. 快门 快门影响的是曝光时间。自动曝光模式下，不同场景曝光时间并不一样，会导致同一物体在不同场景下的灰度值产生差异。另外还想提到的是全局快门（global shutter）和卷帘快门（rolling shutter）。 全局快门保证所有感光元件的曝光起始时间和间隔是一样的 卷帘快门并不能保证。 因此文献中一般推荐使用全局快门。 3.2.6. 响应函数 传感器（CCD/CMOS）将每个像元接收到的光子通过一系列处理转化为亮度值。这里面涉及到光电效应、ADC、DSP等过程。输入的曝光量和输出的亮度值之间的关系称为响应函数（response function）。 响应函数一般来说是非线性的，甚至包含人为调整的成分，比如伽马校正、白平衡、色调、饱和度等。 为图像进行伽马编码的目的是用来对人类视觉的特性进行补偿，从而根据人类对光线或者黑白的感知，最大化地利用表示黑白的数据位或带宽。人眼对暗部比较敏感，因此一般选择提高暗部的分辨率。这些因素会非线性地修正曝光量，因此作者希望通过光度标定来补偿它们的影响。 3.2.7. 光度模型 结合了曝光时间和响应函数[映射到0-255]，(在光照时间ti内对辐照积分，再传入响应函数) \\[ I_i(x)=G(t_i IR(x))=G(t_i V(x)B_i(x)) \\] 这里的I_i(x)可否理解为就是图像上的强度? 3.2.8. 光度矫正 3.2.8.1. 方法一: 标定响应函数G() 标定晕影V(x) 通过标定V和G，可以反求出辐射B，(使用B去做直接法当然要比I准确地多。当然，场景的亮度在不同视角下有差异，这是无法避免的) \\[ I_i&#39;(x)= t_i B_i(x) = \\frac{G^{-1}(I_i(x))}{V(x)} \\] 上面得到的\\(I_i&#39;(x)\\)就是经过矫正之后的光度，仅包含曝光时间和辐射，其中曝光时间在每一帧可能都不一样，因此不是常数。 3.2.8.2. 方法二: 对于做过光度标定的相机，我们可以用上面的方法一处理，对于一般的相机呢？ 通常采用下面的光度仿射变换进行矫正 \\[ I_i&#39;(x)=e^{-\\alpha_i}(I_i(x)-b_i) \\] 总结如下： 光度模型对于直接法来说是十分重要的，因为直接法是基于光度不变性的假设 3.3. 光度误差模型 上面能量函数中: \\(I[p_j] ...\\)指的是经过矫正之后的光度 图像梯度加权：对于边缘处非连续的点，一旦发生移动，那么其光度变化会很大，因此如果引入了外点，会造成明显的影响，因此对于梯度较大的点，那么其权重一般较小。 假设世界坐标系中有某点P，其对于两帧图像上的点为\\(x_i,x_j\\)，有 第i帧归一化平面上的点\\(P_i&#39;\\) \\[ P_i&#39;=\\pi_c^{-1}(p_i)=K^{-1} \\begin{pmatrix} x_i \\\\ 1 \\end{pmatrix} \\] 其中，第i帧相机坐标系上的点\\(P_i=\\frac{P_i&#39;}{d_{pi}}\\) , \\(d_{pi}=\\frac{1}{Z_i}\\)为逆深度 第j帧相机坐标系上的点\\(P_j\\) \\[ P_j=R P_i + t= R\\frac{P_i&#39;}{d_{pi}}+t \\] 对上式两边同时乘以第i帧点\\(P_i\\)的逆深度，得到一个(齐次点)虚拟点\\(P_j^{virtual}\\) \\[ \\begin{aligned} P_j d_{pi} &amp;= R P_i&#39; + t d_{pi} \\\\ P_j^{virtual} &amp;= R P_i&#39; + t d_{pi} \\end{aligned} \\] 那么，第i帧相机坐标系点\\(P_i\\)转换到第j帧相机坐标系的点\\(P_j\\)可以如下表示: \\[ P_j=\\frac{P_j^{virtual}}{d_{pi}} \\] \\[ \\Longrightarrow P_j[2]=\\frac{P_j^{virtual}[2]}{d_{pi}} \\] 最终，第j帧相机坐标系点\\(P_j\\)投影到图像上的点\\(x_j\\)可表示为: \\[ \\begin{aligned} \\begin{pmatrix} x_j \\\\ 1 \\end{pmatrix} =\\pi_c(P_j&#39;) &amp;= \\pi_c(\\frac{P_j}{P_j[2]}) \\\\ &amp;= \\pi_c(\\frac{P_j^{virtual}}{d_{pi} \\cdot P_j[2]}) \\\\ &amp;= \\pi_c(\\frac{P_j d_{pi}}{P_j^{virtual}[2]}) \\end{aligned} \\] 上式子的\\(\\frac{d_{pi}}{P_j^{virtual}[2]}\\)对应DSO代码中ResidualProjections.h文件的new_idepth = idepth*drescale;这一句。 123456789101112131415161718192021222324252627282930EIGEN_STRONG_INLINE bool projectPoint( const float &amp;u_pt,const float &amp;v_pt, const float &amp;idepth, const int &amp;dx, const int &amp;dy, CalibHessian* const &amp;HCalib, const Mat33f &amp;R, const Vec3f &amp;t, float &amp;drescale, float &amp;u, float &amp;v, float &amp;Ku, float &amp;Kv, Vec3f &amp;KliP, float &amp;new_idepth)&#123; // host上归一化平面点 KliP = Vec3f( (u_pt+dx-HCalib-&gt;cxl())*HCalib-&gt;fxli(), (v_pt+dy-HCalib-&gt;cyl())*HCalib-&gt;fyli(), 1); Vec3f ptp = R * KliP + t*idepth; //这就是虚拟点P_j^&#123;virtual&#125; drescale = 1.0f/ptp[2]; new_idepth = idepth*drescale; // 对应这句 if(!(drescale&gt;0)) return false; // 将虚拟点P_j^&#123;virtual&#125;转到归一化平面上 u = ptp[0] * drescale; v = ptp[1] * drescale; // 像素平面 Ku = u*HCalib-&gt;fxl() + HCalib-&gt;cxl(); Kv = v*HCalib-&gt;fyl() + HCalib-&gt;cyl(); return Ku&gt;1.1f &amp;&amp; Kv&gt;1.1f &amp;&amp; Ku&lt;wM3G &amp;&amp; Kv&lt;hM3G;&#125; 3.4. 关于(齐次点)虚拟点\\(P_j^{virtual}\\)的意义 到这里，是时候讨论\\(P_j^{virtual}\\)的内在意义了: 已知将点Pi从第i帧相机坐标系转换到第j帧相机坐标系的坐标q如下: \\[ q=P_j=R P_i + t= R\\frac{P_i&#39;}{d_{pi}}+t \\] 对q转换到归一化平面上，即得到\\(P_j&#39;\\) \\[ \\begin{aligned} P_j&#39;= \\begin{bmatrix} \\frac{P_j[0]}{P_j[2]} \\\\ \\frac{P_j[1]}{P_j[2]} \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} \\frac{q[0]}{q[2]} \\\\ \\frac{q[1]}{q[2]} \\\\ 1 \\end{bmatrix} \\end{aligned} \\] 同时，有虚拟点\\(P_j^{virtual}\\) , (\\(P_i&#39;\\)为点\\(P_i\\)的归一化平面点) \\[ P_j^{virtual}= d_{pi} P_j = R P_i&#39; + t d_{pi} \\] 对虚拟点\\(P_j^{virtual}\\)也转换到归一化平面上 \\[ \\begin{aligned} P_j^{virtual-normal}= \\begin{bmatrix} \\frac{d_{pi} P_j[0]}{d_{pi} P_j[2]} \\\\ \\frac{d_{pi} P_j[1]}{d_{pi} P_j[2]} \\\\ 1 \\end{bmatrix}= \\begin{bmatrix} \\frac{P_j[0]}{P_j[2]} \\\\ \\frac{P_j[1]}{P_j[2]} \\\\ 1 \\end{bmatrix} \\end{aligned} \\] (4)可以看到，归一化之后的虚拟点\\(P_j^{virtual-normal}\\)与归一化之后的真实点\\(P_j&#39;\\)是等价的。 DSO作者采用(齐次点)\\(P_j^{virtual}\\)的目的是希望可以简化下面的雅克比求导过程。 3.5. 雅克比 3.5.1. 损失函数(残差) 上面的残差怎么来的，其实原式如下： \\[ \\begin{aligned} E_{pj}=\\sum_{p_i \\in \\mathcal{N}_p} w_p || \\frac{1}{t_j \\exp^{\\alpha_j}}(I_j[p_j]-b_j)-\\frac{1}{t_i \\exp^{\\alpha_i}}(I_j[p_i]-b_i)||_r \\end{aligned} \\] 其中，\\(t_k\\)是光度矫正，\\(\\exp^{\\alpha}\\)是光度仿射变换 3.5.2. 对光度参数\\(a_{ji},b_{ji}\\)求导 3.5.3. 对相对位姿求导，即\\(\\frac{\\partial e}{\\partial \\delta \\xi}\\) 这个图的雅克比计算是基于DSO作者所使用的(齐次点)\\(P_j^{virtual}\\)进行的，可以简化的雅克比求导过程。 下面给出先使用正常思路进行推导雅克比，在最后证明两种方法的推导结果是一致的: 对于求相对位姿的雅克比，可以对残差作一些简化： \\[ \\begin{aligned} r_k &amp;= \\frac{1}{t_j \\exp^{\\alpha_j}}(I_j[p_j]-b_j)-\\frac{1}{t_i \\exp^{\\alpha_i}}(I_i[p_i]-b_i) \\\\ &amp; \\Longrightarrow r_k = I_j[p_j]-I_i[p_i] \\\\ &amp; \\Longrightarrow r_k = I_1[u]-I_2[p_i] \\end{aligned} \\] 其中, q为第i帧相机坐标系点\\(P_i\\)转换到第j帧相机坐标系的点，u为对应的图像平面点 \\[ \\begin{aligned} q=P_j=TP_i \\\\ u=x_j=\\frac{1}{q[2]} K q \\end{aligned} \\] 现在，回到一个问题： 问什么需要求雅克比？ 目标：最小化损失函数\\(r_k\\)，需要优化的参数有: 光度参数\\(a_{ji},b_{ji}\\) 从第i帧到第j帧的变换(\\(T_{j\\leftarrow i}\\)) 第i帧的3D点的位置(或者说第i帧3D点的逆深度\\(d_{pi}\\)) 推导开始: (1)考虑高斯牛顿法,对损失函数原函数进行泰勒一阶展开 \\[ f(x+\\Delta x)=f(x)+J^T(x)\\Delta x \\] 即, 把\\(\\Delta x\\)看做是姿态的扰动量\\(\\delta \\xi\\), 得到: \\[ \\begin{aligned} e(\\xi \\oplus \\delta \\xi) &amp;= I_1(\\frac{1}{Z_j}K \\exp(\\delta \\xi ^\\wedge)\\exp(\\xi^\\wedge)P_i)-I_2(\\frac{1}{Z_i}KP_i) \\\\ &amp;= I_1(\\frac{1}{Z_j}K (1+\\delta \\xi ^\\wedge)\\exp(\\xi^\\wedge)P_i)-I_2(\\frac{1}{Z_i}KP_i) \\\\ &amp;= I_1(\\frac{1}{Z_j}K \\exp(\\xi^\\wedge)P_i+ \\underbrace{\\frac{1}{Z_j}K(\\delta \\xi ^\\wedge)\\exp(\\xi^\\wedge)P_i}_{u})-I_2(\\frac{1}{Z_i}KP_i) \\end{aligned} \\] 对上式在\\(\\delta \\xi \\approx 0\\)处进行泰勒一阶展开，可以得到 \\[ \\begin{aligned} e(\\xi \\oplus \\delta \\xi) &amp;= I_1(\\frac{1}{Z_j}K \\exp(\\xi^\\wedge)P_i+ \\underbrace{\\frac{1}{Z_j}K(\\delta \\xi ^\\wedge)\\exp(\\xi^\\wedge)P_i}_{u})-I_2(\\frac{1}{Z_i}KP_i) \\\\ &amp;\\approx I_1(\\frac{1}{Z_j}K \\exp(\\xi^\\wedge)P_i)+\\frac{\\partial I_1(\\frac{1}{Z_j}K \\exp(\\xi^\\wedge)P_i+ \\frac{1}{Z_j}K(\\delta \\xi ^\\wedge)\\exp(\\xi^\\wedge)P_i)}{\\partial \\delta \\xi} \\delta \\xi -I_2(\\frac{1}{Z_i}KP_i) \\\\ &amp;= I_1[u]+J^T\\delta \\xi-I_2[p_i] \\end{aligned} \\] 其中，J为雅克比，实际上就是\\(I_1(u)\\)对位姿量的偏导 (2)\\(I_1(u)\\)对位姿量的偏导 \\[ \\begin{aligned} J^T=\\frac{\\partial e}{\\partial T}=\\frac{\\partial I_1(u)}{\\partial \\delta \\xi} &amp;=\\frac{\\partial I_1}{\\partial u} \\frac{\\partial u}{\\partial q} \\frac{\\partial q}{\\partial \\delta \\xi} \\end{aligned} \\] 其中， \\(\\frac{\\partial I_1}{\\partial u}\\)为在点u处的图像像素梯度 \\[ \\frac{\\partial I_1}{\\partial u}=\\frac{\\partial I_1}{\\partial x_j}= \\begin{pmatrix} \\frac{\\partial I_j}{\\partial u_j } &amp; \\frac{\\partial I_j}{\\partial v_j} \\end{pmatrix} =(d_x,d_y) \\] \\(\\frac{\\partial u}{\\partial q}\\)为相机投影方程关于相机坐标系下的三维点\\(q\\)的导数 (点\\(q=[X,Y,Z]^T=(q[0],q[1],q[2])^T\\)为第i帧相机坐标系点\\(P_i\\)转换到第j帧相机坐标系的点) \\[ \\frac{\\partial u}{\\partial q}= \\begin{bmatrix} \\frac{\\partial u}{\\partial X} &amp; \\frac{\\partial u}{\\partial Y} &amp; \\frac{\\partial u}{\\partial Z} \\\\ \\frac{\\partial v}{\\partial X} &amp; \\frac{\\partial v}{\\partial Y} &amp; \\frac{\\partial v}{\\partial Z} \\end{bmatrix} = \\begin{bmatrix} \\frac{f_x}{Z} &amp; 0 &amp; -\\frac{f_x X}{Z^2} \\\\ 0 &amp; \\frac{f_y}{Z} &amp; -\\frac{f_y Y}{Z^2} \\end{bmatrix} \\] \\(\\frac{\\partial q}{\\partial \\delta \\xi}\\)为变换之后的点对位姿变换的导数，即SE3上的李代数求导: \\[ \\begin{aligned} \\frac{\\partial q}{\\partial \\delta \\xi} &amp;= \\begin{bmatrix} I &amp; -q^\\wedge \\end{bmatrix}_{3\\times6} \\\\ &amp;= \\begin{bmatrix} \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp;1 \\end{bmatrix} \\begin{bmatrix} 0 &amp; q[2] &amp; -q[1] \\\\ -q[2] &amp; 0 &amp; q[0] \\\\ q[1] &amp; -q[0] &amp; 0 \\end{bmatrix} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp;1 \\end{bmatrix} \\begin{bmatrix} 0 &amp; Z &amp; -Y \\\\ -Z &amp; 0 &amp; X \\\\ Y &amp; -X &amp; 0 \\end{bmatrix} \\end{bmatrix} \\end{aligned} \\] 一般情况下，可以把\\(\\frac{\\partial u}{\\partial q}\\frac{\\partial q}{\\partial \\delta \\xi}\\)合起来，得到 \\[ \\begin{aligned} \\frac{\\partial u}{\\partial \\delta \\xi} = \\begin{bmatrix} \\frac{f_x}{Z} &amp; 0 &amp; -\\frac{f_x X}{Z^2} &amp; -\\frac{f_x X Y}{Z^2} &amp; f_x+\\frac{f_x X^2}{Z^2} &amp; -\\frac{f_x Y}{Z} \\\\ 0 &amp; \\frac{f_y}{Z} &amp; -\\frac{f_y Y}{Z^2} &amp; -f_y - \\frac{f_y Y^2}{Z^2} &amp; \\frac{f_y X Y}{Z^2} &amp; \\frac{f_y X}{Z} \\end{bmatrix} \\end{aligned} \\] 如果使用虚拟点进行计算(DSO)，那么，第i帧相机坐标系点\\(P_i\\)转换到第j帧相机坐标系的点\\(P_j\\)可以如下表示: \\[ q=P_j=\\frac{P_j^{virtual}}{d_{pi}} \\] \\[ \\Longrightarrow \\left \\{ \\begin{aligned} X=P_j[0]=\\frac{P_j^{virtual}[0]}{d_{pi}} \\\\ Y=P_j[1]=\\frac{P_j^{virtual}[1]}{d_{pi}} \\\\ Z=P_j[2]=\\frac{P_j^{virtual}[2]}{d_{pi}} \\end{aligned} \\right. \\] 使用上式对\\(\\frac{\\partial u}{\\partial q}\\frac{\\partial q}{\\partial \\delta \\xi}\\)进行替换，得到： \\[ \\begin{aligned} \\frac{\\partial u}{\\partial \\delta \\xi} = \\begin{bmatrix} \\frac{f_x d_{pi}}{P_j^{virtual}[2]} &amp; 0 &amp; -\\frac{f_x P_j^{virtual}[0] d_{pi} }{P_j^{virtual}[2]^2} &amp; -\\frac{f_x P_j^{virtual}[0] P_j^{virtual}[1]}{P_j^{virtual}[2]^2} &amp; f_x+\\frac{f_x P_j^{virtual}[0]^2}{P_j^{virtual}[2]^2} &amp; -\\frac{f_x P_j^{virtual}[1]}{P_j^{virtual}[2]} \\\\ 0 &amp; \\frac{f_y d_{pi}}{P_j^{virtual}[2]} &amp; -\\frac{f_y P_j^{virtual}[1] d_{pi}}{P_j^{virtual}[2]^2} &amp;-f_y - \\frac{f_y P_j^{virtual}[1]^2}{P_j^{virtual}[2]^2} &amp; \\frac{f_y P_j^{virtual}[0] P_j^{virtual}[1]}{P_j^{virtual}[2]^2} &amp; \\frac{f_y P_j^{virtual}[0]}{P_j^{virtual}[2]} \\end{bmatrix} \\end{aligned} \\] 于是，最终得到误差e对位姿(李代数)的雅克比 \\[ J^T=\\frac{\\partial I_1}{\\partial u} \\frac{\\partial u}{\\partial \\delta \\xi} \\] 3.5.4. 对逆深度求导 与前文保持一致： \\[ P_j=R P_i + t= R\\frac{P_i&#39;}{d_{pi}}+t \\] \\[ P_j^{virtual}= d_{pi} P_j = R P_i&#39; + t d_{pi} \\] \\[ \\Longrightarrow P_j=\\frac{P_j^{virtual}}{d_{pi}} \\] 根据上面的$ q=P_j=$，残差对逆深度的导数如下: \\[ \\begin{aligned} \\frac{\\partial e}{\\partial \\delta d_{pi}} = \\frac{\\partial I_1}{\\partial u} \\frac{\\partial u}{\\partial q} \\frac{\\partial q}{\\partial d_{pi}} \\end{aligned} \\] 其中，\\(P_j^{virtual} = R P_i&#39; + t d_{pi}\\)也是关于\\(d_{pi}\\)的函数，根据分数求导公式，可得\\(\\frac{\\partial q}{\\partial d_{pi}}\\) \\[ \\frac{\\partial q}{\\partial d_{pi}}=\\frac{t d_{pi}-P_j^{virtual}}{d_{pi}^2} \\] 其中，t为从第i帧相机坐标系到第j帧相机坐标系变换的平移量 在这里，残差对逆深度的导数为: \\[ \\begin{aligned} \\frac{\\partial e}{\\partial \\delta d_{pi}} &amp;= \\frac{\\partial I_1}{\\partial u} \\frac{\\partial u}{\\partial q} \\frac{\\partial q}{\\partial d_{pi}} \\\\ &amp;= \\frac{\\partial I_1}{\\partial u} \\begin{bmatrix} \\frac{f_x}{Z} &amp; 0 &amp; -\\frac{f_x X}{Z^2} \\\\ 0 &amp; \\frac{f_y}{Z} &amp; -\\frac{f_y Y}{Z^2} \\end{bmatrix} (\\frac{t d_{pi}-P_j^{virtual}}{d_{pi}^2}) \\\\ &amp;= \\frac{\\partial I_1}{\\partial u} \\begin{bmatrix} \\frac{f_x d_{pi}}{P_j^{virtual}[2]} &amp; 0 &amp; -\\frac{f_x P_j^{virtual}[0] d_{pi}}{P_j^{virtual}[2]^2} \\\\ 0 &amp; \\frac{f_y d_{pi}}{P_j^{virtual}[2]} &amp; -\\frac{f_y P_j^{virtual}[1] d_{pi}}{P_j^{virtual}[2]^2} \\end{bmatrix} (\\frac{t d_{pi}-P_j^{virtual}}{d_{pi}^2}) \\\\ &amp;= \\frac{\\partial I_1}{\\partial u} \\begin{bmatrix} f_x &amp; 0 \\\\ 0 &amp; f_y \\end{bmatrix} \\begin{bmatrix} \\frac{1}{P_j^{virtual}[2]} &amp; 0 &amp; -\\frac{ P_j^{virtual}[0] }{P_j^{virtual}[2]^2} \\\\ 0 &amp; \\frac{1}{P_j^{virtual}[2]} &amp; -\\frac{ P_j^{virtual}[1] }{P_j^{virtual}[2]^2} \\end{bmatrix} (\\frac{t d_{pi}-P_j^{virtual}}{d_{pi}}) \\\\ &amp;= \\begin{bmatrix} d_x &amp; d_y \\end{bmatrix} \\begin{bmatrix} f_x &amp; 0 \\\\ 0 &amp; f_y \\end{bmatrix} \\frac{1}{P_j^{virtual}[2]} \\begin{bmatrix} 1 &amp; 0 &amp; -\\frac{ P_j^{virtual}[0] }{P_j^{virtual}[2]} \\\\ 0 &amp; 1 &amp; -\\frac{ P_j^{virtual}[1] }{P_j^{virtual}[2]} \\end{bmatrix} (t - q) \\end{aligned} \\] 到这里，是时候讨论\\(P_j^{virtual}\\)的内在意义了: 根据虚拟点\\(P_j^{virtual}\\)的定义 \\[ P_j^{virtual}= d_{pi} P_j = R P_i&#39; + t d_{pi} \\] 对虚拟点\\(P_j^{virtual}\\)也转换到归一化平面上 \\[ \\begin{aligned} P_j^{virtual-normal}= \\begin{bmatrix} \\frac{P_j^{virtual}[0]}{P_j^{virtual}[2]} \\\\ \\frac{P_j^{virtual}[1]}{P_j^{virtual}[2]} \\\\ 1 \\end{bmatrix} \\begin{bmatrix} \\frac{d_{pi} P_j[0]}{d_{pi} P_j[2]} \\\\ \\frac{d_{pi} P_j[1]}{d_{pi} P_j[2]} \\\\ 1 \\end{bmatrix}= \\begin{bmatrix} \\frac{P_j[0]}{P_j[2]} \\\\ \\frac{P_j[1]}{P_j[2]} \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} \\frac{q[0]}{q[2]} \\\\ \\frac{q[1]}{q[2]} \\\\ 1 \\end{bmatrix} \\end{aligned} \\] 因此，最终可以将上面的残差对逆深度的导数进一步化简: \\[ \\begin{aligned} \\frac{\\partial e}{\\partial \\delta d_{pi}} &amp;= \\begin{bmatrix} d_x &amp; d_y \\end{bmatrix} \\begin{bmatrix} f_x &amp; 0 \\\\ 0 &amp; f_y \\end{bmatrix} \\frac{1}{P_j^{virtual}[2]} \\begin{bmatrix} 1 &amp; 0 &amp; -\\frac{ P_j^{virtual}[0] }{P_j^{virtual}[2]} \\\\ 0 &amp; 1 &amp; -\\frac{ P_j^{virtual}[1] }{P_j^{virtual}[2]} \\end{bmatrix} (t - q) \\\\ &amp;= \\begin{bmatrix} d_x f_x &amp; d_y f_y \\end{bmatrix} \\frac{1}{P_j^{virtual}[2]} \\begin{bmatrix} 1 &amp; 0 &amp; -\\frac{ q[0] }{q[2]} \\\\ 0 &amp; 1 &amp; -\\frac{ q[1] }{q[2]} \\end{bmatrix} \\begin{bmatrix} t[0]-q[0] \\\\ t[1]-q[1] \\\\ t[2]-q[2] \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} d_x f_x &amp; d_y f_y \\end{bmatrix} \\frac{1}{P_j^{virtual}[2]} \\begin{bmatrix} 1 &amp; 0 &amp; -\\frac{ q[0] }{q[2]} \\\\ 0 &amp; 1 &amp; -\\frac{ q[1] }{q[2]} \\end{bmatrix} \\begin{bmatrix} t[0] \\\\ t[1] \\\\t[2] \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} d_x f_x &amp; d_y f_y \\end{bmatrix} \\frac{1}{P_j^{virtual}[2]} \\begin{bmatrix} 1 &amp; 0 &amp; -\\frac{ P_j^{virtual}[0] }{P_j^{virtual}[2]} \\\\ 0 &amp; 1 &amp; -\\frac{ P_j^{virtual}[1] }{P_j^{virtual}[2]} \\end{bmatrix} \\begin{bmatrix} t[0] \\\\ t[1] \\\\t[2] \\end{bmatrix} \\end{aligned} \\] 总结PPT: DSO作者采用(齐次点)\\(P_j^{virtual}\\)的目的是希望可以简化的雅克比求导过程。 4. 初始化 将图像分成许多个32x32的block 在block内创建直方图hist0 直方图，统计block内像素点的梯度 取block内直方图的梯度中位数作为阈值 使用 size=3x3 的窗口, 对每个block的阈值进行滤波 DSO代码中初始化时候的雅克比: \\[ \\begin{aligned} J &amp;= \\begin{bmatrix} \\frac{\\partial e}{\\partial \\delta x} &amp; \\frac{\\partial e}{\\partial \\delta y} &amp; \\frac{\\partial e}{\\partial \\delta z} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_x} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_y} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_z} &amp; \\frac{\\partial e}{\\partial a} &amp; \\frac{\\partial e}{\\partial b} &amp; \\frac{\\partial e}{\\partial d_{pi_1}} &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\frac{\\partial e}{\\partial \\delta x} &amp; \\frac{\\partial e}{\\partial \\delta y} &amp; \\frac{\\partial e}{\\partial \\delta z} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_x} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_y} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_z} &amp; \\frac{\\partial e}{\\partial a} &amp; \\frac{\\partial e}{\\partial b} &amp; 0 &amp; \\frac{\\partial e}{\\partial d_{pi_2}} &amp; \\cdots &amp; 0 \\\\ \\frac{\\partial e}{\\partial \\delta x} &amp; \\frac{\\partial e}{\\partial \\delta y} &amp; \\frac{\\partial e}{\\partial \\delta z} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_x} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_y} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_z} &amp; \\frac{\\partial e}{\\partial a} &amp; \\frac{\\partial e}{\\partial b} &amp; 0 &amp; 0 &amp; \\ddots &amp; 0 \\\\ \\frac{\\partial e}{\\partial \\delta x} &amp; \\frac{\\partial e}{\\partial \\delta y} &amp; \\frac{\\partial e}{\\partial \\delta z} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_x} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_y} &amp; \\frac{\\partial e}{\\partial \\delta \\phi_z} &amp; \\frac{\\partial e}{\\partial a} &amp; \\frac{\\partial e}{\\partial b} &amp; 0 &amp; 0 &amp; \\cdots &amp; \\frac{\\partial e}{\\partial d_{pi_n}} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} \\begin{bmatrix} &amp; &amp; &amp; &amp; &amp; &amp; &amp; J_{c} &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; \\end{bmatrix} &amp; \\frac{\\partial e}{\\partial d_{pi_1}} &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\begin{bmatrix} &amp; &amp; &amp; &amp; &amp; &amp; &amp; J_{c} &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; \\end{bmatrix} &amp; 0 &amp; \\frac{\\partial e}{\\partial d_{pi_2}} &amp; \\cdots &amp; 0 \\\\ \\begin{bmatrix} &amp; &amp; &amp; &amp; &amp; &amp; &amp; J_{c} &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; \\end{bmatrix} &amp; 0 &amp; 0 &amp; \\ddots &amp; 0 \\\\ \\begin{bmatrix} &amp; &amp; &amp; &amp; &amp; &amp; &amp; J_{c} &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; \\end{bmatrix} &amp; 0 &amp; 0 &amp; \\cdots &amp; \\frac{\\partial e}{\\partial d_{pi_n}} \\end{bmatrix} \\end{aligned} \\] 其中，前6个是残差对位姿(SE3)的偏导，继续后两个是残差对光度参数(a,b)的偏导，然后就是残差对该层图像各个点的逆深度的偏导。 那么对应的hessian近似可以写成这个样子: \\[ \\begin{aligned} J^T J &amp;= \\begin{bmatrix} \\begin{bmatrix} &amp; &amp; &amp; &amp; \\\\ &amp; &amp; &amp; &amp; \\\\ &amp; &amp; n*J_c^TJ_c &amp; \\\\ &amp; &amp; &amp; &amp; \\\\ &amp; &amp; &amp; &amp; \\\\ \\end{bmatrix} , &amp; \\begin{bmatrix} \\\\ \\\\ J_c^T \\\\ \\\\ \\\\ \\end{bmatrix} \\frac{\\partial e}{\\partial d_{pi_1}} ,&amp; \\begin{bmatrix} \\\\ \\\\ J_c^T \\\\ \\\\ \\\\ \\end{bmatrix} \\frac{\\partial e}{\\partial d_{pi_2}} ,&amp; \\cdots &amp; \\begin{bmatrix} \\\\ \\\\ J_c^T \\\\ \\\\ \\\\ \\end{bmatrix} \\frac{\\partial e}{\\partial d_{pi_n}} \\\\ \\frac{\\partial e}{\\partial d_{pi_1}} \\begin{bmatrix} &amp; &amp; &amp; J_c &amp; &amp; &amp; \\end{bmatrix} &amp; \\frac{\\partial e}{\\partial d_{pi_1}} \\cdot \\frac{\\partial e}{\\partial d_{pi_1}} &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\frac{\\partial e}{\\partial d_{pi_2}} \\begin{bmatrix} &amp; &amp; &amp; J_c &amp; &amp; &amp; \\end{bmatrix} &amp; 0 &amp; \\frac{\\partial e}{\\partial d_{pi_2}} \\cdot \\frac{\\partial e}{\\partial d_{pi_2}} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; 0 &amp; 0 &amp; \\ddots &amp; 0 \\\\ \\frac{\\partial e}{\\partial d_{pi_n}} \\begin{bmatrix} &amp; &amp; &amp; J_c &amp; &amp; &amp; \\end{bmatrix} &amp; 0 &amp; 0 &amp; \\cdots &amp; \\frac{\\partial e}{\\partial d_{pi_n}} \\cdot \\frac{\\partial e}{\\partial d_{pi_n}} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} \\begin{bmatrix} \\\\ &amp; &amp; U(or B) &amp; \\\\ \\\\ \\end{bmatrix} , &amp; \\begin{bmatrix} \\\\ &amp; &amp; &amp; &amp; W(or E) &amp; &amp; &amp; &amp; \\\\ \\\\ \\end{bmatrix} \\\\ \\\\ \\begin{bmatrix} \\\\ \\\\ \\\\ &amp; W^T (or E^T) &amp; \\\\ \\\\ \\\\ \\\\ \\end{bmatrix} ,&amp; \\begin{bmatrix} &amp; \\\\ &amp; \\\\ &amp; \\\\ &amp;&amp;&amp;&amp; V (or C) &amp;&amp;&amp;&amp; \\\\ &amp; \\\\ &amp; \\\\ &amp; \\\\ \\end{bmatrix} \\end{bmatrix} \\end{aligned} \\] Tips 在应用舒尔补的时候，需要计算\\(WV^{-1}W^T\\)，那么有： \\[ \\begin{aligned} WV^{-1}W^T &amp;=V^{-1}WW^T \\\\ &amp;=(V^{-1}[1][1]W.col[1]W^T.row[1]+V^{-1}[2][2]W.col[2]W^T.row[2]+ \\\\ &amp;\\cdots+V^{-1}[n][n]W.col[n]W^T.row[n]) \\end{aligned} \\] 其中， \\(W.col[]\\)表示\\(J^TJ\\)矩阵右上角块的按列取 \\(W^T.row[]\\)表示\\(J^TJ\\)矩阵左下角块的按行取 优点：这样就可以把大矩阵的运算变成小矩阵的加法运算，通过遍历观测到的每一个点，计算一个8x8的小矩阵，对这些矩阵进行求和，就可以得到原本需要计算(8xn)x(nx8)大矩阵来得到的\\(WV^{-1}W^T\\)。 (DSO就是通过这样的思路+SSE进行加速运算) 4.1. 初始化流程总结 5. DSO框架 DSO之光度标定","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"DSO","slug":"SLAM代码课程/DSO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/"}],"tags":[]},{"title":"Cartographer-[0]-运行Demo数据集和MIT数据集","slug":"Cartographer-Google相关/Cartographer-0-运行Demo数据集和MIT数据集","date":"2020-03-16T00:48:37.000Z","updated":"2020-03-16T03:56:56.000Z","comments":true,"path":"2020/03/16/Cartographer-Google相关/Cartographer-0-运行Demo数据集和MIT数据集/","link":"","permalink":"http://yoursite.com/2020/03/16/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer-0-%E8%BF%90%E8%A1%8CDemo%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8CMIT%E6%95%B0%E6%8D%AE%E9%9B%86/","excerpt":"","text":"1. 运行官方Demo 德意志博物馆数据集 1.1. 下载数据集 1wget -P ~/Downloads https://storage.googleapis.com/cartographer-public-data/bags/backpack_2d/cartographer_paper_deutsches_museum.bag 使用rosbag回放一下数据集，检查有哪些传感器： 1234567msi@msi:~/carto/carto_ros/data$ rostopic list/clock/horizontal_laser_2d/imu/rosout/rosout_agg/vertical_laser_2d 可以看到，数据集仅仅包含imu传感器，两个激光雷达（水平+垂直放置），没有里程计，也没有TF变换。 疑惑：那么，IMU、激光雷达与机器人本体base_link之间的相对位置关系是在哪里确定的呢？[代码中sensorBridge需要将传感器的数据转换到机器人本体坐标系下，那么就需要这些相对位置关系] 答：在carto_ros/src/cartographer_ros/cartographer_ros/urdf/ 文件夹中，有一个backpack_2d.urdf，里面定义了机器人本体与各个传感器之间的相对位置关系，同时，在启动文件中，可以找到如下两行： 12345&lt;param name=\"robot_description\" textfile=\"$(find cartographer_ros)/urdf/backpack_2d.urdf\" /&gt;&lt;node name=\"robot_state_publisher\" pkg=\"robot_state_publisher\" type=\"robot_state_publisher\" /&gt; 这两行定义了机器人的模型，同时发布了机器人模型中的各个相对坐标关系，在下面的Demo运行中，可以看到由robot_state_publisher节点读取backpack_2d.urdf模型然后发布的TF变换。 1.2. 运行官方给出的Demo启动文件 123source ./install/setup.bashroslaunch cartographer_ros demo_backpack_2d.launch bag_filename:=$&#123;HOME&#125;/Downloads/cartographer_paper_deutsches_museum.bag 1.3. rqt查看节点关系和TF变换 1.3.1. 节点关系 1.3.2. TF变换(由backpack_2d.urdf模型定义) 可以看到，红色框标注的地方，就是由robot_state_publisher节点读取backpack_2d.urdf模型然后发布的TF变换。上面的部分则是由cartographer节点定位所发布的map--&gt;odom的TF变换。 传感器与机器人本体之间的TF变换对于运行cartographer来说是十分重要的，如果没有这些相对坐标关系，cartographer将无法运行。 1.4. 运行效果 初始启动: 最终完成: 1.5. 总结 从最终的效果来看，官方Demo的效果（建图和跟踪）都比传统的滤波方法好很多，另外，在这个数据集中，仅有激光雷达和IMU，连里程计都没有使用，这说明了程序对这个数据集做了很多的适配工作。为了验证cartographer对其他数据集是否具有普适性，接下来将使用MIT数据集进行测试。 2. 运行MIT数据集 数据集官方地址：mit stata center data set 从官方给出的数据集详细来看，有这些传感器TOpic /base_scan: 水平放置的激光雷达 /tilt_scan: 倾斜放置的激光雷达 /base_odometry/odom: 里程计 /robot_pose_ekf/odom_combined: 使用EFK滤波得到的里程计数据（可能是里程计+IMU融合） /torso_lift_imu/data: IMU数据 /tf: 传感器相对位置？ ... 2.1. 下载数据集 这个数据集有点坑的地方就是，它的机器人是会坐电梯在楼层之间跑的，因此需要选择一个只在一个平面上跑的数据集。 1wget http://infinity.csail.mit.edu/data/2011/2011-03-28-08-38-59.bag 使用rosbag回放，检查数据集内容： TF变换信息 从TF变换树可以看到，这里的里程计信息是采用经过EKF滤波之后的里程计坐标系odom_combined，而不是直接的odom。 传感器话题 2.2. 使用IMU+激光扫描,运行cartographer 2.2.1. 配置文件适配 (1).launch启动文件 在运行之前，需要对配置文件进行修改，因为数据集的传感器Topic与官方Demo的不一样，主要是IMU和激光扫描的Topic 对backpack_2d.launch文件进行修改： 修改之后的内容如下： 移除了robot_state_publisher节点以及urdf机器人模型 ： 这是因为在数据集中已经提供了传感器与机器人本体的相对位置关系 传感器Topic的重映射： 将数据集中的激光扫描\"base_scan\"映射为\"scan\"，将IMU话题\"torso_lift_imu/data\"映射为\"imu\" 指定参数配置文件为my_script_backpack_2d.lua my_script_backpack_2d.launch 1234567891011121314&lt;launch&gt; &lt;node name=\"cartographer_node\" pkg=\"cartographer_ros\" type=\"cartographer_node\" args=\" -configuration_directory $(find cartographer_ros)/configuration_files -configuration_basename my_script_backpack_2d.lua\" output=\"screen\"&gt; &lt;remap from=\"scan\" to=\"base_scan\" /&gt; &lt;remap from=\"imu\" to=\"torso_lift_imu/data\" /&gt; &lt;/node&gt; &lt;node name=\"cartographer_occupancy_grid_node\" pkg=\"cartographer_ros\" type=\"cartographer_occupancy_grid_node\" args=\"-resolution 0.05\" /&gt;&lt;/launch&gt; (2).lua参数配置文件 因为数据集的TF变换中，机器人本体坐标系不是base_link，而是base_footprint，因此需要修改。 对backpack_2d.lua文件进行修改，然后保存为my_script_backpack_2d.lua，主要修改内容： 修改\"tracking_frame\"，为\"base_footprint\" 修改\"published_frame\"，为\"base_footprint\" 修改\"num_laser_scans\"，为1 (这是因为数据集中的激光扫描是LaserScan消息类型) 修改\"num_multi_echo_laser_scans\"，\"num_point_clouds\"，均为0 my_script_backpack_2d.lua: 12345678910111213141516171819202122232425262728293031323334include \"map_builder.lua\"include \"trajectory_builder.lua\"options = &#123; map_builder = MAP_BUILDER, trajectory_builder = TRAJECTORY_BUILDER, map_frame = \"map\", tracking_frame = \"base_footprint\", published_frame = \"base_footprint\", --这个实际上与`use_odometry`选项无关, odom_frame = \"odom\", --(如果不使用里程计，直接设置为\"odom\"即可)，如果使用里程计，那么将这个设置为：查看tf-tree里面,odom的坐标系 provide_odom_frame = true, publish_frame_projected_to_2d = false, use_odometry = false, use_nav_sat = false, use_landmarks = false, num_laser_scans = 1, num_multi_echo_laser_scans = 0, num_subdivisions_per_laser_scan = 1, num_point_clouds = 0, lookup_transform_timeout_sec = 0.2, submap_publish_period_sec = 0.3, pose_publish_period_sec = 5e-3, trajectory_publish_period_sec = 30e-3, rangefinder_sampling_ratio = 1., odometry_sampling_ratio = 1., fixed_frame_pose_sampling_ratio = 1., imu_sampling_ratio = 1., landmarks_sampling_ratio = 1.,&#125;MAP_BUILDER.use_trajectory_builder_2d = trueTRAJECTORY_BUILDER_2D.use_imu_data = trueTRAJECTORY_BUILDER_2D.num_accumulated_range_data = 1return options 2.2.2. 启动cartographer (修改完配置文件之后，需要重新编译一下，否则修改无效) 123source ./install/setup.bashroslaunch cartographer_ros my_script_launch.launch bag_filename:=/home/msi/carto/carto_ros/data/2011-03-28-08-38-59.bag 2.2.3. 运行效果 初始启动 遇到长直走廊: 在走廊中定位错误，导致建图重叠： 2.2.4. 总结 单纯使用IMU+激光扫描时，在特征良好的环境下定位、建图效果都不错，但是遇到长直走廊，就出现定位失败的问题，使得建图也出现错误。这种情况下，下面尝试把里程计也融合进去，再看效果如何。 2.3. 使用IMU+里程计+激光扫描,运行cartographer 2.3.1. 配置文件适配 (1).launch启动文件，需要对里程计topic进行重映射 1&lt;remap from=\"odom\" to=\"base_odometry/odom\" /&gt; (2).lua参数配置文件 重点 由于数据集包含的TF变换中，里程计的坐标系是odom_combined而不是odom，（可以往回看看），因此需要修改。 在上面的IMU尝试的基础上，继续my_script_backpack_2d.lua文件进行修改，主要修改内容： 修改\"odom_frame\"，为\"odom_combined\" 修改\"provide_odom_frame\"，改成false，因为数据集已经提供了里程计的坐标系了 修改\"use_odometry\"，为true 修改之后的my_script_backpack_2d.lua完整内容: 12345678910111213141516171819202122232425262728293031323334include \"map_builder.lua\"include \"trajectory_builder.lua\"options = &#123; map_builder = MAP_BUILDER, trajectory_builder = TRAJECTORY_BUILDER, map_frame = \"map\", tracking_frame = \"base_footprint\", published_frame = \"base_footprint\", --这个实际上与`use_odometry`选项无关, odom_frame = \"odom_combined\", --这个请查看tf-tree里面,odom的坐标系 odom_combined provide_odom_frame = false, publish_frame_projected_to_2d = false, use_odometry = true, use_nav_sat = false, use_landmarks = false, num_laser_scans = 1, num_multi_echo_laser_scans = 0, num_subdivisions_per_laser_scan = 1, num_point_clouds = 0, lookup_transform_timeout_sec = 0.2, submap_publish_period_sec = 0.3, pose_publish_period_sec = 5e-3, trajectory_publish_period_sec = 30e-3, rangefinder_sampling_ratio = 1., odometry_sampling_ratio = 1., fixed_frame_pose_sampling_ratio = 1., imu_sampling_ratio = 1., landmarks_sampling_ratio = 1.,&#125;MAP_BUILDER.use_trajectory_builder_2d = trueTRAJECTORY_BUILDER_2D.use_imu_data = trueTRAJECTORY_BUILDER_2D.num_accumulated_range_data = 1return options 2.3.2. 启动cartographer (修改完配置文件之后，需要重新编译一下，否则修改无效) 123source ./install/setup.bashroslaunch cartographer_ros my_script_launch.launch bag_filename:=/home/msi/carto/carto_ros/data/2011-03-28-08-38-59.bag 出现报错 12at line 126 in &#x2F;tmp&#x2F;binarydeb&#x2F;ros-melodic-tf2-0.6.5&#x2F;src&#x2F;buffer_core.cppWarning: Invalid argument passed to canTransform argument source_frame in tf2 frame_ids cannot be empty 出现这个错误，实际上是因为这个MIT数据集的里程计消息不完整 2.3.3. 错误检查 检查里程计消息： 1rostopic echo &#x2F;base_odometry&#x2F;odom 得到如下: 问题出现在红色框部分： odom消息的child_frame_id居然为空，正常的里程计消息中，child_frame_id一般为base_link，用来指定这是哪个坐标系相对于里程计坐标系的里程信息。 蓝色框部分是需要注意的地方，cartographer要求里程计信息带有四元数旋转信息，这个数据集有，是可以的。 2.3.4. 进一步适配 现在知道了错误所在，那么接下来就是对里程计信息进行修正。 从数据集的TF变换： 可以看到，这里的里程计坐标系是采用经过EKF滤波之后的里程计坐标系odom_combined，而不是直接的odom。 那么干脆使用经过EKF滤波之后融合里程计/robot_pose_ekf/odom_combined好了，但是问题来了，这个msg的消息类型是geometry_msgs/PoseWithCovarianceStamped而不是nav_msgs/Odometry 接下来需要编写一个节点，订阅/robot_pose_ekf/odom_combined这个Topic，然后发布nav_msgs/Odometry类型的里程msg 这个节点我已经写好了 Pose2Odom.cpp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;ros/ros.h&gt;#include &lt;message_filters/subscriber.h&gt;#include &lt;message_filters/synchronizer.h&gt;#include &lt;message_filters/sync_policies/approximate_time.h&gt;#include &lt;nav_msgs/Odometry.h&gt;#include &lt;nav_msgs/Path.h&gt;#include &lt;sensor_msgs/Imu.h&gt;#include &lt;sensor_msgs/NavSatFix.h&gt;#include &lt;geometry_msgs/Vector3.h&gt;#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;#include &lt;tf/tf.h&gt;#include &lt;tf/transform_broadcaster.h&gt;#include &lt;boost/array.hpp&gt;ros::NodeHandle *nh;tf::TransformBroadcaster *tfb_;ros::Publisher *odom_pub; //odom发布器void odom_callback(const geometry_msgs::PoseWithCovarianceStampedPtr&amp; odomMsg)&#123; nav_msgs::Odometry msg; msg.header=odomMsg-&gt;header; msg.pose.pose=odomMsg-&gt;pose.pose; msg.child_frame_id=\"base_footprint\"; odom_pub-&gt;publish(msg);&#125;int main(int argc, char **argv)&#123; ros::init(argc, argv, \"Pose2Odom\"); nh=new ros::NodeHandle(\"\"); tfb_=new tf::TransformBroadcaster(); odom_pub=new ros::Publisher; *odom_pub=nh-&gt;advertise&lt;nav_msgs::Odometry&gt;(\"odom\",10,true); //订阅里程计 message_filters::Subscriber&lt;geometry_msgs::PoseWithCovarianceStamped&gt; odom_sub(*nh, \"/robot_pose_ekf/odom_combined\", 10); odom_sub.registerCallback(&amp;odom_callback); //消息同步// typedef message_filters::sync_policies::ApproximateTime&lt;nav_msgs::Odometry, nav_msgs::Odometry&gt; MySyncPolicy;// message_filters::Synchronizer&lt;MySyncPolicy&gt; sync(MySyncPolicy(10), odom_sub, ekf_sub);//queue size=10// sync.registerCallback(&amp;callback/*boost::bind(&amp;callback, _1, _2)*/); ROS_INFO(\"Msg block control node start\"); ros::spin();&#125; 这个节点的主要功能是： 订阅\"/robot_pose_ekf/odom_combined\"，然后转换成\"nav_msgs::Odometry\"消息类型 同时，设置child_frame_id为:base_footprint 2.3.5. 再次启动cartographer (1)把.launch里面的关于里程计的reamap去掉，因为上面的节点直接发布Topic为odom的消息，就不需要重映射了。 (2)启动上面的Pose2Odom节点 (3)启动cartographer 123source ./install/setup.bashroslaunch cartographer_ros my_script_launch.launch bag_filename:=/home/msi/carto/carto_ros/data/2011-03-28-08-38-59.bag 2.3.6. 运行效果 初始运行(可以正常启动了) 再次遇到长直走廊 没有出现地图重叠的情况了 最终建立完整的地图: 2.4. 总结 通过使用MIT数据集进行测试，可以发现，cartographer具有一定的普适性，但是对于长直走廊时的建图和定位，cartographer其实是会受到影响的，单纯使用IMU+激光扫描会出现定位失败，从而导致建图错误的情况，融合里程计之后，情况有所改善(这是因为cartographer里面关于位姿图的优化问题中添加了里程计残差项作为约束)，同时里程计也为姿态外推器(航迹推算)提供了比较好的先验信息(因为在较短时间内，里程计数据可看作是准确的)。 3. 一些思考 3.1. cartographer已经实现的 (1)定位方式有3种 correlative_scan_matching: ～公司采用的 fast_correlative_scan_matching: 分枝定界加速相关性匹配 ceres_scan_matching: 非线性优化位姿 (2)图优化理论 Pose_Graph: 位姿图 顶点： 子图全局位姿 节点全局位姿 约束项(残差项): 节点与当前子图的correlative_scan_matching可产生一个节点--子图约束 节点与所有子图的fast_correlative_scan_matching可产生多个节点--子图约束(即回环检测，如果回环匹配上了，则可构成约束) 节点之间的里程计信息产生节点--节点约束 节点之间的局部SLAM( local SLAM: 即节点与子图correlative_scan_matching得到节点在local map的位姿)可构成节点--节点约束[利用两个节点的local map位姿产生] 路标点，产生路标--节点的约束？ (这一块代码还没详细阅读) 3.2. cartographer还没有实现的 GPS数据的融合(用于重定位、检测回环、产生约束) 重定位功能 视觉信息的融合 3.3. 可以有突破点的地方 基于路标的长直走廊定位(基于视觉的路标信息) 重定位 GPS融合","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"Cartographer-[X]-传感器消息回调","slug":"Cartographer-Google相关/Cartographer-X-传感器消息回调","date":"2020-03-15T16:17:39.000Z","updated":"2020-03-15T16:19:23.000Z","comments":true,"path":"2020/03/16/Cartographer-Google相关/Cartographer-X-传感器消息回调/","link":"","permalink":"http://yoursite.com/2020/03/16/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer-X-%E4%BC%A0%E6%84%9F%E5%99%A8%E6%B6%88%E6%81%AF%E5%9B%9E%E8%B0%83/","excerpt":"","text":"以Ros::sensormsg::LaserScan为例 下图给出了cartographer中关于传感器消息的回调处理过程","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"Cartographer-[X]-初始化","slug":"Cartographer-Google相关/Cartographer-X-初始化","date":"2020-03-15T16:15:43.000Z","updated":"2020-03-15T16:17:14.000Z","comments":true,"path":"2020/03/16/Cartographer-Google相关/Cartographer-X-初始化/","link":"","permalink":"http://yoursite.com/2020/03/16/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer-X-%E5%88%9D%E5%A7%8B%E5%8C%96/","excerpt":"","text":"","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"Cartographer-[X]-顶层接口结构图","slug":"Cartographer-Google相关/Cartographer-X-顶层接口结构图","date":"2020-03-15T03:51:58.000Z","updated":"2020-03-15T04:27:14.000Z","comments":true,"path":"2020/03/15/Cartographer-Google相关/Cartographer-X-顶层接口结构图/","link":"","permalink":"http://yoursite.com/2020/03/15/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer-X-%E9%A1%B6%E5%B1%82%E6%8E%A5%E5%8F%A3%E7%BB%93%E6%9E%84%E5%9B%BE/","excerpt":"","text":"Cartographer顶层接口 个人总结","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"Cartographer-[4]-从node_main.cc开始","slug":"Cartographer-Google相关/Cartographer-4-从node-main-cc开始","date":"2020-03-08T09:42:18.000Z","updated":"2020-03-15T04:42:12.000Z","comments":true,"path":"2020/03/08/Cartographer-Google相关/Cartographer-4-从node-main-cc开始/","link":"","permalink":"http://yoursite.com/2020/03/08/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer-4-%E4%BB%8Enode-main-cc%E5%BC%80%E5%A7%8B/","excerpt":"","text":"1. 从node_main.cc开始 虽说从node_main.cc开始，但是，实际上还是从demo开始吧 2. demo_backpack_2d.launch 官方的demo启动如下： 2D: 12wget -P ~&#x2F;Downloads https:&#x2F;&#x2F;storage.googleapis.com&#x2F;cartographer-public-data&#x2F;bags&#x2F;backpack_2d&#x2F;cartographer_paper_deutsches_museum.bagroslaunch cartographer_ros demo_backpack_2d.launch bag_filename:&#x3D;$&#123;HOME&#125;&#x2F;Downloads&#x2F;cartographer_paper_deutsches_museum.bag 可以发现，主要是启动了demo_backpack_2d.launch文件，该文件内容如下: 12345678910&lt;launch&gt; &lt;param name=\"/use_sim_time\" value=\"true\" /&gt; &lt;include file=\"$(find cartographer_ros)/launch/backpack_2d.launch\" /&gt; &lt;node name=\"rviz\" pkg=\"rviz\" type=\"rviz\" required=\"true\" args=\"-d $(find cartographer_ros)/configuration_files/demo_2d.rviz\" /&gt; &lt;node name=\"playbag\" pkg=\"rosbag\" type=\"play\" args=\"--clock $(arg bag_filename)\" /&gt;&lt;/launch&gt; 该launch文件实现了 调用backpack_2d.launch文件 启动rviz 使用playbag进行数据包回放 3. backpack_2d.launch 接下来，继续跟踪backpack_2d.launch文件，该文件内容如下: 123456789101112131415161718&lt;launch&gt; &lt;param name=\"robot_description\" textfile=\"$(find cartographer_ros)/urdf/backpack_2d.urdf\" /&gt; &lt;node name=\"robot_state_publisher\" pkg=\"robot_state_publisher\" type=\"robot_state_publisher\" /&gt; &lt;node name=\"cartographer_node\" pkg=\"cartographer_ros\" type=\"cartographer_node\" args=\" -configuration_directory $(find cartographer_ros)/configuration_files -configuration_basename backpack_2d.lua\" output=\"screen\"&gt; &lt;remap from=\"echoes\" to=\"horizontal_laser_2d\" /&gt; &lt;/node&gt; &lt;node name=\"cartographer_occupancy_grid_node\" pkg=\"cartographer_ros\" type=\"cartographer_occupancy_grid_node\" args=\"-resolution 0.05\" /&gt;&lt;/launch&gt; backpack_2d.launch文件实现了 启动robot_state_publisher节点，发布TF变换 启动了cartographer_node节点，传入lua文件进行参数加载configuration_files/backpack_2d.lua 启动了cartographer_occupancy_grid_node节点，传入分辨率参数-resolution 0.05 4. 继续node_main.cc 上面的launch文件最终启动了Cartographer_ros节点，而这个主节点在node_main.cc启动。 4.1. int main() 初始化google的日志输出 初始化节点\"cartographer_node\" 调用cartographer_ros::Run() 4.2. cartographer_ros::Run() 初始化tf2的缓冲区tf_buffer 创建tf变换监听器 获取命令行传入的配置文件 [重点来了]创建MapBuilder对象，返回对象指针，赋值map_builder new一个Google自己定义的Node节点，传入配置文件、map_builder指针、tf缓冲区进行构造 启动上面new出来的Node节点 ...建图... 结束轨迹 调用最后一次全局BA优化 根据标志位判断是否进行序列化输出 5. Google自己定义的Node节点(类) 从main()函数来看，最终都交给了Node节点来处理","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"Cartographer-[3]-ROS封装API","slug":"Cartographer-Google相关/Cartographer-3-ROS封装API","date":"2020-03-08T08:55:13.000Z","updated":"2020-03-08T09:35:12.000Z","comments":true,"path":"2020/03/08/Cartographer-Google相关/Cartographer-3-ROS封装API/","link":"","permalink":"http://yoursite.com/2020/03/08/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer-3-ROS%E5%B0%81%E8%A3%85API/","excerpt":"","text":"1. Cartographer-ROS封装API 2. 主节点 node_main.cc是运行Cartographer Ros的主节点。具体文件 2.1. 订阅主题 scan (sensor_msgs/LaserScan) echoes (sensor_msgs/MultiEchoLaserScan) points2 (sensor_msgs/PointCloud2) imu (sensor_msgs/Imu) : 3D情况下必须要有IMU odom (nav_msgs/Odometry): 如果use_odometry设置为enable那么里程计数据也输入到SLAM系统中 2.2. 发布Topic scan_matched_points2 (sensor_msgs/PointCloud2) : 用来进行scan-to-submap匹配的点云 submap_list (cartographer_ros_msgs/SubmapList) : 所有轨迹子图的列表，包括每个子图的姿态和最新编号 2.3. 服务 所有服务响应还包括一个StatusResponse，它包含一个code和一个message。为了一致性，整数code等价于gRPCAPI中使用的状态代码 submap_query (cartographer_ros_msgs/SubmapQuery) ： 子图查询 start_trajectory (cartographer_ros_msgs/StartTrajectory)：以二进制编码的proto指定传感器主题和轨迹选项，开始另一个轨迹，返回轨迹ID finish_trajectory (cartographer_ros_msgs/FinishTrajectory) ：通过运行最后的优化完成给定id的轨迹优化。 write_state (cartographer_ros_msgs/WriteState)：将当前的内部状态写入磁盘到文件名中，文件名通常以.ros结尾，此文件可作为主程序的输入，以生成诸如概率网格、 X-Rays 或者 PLY files. get_trajectory_states (cartographer_ros_msgs/GetTrajectoryStates) ： 返回id和轨迹的状态，这对于从单独的节点观察Cartographer的状态 read_metrics (cartographer_ros_msgs/ReadMetrics)：进行指标衡量 2.4. 需要的TF 变换 来自各个传感器坐标系的到tracking_frame和published_frame的TF变换必须存在，这些TF变换通常由robot_state_publisher或者static_transform_publisher发布。 3. 离线节点 离线节点是对一个传感器数据rosbag进行SLAM的最快方式，它不会监听任何话题，而是从命令行上提供的一组包中读取 TF 和传感器数据。 它还发布了一个带有前进传感器数据的时钟，即取代了 rosbag play。在所有其他方面，它表现得像Cartographer节点。 每个袋子将成为一个独立的轨迹，在最后的状态。 一旦处理完所有数据，它就会写出最终的Cartographer状态并退出。 4. Occupancy grid Node (占用网格节点) 占用网格节点监听 SLAM 发布的子地图，从中构建 ROS 占用网格并发布它。生成地图是昂贵和缓慢的，因此地图更新的顺序是秒。 4.1. 订阅主题 submap_list ：只定于Cartographer的子地图列表主题 4.2. 发布的主题 map (nav_msgs/OccupancyGrid) ： 如果订阅，节点将继续计算和发布映射。 更新之间的时间将随着地图的大小而增加。 要获得更快的更新，请使用子图api 5. Pbstream Map Publisher Node P(bstream地图发布器节点) Pbstream map publisher是一个简单的节点，它在序列化的 Cartographer 状态(pbstream 格式)之外创建一个静态占用网格。 如果实时更新不重要，它是占用网格节点的一个有效替代方案。 5.1. 订阅主题 无 5.2. 发布的主题 map (nav_msgs/OccupancyGrid) ：发布的占用网格主题是锁定的","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"Cartographer-[2]-系统参数配置说明","slug":"Cartographer-Google相关/Cartographer-2-系统参数配置说明","date":"2020-03-08T05:13:20.000Z","updated":"2020-03-08T09:35:02.000Z","comments":true,"path":"2020/03/08/Cartographer-Google相关/Cartographer-2-系统参数配置说明/","link":"","permalink":"http://yoursite.com/2020/03/08/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer-2-%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/","excerpt":"","text":"1. Algorithm walkthrough for tuning 1.1. 两个子系统 第一个是局部 SLAM (有时也称为前端或局部轨迹构建器)。 它的工作是构建一系列子地图。 每个子地图都意味着本地一致性，但我们接受本地 SLAM 随着时间的推移而漂移。 另一个子系统是全局 SLAM (有时称为后端)。 它在后台线程中运行，其主要任务是找到闭环约束。 它通过对子图进行扫描匹配扫描(聚集在节点中)来实现这一点。 它还结合了其他传感器数据，以获得更高层次的看法，并确定最一致的全局解决方案。 在3D 中，它还试图找到重力的方向。 上述两个模块的基本选项配置文件可以参见 2D Trajectory_builder_2d.lua 3D Trajectory_builder_3d.lua global_pose_graph.lua 1.2. Local SLAM 当一帧扫描从激光数据经过滤波和嵌入，就可以开始执行Local SAM，Local SLAM通过使用pose extrapolator 来得到位姿的初始估计进行扫描匹配，得到优化的位姿后，将新的扫描插入到子图中。 有两种扫描匹配策略可用: CeresScanMatcher将最初的猜测作为优先值，并找到扫描匹配子图的最佳位置。这是通过插值子图和子像素对齐扫描来实现的。 这很快，但不能修复明显大于子图分辨率的错误。(如果您的传感器设置和时间是合理的，只使用CeresScanMatcher通常是最好的选择) RealTimeCorrelativeScanMatcher如果您没有其他传感器或者您不信任它们，则可以启用它，它使用的方法类似于如何将扫描与的子图进行匹配形成闭环(后面将描述) ，一种用法是使用RealTimeCorrelativeScanMatcher作为先验的初值，提供给CeresScanMatcher进行位姿估计。 无论哪种方式，CeresScanMatcher 都可以配置为给每个输入赋予一定的权重。 权重是对数据的信任度量，这可以看作是一个静态的协方差。 权重参数的单位是无量纲量，不能相互比较。 一个数据源的权重越大，制图师在进行扫描匹配时就越重视这个数据源。 数据源包括占据空间(扫描点)、来自pose extrapolator(或 RealTimeCorrelativeScanMatcher)的平移和旋转 权重配置选项为 12345TRAJECTORY_BUILDER_3D.ceres_scan_matcher.occupied_space_weightTRAJECTORY_BUILDER_3D.ceres_scan_matcher.occupied_space_weight_0TRAJECTORY_BUILDER_3D.ceres_scan_matcher.occupied_space_weight_1TRAJECTORY_BUILDER_nD.ceres_scan_matcher.translation_weightTRAJECTORY_BUILDER_nD.ceres_scan_matcher.rotation_weight 在三维空间中，占用空间权重为0和占用空间权重为1的参数分别与高分辨率和低分辨率滤波点云有关。 1.2.1. CeresScanMatcher Ceresscanmatcher的名字来源于谷歌开发的用于解决非线性最小二乘问题的 ceressolver 库。 扫描匹配问题被建模为这样一个问题的最小化，扫描之间的运动(变换矩阵)是一个参数确定。 使用梯度下降法来优化位姿，它可以调整通过配置调整收敛的速度 参数项为: 123TRAJECTORY_BUILDER_nD.ceres_scan_matcher.ceres_solver_options.use_nonmonotonic_stepsTRAJECTORY_BUILDER_nD.ceres_scan_matcher.ceres_solver_options.max_num_iterationsTRAJECTORY_BUILDER_nD.ceres_scan_matcher.ceres_solver_options.num_threads 1.2.2. RealTimeCorrelativeScanMatcher RealTimeCorrelativeScanMatcher可以根据您对传感器的信任进行切换，它的工作原理是在一个搜索窗口中搜索相似的扫描，该窗口由最大距离半径和最大角度半径定义。当寻找到一个良好的匹配位姿时，平移和旋转的部分可以各自拥有不同的权重，比如你知道你的机器人实际上并没有旋转这么大的角度，则可以调小权重。 参数项为: 12345TRAJECTORY_BUILDER_nD.use_online_correlative_scan_matchingTRAJECTORY_BUILDER_nD.real_time_correlative_scan_matcher.linear_search_windowTRAJECTORY_BUILDER_nD.real_time_correlative_scan_matcher.angular_search_windowTRAJECTORY_BUILDER_nD.real_time_correlative_scan_matcher.translation_delta_cost_weightTRAJECTORY_BUILDER_nD.real_time_correlative_scan_matcher.rotation_delta_cost_weight 1.2.3. 运动间隔 为了避免每个子图插入太多的扫描，一旦扫描匹配程序发现两个扫描之间的运动，它就会通过运动过滤器。 如果导致扫描的运动被认为不够重要，那么扫描就会被丢弃。 只有当扫描的运动超过一定的距离、角度或时间阈值时，扫描才会插入当前子图。 配置项: 123TRAJECTORY_BUILDER_nD.motion_filter.max_time_secondsTRAJECTORY_BUILDER_nD.motion_filter.max_distance_metersTRAJECTORY_BUILDER_nD.motion_filter.max_angle_radians 1.2.4. 子图配置 当Local SLAM 接收到给定数量的激光数据时，子地图被认为是完整的。 随着时间的推移，局部 SLAM 漂移，全局 SLAM 被用来修正这种漂移。 子图必须足够小，使其内部的漂移低于分辨率，以便它们在局部是正确的。 另一方面，它们应该足够大，以便使闭环能够正常工作。 配置项: 1TRAJECTORY_BUILDER_nD.submaps.num_range_data 子图可以将它们的范围数据存储在两个不同的数据结构中: 最广泛使用的表示方式称为概率网格。 但是，在2D 中，也可以选择使用截断有符号距离字段(TSDF) 配置项: 1TRAJECTORY_BUILDER_2D.submaps.grid_options_2d.grid_type 概率网格将空间切割成二维或三维表格，其中每个单元格都有固定的大小，每个单元格的值表示被占据的概率。这个概率根据“命中”(测量距离数据的地方)和“未命中”(传感器和测量点之间的空闲空间)更新，在占用概率计算中，命中和未命中可能具有不同的权重，从而给予占用空间或自由空间测量或多或少的信任。 配置项: 1234TRAJECTORY_BUILDER_2D.submaps.range_data_inserter.probability_grid_range_data_inserter.hit_probabilityTRAJECTORY_BUILDER_2D.submaps.range_data_inserter.probability_grid_range_data_inserter.miss_probabilityTRAJECTORY_BUILDER_3D.submaps.range_data_inserter.hit_probabilityTRAJECTORY_BUILDER_3D.submaps.range_data_inserter.miss_probability 在2D 中，每个子图只存储一个概率网格。 在三维中，由于扫描匹配性能的原因，采用了两种混合概率网格。 (术语“混合”仅指内部树状数据表示形式) : a low resolution hybrid grid for far measurements 用于远距离测量的低分辨率混合网格 a high resolution hybrid grid for close measurements 用于近距离测量的高分辨率混合网格 扫描匹配首先用低分辨率混合网格对齐低分辨率点云的远端点，然后用高分辨率混合网格对齐高分辨率点，从而改进姿态。 配置项 12345TRAJECTORY_BUILDER_2D.submaps.grid_options_2d.resolutionTRAJECTORY_BUILDER_3D.submaps.high_resolutionTRAJECTORY_BUILDER_3D.submaps.low_resolutionTRAJECTORY_BUILDER_3D.high_resolution_adaptive_voxel_filter.max_rangeTRAJECTORY_BUILDER_3D.low_resolution_adaptive_voxel_filter.max_range Cartographer ROS提供了一个 RViz 插件来可视化子地图。 您可以从子图的编号中选择要查看的子映射。 在3D 中，RViz 仅显示3D 混合概率网格的2D 投影(以灰度形式)。 Rviz 的左侧面板提供了在低分辨率和高分辨率混合网格可视化之间切换的选项 1.3. Global SLAM 当局部 SLAM 生成一系列子地图时，一个全局优化(通常称为“最佳化问题”或“稀疏姿态调整”)任务在后台运行。 它的作用是重新安排彼此之间的子图，以便它们形成一个连贯的全局地图。 例如，这个优化负责改变当前构建的轨迹，使子图与闭环链接正确对齐。 1.3.1. 全局BA优化频率 一旦插入了一定数量的轨迹节点，就可以分批进行优化。 根据需要运行它的频率，可以调优这些批处理的大小。 参数项: 1POSE_GRAPH.optimize_every_n_nodes 提示： 将POSE_GRAPH.optimize_every_n_nodes设置为0是禁用全局 SLAM 和关注Local SLAM 行为的一种简便方法。 这通常是调整制图师的第一件事情。 1.3.2. 约束及搜索窗口 Global SLAM 是一种“图 SLAM” ，它本质上是一种姿态图优化，通过在节点和子图之间建立约束，然后优化产生的约束图来实现。 约束可以直观地被认为是将所有节点绑在一起的小绳索。 稀疏位置调整将这些绳子一起扣紧。 由此产生的网络称为“姿态图”。 非全局约束: 也称内部子图约束，是根据轨迹上的每个位姿自动连接的，直观地说，这些非全局约束保持了轨迹的局部结构一致 全局约束：也称闭环约束，通过对新的子图和旧的位姿顶点(取认为比较接近的)，然后在搜索窗口中进行匹配，如果足够的匹配，则认为形成闭环。 参数项 12345POSE_GRAPH.constraint_builder.max_constraint_distancePOSE_GRAPH.fast_correlative_scan_matcher.linear_search_windowPOSE_GRAPH.fast_correlative_scan_matcher_3d.linear_xy_search_windowPOSE_GRAPH.fast_correlative_scan_matcher_3d.linear_z_search_windowPOSE_GRAPH.fast_correlative_scan_matcher*.angular_search_window 实际上，全局约束可以做的不仅仅是在单一轨迹上寻找闭环，它也可以用于对齐由多个机器人记录的不同轨迹，但是这里不讨论 为了限制约束(和计算)的数量，Cartographer只考虑用于约束生成的所有紧密节点的下采样集。 这是由一个采样比率常数控制。 采样太少的节点可能会导致错过约束和无效的循环关闭。 采样太多的节点会降低全局 SLAM 的速度并阻碍实时闭环。参数设置： 1POSE_GRAPH.constraint_builder.sampling_ratio 当考虑为一个节点和子图之间建立约束时，将使用名为FastCorrelativeScanMatcher的第一个扫描匹配程序，依靠“分枝定界”机制在不同的网格分辨率下工作，并有效地消除不正确的匹配。它工作在一棵可以控制深度的扩展树上。参数设置： 123POSE_GRAPH.constraint_builder.fast_correlative_scan_matcher.branch_and_bound_depthPOSE_GRAPH.constraint_builder.fast_correlative_scan_matcher_3d.branch_and_bound_depthPOSE_GRAPH.constraint_builder.fast_correlative_scan_matcher_3d.full_resolution_depth 一旦 FastCorrelativeScanMatcher有了一个足够好的方案(超过最低匹配分数) ，它就会被输入 Ceres Scan Matcher 来优化这个姿态。参数为： 123POSE_GRAPH.constraint_builder.min_scorePOSE_GRAPH.constraint_builder.ceres_scan_matcher_3dPOSE_GRAPH.constraint_builder.ceres_scan_matcher 1.3.3. 全局BA的Cost function相关 当Cartographer求解优化问题时，Ceres被用来根据多个残差来重新排列子图，残差使用加权的cost function，全局优化的cost function包括了全局(闭环)约束，非全局约束，IMU加速度和角速度，Local SLAM的粗略姿态估计，里程计测量，(或者GPS固定坐标系的测量) 这些项。 参数项: 123456POSE_GRAPH.constraint_builder.loop_closure_translation_weightPOSE_GRAPH.constraint_builder.loop_closure_rotation_weightPOSE_GRAPH.matcher_translation_weightPOSE_GRAPH.matcher_rotation_weightPOSE_GRAPH.optimization_problem.*_weightPOSE_GRAPH.optimization_problem.ceres_solver_options 在残差分析中，异常值的影响由一个配置有一定胡贝尔标度的Huber损失函数来处理。 Huber 尺度越大，(潜在的)异常值的影响越大。 核函数配置: 1POSE_GRAPH.optimization_problem.huber_scale 一旦轨迹完成，Cartographer将运行一次新的全局BA优化，将比前面的全局优化迭代更多次数，这样做是为了完善制图师的最终结果，通常不需要实时，因此大量的迭代通常是正确的选择。 参数: 1POSE_GRAPH.max_num_final_iterations 2. 其他配置项 2.1. 激光配置项 测距传感器(例如: LIDARs)在多个方向上提供深度信息。 然而，有些测量结果与 SLAM 无关。 如果传感器部分被灰尘覆盖，或者如果它指向机器人的一部分，一些测量的距离可以被认为是 SLAM 的噪音。 另一方面，一些最远距离的测量也可以来自不希望得到的源(反射、传感器噪声) ，与 SLAM 也无关。 为了解决这些问题，Cartographer首先应用带通滤波器，并只保持范围值之间的一定最小和最大范围。 这些最小值和最大值应根据您的机器人和传感器的规格选择。 12TRAJECTORY_BUILDER_nD.min_rangeTRAJECTORY_BUILDER_nD.max_range 在2D情况下，将会使用TRAJECTORY_BUILDER_2D.missing_data_ray_length来替换超过最大范围的数据，对于3D则提供max_z和min_z来裁剪3D点云。 (配置文件中，每个距离都以米为单位定义) 当机器人实际上在移动的时候，距离是在一段时间内测量的。 然而，距离是通过传感器“批量”传递的大型 ROS 消息。每条消息的时间戳都可以被Cartographer独立地考虑，用来考虑机器人运动引起的变化。Cartographer得到的传感器观测的次数越多，就越能修正地图的弯曲，消除累计误差。因此，强烈推荐提供尽可能多的回环以进行建图。 2.2. 体素滤波器 2.2.1. 固定szie体素滤波 距离数据通常是从机器人上的一个单点测量，但在多个角度。 这意味着靠近的路面(例如道路)经常被撞击并提供许多点。 相反，远处的物体被击中的次数更少，点数也更少。 为了减少点处理的计算量，通常需要对点云进行子采样。 然而，一个简单的随机抽样会从我们已经有一个低密度测量的地区移除点，而高密度的地区仍然会有比需要的更多的点。 为了解决这个密度问题，我们可以使用体素滤波器，将原始点降格为常量大小的立方体，并且只保留每个立方体的质心。 小的立方体大小将导致更密集的数据表示，从而导致更多的计算。 大的多维数据集大小会导致数据丢失，但是速度会快得多。 配置选项为 1TRAJECTORY_BUILDER_nD.voxel_filter_size 2.2.2. 自适应体素滤波 在应用了固定大小的体素滤波器之后，制图师还应用了自适应的体素滤波器。 这个过滤器试图确定最佳体素大小(在最大长度之下)以实现目标点数。 在3D 中，两个自适应体素滤波器用于生成高分辨率和低分辨率点云 配置选项为 12TRAJECTORY_BUILDER_nD.*adaptive_voxel_filter.max_lengthTRAJECTORY_BUILDER_nD.*adaptive_voxel_filter.min_num_points 2.3. IMU 惯性导航系统可以成为 SLAM 的一个有用的信息来源，因为它提供了一个准确的重力方向(因此，地面)和一个嘈杂但很好的机器人旋转的整体指示。 为了过滤 IMU 噪声，需要在一定时间内观测重力。 如果您使用2D SLAM，距离数据可以实时处理，不需要额外的信息源，因此您可以选择是否要制图员使用 IMU。 使用3D SLAM，您需要提供一个 IMU，因为它用作扫描方向的初始猜测，大大降低了扫描匹配的复杂性。 配置选项为 12TRAJECTORY_BUILDER_2D.use_imu_dataTRAJECTORY_BUILDER_nD.imu_gravity_time_constant 配置文件中，每个时间值都以秒为单位定义","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"智能指针-unique_ptr-shared_ptr-make_unique","slug":"C++/智能指针-unique-ptr-shared-ptr-make-unique","date":"2020-03-08T02:51:34.000Z","updated":"2020-03-08T02:53:23.000Z","comments":true,"path":"2020/03/08/C++/智能指针-unique-ptr-shared-ptr-make-unique/","link":"","permalink":"http://yoursite.com/2020/03/08/C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88-unique-ptr-shared-ptr-make-unique/","excerpt":"","text":"C++——智能指针简介[From Net] 一、什么是对象所有权？ 在接触智能指针之前首先要理解对象的所有权是什么，在这之前我们总是用new和delete来进行内存的申请与释放，在这种堆内存分配的方式中，要遵守一个很基本的原则——谁创建谁销毁原则，简单地举个例子，类foo构造函数中中通过new申请了一个数组，那么就要在类foo的析构函数中delete这个数组，而对象的所有权指的就是谁负责delete这个对象的关系。 根据几种智能指针的用途来分，对象的所有权可以分为独占所有权、分享所有权和弱引用。现在来一一介绍它们： 独占所有权：假设Dad拥有Son的独占所有权，那么Son就必须由Dad来delete，再从字面上看，独占意味如果有另一个对象OldWang想要持有Son的话，就必须让Dad放弃对Son的所有权，此所谓独占，亦即不可分享。 分享所有权：假设Dad拥有PS4的分享所有权，那么由最后一个持有PS4的对象来对其进行delete，也就是说，如果这个时候Son也想要持有PS4，Dad不必放弃自己的所有权，而是把所有权分享给Son，而如果Dad被销毁（生命周期结束、被释放等），那PS4就在Son被销毁时被释放，反之如果Son先于Dad被销毁，那么PS4就由Dad来释放。 弱引用：假设AccountThief对Account有弱引用的话，那么AccountThief可以使用Account，但是AccountThief不负责释放Account，如果Account已经被拥有其所有权的对象（比如AccountOwner）释放后，AccountThief还想继续使用Account的时候就会取得一个nullptr（nullptr勉强可以当做NULL来看，前者是关键字，后者是宏定义）。 二、什么是智能指针？ 智能指针是行为类似于指针的模板类对象，可以对其进行解引用*，指向结构体成员-&gt;等操作但是不能进行指针算术运算比如自加++、自减--等，因为指针算术运算实现上是根据指针所指空间大小来进行内存位置上的偏移，而智能指针是类对象，这种运算是没有意义的。当然它具有智能的地方，智能指针最为方便的就是能自动管理堆内存，无需关心何时收回已分配的内存。这么一听是不是觉得它很强？但先别高兴的太早，也有一些需要注意的地方，所有事情都有两面性，了解智能指针后我们将会提到一些需要注意的地方。 然后根据以上介绍的所有权类型，一一对应地，我们有unique_ptr、shared_ptr、weak_ptr，还有被时代抛弃的auto_ptr（稍后也会谈谈它为什么被抛弃）。 三、怎么使用智能指针？ 1、怎么使用unique_ptr？ 在使用unique_ptr的时候，首先要知道它的make函数make_unique()，make_unique()可以构造一个类对象并返回指向它的unique_ptr，例如make_unique()，就会返回一个指向int的unique_ptr，而像make_unique(1)一样带有参数就会返回一个指向值为1的int的unique_ptr，实际上就上面两个就相当于先通过int{}和int{1}创建对象并构造指向它们的unique_ptr。那么对于得到的unique_ptr，我们可以像使用指针一样去使用。 现在我们有Dad对象是指向Son的unique_ptr，如果要Dad放弃对这个对象的所有权，就需要调用Dad.release()来将所有权进行释放，这个函数将会返回指向Son的普通指针Son*，现在就可以用这个不属于任何人的普通指针来构造一个新的unique_ptr。如果这个sonPtr是假的（这个指针没有管理对象，也就是说Son是不存在的），那么调用release()的时候就会返回nullptr。 先来看一段代码： 1#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std; &#x2F;&#x2F;不提倡int main() &#123; unique_ptr&lt;string&gt; Dad&#123;make_unique&lt;string&gt;(&quot;Son&quot;)&#125;; unique_ptr&lt;string&gt; OldWang&#123;Dad&#125;;&#125; 根本就过不了编译！试图把unique_ptr赋值给另一个unique_ptr在编译时就会出错！ 说一句题外话：其具体实现方法是重载了unique_ptr的拷贝构造函数，unique_ptr的定义中有一句： unique_ptr(const unique_ptr&amp;) = delete; 所以调用它的时候是会出错的。 再来看一段代码： 1#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std; &#x2F;&#x2F;不提倡int main() &#123; unique_ptr&lt;string&gt; Dad&#123;make_unique&lt;string&gt;(&quot;Son&quot;)&#125;; cout &lt;&lt; &quot;Dad owns &quot; &lt;&lt; (Dad ? *Dad : &quot;nothing&quot;) &lt;&lt; endl; unique_ptr&lt;string&gt; OldWang&#123;Dad.release()&#125;; cout &lt;&lt; &quot;Dad owns &quot; &lt;&lt; (Dad ? *Dad : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; &quot;OldWang owns &quot; &lt;&lt; (OldWang ? *OldWang : &quot;nothing&quot;) &lt;&lt; endl;&#125; 上面有一个用法，就是直接把unique_ptr转换成bool值来判断其是否为空。 那么这段程序的输出，不出所料的是： Dad owns Son Dad owns nothing OldWang owns Son 那么如果这样呢？（差别仅仅是Dad为nullptr） 1#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std; &#x2F;&#x2F;不提倡int main() &#123; unique_ptr&lt;string&gt; Dad&#123;nullptr&#125;; cout &lt;&lt; &quot;Dad owns &quot; &lt;&lt; (Dad ? *Dad : &quot;nothing&quot;) &lt;&lt; endl; unique_ptr&lt;string&gt; OldWang&#123;Dad.release()&#125;; cout &lt;&lt; &quot;Dad owns &quot; &lt;&lt; (Dad ? *Dad : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; &quot;OldWang owns &quot; &lt;&lt; (OldWang ? *OldWang : &quot;nothing&quot;) &lt;&lt; endl;&#125; 那么调用Dad.release()后就得到了一个空指针。 显然输出将会变成： Dad owns nothing Dad owns nothing OldWang owns nothing 2、怎么使用shared_ptr？ 接下来让我们看shared_ptr，了解了unique_ptr之后，shared_ptr的使用就显得不陌生了，具体使用时，同样需要用到make函数make_shared()，shared_ptr和unique_ptr的不同之处它在于是可以共享的，它可以赋值给其他shared_ptr，分享所有权。 看下面这段代码： 1#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;int main() &#123; shared_ptr&lt;string&gt; Dad&#123;make_shared&lt;string&gt;(&quot;PS4&quot;)&#125;; shared_ptr&lt;string&gt; Son&#123;nullptr&#125;; cout &lt;&lt; &quot;Dad owns &quot; &lt;&lt; (Dad ? *Dad : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; &quot;Son owns &quot; &lt;&lt; (Son ? *Son : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; endl; Son &#x3D; Dad; cout &lt;&lt; &quot;Dad owns &quot; &lt;&lt; (Dad ? *Dad : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; &quot;Son owns &quot; &lt;&lt; (Son ? *Son : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; endl; Dad &#x3D; nullptr; cout &lt;&lt; &quot;Dad owns &quot; &lt;&lt; (Dad ? *Dad : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; &quot;Son owns &quot; &lt;&lt; (Son ? *Son : &quot;nothing&quot;) &lt;&lt; endl;&#125; 这段代码的输出会是： Dad owns PS4 Son owns nothing Dad owns PS4 Son owns PS4 Dad owns nothing Son owns PS4 可以看出，shared_ptr的用法和unique_ptr的用法比较相似，只不过可以共享对指向对象的所有权而已。 如果有多个shared_ptr指向某对象，则在最后一个指针过期时才释放该对象，这个功能在实现的时候运用到了引用计数，即跟踪引用特定对象的智能指针数，例如：赋值给新指针时，计数将+1，指针过期时，计数将-1，当计数为0时，该特定对象将会被delete。 ３、怎么使用weak_ptr？ 我们需要从shared_ptr构造一个weak_ptr，也就是说有weak_ptr就肯定有shared_ptr，如果要使用weak_ptr所指向的对象，我们需要调用lock()函数，这个函数会返回所指对象的shared_ptr（在对象被销毁后就会得到空的share_ptr）。 weak_ptr还有expired()函数来取得它所指向的对象是否还存在的bool值，expired意为期满的，所以若返回值为真，则所指对象已被销毁，反之所指对象仍存在。这个函数存在的意义在于如果仅仅是为了判断对象是否健在，那么不需要调用lock()函数。 来看下面这段代码： 1#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std; &#x2F;&#x2F;不提倡int main() &#123; shared_ptr&lt;string&gt; AccountOwner&#123;make_shared&lt;string&gt;(&quot;Account&quot;)&#125;; weak_ptr&lt;string&gt; AccountThief&#123;AccountOwner&#125;; cout &lt;&lt; &quot;AccountOwner owns &quot; &lt;&lt; (AccountOwner ? *AccountOwner : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; &quot;AccountThief can use &quot; &lt;&lt; (!AccountThief.expired() ? *AccountThief.lock() : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; endl; AccountOwner &#x3D; nullptr; cout &lt;&lt; &quot;AccountOwner owns &quot; &lt;&lt; (AccountOwner ? *AccountOwner : &quot;nothing&quot;) &lt;&lt; endl; cout &lt;&lt; &quot;AccountThief can use &quot; &lt;&lt; (!AccountThief.expired() ? *AccountThief.lock() : &quot;nothing&quot;) &lt;&lt; endl;&#125; 这段代码的输出将会是： AccountOwner owns Account AccountThief can use Account AccountOwner owns nothing AccountThief can use nothing weak_ptr的用法可以从这段代码中窥见一斑。 4、如何选取智能指针？ 上面介绍了三种智能指针，那么什么时候使用哪种呢？先来看一下shared_ptr和unique_ptr的使用场景，weak_ptr稍后再谈。 如果程序要使用多个指向同一个对象的指针，应选择 1shared_ptr 。这样的情况包括： 有一个指针数组，并使用一些辅助指针来标识特定的元素，如最大和最小（需要被赋值指向特定元素）。 两个对象都包含指向第三个对象的指针。 STL容器包含指针。 …… 如果程序不需要多个指向同一个对象的指针，则可使用unique_ptr，还有如果某函数使用new分配了内存，并返回指向该内存的指针，那么返回一个unique_ptr会是一个很好的选择。 有兴趣可以了解一下单例模式，并且想想其中的instance需要用哪种智能指针？ 四、auto_ptr为什么被抛弃了？ 首先来看一下auto_ptr的概念，auto_ptr是在C++11标准前使用的智能指针，虽然也建立了所有权的概念，但是定位不够明确，一个auto_ptr（例如oldPtr）能够赋值给其他auto_ptr（例如newPtr），但是oldPtr对指向对象（例如Object）的所有权将被newPtr剥夺，虽然这将避免oldPtr和newPtr各自调用一次Object的析构函数，但是再次使用oldPtr的时候会导致难以预料的结果，因为它不再指向有效的数据。这样看看，auto_ptr是不是同时具有了shared_ptr的赋值功能，以及unique_ptr对对象的独占所有权？所以使用不当会导致各种问题，有的时候还会难以发现。因此使用unique_ptr比使用auto_ptr更加安全，在编译时就可以避免非法的赋值操作，如果想要分享所有权，那很自然的就应该使用shared_ptr。 五、智能指针注意事项 我们不能把并不指向堆内存的指针赋值给智能指针，试想delete一个指向栈内存的指针会发生什么？智能指针还没有智能到自动分辨堆上对象和栈上对象。 unique_ptr和shared_ptr都有get()函数，能在不放弃所有权的情况下返回所指向对象的普通指针。 unique_ptr和shared_ptr还有reset()函数，效果相当于把nullptr赋值给它们。 智能指针的内存泄漏：千万不要以为智能指针就不会导致内存泄漏了。现在我们来看一段代码： 1#include &lt;memory&gt;using namespace std; &#x2F;&#x2F;不提倡class foo &#123; public: shared_ptr&lt;foo&gt; father;&#125;;int main() &#123; shared_ptr&lt;foo&gt; a&#123;make_shared&lt;foo&gt;()&#125;; shared_ptr&lt;foo&gt; b&#123;make_shared&lt;foo&gt;()&#125;; a-&gt;father &#x3D; b; b-&gt;father &#x3D; a;&#125; 这种情况下两个对象都分别被两个shared_ptr所指，一个是a和b-&gt;father，一个是b和a-&gt;father，当函数执行完以后，虽然a和b被析构，但是原来的a-&gt;father和b-&gt;father（对象自身含有的指针）仍然指着这两个对象，也就是说在这种情况下，一个对象的智能指针通过某种路径的一连串智能指针最终指向了自身，最终构成了一个环，这个对象就永远不会被自动释放了，这就是智能指针会造成的内存泄漏，那么为了避免这种情况，就轮到了我们的weak_ptr出场了。将上述类foo中的father替换成weak_ptr类型，就可以既实现相同的效果（当然取得对象的时候要用lock()），又避免了内存泄漏。 这种误用导致的问题，在链表中比较常见，比如双向链表、循环链表等等，又比如说需要记录父节点的树，在这些情况下，会出现某对象内指针指向的对象内的指针指向自己的情况，使用shared_ptr就会引发内存泄漏，这是要务必小心的。 不要把智能指针作为节省delete语句的工具，它们本身就是用来表示所有权关系的，使用的时候还是要从所有权的角度进行分析。 六、总结 智能指针给程序设计带来了极大的方便，使得“别忘记delete”不再那么困扰程序员，并且解决了某些场景下不知如何安放delete的问题，使得程序员能够高效而安全地管理堆内存","categories":[{"name":"C++","slug":"C","permalink":"http://yoursite.com/categories/C/"}],"tags":[]},{"title":"Cartographer-[1]概述","slug":"Cartographer-Google相关/Cartographer-1-概述","date":"2020-03-07T15:28:57.000Z","updated":"2020-03-16T03:56:50.000Z","comments":true,"path":"2020/03/07/Cartographer-Google相关/Cartographer-1-概述/","link":"","permalink":"http://yoursite.com/2020/03/07/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer-1-%E6%A6%82%E8%BF%B0/","excerpt":"","text":"1. Cartographer-[1]概述 2. 整体架构 Cartographer可以看作是两个独立的，但相互关联的子系统。 3. 数据结构 整个库采用protobuf数据格式，可参见configuration cartographer.common.proto.CeresSolverOptions cartographer.mapping.pose_graph.proto.ConstraintBuilderOptions cartographer.mapping.pose_graph.proto.OptimizationProblemOptions cartographer.mapping.proto.MapBuilderOptions cartographer.mapping.proto.MotionFilterOptions cartographer.mapping.proto.PoseGraphOptions cartographer.mapping.proto.TrajectoryBuilderOptions cartographer.mapping_2d.proto.LocalTrajectoryBuilderOptions cartographer.mapping_2d.proto.RangeDataInserterOptions cartographer.mapping_2d.proto.SubmapsOptions cartographer.mapping_2d.scan_matching.proto.CeresScanMatcherOptions cartographer.mapping_2d.scan_matching.proto.FastCorrelativeScanMatcherOptions cartographer.mapping_2d.scan_matching.proto.RealTimeCorrelativeScanMatcherOptions cartographer.mapping_3d.proto.LocalTrajectoryBuilderOptions cartographer.mapping_3d.proto.RangeDataInserterOptions cartographer.mapping_3d.proto.SubmapsOptions cartographer.mapping_3d.scan_matching.proto.CeresScanMatcherOptions cartographer.mapping_3d.scan_matching.proto.FastCorrelativeScanMatcherOptions cartographer.sensor.proto.AdaptiveVoxelFilterOptions 4. 标准定义 4.1. Frames(坐标系) global map frame 这是表示全局 SLAM 结果的坐标系。 它是包含所有闭环和优化结果的固定地图坐标系。 当新的优化结果出现时，该帧与其他帧之间的转换可以跳转。 它的 z 轴指向上方，也就是重力加速度矢量指向-z 方向，也就是说加速计测量的重力分量是 + z 方向 local map frame 局部SLAM结果的坐标系，不包括闭环以及位姿BA优化，对于给定某个时间点，该帧与全局地图之间的变换可能会发生变化，但是该帧和其他帧的变换不会发生变化。 submap frame 每个子图都有一个单独的坐标系 tracking frame(跟踪坐标系) 传感器数据表示的坐标系，不固定 gravity-aligned frame 重力对准坐标系，只在2D中使用，与跟踪坐标系有相同位置，但是坐标系方向不一致，类似于导航坐标系 4.2. Transforms (变换) local_pose(局部姿态) 将数据从跟踪坐标系(Tracking frame)或者子图坐标系转换到local map frame的变换 global_pose(全局位姿) 将数据从跟踪坐标系(Tracking frame)或者子图坐标系转换到全局坐标系的变换 local_submap_pose(局部子图位姿) 将子图坐标系中的数据转换到local map 坐标系的变换 global_submap_pose(全局子图位姿) 将子图坐标系中的数据转换到全局地图坐标系 5. 文件目录结构 整个cartographer_ros工程目录 1234.├── cartographer #cartographer核心C++库├── cartographer_ros #基于ROS的封装调用└── ceres-solver #优化器 5.1. cartographer核心库 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209.├── BUILD.bazel├── cloud //建图服务器相关│ ├── BUILD.bazel│ ├── client│ ├── internal│ ├── map_builder_server_interface.cc│ ├── map_builder_server_interface.h│ ├── map_builder_server_main.cc│ ├── map_builder_server_options.cc│ ├── map_builder_server_options.h│ ├── metrics│ └── proto├── common //通用库│ ├── blocking_queue.h #阻塞│ ├── blocking_queue_test.cc│ ├── ceres_solver_options.cc #优化器选项│ ├── ceres_solver_options.h│ ├── config.h.cmake│ ├── configuration_file_resolver.cc│ ├── configuration_file_resolver.h│ ├── configuration_files_test.cc│ ├── fixed_ratio_sampler.cc │ ├── fixed_ratio_sampler.h #采样器│ ├── fixed_ratio_sampler_test.cc│ ├── histogram.cc│ ├── histogram.h #直方图│ ├── internal│ ├── lockless_queue.h #锁│ ├── lockless_queue_test.cc│ ├── lua.h #lua配置文件读取│ ├── lua_parameter_dictionary.cc│ ├── lua_parameter_dictionary.h│ ├── lua_parameter_dictionary_test.cc│ ├── lua_parameter_dictionary_test_helpers.h│ ├── make_unique.h #基于C++11实现的make_unique│ ├── math.h #数学转换库│ ├── math_test.cc│ ├── mutex.h #线程锁│ ├── optional.h│ ├── optional_test.cc│ ├── port.h #压缩、解压库│ ├── proto│ ├── rate_timer.h │ ├── rate_timer_test.cc│ ├── task.cc│ ├── task.h│ ├── task_test.cc│ ├── thread_pool.cc│ ├── thread_pool.h #线程池│ ├── thread_pool_test.cc│ ├── time.cc│ └── time.h #时间转换├── ground_truth│ ├── autogenerate_ground_truth_main.cc│ ├── compute_relations_metrics_main.cc│ ├── proto│ ├── relations_text_file.cc│ └── relations_text_file.h├── io│ ├── color.cc│ ├── color.h│ ├── coloring_points_processor.cc│ ├── coloring_points_processor.h│ ├── counting_points_processor.cc│ ├── counting_points_processor.h│ ├── draw_trajectories.cc│ ├── draw_trajectories.h│ ├── fake_file_writer.cc│ ├── fake_file_writer.h│ ├── fake_file_writer_test.cc│ ├── file_writer.cc│ ├── file_writer.h│ ├── fixed_ratio_sampling_points_processor.cc│ ├── fixed_ratio_sampling_points_processor.h│ ├── frame_id_filtering_points_processor.cc│ ├── frame_id_filtering_points_processor.h│ ├── hybrid_grid_points_processor.cc│ ├── hybrid_grid_points_processor.h│ ├── image.cc│ ├── image.h│ ├── intensity_to_color_points_processor.cc│ ├── intensity_to_color_points_processor.h│ ├── internal│ ├── migrate_serialization_format_main.cc│ ├── min_max_range_filtering_points_processor.cc│ ├── min_max_range_filtering_points_processor.h│ ├── null_points_processor.h│ ├── outlier_removing_points_processor.cc│ ├── outlier_removing_points_processor.h│ ├── pcd_writing_points_processor.cc│ ├── pcd_writing_points_processor.h│ ├── ply_writing_points_processor.cc│ ├── ply_writing_points_processor.h│ ├── points_batch.cc│ ├── points_batch.h│ ├── points_processor.h│ ├── points_processor_pipeline_builder.cc│ ├── points_processor_pipeline_builder.h│ ├── points_processor_pipeline_builder_test.cc│ ├── probability_grid_points_processor.cc│ ├── probability_grid_points_processor.h│ ├── proto_stream.cc│ ├── proto_stream_deserializer.cc│ ├── proto_stream_deserializer.h│ ├── proto_stream_deserializer_test.cc│ ├── proto_stream.h│ ├── proto_stream_interface.h│ ├── proto_stream_test.cc│ ├── serialization_format_migration.cc│ ├── serialization_format_migration.h│ ├── serialization_format_migration_test.cc│ ├── submap_painter.cc│ ├── submap_painter.h│ ├── xray_points_processor.cc│ ├── xray_points_processor.h│ ├── xyz_writing_points_processor.cc│ └── xyz_writing_points_processor.h├── mapping│ ├── 2d│ ├── 3d│ ├── detect_floors.cc│ ├── detect_floors.h│ ├── grid_interface.h│ ├── id.h│ ├── id_test.cc│ ├── imu_tracker.cc│ ├── imu_tracker.h│ ├── imu_tracker_test.cc│ ├── internal│ ├── local_slam_result_data.h│ ├── map_builder.cc│ ├── map_builder.h│ ├── map_builder_interface.h│ ├── map_builder_test.cc│ ├── pose_extrapolator.cc│ ├── pose_extrapolator.h│ ├── pose_extrapolator_test.cc│ ├── pose_graph.cc│ ├── pose_graph.h│ ├── pose_graph_interface.h│ ├── pose_graph_test.cc│ ├── pose_graph_trimmer.cc│ ├── pose_graph_trimmer.h│ ├── pose_graph_trimmer_test.cc│ ├── probability_values.cc│ ├── probability_values.h│ ├── probability_values_test.cc│ ├── proto│ ├── range_data_inserter_interface.cc│ ├── range_data_inserter_interface.h│ ├── submaps.h│ ├── submaps_test.cc│ ├── trajectory_builder_interface.cc│ ├── trajectory_builder_interface.h│ ├── trajectory_node.cc│ ├── trajectory_node.h│ └── trajectory_node_test.cc├── metrics│ ├── counter.cc│ ├── counter.h│ ├── family_factory.h│ ├── gauge.cc│ ├── gauge.h│ ├── histogram.cc│ ├── histogram.h│ ├── register.cc│ └── register.h├── sensor│ ├── collator_interface.h│ ├── compressed_point_cloud.cc│ ├── compressed_point_cloud.h #点云压缩│ ├── compressed_point_cloud_test.cc│ ├── data.h #根据传感器id，进行数据封装│ ├── fixed_frame_pose_data.cc│ ├── fixed_frame_pose_data.h #固定坐标系的数据如gps│ ├── imu_data.cc│ ├── imu_data.h #imu数据结构│ ├── internal #进一步实现│ ├── landmark_data.cc│ ├── landmark_data.h #路标点数据结构│ ├── landmark_data_test.cc│ ├── map_by_time.h #按时间戳进行轨迹拼接？│ ├── map_by_time_test.cc│ ├── odometry_data.cc│ ├── odometry_data.h #里程计数据结构│ ├── point_cloud.cc│ ├── point_cloud.h #点云数据结构│ ├── point_cloud_test.cc│ ├── proto│ ├── range_data.cc│ ├── range_data.h #激光数据储存结构│ ├── range_data_test.cc│ ├── timed_point_cloud_data.cc│ └── timed_point_cloud_data.h #带时间戳的点云└── transform //2D、3D变换 ├── proto ├── rigid_transform.cc #定义刚体变换2D/3D ├── rigid_transform.h ├── rigid_transform_test.cc ├── rigid_transform_test_helpers.h ├── timestamped_transform.cc #带时间戳的刚体变换数据结构 ├── timestamped_transform.h ├── transform.cc #变换，2D/3D数据结构相互转换，proto/Eigen数据转换 ├── transform.h ├── transform_interpolation_buffer.cc #根据时间戳线性插值 ├── transform_interpolation_buffer.h ├── transform_interpolation_buffer_test.cc └── transform_test.cc","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"3D-NDT-匹配算法","slug":"Autoware.ai/3D-NDT-匹配算法","date":"2020-03-06T02:56:45.000Z","updated":"2020-03-07T15:27:43.000Z","comments":true,"path":"2020/03/06/Autoware.ai/3D-NDT-匹配算法/","link":"","permalink":"http://yoursite.com/2020/03/06/Autoware.ai/3D-NDT-%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95/","excerpt":"","text":"1. 3D-正态分布变换(The Normal Distributions Transform) 前面探讨过2D-NDT匹配算法的原理和推导以及代码阅读，接下来将这个思想扩展到3D，这个工作可参见如下博士论文:The Three-Dimensional Normal-Distributions Transform— an Efficient Representation for Registration,Surface Analysis, and Loop Detection 该论文中，关于NDT的描述，从第六章开始 2. The normal-distributionstransform 使用点云来表示表面有许多限制，举例如点云不包含关于表面特征(如方向、平滑度或孔洞)的显式信息，根据传感器的配置，点云也可能是低效的，需要不必要的大量存储，为了在远离传感器位置的地方获得足够的样本分辨率，通常需要以一种从传感器附近的表面产生大量冗余数据的方式配置传感器。 正态分布变换可以看做是描述平面的一种方法，首先被 Biberand和 Straße在2003年提出用于2D扫描匹配。后来与Sven Fleck 联合，讨论了在扫描匹配和建图方面的扩展。该变换将点云映射到平滑的表面表示，描述为一组局部概率密度函数(PDFs)，每一个都描述了一段表面的形状。 该算法的第一步是将扫描程序占用的空间细分为网格单元格(在2D情况下为正方形，在3D情况下为立方体)。为每一个cell都计算一个概率密度函数PDF。每一个cell的概率密度函数PDF可以被解释为生成一个在cell里面的平面点\\(\\vec{x}\\)的过程。换句话说，它假设\\(\\vec{x}\\)的位置是被这个分布采样出来的。 假设参考点的位置是由一个D维的正态分布随机过程产生的，那么\\(\\vec{x}\\)被观测的可能性是： 其中，\\(\\vec{\\mu}\\)和\\(\\Sigma\\)分别代表参考平面点在\\(\\vec{x}\\)所在的cell的这个分布的均值和协方差矩阵。 前面的系数可以整合成一个常数，常用\\(c_0\\)代替，那么均值和协方差可以表示成如下： 其中，\\(\\vec{y}_{k=1,\\cdots,m}\\)是参考帧在这个cell里面的扫描点。 NDT 给出了点云的可微分的平滑表示，每一个概率密度函数PDF可以看做是可以看作是局部表面的近似化，描述表面的位置以及它的方向和平滑度。 一帧2D扫描以及敌营的NDT如下图6.1，另外图6.2展示了一帧在矿洞隧道扫描的NDT 下面从单变量正态分布讲起，一维的随机变量\\(x\\)具有期望\\(\\mu\\)，该不确定性使用\\(\\sigma\\)来表示： 在多维的情况下，协方差矩阵的对角元素表示每个变量的方差，非对角元素表示变量的协方差，下图6.3展示了一维、二维、三维的正态分布 在二维和三维的情况下，可以通过协方差矩阵的特征向量和特征值来评估曲面的方向和平滑度 特征向量描述了分布的主成分，即与各变量协方差的主导方向对应的正交向量的集合 根据方差的比例，二维正态分布可以是点状的(如果方差相似的话)，也可以是线状的(如果一个变量的方差比另外一个大很多)，又或者是两者之间 在三维情况下，如图6.4展示的 正态分布可以描述点或球(如果方差的大小在各个方向上是相似的)， 或者是一条线(如果一个方向的方差远远大于另两个方向)， 或者是一个平面((如果一个方向的方差比另两个方向的方差小得多)) 3. NDT扫描匹配 当使用NDT进行扫描配准时，目标是找到当前扫描点最大可能位于参考扫描面上的位置。 需要被优化的参数有：当前帧扫描的位姿估计的旋转和平移，可以使用向量\\(\\vec{p}\\)来表示(pose)。 当前帧扫描可以使用点云\\(\\mathcal{X}={\\vec{x_1},\\cdots,\\vec{x_n}}\\)来表示。假设存在空间变换函数\\(T(\\vec{p},\\vec{x})\\)，可以把当前帧坐标系下的点\\(\\vec{x}\\)通过当前位姿\\(\\vec{p}\\)映射到世界坐标系。对扫描点给出一些概率密度函数PDF\\(p\\vec{x}\\)，那么最佳的位姿\\(\\vec{p}\\)应该是使下面的似然函数最大化： 或者最小化带负号的似然函数 概率密度PDF不一定非得是正态分布，任何一种局部捕获表面点结构并对异常值具有鲁棒性的pdf都是合适的。当点远离均值时，正态分布的负对数可能是无限的增加，因此，扫描数据中的异常值可能对结果有很大的影响。 Biber, Fleck,and Straße的工作中，使用了高斯模型和均匀分布的混合， 其中,\\(p_o\\)是预计outiler的比率。使用这个函数，outliers对于函数的影响是有限的，这个结果如下图6.5展示。常数\\(c_1\\)和\\(c_2\\)can be determined by requiring that the probability mass of ̄p(~x) equals onewithin the space spanned by a cell. 要优化的对数似然函数具有这样的形式：\\(-\\log(c_1 \\exp (-[(\\vec{x}-\\vec{\\mu})^T\\Sigma^{-1}(\\vec{x_1}-\\vec{\\mu})]/2)+c2)\\)，它们没有简单的一阶和二阶导数，然而，图6.5(b)表明，对数似然函数又可以近似为高斯函数。即可以使用高斯模型\\(\\tilde{p}(x)=d_1 \\exp (- d_2 x^2 / (2 \\sigma^2))+d_3\\)来近似，其中，参数\\(d_1,d_2,d_3\\)需要使用下式来计算得到： 使用这种高斯近似，当前帧扫描的一个点对NDT评分函数的影响是： 其中，\\(\\mu_k\\)和\\(\\Sigma_k\\)是点\\(\\vec{x_k}\\)所在的cell的NDT变换的均值和方差。这个NDT评分函数具有比式6.7更加简单的微分形式，但在优化时仍然表现出相同的一般属性。注意，方程6.9中省略了\\(d_3\\)项，当使用NDT进行扫描匹配时，它不是必需的，因为它只是给评分函数增加一个常量偏移量。 给定一个点集\\(\\mathcal{X}={\\vec{x_1},\\cdots,\\vec{x_n}}\\)，以及一个位姿\\(\\vec{p}\\)和一个变换函数\\(T(\\vec{p},\\vec{x})\\)，将点\\(\\vec{x}\\)使用位姿\\(\\vec{p}\\)进行变换，当前参数向量的NDT评分函数\\(s(\\vec{p})\\)为: 似然函数需要协方差矩阵的逆\\(\\Sigma^{-1}\\)。如果一个cell中的点是完全共面或共线的，则协方差矩阵是奇异的，不能求逆。在3D的情况下，由三个或更少的点组成的协方差矩阵总是奇异的。因此，PDFs仅计算包含5个以上点的cell，此外，需要警惕数值问题，为了防止协方差矩阵奇异，如果协方差矩阵\\(\\Sigma\\)最大的特征值\\(\\lambda_3\\)比其他两个特征值\\(\\lambda_1,\\lambda_2\\)大100倍，那么最小的特征值应该使用最大特征值的1/100来替换，即\\(\\lambda_j&#39;=\\lambda_3/100\\)。 牛顿迭代法通常求解增量方程\\(\\boldsymbol{H\\Delta \\vec{p}=-\\vec{g}}\\)，其中\\(\\boldsymbol{H}\\)和\\(g\\)是评分函数\\(s(\\vec{p})\\)的海森矩阵和梯度向量。求得的增量用来更新优化位姿变量,\\(\\vec{p}\\leftarrow\\vec{p}+\\Delta \\vec{p}\\) 简要来说，令\\(\\vec{x}_k&#39;\\equiv T(\\vec{p},\\vec{x}_k)-\\vec{\\mu}_k\\)，也就是\\(\\vec{x}_k‘\\)是点\\(\\vec{x}_k\\)变换之后的点。 那么梯度向量\\(\\vec{g}\\)中的每一个元素\\(g_i\\)可以如下表示： 海森矩阵\\(\\boldsymbol{H}\\)中的每个元素\\(H_{ij}\\)是 NDT评分函数的梯度(6.12)和Hessian(6.13)以相同的方式表示，无论匹配是在2D还是3D中执行。它们同样独立于所使用的转换表示，另一方面，方程6.12和6.13中\\(\\vec{x}&#39;\\)的一阶和二阶偏导数依赖于变换函数\\(T()\\)。 总结： 下面的算法2流程，描述了整个NDT的匹配过程 4. 3D-NDT 2D与3D的NDT配准的主要区别在于空间变换函数\\(T(\\vec{p}，\\vec{x})\\)及其偏导数。在三维的情况下，有几种可能的方法来表示旋转。 在之前对3D-NDT的研究中[63,66]，使用了轴/角旋转表示。然而，这样做会给优化问题增加一个额外的变量，并且需要额外的约束来保持旋转轴对称的单位长度，牛顿优化法是一种迭代法，在每次牛顿迭代后，只需将旋转表示重新归一化，就可以实现对单位轴的约束。然而，当牛顿更新方向偏离到位姿参数空间的不可行区域时，这种策略仍然会导致问题，这也许可以解释早期结果中的一些不一致。为了完整起见，附录中提供了轴/角变换函数及其导数。 接下来，3D欧拉角用于描述旋转，尽管这种旋转表示法有潜在的问题。(ps: 个人想法：为什么不用李群李代数来表示位姿？se3)。优点是数值优化过程不需要约束，导数稍微简单一些，这样做会产生Gimbal Lock的风险，这以为着在大角度的情况下，配准可能会失效。利用欧拉角，有六个转换参数需要优化:三个平移量，三个旋转量，可使用6维向量表示\\(\\vec{p}_6=[t_x,t_y,t_z,\\phi_x,\\phi_y,\\phi_z]^T\\)。 使用(z-y-x)321欧拉角顺序，其旋转矩阵可参见：MIT材料 上图中，旋转矩阵\\(T_{0,3}\\)表示了从载体坐标系到参考坐标系的旋转变换 因此，使用欧拉角的变换函数为： 描述了从当前帧的点到参考帧的变换。 上式6.17对第i维优化变量的一阶偏到对于与雅克比\\(\\frac{\\delta T_E(\\vec{p}_6,\\vec{x})}{\\delta p_i}\\)矩阵的第i列，雅克比矩阵可以写成如下形式：(一般在SLAM里面，通常写成行的形式，也就是下面的\\(J_E\\)的转置形式，即\\(J_E^T\\)) 那么二阶导\\(\\frac{\\delta ^2 T_E(\\vec{p}_6,\\vec{x})}{\\delta p_i \\delta p_j}\\) 如果旋转角度比较小，那么利用下面的小角度三角近似法可以大大简化计算 对于小于\\(10\\degree\\)的角，可以认为这些近似是精确的，对于正弦函数，在角度为\\(14\\degree\\)时近似误差达到1%，对于余弦函数，同样的误差发生在\\(8.2\\degree\\)上。利用小角度方法计算变换函数及其导数的速度较快，但是，与在某些情况下使用6.17方程相比，用近似进行配准的鲁棒性要差一些。附录B.1提供了相应的小角度近似值变换函数，在时间要求严格的应用中，建议采用近似公式，尽管差别不大。 用于非线性优化的许多应用，通常实用Hessian的数值近似来代替严格Hessian，因为海森矩阵是很难进行解析计算的，因为计算成本太高。然而，由于NDT评分函数的海森矩阵可以被分析计算，并且它的大部分元素为零，不使用近似值反而是有利的。 5. 一些测试评估 结论 Cell Size： 在使用NDT时，选择合适的Cell大小是很重要的，如果Cell太大，单个Cell的结构就不能通过实用单个高斯模型很好地描述，如果Cell太小，那么得到的高斯模型很有可能受噪声影响很大。 对于稀疏采样的点云，如果Cell很小，每个Cell内的点可能太少，无法计算出可靠的密度函数 最佳单元格大小主要取决于输入数据的规模，如果使用Sick激光雷达，Cell的尺寸应该在1m到3m比较好。如果使用3D相机，由于传感器捕获的视野很窄，距离很短，使用这么大的Cell显然是不合适的，通过实验发现，这种情况下Cell的尺寸应该选择0.5m到0.75m 对于具有大规模特征的扫描对，可以使用较大的单元而不牺牲精度 最好的Cell尺寸取决于扫描的范围以及扫描中结构的数量，对于lidars在移动机器人应用程序中获取的尺度扫描，1m到2mare之间的Cell通常是最佳选择，对于困难的扫描，没有突出的结构，建议使用较小的Cell而不是较大的Cell。平移估计通常比旋转更受到超大Cell的影响。当Cell较大时，运行时间通常稍微短一些(因此更少)，当单元格更小时，一些额外的时间花在初始化单元格上，但是执行实际优化时每次迭代的时间不依赖于单元格的大小。 6. Code And Result 基于PCL的NDT匹配算法示例代码如下 main.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;pcl/io/pcd_io.h&gt;#include &lt;pcl/point_types.h&gt;#include &lt;pcl/registration/ndt.h&gt;#include &lt;pcl/filters/approximate_voxel_grid.h&gt;#include &lt;pcl/visualization/pcl_visualizer.h&gt;using namespace std::chrono_literals;intmain (int argc, char** argv)&#123; // Loading first scan of room. // 加载房间的第一帧扫描 pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr target_cloud (new pcl::PointCloud&lt;pcl::PointXYZ&gt;); if (pcl::io::loadPCDFile&lt;pcl::PointXYZ&gt; (\"/home/msi/laser_scan_macher/3D_NDT_Matching_Pcl/room_scan1.pcd\", *target_cloud) == -1) &#123; PCL_ERROR (\"Couldn't read file room_scan1.pcd \\n\"); return (-1); &#125; std::cout &lt;&lt; \"Loaded \" &lt;&lt; target_cloud-&gt;size () &lt;&lt; \" data points from room_scan1.pcd\" &lt;&lt; std::endl; // Loading second scan of room from new perspective. // 加载从新视角得到的房间的第二帧扫描作为输入 pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr input_cloud (new pcl::PointCloud&lt;pcl::PointXYZ&gt;); if (pcl::io::loadPCDFile&lt;pcl::PointXYZ&gt; (\"/home/msi/laser_scan_macher/3D_NDT_Matching_Pcl/room_scan2.pcd\", *input_cloud) == -1) &#123; PCL_ERROR (\"Couldn't read file room_scan2.pcd \\n\"); return (-1); &#125; std::cout &lt;&lt; \"Loaded \" &lt;&lt; input_cloud-&gt;size () &lt;&lt; \" data points from room_scan2.pcd\" &lt;&lt; std::endl; // Filtering input scan to roughly 10% of original size to increase speed of registration. // 将输入的扫描进行降采样滤波到原始尺寸的大概10%以提高匹配的速度。 pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr filtered_cloud (new pcl::PointCloud&lt;pcl::PointXYZ&gt;); pcl::ApproximateVoxelGrid&lt;pcl::PointXYZ&gt; approximate_voxel_filter; // 设置八叉树网格大小 approximate_voxel_filter.setLeafSize (0.2, 0.2, 0.2); approximate_voxel_filter.setInputCloud (input_cloud); approximate_voxel_filter.filter (*filtered_cloud); std::cout &lt;&lt; \"Filtered cloud contains \" &lt;&lt; filtered_cloud-&gt;size () &lt;&lt; \" data points from room_scan2.pcd\" &lt;&lt; std::endl; // Initializing Normal Distributions Transform (NDT). // 初始化正态分布变换（NDT） pcl::NormalDistributionsTransform&lt;pcl::PointXYZ, pcl::PointXYZ&gt; ndt; // Setting scale dependent NDT parameters // Setting minimum transformation difference for termination condition. // 设置终止迭代的参数 ndt.setTransformationEpsilon (0.01); // Setting maximum step size for More-Thuente line search. // 设置More-Thuente线搜索最大步长 ndt.setStepSize (0.1); // Setting Resolution of NDT grid structure (VoxelGridCovariance). // 设置NDT网格结构的分辨率(尺寸)（VoxelGridCovariance） ndt.setResolution (1.0); // Setting max number of registration iterations. // 设置匹配迭代的最大次数 ndt.setMaximumIterations (35); // Setting point cloud to be aligned. // 设置要配准的点云(也就是新的一帧扫描) ndt.setInputSource (filtered_cloud); // Setting point cloud to be aligned to. // 设置参考帧扫描，也就是目标 ndt.setInputTarget (target_cloud); // Set initial alignment estimate found using robot odometry. // 使用里程计作为初始值 Eigen::AngleAxisf init_rotation (0.6931, Eigen::Vector3f::UnitZ ()); Eigen::Translation3f init_translation (1.79387, 0.720047, 0); Eigen::Matrix4f init_guess = (init_translation * init_rotation).matrix (); // Calculating required rigid transform to align the input cloud to the target cloud. // 开始运算，进行匹配 pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr output_cloud (new pcl::PointCloud&lt;pcl::PointXYZ&gt;); ndt.align (*output_cloud, init_guess); std::cout &lt;&lt; \"Normal Distributions Transform has converged:\" &lt;&lt; ndt.hasConverged () &lt;&lt; \" score: \" &lt;&lt; ndt.getFitnessScore () &lt;&lt; std::endl; // Transforming unfiltered, input cloud using found transform. // 使用优化得到的变换T，变换没有滤波的点云 pcl::transformPointCloud (*input_cloud, *output_cloud, ndt.getFinalTransformation ()); // Saving transformed input cloud. // 保存 pcl::io::savePCDFileASCII (\"room_scan2_transformed.pcd\", *output_cloud); // Initializing point cloud visualizer pcl::visualization::PCLVisualizer::Ptr viewer_final (new pcl::visualization::PCLVisualizer (\"3D Viewer\")); viewer_final-&gt;setBackgroundColor (0, 0, 0); // Coloring and visualizing target cloud (red). // 目标点云（参考帧）红色 pcl::visualization::PointCloudColorHandlerCustom&lt;pcl::PointXYZ&gt; target_color (target_cloud, 255, 0, 0); viewer_final-&gt;addPointCloud&lt;pcl::PointXYZ&gt; (target_cloud, target_color, \"target cloud\"); viewer_final-&gt;setPointCloudRenderingProperties (pcl::visualization::PCL_VISUALIZER_POINT_SIZE, 1, \"target cloud\"); // Coloring and visualizing transformed input cloud (green). // 输入点云，第二帧(绿色) pcl::visualization::PointCloudColorHandlerCustom&lt;pcl::PointXYZ&gt; output_color (output_cloud, 0, 255, 0); viewer_final-&gt;addPointCloud&lt;pcl::PointXYZ&gt; (output_cloud, output_color, \"output cloud\"); viewer_final-&gt;setPointCloudRenderingProperties (pcl::visualization::PCL_VISUALIZER_POINT_SIZE, 1, \"output cloud\"); // Starting visualizer // 显示 viewer_final-&gt;addCoordinateSystem (1.0, \"global\"); viewer_final-&gt;initCameraParameters (); // Wait until visualizer window is closed. while (!viewer_final-&gt;wasStopped ()) &#123; viewer_final-&gt;spinOnce (100); std::this_thread::sleep_for(100ms); &#125; return (0);&#125; CMakeLists.txt 123456789101112131415cmake_minimum_required(VERSION 2.8)project(3D_NDT_Matching_Pcl)set(CMAKE_CXX_STANDARD 14)#PCLfind_package(PCL REQUIRED)include_directories($&#123;PCL_INCLUDE_DIRS&#125;)link_directories($&#123;PCL_LIBRARY_DIRS&#125;)add_definitions($&#123;PCL_DEFINITIONS&#125;)add_executable($&#123;PROJECT_NAME&#125; \"main.cpp\")target_link_libraries($&#123;PROJECT_NAME&#125; $&#123;PCL_LIBRARIES&#125;) 6.1. 结果 红色为参考帧，绿色为输入帧点云 6.1.1. 参数1 ， Cell分辨率为1m 可以看到，当Cell=1m的时候，对齐得比较好 6.1.2. 参数2 ， Cell尺寸 2m 粗看可发现基本对齐，但是有很多瑕疵的地方 细看边界，可以发现没有严格对齐 7. 扩展 Fixed discretisation Octree discretisation Iterative discretisation Adaptive clustering Linked cells Trilinear interpolation ... 8. 参考资料 The Three-Dimensional Normal-Distributions Transform— an Efficient Representation for Registration,Surface Analysis, and Loop Detection","categories":[{"name":"Autoware.ai","slug":"Autoware-ai","permalink":"http://yoursite.com/categories/Autoware-ai/"}],"tags":[]},{"title":"Question-About-Localization(定位相关问题)","slug":"Autoware.ai/QuestionAbout-Localization","date":"2020-03-05T13:15:18.000Z","updated":"2020-03-05T13:19:10.000Z","comments":true,"path":"2020/03/05/Autoware.ai/QuestionAbout-Localization/","link":"","permalink":"http://yoursite.com/2020/03/05/Autoware.ai/QuestionAbout-Localization/","excerpt":"","text":"1. Mapping/Localization 1.1. Why does mapping needed in the slam? In Autoware, localization(ndt_matching) and mapping(ndt_mapping) are completely separate functions. ndt_mapping is a function that create a map in a unknown environment from scratch so you don't need a map. On the other hand, ndt_matching is a localization function within a map so map is needed as a input of the function. 在 Autoware 中，定位(ndt-matching)和建图(ndt-mapping)是完全分离的函数。 Ndt建图是一个在未知环境中从头创建地图的函数。另一方面，ndt-matching是建图中的一个定位函数。 The reason why we need to match the scan and the existing map is, it is faster and more accurate than matching the current scan and the previous scans. Simultaneously localize and mapping using NDT can not be done in real-time so far. If you want to know about NDT algorithm, please refer to the following paper. 我们使用扫描和现有地图的进行匹配的原因是，它比匹配当前的扫描和以前的扫描更快、更准确。 利用NDT检测技术进行同时定位和映射目前还不能实时完成。 如果你想了解无损检测算法，请参阅以下论文Scan registration for autonomous mining vehicles using 3D‐NDT。 1.2. What is the relationship between the grid size of voxel grid filter and accuracy of localization? 体素网格滤波器的网格大小与定位精度之间有什么关系？ Theoretically, larger grid sizes decrease the accuracy of localization. 理论上，较大的网格尺寸会降低定位精度。 1.3. What criteria should be used to determine voxel grid size? 应该使用什么标准来确定体素网格大小？ Computation cost becomes smaller if you use larger voxel grid size. We use 2.0 meter by default because it keeps accuracy of localization and computation finishes in the measurement interval of the scan. 如果使用更大的体素网格大小，计算成本将变得更小。我们默认使用2.0米，因为它保持精确的定位和计算完成在测量间隔的扫描。 1.4. What is the difference between ndt_mapping and lazy ndt_mapping? lazy_ndt_mapping does not use all points for matching while ndt_mapping uses all the points as reference. lazy_ndt_mapping uses only three previous scans as reference by default. lazy_ndt_mapping is faster than ndt_mapping, but with lower accuracy. Lazy_ndt_mapping不使用所有点进行匹配，而 ndt_mapping使用所有点作为参考。 Lazy_ndt_mapping默认只使用前三次扫描作为引用。 Lazy_ndt_mapping比 ndt_mapping更快，但精度较低。 1.5. I just want to use ndt_mapping or icp_mapping with my own data only, instead of running Autoware everytime, but everytime I try to run ndt_mapping isolated, I get an error. 我想使用我自己的数据来进行ndt_mapping或icp_mapping，而不是运行 Autoware，但每次尝试单独运行ndt_mapping，出现错误 ndt_localizer package depends on runtime_manager package in relation to message generation. Therefore you need to build the all packages in Autoare using ./catkin_make_release in Autoware/ros directory. Ndt_Localization 包依赖于与消息生成相关的运行时管理器包。 因此，需要构建整个Autoware来生成这些消息。(using ./catkin_make_release in Autoware/ros directory.) 1.6. Can I use my '.pcap' file to run autoware mapping and then save the result? 我可以使用我的.Pcap文件运行autoware来建图，然后保存结果吗？ Yes. First, convert pcap to rosbag. http://answers.ros.org/question/213080/convert-raw-velodyne-vlp16-pcap-to-bagfile/ The rosbag includes the topic, velodyne_packets, so you have to convert the topic from /velodyne_packets to /points_raw using VLP-16 driver in Sensing tab. 是的。 首先，将.pcap转换为rosbag. Http://answers.ros.org/question/213080/convert-raw-velodyne-vlp16-pcap-to-bagfile/ 包 包含了主题 velodyne 数据包，所以你必须使用传感标签中的 VLP-16驱动程序将主题从 velodyne 数据包转换为 / points raw。 1.7. My map size is huge. Can I reduce the map size? 我的地图尺寸很大，我可以缩小地图尺寸吗？ Yes. You can reduce the file size using voxel grid filter. It is in the Map tab. 是的。 您可以使用体素网格过滤器减少文件大小。 它在 Map 选项卡中。 1.8. What is the difference between ndt_mapping and approximate_NDT_mapping? Ndt_mapping和近似_Ndt_mapping的区别是什么？ ndt_mapping loads all the pointcloud as map where approximate_ndt_mapping loads a portion of the current map and outputs PCDs only at certain distances. If you are going to create narrow range of map, use ndt_mapping. If you are going to create long distance of map, it is better to use approximate_ndt_mapping. The sample Moriyama map is created in another method called MMS(Mobile Mapping system) which is the product of Aisan Technology. ndt_mapping将所有的点云作为映射加载，其中approximate_ndt_mapping加载当前地图的一部分，只在特定的距离输出PCDs。 如果要创建小范围的地图，请使用 ndt_mapping。 如果要创建长距离的地图，最好使用approximate_ndt_mapping。 示例 Moriyama 地图是用另一种称为 MMS (移动地图系统)的方法创建的，MMS 是 Aisan 技术的产品。 1.9. I followed the instructions in the manual. I pressed the mapping button. It loads all the pcl files but is stuck on this step for a long time. I never get \"OK\".How do I generate the map? 我按照说明书上的说明做了。 我按下了绘图按钮。 它加载所有的 pcl 文件，但是长时间停留在这个步骤上。 我从来没有得到“ OK”。 如何生成地图？ This happens when you don't have the rosbag simulation or any have incoming velodyne/nmss data. Once you start simulation it should work. 这种情况发生时，你没有rosbag模拟或任何有传入 velodyne / nmss 数据。 一旦你开始模拟，它应该可以工作。","categories":[{"name":"Autoware.ai","slug":"Autoware-ai","permalink":"http://yoursite.com/categories/Autoware-ai/"}],"tags":[]},{"title":"Design-Rules(设计规范)","slug":"Autoware.ai/Design-Rules(设计规范)","date":"2020-03-05T12:45:18.000Z","updated":"2020-03-05T13:18:58.000Z","comments":true,"path":"2020/03/05/Autoware.ai/Design-Rules(设计规范)/","link":"","permalink":"http://yoursite.com/2020/03/05/Autoware.ai/Design-Rules(%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83)/","excerpt":"","text":"Design is important for readability and maintainability. It is highly recommended to follow the design rules for distributing your idea. The outline is based on the overview. 设计对于可读性和可维护性非常重要。强烈建议遵循设计规则来实现你的想法。 Namespace 消息类型 autoware_(namespace)_msgs::typename Examples: - autoware_detection_msgs - autoware_localization_msgs - autoware_prediction_msgs - autoware_intelligence_msgs - autoware_state_msgs - autoware_mission_msgs - autoware_motion_msgs - autoware_sensor_msgs 话题Topic /detection/ParentComponent/DataName Examples: - /detection/lidar_detector/objects - /detection/image_detector/objects - etc... A Motif A Motif","categories":[{"name":"Autoware.ai","slug":"Autoware-ai","permalink":"http://yoursite.com/categories/Autoware-ai/"}],"tags":[]},{"title":"Autoware.ai-Overview(概述)","slug":"Autoware.ai/Overview(概述)","date":"2020-03-05T12:35:18.000Z","updated":"2020-03-05T13:18:43.000Z","comments":true,"path":"2020/03/05/Autoware.ai/Overview(概述)/","link":"","permalink":"http://yoursite.com/2020/03/05/Autoware.ai/Overview(%E6%A6%82%E8%BF%B0)/","excerpt":"","text":"Autoware Overview This page describes an overview of Autoware based on the Version 2.0 design and implementation. For more details, you may refer to the design rules and the specification of Autoware. 本页描述了基于2.0版本设计和实现的 Autoware 的概述。 更多的细节，你可以参考设计规则和 Autoware 的规范。 1. 传感器 Autoware supports Camera, LiDAR, IMU, and GPS as primary sensors. The following are examples of those already verified with Autoware through field testing. Technically speaking, if not verified, almost all types of Camera, LiDAR, IMU, and GPS should be available for Autoware, as far as sensor driver software is provided. Autoware 支持相机，激光雷达，IMU 和 GPS 作为主要传感器。 下面是已经通过 Autoware 实地测试验证的例子。 从技术上讲，如果没有经过验证，几乎所有类型的相机，激光雷达，IMU，和 GPS 都应该可以在 Autoware 上使用，只要传感器驱动软件已经提供。 1.1. 相机 PointGrey (FLIR) Grasshopper 3 (USB/GigE) [link] PointGrey (FLIR) Flea 2/3 (USB/GigE) [link] PointGrey (FLIR) Blackfly (USB3/GigE) [link] Baumer VLG-22C (USB3/GigE) [link] Baumer VCXU-24C (USB3/GigE) [link] Allied Vision Camera Mako G-319C (PoE GigE) [link] Generic UVC Webcam (USB2/3) 支持多个摄像机传感器，但是它们应该根据不同的目的分别配置。 请为每个实例使用名称空间或名称来验证 ROS 文档。 分离每个相机的目的，如目标检测和交通信号灯识别。 从本质上讲，Autoware 不支持将多个图像连接到单个大图像中。 1.2. 激光雷达 VELODYNE HDL-64E (S1/S2/S3) [link] VELODYNE HDL-32E [link] VELODYNE VLP-32C [link] VELODYNE VLP-16 [link] VELODYNE VLP-16 Lite [link] VELODYNE VLP-16 Hi-Res [link] HOKUYO YVT-35LX (3D-URG) [link] HOKUYO UTM-30LX (TOP-URG) [link] SICK LMS511 [link] PIONEER 3D LiDAR (yet to be released) [link] You may combine multiple units of the above LiDAR scanners through TF, providing rich fused pointcloud data for more precise object detection, tracking, and localization. Please check Velodyne's documentation on how to use multiple sensors in the same network. 您可以通过 TF 组合上述 LiDAR 扫描仪的多个单元，提供丰富的融合点云数据，以实现更精确的目标检测、跟踪和定位。 请查看 Velodyne 的文档，了解如何在同一个网络中使用多个传感器。 1.3. 毫米波雷达 Delphi ESR [link] 自动检测主要是基于激光雷达扫描仪。 毫波雷达驱动程序也可用于远距离目标跟踪。 然而，它与感知包的整合仍然是一项进展中的工作 1.4. IMU Memsic VG440 [link] Xsens MTi-300 [link] MicroStrain 3DM-GX5-15 [link] Novatel IGM S1 IMU [link] Currently, advanced users of Autoware are not in favor of IMU, because SLAM-based localization augmented by 3D maps and odometers is reliable enough without the use of an IMU. However, we believe IMU is still useful in some scenarios, therefore Autoware supports IMU drivers and data integration into the localization modules. 目前，Autoware 的高级用户并不支持 IMU，因为不使用 IMU，基于 slam 的定位加上3D 地图和里程表就足够可靠了。 然而，我们相信 IMU 在某些情况下仍然是有用的，因此 Autoware 支持 IMU 驱动程序并将数据集成到本地化模块中。 1.5. GPS/GNSS Javad DELTA-3 [link] MITSUBISHI AQLOC (only available in Japan) [link] Trimble NetR9 [link] Leica Viva GS25 [link] Applanix APX-15 UAV [link] GPS/GNSS receivers typically generate NMEA-compliant sentences (text strings), which is entirely supported by Autoware, via the serial interface. Therefore, we believe that as long as the device is NMEA compliant, virtually all GPS/GNSS products, would be compatible for Autoware with the existing nmea2tfpose node. Gps / gnss 接收机通常通过串行接口生成符合 nmea 标准的句子(文本字符串) ，Autoware 完全支持这些句子。 因此，我们相信，只要设备符合 NMEA，几乎所有的 gps / gnss 产品，将与现有的 nmea2tfpose 节点兼容 Autoware。 2. Computing/Perception(计算和感知) Autoware 的感知能力由定位、检测和预测三部分组成。 定位是通过结合 GNSS 和 IMU 传感器的3D 地图和 SLAM 算法实现的。 检测使用摄像机和 LiDARs 传感器融合算法和深层神经网络。 预测是基于定位和检测的结果。 下面是由 Autoware 提供的突出显示的包和函数。 2.1. Localization(定位) lidar_localizer ： 激光雷达定位器使用激光雷达扫描数据和预先构建的3D 地图信息，计算自我车辆在全局坐标系中的(x，y，z，roll，pitch，yaw)位置。 我们推荐使用正态分布变换(NDT)算法进行 LiDAR 扫描与三维地图的匹配，同时也支持迭代匹配(ICP)算法 gnss_localizer ：transforms the NMEA message from a GNSS receiver to the (x, y, z, roll, pitch, yaw) position. 该结果可以单独作为车辆的定位，也可以用于初始化和激光雷达定位器的定位结果进行融合互补 dead_reckoner ：该算法主要利用 IMU 传感器预测车辆的下一帧位置，并对激光雷达定位器和卫星定位器的定位结果进行插值处理。 2.2. Detection lidar_detector reads point cloud data from 3D laser scanners, and provides LiDAR-based object detection capabilities. The basic performance comes from the Euclidean Clustering algorithm, which finds clusters of the LiDAR scan (point cloud) above the ground. To classify the clusters, DNN-based algorithms are also supported, such as VoxelNet and LMNet. vision_detector reads image data from cameras, and provides image-based object detection capabilities. The main algorithms include R-CNN, SSD, and Yolo, which are designed to perform single DNNs for real-time performance. Multiple classes of detection are supported, such as cars and passengers. vision_tracker provides a tracking function for the results of vision_detector. The algorithm is based on Beyond Pixels. The results of tracking on an image plane are projected and combined with the result of lidar_detector in a 3D space through fusion_tools. fusion_detector reads both point cloud data from laser scanners and image data from cameras, and achieves further accurate object detection in a 3D space. The positions of laser scanner(s) and camera(s) must be calibrated in advance. The current implementation is based on the MV3D algorithm with a minor extension of the network as compared to the original algorithm. fusion_tools combines the results from lidar_detector and vision_tracker. The class information identified by vision_detector is added to the clusters of point cloud detected by lidar_detector. object_tracker predicts the motion of objects detected and identified by the above packages. The result of tracking can be further used for prediction of the object behavior and estimation of the object velocity. The tracking algorithm is based on the Kalman Filters. Another variant supports the Particle Filters as well. 2.3. Prediction object_predictor uses the result of object tracking described above to predict the future trajectories of moving objects, such as cars and passengers. collision_predictor uses the result of object_predictor to predict if the ego vehicle is involved in possible collision against the moving objects. The waypoint trajectory and the velocity information of the ego vehicle is also required as input data in addition to the result of object tracking. cutin_predictor uses the same pieces of information as collision_predictor to predict if neighbor cars cut in the front of the ego vehicle. 3. Computing/Decision The decision module of Autoware bridges across the perception and the planning modules. Upon the result of perception, Autoware decides a driving behavior, represented by a finite state machine, so that an appropriate planning function can be selected. The current approach to decision making is a rule-based system. 3.1. Intelligence decision_maker subscribes a large set of topics related to the result of perception, map information, and the current state in order to publish the next-moment state topic. This state change will activate an appropriate planning function. 3.2. State state_machine changes the state within pre-defined rules, orchestrating with decision_maker. 4. Computing/Planning The last piece of computing in Autoware is a planning module. The role of this module is to make plans of global mission and local (temporal) motion based on the results of the perception and the decision modules. A global mission is often determined when the ego vehicle starts or restarts, while a local motion is updated according to state changes. For example, the velocity of the ego vehicle is planned to become zero in front of an object with a safety margin or at a stop line if the state of Autoware is set to \"stop\". Another example is that the trajectory of the ego vehicle is planned to bypass an obstacle if the state of Autoware is set to \"avoid\". The primary packages included in the planning module are the following. 4.1. Mission route_planner searches for a global route to the destination. The route is represented by a set of intersections in the road network. lane_planner determines which lanes to be used along with the route published by route_planner. The lanes are represented by an array of waypoints, i.e., multiple waypoints, each of which corresponds to a single lane, are published by this package. waypoint_planner can be alternatively used to generate a set of waypoints to the destination. This package differs from lane_planner in that it publishes a single stroke of waypoints rather than an array of waypoints. waypoint_maker is a utility tool to save and load hand-made waypoints. To save waypoints to the specified file, you drive a vehicle manually while localization is activated, and Autoware records waypoints of the driving path with velocity information. The recorded waypoints can be loaded later on from the specified file to have the motion planning module subscribe them to follow that path. 4.2. Motion velocity_planner updates a velocity plan on the waypoints subscribed from either lane_planner, waypoints_planner, or *waypoints_maker** so as to speed down/up against surrounding vehicles and road features such as stop lines and traffic lights. Note that the velocity information embedded in the given waypoints is static, while this package updates a velocity plan according to driving scenes. astar_planner implements the Hybrid-State A* search algorithm that generates a feasible trajectory from the current position to the specified position. This package can be used for obstacle avoidance and sharp turns on the given waypoints as well as routing in free space such as parking lots. adas_lattice_planner implements the State Lattice planning algorithm that generates multiple feasible trajectories ahead of the current position based on spline curves, a pre-defined parameter table, and the ADAS Map (a.k.a., Vector Map) information. This package can be used mostly for obstacle avoidance and lane changes. waypoint_follower implements the Pure Pursuit algorithm that generates a twisted set of velocity and angular velocity (or just angle) to move the ego vehicle by uniform circular motion to a target waypoint over the given waypoints. This package should be used in combination with velocity_planner, astar_planner, and/or adas_lattice_planner. The published twisted set of velocity and angular velocity (or just angle) will be read by a vehicle controller or a by-wire interface, and finally the ego vehicle is controlled autonomously. 5. Actuation Autoware has been installed and tested with a number of by-wired vehicles. Examples of \"Powered by Autoware\" are listed here. The computational output of Autoware is a set of velocity, angular velocity, wheel angle, and curvature. These pieces of information are sent as commands to the by-wire controller through the vehicle interface. Controlling the steering and throttle needs to be taken care of by the by-wire controller.","categories":[{"name":"Autoware.ai","slug":"Autoware-ai","permalink":"http://yoursite.com/categories/Autoware-ai/"}],"tags":[]},{"title":"第二章-状态空间描述","slug":"控制相关/线性系统理论/第二章-状态空间描述","date":"2020-03-05T08:50:50.000Z","updated":"2020-03-23T06:37:58.000Z","comments":true,"path":"2020/03/05/控制相关/线性系统理论/第二章-状态空间描述/","link":"","permalink":"http://yoursite.com/2020/03/05/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4%E6%8F%8F%E8%BF%B0/","excerpt":"","text":"1. 状态空间描述 1.1. 输入-输出描述与状态空间描述的差异 输入—输出描述(外部描述) 用传递函数、微分方程表征; 是系统的外部描述 是对系统的不完全描述 状态空间描述(内部描述) 用状态空间表达式表征 是系统的内部描述 是对系统的完全描述 1.2. 状态、状态变量和状态向量 状态 系统在时间域中的行为或运动信息的集合称为状态。 系统的状态是描述系统的过去、现在和未来行为的变量组,是用来完全表征系统时域行为的最小的一组变量，记为\\(x_1(t),x_2(t)\\cdots,x_n(t)\\) 状态变量 是构成系统状态的变量,是指能完全表征系统行为的最小变量组中的每一个变量 状态向量 是由状态变量所构成的向量,即向量\\(x(t)=[x_1(t),x_2(t),\\cdots,x_n(t)]^T\\)称为n维状态向量。给定t =t0 时的初始状态向量x(t0)及t≥t0 的输入向量u(t),则t≥t 0的状态由状态向量x(t)唯一确定。 状态变量不是所有变量的总和 状态变量的选取不唯一 输出量可以选作状态变量 输入量不允许选作状态变量 状态变量有时是不可测量的 状态变量是时域的 1.3. 状态方程 状态方程是描述内部变量\\(x=[x_1,x_2,\\cdots,x_n]^T\\)与输入变量\\(u=[u_1,u_2,\\cdots,u_p]^T\\)之间的因果关系数学表达是，常具有微分方程或差分方程的形式。 状态方程：描述系统状态变量与输入变量之间关系的一阶微分方程组(连续时间系统)或一阶差分方程组(离散时间系统)称为系统的状态方程。状态方程表征了系统由输入所引起的内部状态变化。 连续时间系统状态方程的一般形式为: \\[ \\dot{x}(t)=f[x(t),u(t),t] \\] 离散时间系统状态方程的一般形式为: \\[ x(t_{k+1})=f[x(t_k),u(t_k),t_k] \\] 1.4. 输出方程 是表征系统内部变量\\(x=[x_1,x_2,\\cdots,x_n]^T\\)和输入变量\\(u=[u_1,u_2,\\cdots,u_p]^T\\)与输出变量\\(y=[x_1,x_2,\\cdots,x_n]^T\\)之间的转换关系，就有代数方程形式 连续时间系统输出方程的一般形式为: \\[ y(t)=g[x(t),u(t),t] \\] 离散时间系统输出方程的一般形式为: \\[ y(t_{k})=g[x(t_k),u_(t_k),t_k] \\] 1.5. 状态空间 状态方程与输出方程的组合称为状态空间表达式,又称为动态方程或状态空间描述。 连续时间系统: 离散时间系统: 1.6. 线性系统状态空间表达式 状态方程与输出方程都是线性方程的系统是线性系统。线性系统的状态方程是一阶向量线性微分方程或一阶向量线性差分方程。 1.7. 线性定常系统状态空间表达式 线性系统的状态空间描述中,系统矩阵(A(t)或G(k))、控制矩阵(B(t)或H(k))、输出矩阵(C(t)或C(k))和前馈矩阵(D(t)或D(k))的每一个元素都是常数,则称该系统为线性定常系统(线性时不变系统), 否则为线性时变系统。 矩阵\\(D\\)描述了输入u不经状态变量x对输出y的直接影响,它不影响系统的动态过程,实质上是系统外部模型的一部分，因此,当利用状态模型来分析系统动态行为时,常假设D≡0,并不失对问题讨论的一般性。 1.8. 线性系统和非线性系统 泰勒展开，主要是求雅克比矩阵如下 2. 传递函数导出状态空间描述 2.1. 给定单输入,单输出线性时不变系统的输入输出描述 给定单输入,单输出线性时不变系统的输入输出描述如下 (1)m&lt;n，系统为严真情形 (2)m=n，系统为真情形 举例： 2.2. 给定单输入,单输出线性时不变系统的输入输出描述 (1)m=0情形 (2)m≠0情形 举例： 2.3. 给定单输入,单输出线性时不变系统的传递函数描述 给定单输入单输出线性时不变系统的传递函数描述为 极点： 传递函数中，分母方程的根 要求，极点\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n\\)都是两两互异的实数，即没有重根，可以分两种情况讨论 (1)m&lt;n，系统为严真情形 对应的状态空间描述为 \\[ \\begin{aligned} \\dot{x}= \\begin{bmatrix} \\lambda_1, &amp;~ &amp; ~&amp;~ \\\\ ~ &amp; \\lambda_1 &amp; ~ &amp;~ \\\\ ~ &amp; ~ &amp; \\ddots &amp; ~ \\\\ ~ &amp; ~ &amp; ~ &amp; \\lambda_n \\end{bmatrix} x + \\begin{bmatrix} k_1 \\\\ k_2 \\\\ \\vdots \\\\ k_n \\end{bmatrix} u \\end{aligned} \\] \\[ y=[1,1,\\cdots,1]x \\] (1)m=n，系统为真情形 对应的状态空间描述为 2.4. 由方框图描述导出状态空间描述 3. 状态空间描述化标准型、约旦型 3.1. 前提基础 3.1.1. 特征多项式 对于连续时间线性时不变系统\\(\\boldsymbol{\\dot{x}=A x + B u}\\) 特征矩阵： \\((sI-A)\\) 预解矩阵: \\((sI-A)^{-1}\\) 特征多项式: \\(\\det(sI-A)\\) (1)特征多项式 \\[ \\alpha(s)=\\det(sI-A)=s^n + \\alpha_{n-1}s^{n-1}+\\cdots + \\alpha_1 s + \\alpha_0 \\] 其中，\\(\\alpha_0,\\cdots,\\alpha_{n-1}\\)均为实数 (2)凯莱哈密顿定理 \\[ \\alpha(A)=A^n+ \\alpha_{n-1}A^{n-1}+ \\cdots + \\alpha_1 A + \\alpha_0 I =0 \\] 其中，\\(A\\)为矩阵根 (3)莱弗勒算法——计算特征多项式 通过迭代的方式，求出大常数矩阵A的特征多项式\\((sI-A)\\) 3.1.2. 特征值和特征向量 已知n阶线性定常系统的状态方程 \\[ \\dot{x}=Ax+Bu \\] 系统的特征方程为: \\[ \\det(sI-A)=0 \\] 特征值为上述特征方程的根，即\\(\\{\\lambda_1,\\lambda_2,\\cdots \\lambda_n\\}\\) 将矩阵A的第i个特征值\\(\\lambda_i\\)代入下列方程，如果存在一个非零向量\\(v_i\\)使得等式成立，那么该非零向量\\(v_i\\)就是关于特征值\\(\\lambda_i\\)的特征向量。 \\[ \\begin{aligned} \\lambda_i v_i = A v_i \\\\ \\Longrightarrow (\\lambda_i I -A)v_i = 0 \\end{aligned} \\] 3.1.3. 特征值的代数重数和几何重数 (1)代数重数\\(\\sigma_i\\) 即某个特征值\\(\\lambda_i\\)的重根数 (2)几何重数\\(\\alpha_i\\) 即将特征值代入上面齐次方程组基础解系的解向量个数 \\[ \\alpha_i=n- rank(\\lambda_i I -A) \\] 特征值的几何重数\\(\\alpha_i\\)表示了属于该特征值\\(\\lambda_i\\)的线性无关特征向量的个数 单特征值只对应一个特征向量(即\\(\\alpha_i=1\\)) 有重根的特征值，可能对应多个独立的特征向量 只有当所有特征值的代数重数\\(\\sigma_i\\)等于其几何重数\\(\\alpha_i\\)时,矩阵A可以化为对角线规范形 3.2. 标准型 3.2.1. 特征值两两互异(没有重根) 可通过线性非奇异变换\\(\\bar{x}=P^{-1}x\\)将状态方程化为对角型(标准型) 步骤: 对A矩阵进行特征值分解\\(A=P \\Lambda P^{-1}\\) 那么，可得到化为标准型之后的\\(\\bar{A},\\bar{B}\\) \\(\\bar{A}=P^{-1}AP\\) \\(\\bar{B}=p^{-1}B\\) 状态方程可重写为\\(\\dot{x}=\\bar{A}x+\\bar{B}u\\) 例子1 (特例)友矩阵形式 那么，可以直接写出变换矩阵P，不用进行特征值分解了 直接写出矩阵P 3.2.2. 特征值有重根(但是仍然有n个独立特征向量) 状态方程中的矩阵A虽然有重根，但是仍然有n个独立的特征向量，此时仍然可以化为对角标准型 例子 小结 两种情况可以化为对角标准型 系统矩阵A的n个特征值两两互异 系统矩阵A有重特征值，且所有特征值的几何重数都等于其代数重数 在对角线规范形下,系统矩阵是以特征值为元素的一个对角线矩阵,这意味着系统状态在对角线规范形下,系统各个状态变量之间实现了完全解耦 3.3. 约当规范形 当矩阵A有重根，并且独立向量个数\\(&lt;n\\)，此时矩阵A不能化为对角型，但是可以化成约旦(Jordan)规范型 例子1 例子2 (特例)友矩阵形式 4. 状态空间===&gt;传递函数矩阵 4.1. 传递函数矩阵 定义: 单输入单输出 单输入单输出线性时不变系统,在零初始条件下,输出变量拉普拉斯变换和输入变量拉普拉斯变换之比,称为系统的传递函数,即 多输入多输出 多输入多输出线性时不变系统,在零初始条件下,输出变量拉普拉斯变换和输入变量拉普拉斯变换因果关系,即 4.2. 传递函数严真性 4.3. ABCD矩阵===&gt;传递函数(重点在这里) 考虑连续时间线性时不变系统 \\[ \\begin{aligned} \\dot{x}=Ax+Bu \\\\ y=Cx+Du \\\\ \\\\ \\Longrightarrow G(s)=C(sI-A)^{-1}B+D \\end{aligned} \\] 计算机进行迭代计算，避免求逆的算法: 5. 关于代数等价 两个系统为代数等价的必要条件是它们具有相同的维数 同一系统采用不同的状态变量组所导出的两个状态空间描述之间,必然是代数等价的 代数等价系统具有相同的传递函数矩阵,但相反的情况却不一定成立 代数等价系统具有相同的特征值 系统经过线性非奇异变换后,不会改变系统原有特性(包括系统特征值、传递函数矩阵、可控性、可观性等),这就是所谓的线性非奇异变换的不变特性","categories":[{"name":"控制相关","slug":"控制相关","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/"},{"name":"线性系统理论","slug":"控制相关/线性系统理论","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"}],"tags":[]},{"title":"CVPR2020-D3VO-基于自监督的单目VO网络","slug":"文献阅读/CVPR2020-D3VO-基于自监督的单目VO网络","date":"2020-03-03T04:04:59.000Z","updated":"2020-03-04T09:51:54.000Z","comments":true,"path":"2020/03/03/文献阅读/CVPR2020-D3VO-基于自监督的单目VO网络/","link":"","permalink":"http://yoursite.com/2020/03/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/CVPR2020-D3VO-%E5%9F%BA%E4%BA%8E%E8%87%AA%E7%9B%91%E7%9D%A3%E7%9A%84%E5%8D%95%E7%9B%AEVO%E7%BD%91%E7%BB%9C/","excerpt":"","text":"1. D3VO: Deep Depth, Deep Pose and Deep Uncertaintyfor Monocular Visual Odometry 2. 摘要 3. 方法 首先提出一种自监督网络，用来预测深度、位姿、和不确定性，网络同时估计仿射亮度变换参数来对齐训练图片的光照度，在这个自监督框架里面。光度不确定度是根据每个像素可能的亮度值的分布来预测的。因此提出这个D3VO作为直接的VO框架，将预测到的特性分别包含在前端跟踪和后端BA优化中。 3.1. 自监督网络 提出的单目深度估计网络的核心是对视频序列进行使用\\(DepthNet\\)来学习深度，并同时使用\\(PoseNet\\)学习运动 (文献24,81)。这种自监督训练是通过最小化当前图像和静态立体图像之间的光度重投影误差来实现的 其中，\\(V\\)是在图片\\(I_t\\)上的所有像素集合，\\(t&#39;\\)表示所有图像帧中的索引idx。在作者的设置中，\\(I_t\\)是左侧Image，\\(I_{t&#39;}\\)包含了它的两个相邻的两个时间Frame和它的对位(右)的Frame，(如\\(I_{t&#39;}\\in \\{ I_{t-1},I_{t+1},I_{t^s} \\}\\))。每个像素的最小化loss使用文献24提出的\\(Monodepth2\\)，这是为了解决不同源Frame之间的遮挡问题。 为了简化表示，使用\\(I\\)来取代\\(I(p)\\)，\\(I_{t&#39; \\rightarrow t}\\)表示使用预测的深度\\(D_t\\)对双目立体相机图像进行变换，以及相机的位姿\\(T_{t}^{t&#39;}\\)，相机的内参\\(K\\)，以及可微分的双线性采样器（文献30）来合成，[说白了就是重投影？]. 注意到对于从右目相机到左目相机的\\(I_{t^s \\rightarrow t}\\)，相机位姿变换\\(T_{t}^{t&#39;}\\)是已知的、固定的。\\(DepthNet\\)同时预测右目图像\\(I_{t^s}\\)的深度图\\(D_{t^s}\\)，通过向网络输入左侧图像\\(I_t\\)的方式，文献25提出的。 训练\\(D_t\\)需要通过生成\\(I_{t\\rightarrow t^s}\\)(即输入左目图像，生成右目深度图)，然后与\\(I_{t^s}\\)(实际的右目的深度图)做比较。 为了简化，下面只讨论左侧图像的loss，通用的光度误差公式为： 这是基于光度不变性的假设。然而，由于相机的光照变化和自动曝光，L1和SSIM[文献72]都不是固定不变的，可能会违反这一原则。因此，我们提出了明确的使用预测的亮度转换参数对摄像机曝光变化进行建模。 3.1.1. 亮度转换参数 相机曝光调整引起的图像强度变化可以用2个参数的仿射变换来表示 尽管它很简单，这个公式在直接法SLAM中表现出十分有效，在[文献15,17,31,70]提到的。受这些工作的启发，作者提出了预测变形参数的方法，即根据参数来将左侧图像\\(I_t\\)的光度条件与\\(I_{t&#39;}\\)对齐，于是可以将等式1进行重写： 其中，\\(a_{t\\rightarrow t&#39;}\\)和\\(b_{t\\rightarrow t&#39;}\\)是将左侧图像\\(I_t\\)对齐到\\(I_{t&#39;}\\)的参数。注意，这两个参数都可以在没有任何监督信号的情况下以自我监督的方式进行训练。下图展示了变换的结果： 3.1.2. 光度不确定性 仅建模亮度变化参数不足以应对光度不变性假设的所有失效情况，其他情况，如非朗伯曲面和运动物体，是由相应物体的固有性质引起的，这些性质对于分析建模来说有一定影响。由于这些方面可以看作是观测噪声，我们(leverage)利用Kendall等人提出的深度神经网络的异方差任意不确定性概念[文献33]，其主要的思想是基于ground-true label y来预测每个像素的后验概率分布(使用它的均值和方差\\(p(y|\\tilde{y},\\sigma)\\))，例如，通过假设噪音是拉普拉斯的，该分布的负对数似然函数可以写成： 注意，对于方差\\(\\sigma\\)并不需要真实的标签label来训练。预测不确定性允许网络根据数据输入调整残差的权重，这样有利于提高模型对噪声数据或错误标签的鲁棒性[文献33]。 在这个例子中，真实标签y就是目标图像的像素强度。对于左侧图像\\(I_t\\)上的哪些可能违反光度不变性的像素区域而言，网络将会预测更高的\\(\\sigma\\)，类似与[文献38]，通过对等式4进行变换来实现： 其中，\\(\\Sigma_t\\)是左侧图像\\(I_t\\)的不确定性map(映射？图？)。下图4分别展示了在KITTI和EuRoC数据集上预测不确定性map的结果。接下来，将展示证明学习\\(\\Sigma_t\\)对光度残差进行加权对于D3VO的有效作用。 4. D3VO 上面讲了自监督网络来预测深度图\\(D\\)，不确定性图\\(\\Sigma\\)和相对位姿\\(T_{t}^{t&#39;}\\)。接下来，是关于D3VO如何将这些预测整合到一个滑动窗口的稀疏(光度重投影)BA调整公式中，如[文献15]提及的。 接下来的讨论将使用\\(~\\tilde{\\cdot}~\\)来表示从网络中得到的预测值，如\\(\\tilde{D},\\tilde{\\Sigma},\\tilde{T_t^{t&#39;}}\\)，来避免歧义。 4.1. 光度能量 像其他直接法如[文献15,16,18]，D3VO旨在最小化总的光度误差\\(E_{photo}\\)如下： 其中，\\(\\mathcal{F}\\)是关键帧的集合，\\(\\mathcal{P}_i\\)是第i个关键帧的点集(注意，不是一个点)，\\(obs(\\boldsymbol{p})\\)是能够观测到点\\(\\boldsymbol{p}\\)的关键帧集合。\\(E_{\\boldsymbol{p}j}\\)是将\\(\\boldsymbol{p}\\)点投影到关键帧\\(j\\)时的加权光度： 上式中，\\(\\mathcal{N}\\)是点\\(\\boldsymbol{p}\\)的8个邻近像素集合[文献15]，\\(a,b\\)是光度变换参数，\\(||\\cdot||_{\\gamma}\\)是Huber核函数规范化，在[文献15]中，残差的权重定义为： 意义是降权像素具有高的图像梯度来补偿小的独立几何噪声。在现实的情况下，有更多的噪声源，例如，反射，这需要被建模用于精确和鲁棒的运动估计。于是，作者提出了使用学习的不确定性\\(\\tilde{\\Sigma}\\)来表示权重函数： 这可能不仅仅是依赖局部图像的梯度，有可能是更高级别的噪声模式(higher level noise pattern)。如上图4中，对于车辆的窗户，移动的物体如骑自行车的人，在深度不连续的地方如物体边界，网络都能预测出较高的不确定性。 投影点\\(p&#39;\\)的位置由下式给定： 其中，\\(d_p\\)是点\\(\\boldsymbol{p}\\)在第i个关键帧的相机坐标系的深度，\\(\\Pi(\\cdot)\\)是利用已知相机内参进行投影，这里定义\\(\\Pi(\\cdot)\\)来获得齐次坐标。相比于传统直接法[文献15,16]中使用随机初始化深度\\(d_p\\)，作者提出使用估计的深度\\(d_p=\\tilde{D}_i[\\boldsymbol{p}]\\)，可以提供(metric scale)衡量尺度的？ 受[文献78]启发，作者提出对等式11的立体相机版本： 其中，\\(\\boldsymbol{T_s}\\)是从左侧图像到右侧图像的变换矩阵，其中应用了训练得到的\\(DepthNet\\)和下式： 虚拟立体项优化了估计的来自VO系统中的深度\\(d_p\\)，使其与所提出的深度网络预测的深度一致。 姿态能量 不像传统的直接法VO一样，使用恒速度模型来为新的一帧初始化前端跟踪，作者提出了使用连续帧之间的姿态预测值来初始化前端，而不是初始化直接图像对齐。这个来自跟踪前端的位姿估计将用于初始化后端BA优化。利用所预测的关键帧姿态\\(\\tilde{T}_{i-1}^{i}\\)，进一步介绍相对关键帧姿态\\(T_{i-1}^{i}\\)的先验。 即\\(\\tilde{T}_{i-1}^{i}\\)通过连接第i-1和第i帧之间所有帧间位姿预测值计算得到。 于是，姿态能量可以表示为： 其中，\\(Log:SE(3)\\rightarrow \\R^6\\) 表示将李群中的SE3变换矩阵映射到它的李代数形式，\\(\\xi \\in \\R^6\\)，即变成6维向量。另外，对角逆协方差矩阵\\(\\Sigma_{\\tilde{\\xi}_{i-1}^i}^{-1}\\)，可以通过在连续的帧匹配对传播协方差矩阵得到，被建模为常数对角矩阵。 总的能量函数可以写成： 将式21中的位姿先验项\\(E_{pose}\\)考虑在内，可以类比于用高斯噪声模型将MU预积分位姿先验集成到系统中 \\(E_{total}\\)使用高斯牛顿法来进行优化。 总结： 介绍了将预测的位姿作为前端跟踪和后端优化初始值，并且将它们进行正则化到光度BA优化的能量函数中的思路。","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"第四讲-ORB-SLAM2-全局闭环","slug":"SLAM代码课程/ORB_SLAM2/第四讲-ORB-SLAM2-全局闭环","date":"2020-03-03T02:00:50.000Z","updated":"2020-03-05T08:44:09.000Z","comments":true,"path":"2020/03/03/SLAM代码课程/ORB_SLAM2/第四讲-ORB-SLAM2-全局闭环/","link":"","permalink":"http://yoursite.com/2020/03/03/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB_SLAM2/%E7%AC%AC%E5%9B%9B%E8%AE%B2-ORB-SLAM2-%E5%85%A8%E5%B1%80%E9%97%AD%E7%8E%AF/","excerpt":"","text":"第四讲-ORB-SLAM2-全局闭环 闭环部分 基于bow的闭环实际上比较弱，也是迟早被CNN取代的模块之一 主要看下面的即可 看这里 g2o扩展 同时优化位姿和3D点 只优化位姿 闭环成功之后的优化 Sim3优化","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"ORB_SLAM2","slug":"SLAM代码课程/ORB-SLAM2","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB-SLAM2/"}],"tags":[]},{"title":"车辆动力学模型","slug":"控制相关/车辆动力学模型","date":"2020-03-02T14:37:09.000Z","updated":"2020-03-03T16:52:11.000Z","comments":true,"path":"2020/03/02/控制相关/车辆动力学模型/","link":"","permalink":"http://yoursite.com/2020/03/02/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E8%BD%A6%E8%BE%86%E5%8A%A8%E5%8A%9B%E5%AD%A6%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"车辆动力学模型 变量约定 变量名 意义 变量名 意义 \\(F_y\\) 整车受到y方向的力 \\(\\delta\\) 方向盘转角 \\(F_{yf}\\) 前轮胎受到y方向的力 \\(\\delta_f\\) 前轮转角 \\(F_{yr}\\) 后轮胎受到y方向的力 \\(\\delta_r\\) 后轮转角 \\(V_x\\) 纵向速度 \\(\\delta_o\\) 外轮转向角 \\(V\\) 全速度 \\(\\delta_i\\) 内轮转向角 \\(\\dot{y}\\) 横向速度 \\(l_w\\) 宽度 \\(V_{y}\\) 横向速度，等于\\(\\dot{y}\\) \\(\\alpha_f\\) 前轮胎滑移角 $m $ 质量 \\(\\alpha_r\\) 后轮胎滑移角 \\(I_z\\) Z轴转动惯量 \\(C_\\alpha\\) 轮胎转向刚度 \\(l_f\\) 前悬长度 \\(F_z\\) 轮胎法向力 \\(l_r\\) 后悬长度 \\(\\mu\\) 摩擦系数 \\(L\\) \\(L=l_f+l_r\\) \\(\\dot{\\psi}_{des}\\) 期望的偏航角速度 \\(\\psi\\) 偏航角 \\(\\beta\\) 在车辆重心处的滑动角度 \\(\\dot{\\psi}\\) 偏航角速度 \\(\\theta_v\\) 速度方向与纵轴的角速度 \\(r\\) 偏航角速度\\(r=\\dot{\\psi}\\) \\(\\phi\\) road bank angle \\(X,Y\\) 轴 \\(R\\) 转弯半径 \\(e_1\\) 相对于路面的横向位置误差 \\(e_2\\) 相对于路面的偏航角误差 \\(C(t)\\) 菲涅耳积分(Fresnel Integral) \\(S(t)\\) 菲涅耳积分(Fresnel Integral) 车辆横向运动的运动学模型 运动学模型提供了车辆运动的数学描述，而不考虑影响运动的力。运动方程完全是基于支配系统的几何关系。 考虑一个单车模型 表示前轮和后轮的转向角分别为\\(\\delta_f\\)和\\(\\delta_r\\)，该模型是在假定前轮和后轮都可以操纵的情况。对于只有前轮可以操纵的情况，那么有\\(\\delta_r=0\\)。整车质心在点C，从前轮胎A到质心点C的距离为\\(l_f\\)，后轮胎到点C为\\(l_r\\)，其中\\(L=l_f+l_r\\)。 假设车辆具有平面运动，则可以使用\\((X,Y,\\psi)\\)来描述。整车速度使用向量\\(V\\)来描述，与车辆的纵轴成一个角度\\(\\beta\\)，其中，\\(\\beta\\)称为车的侧滑角度。 假设 运动学模型建立的主要假设是:点A和点B的速度矢量分别与前轮和后轮的方向一致，换句话说，就是前轮胎的速度向量与纵轴方向成\\(\\delta_f\\)的角，后轮的速度向量与纵轴方向成\\(\\delta_r\\)的角。这相当于假设两个轮子的“滑动角度”为零 (？不懂) 。 这是一个合理的假设为低速运动的车辆(例如，速度低于5米/秒)，这是因为在低速时，轮胎产生的侧向力很小。 为了在半径为R的环形路上行驶，两个轮胎的总侧向力为： \\[ \\begin{aligned} \\frac{mV^2}{R} \\end{aligned} \\] 当速度很小时，侧向力很小。当侧向力很小时，如2.4节后面所解释的那样，假设每个轮子上的速度矢量都在轮子的方向上确实是非常合理的。 车辆路径R的半径即为由连接重心C到瞬时旋转中心O的直线OC的长度。车辆速度与直线OC垂直，速度方向相对于车辆纵轴方向称为滑移角\\(\\beta\\)。 车辆的朝向角为\\(\\psi\\)，于是有\\(\\gamma=\\psi+\\beta\\) 对三角形\\(OCA\\)使用正弦定理： \\[ \\begin{aligned} \\frac{\\sin(\\delta_f-\\beta)}{l_f} &amp;= \\frac{\\sin(\\frac{\\pi}{2}-\\delta_f)}{R} \\\\ \\frac{\\sin(\\delta_f)\\cos(\\beta)-\\sin(\\beta)\\cos(\\delta_f)}{l_f} &amp;= \\frac{\\cos(\\delta_f)}{R} \\end{aligned} \\tag{2.5} \\] 对三角形\\(OCB\\)使用正弦定理 \\[ \\begin{aligned} \\frac{\\sin(\\beta-\\delta_r)}{l_r} &amp;= \\frac{\\sin(\\frac{\\pi}{2}+\\delta_r)}{R} \\\\ \\frac{\\cos(\\delta_r)\\sin(\\beta)-\\cos(\\beta)\\sin(\\delta_r)}{l_r} &amp;= \\frac{\\cos(\\delta_r)}{R} \\end{aligned} \\tag{2.6} \\] 两式分别乘以\\(\\frac{l_f}{\\cos(\\delta_f)}\\)和\\(\\frac{l_r}{\\cos(\\delta_r)}\\)，分别得到 \\[ \\tan(\\delta_f)\\cos(\\beta)-\\sin(\\beta)=\\frac{l_f}{R} \\] \\[ \\tan(\\beta)-\\tan(\\delta_r)\\cos(\\beta)=\\frac{l_r}{R} \\] 两式相加，得到 \\[ [\\tan(\\delta_f)-\\tan(\\delta_r)]\\cos(\\beta)=\\frac{l_f+l_r}{R} \\tag{2.8} \\] 如果我们假设车辆路径的半径由于车速较低而变化缓慢，那么车辆的方向变化率(\\(\\psi\\))一定等于车辆的角速度，由车辆角速度等于\\(\\frac{V}{R}\\)，于是有： \\[ \\dot{\\psi}=\\frac{V}{R} \\] 于是，替换变量\\(R\\)，重写式2.8 \\[ \\dot{\\psi}=\\frac{V\\cos(\\beta)}{l_f+l_r}(\\tan(\\delta_f)-\\tan(\\delta_r)) \\tag{2.12} \\] 得到的模型，有三个输入\\(\\delta_f,\\delta_r,V\\)，速度V是一个外部变量，可以假设为一个时变函数，也可以从纵向车辆模型中得到。 通过将式2.5乘以\\(l_r\\)，对式2.6乘以\\(l_f\\)，两式相减，可以得到侧滑角\\(\\beta\\): \\[ \\beta=\\tan^{-1} \\frac{l_f \\tan \\delta_r + l_r \\tan \\delta_f}{l_f+l_r} \\] 阿克曼转向 令\\(l_w\\)为宽度，\\(\\delta_o\\)和\\(\\delta_i\\)分别为前轮的外轮和内轮的转角。并且假设\\(L=l_f+l_r &lt;&lt; R\\)，并且侧滑角\\(\\beta\\)很小 \\((\\cos \\beta) \\approx 1\\)，那么式2.12可以近似为: \\[ \\begin{aligned} &amp; \\psi=\\frac{V}{R}=\\frac{V \\delta}{L} \\\\ &amp; \\Longrightarrow \\frac{\\dot{\\psi}}{V} \\approx \\frac{1}{R} = \\frac{\\delta}{L} \\\\ &amp;\\Longrightarrow \\delta = \\frac{L}{R} \\end{aligned} \\] 又因为内外车轮的行驶路径曲率是不同的，于是有 \\[ \\delta_o=\\frac{L}{R+\\frac{l_w}{2}} \\] \\[ \\delta_i=\\frac{L}{R-\\frac{l_w}{2}} \\] 前轮平均转向角约为: \\[ \\delta=\\frac{\\delta_o+\\delta_i}{2} \\approx \\frac{L}{R} \\] 其中，差为 \\[ \\delta_i-\\delta_o =\\frac{L}{R^2}l_w =\\delta^2 \\frac{l_w}{L} \\] 因此，两个前轮转角的差值与平均转角的平方成正比，这种差动转向可以从梯形拉杆装置中获得，从图中可以看出，无论是左转还是右转，内转轮的转向角度都比较大。 总结 符号 意义 等式 X 全局坐标系X坐标轴 \\(\\dot{X}=V\\cos(\\psi+\\beta)\\) Y 全局Y轴 \\(\\dot{Y}=V\\sin(\\psi+\\beta)\\) \\(\\psi\\) 朝向角:车体纵轴与X轴的夹角 \\(\\dot{\\psi}=\\frac{V\\cos(\\beta)}{l_f+l_r}(\\tan(\\delta_f)-\\tan(\\delta_r))\\) \\(\\beta\\) 侧滑角 \\(\\beta=\\tan^{-1} \\frac{l_f \\tan \\delta_r + l_r \\tan \\delta_f}{l_f+l_r}\\) 车辆动力学模型 在较高的车辆速度下，不能再假设每个轮子上的速度是在轮子的方向上。在这种情况下，必须建立横向车辆运动的动态模型，而不是运动学模型。 考虑具有两个自由度的车辆的“自行车”模型，如图2-6所示 两个自由度分别是横向位置\\(y\\)和车辆的偏航角\\(\\psi\\)。车辆的横向位置是沿着车辆的横向轴测量到0点，即车辆的旋转中心，车辆的偏航角\\(\\psi\\)是根据全局X轴来测量的，车辆在c.g.处的纵向速度用\\(V_x\\)表示。 这里暂时不讨论道路的倾斜角。然后应用牛顿第二定律： \\[ ma_y=F_{yf}+F_{yr} \\tag{2.19} \\] 其中，\\(a_y=\\frac{d^2}{d t^2}_{inertial}\\)是车辆的在\\(y\\)轴方向的惯性加速度，\\(F_{yf},F_{yr}\\)分别是前轮胎和后轮胎的横向力，这两项对\\(y\\)轴方向的惯性加速度产生贡献，即加速度\\(\\ddot{y}\\)是由\\(y\\)轴方向的运动和向心加速度\\(V_x \\dot{\\psi}\\)产生的，因此有： \\[ a_y=\\ddot{y}+V_x \\dot{\\psi} \\tag{2.20} \\] 同时，将式2.19代入2.20，车辆横向平动运动方程为： \\[ m(\\ddot{y}+V_x \\dot{\\psi})=F_{yf}+F_{fr} \\tag{2.21} \\] 关于z轴的力矩平衡得到了偏航动力学方程： \\[ l_z \\ddot{\\psi}=l_f F_{yf}-l_r F_{yr} \\tag{2.22} \\] 补充材料： 力矩与转动惯量 从补充材料可知，上面的等式只是从向量的模来考虑。 下一步是对作用于车辆轮胎的横向力\\(F_{yf},F_{yr}\\)进行建模。试验结果表明，在小滑角情况下，轮胎的侧向力(横向力)与滑角成正比。轮胎的滑移角定义为轮胎方向与车轮速度矢量方向之间的夹角，如图2.7 如图所示，前轮的滑移角为: \\[ \\alpha_f=\\delta-\\theta_{vf} \\tag{2.23} \\] 其中，\\(\\theta_{vf}\\)是速度矢量与车辆纵轴的夹角，\\(\\delta\\)是前轮与纵轴的夹角。同样的，后轮的滑移角近似为： \\[ \\alpha_r=-\\theta_{vr} \\tag{2.24} \\] 这里暂不解释为什么会有滑移角的存在，具体可见第13章。 接下来，前轮受到的横向力可以写成: \\[ F_{yf}=2C_{\\alpha f}(\\delta-\\theta_{vf}) \\] 其中，常数\\(C_{\\alpha f}\\)称为前轮的转向刚度，\\(\\theta_{vf}\\)是前轮速度矢量与车辆纵轴的夹角，\\(\\delta\\)是前轮与纵轴的夹角。有一个系数2是因为有两个前轮。 相似的，后轮的轮胎横向力可以写成： \\[ F_{yr}=2C_{\\alpha r}(-\\theta_{vr}) \\] 其中，\\(C_{\\alpha r}\\)是前轮的转向刚度，\\(\\theta_{vr}\\)是后轮速度矢量与车辆纵轴的夹角。 于是有：(怎么来的没说) \\[ \\tan(\\theta_{vf})=\\frac{V_y+l_f \\dot{\\psi}}{V_x} \\tag{2.29} \\] \\[ \\tan(\\theta_{vr})=\\frac{V_y-l_r \\dot{\\psi}}{V_x} \\tag{2.30} \\] 使用小角度近似，\\(\\tan(x)=x\\)，有： \\[ (\\theta_{vf})=\\frac{\\dot{y}+l_f \\dot{\\psi}}{V_x} \\] \\[ (\\theta_{vr})=\\frac{\\dot{y}-l_r \\dot{\\psi}}{V_x} \\] 将式2.23、2.24、2.29、2.30代入2.21和2.22，可以得到状态空间模型： \\[ \\begin{aligned} \\frac{d}{dt} \\begin{bmatrix} y \\\\ \\dot{y} \\\\ \\psi \\\\ \\dot{\\psi} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; -\\frac{2C_{\\alpha_f}+2C_{\\alpha_r}}{mV_x} &amp; 0 &amp; -V_x-\\frac{2C_{\\alpha_f} l_f-2C_{\\alpha_r}l_r}{mV_x} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; -\\frac{2C_{\\alpha_f} l_f-2C_{\\alpha_r}l_r}{I_z V_x} &amp; 0 &amp; -\\frac{2 l_f^2 C_{\\alpha_f}+2l_r^2 C_{\\alpha_r}}{mV_x} \\end{bmatrix} \\begin{bmatrix} y \\\\ \\dot{y} \\\\ \\psi \\\\ \\dot{\\psi} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\frac{2C_{\\alpha f}}{m} \\\\ 0 \\\\ \\frac{2 l_f C_{\\alpha f}}{I_z} \\end{bmatrix} \\delta \\end{aligned} \\]","categories":[{"name":"控制相关","slug":"控制相关","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"Autoware.ai代码解读::NDT模块-1","slug":"Autoware.ai/Autoware-ai代码解读-NDT模块-1","date":"2020-03-02T11:13:47.000Z","updated":"2020-03-05T13:59:02.000Z","comments":true,"path":"2020/03/02/Autoware.ai/Autoware-ai代码解读-NDT模块-1/","link":"","permalink":"http://yoursite.com/2020/03/02/Autoware.ai/Autoware-ai%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB-NDT%E6%A8%A1%E5%9D%97-1/","excerpt":"","text":"Autoware.ai代码解读::NDT模块-1 在Autoware.ai的官方rosbag例子中，采用了NDT定位的算法进行演示，先看演示效果 Youtube https://www.youtube.com/watch?v=OWwtr_71cqI&amp;t=217s 例子中使用的定位launch文件如下 my_localization.launch 123456789101112131415161718192021222324252627282930&lt;launch&gt; &lt;!-- setting path parameter --&gt; &lt;arg name=\"get_height\" value=\"true\" /&gt; &lt;!-- Setup: --&gt; &lt;include file=\"$(find runtime_manager)/launch_files/setup_tf.launch\"&gt; &lt;arg name=\"x\" value=\"1.2\" /&gt; &lt;arg name=\"y\" value=\"0.0\" /&gt; &lt;arg name=\"z\" value=\"2.0\" /&gt; &lt;arg name=\"yaw\" value=\"0.0\" /&gt; &lt;arg name=\"pitch\" value=\"0.0\" /&gt; &lt;arg name=\"roll\" value=\"0.0\" /&gt; &lt;arg name=\"frame_id\" value=\"/base_link\" /&gt; &lt;arg name=\"child_frame_id\" value=\"/velodyne\" /&gt; &lt;arg name=\"period_in_ms\" value=\"10\"/&gt; &lt;/include&gt; &lt;include file=\"$(find vehicle_description)/launch/vehicle_model.launch\" /&gt; &lt;!-- points downsampler --&gt; &lt;include file=\"$(find points_downsampler)/launch/points_downsample.launch\" /&gt; &lt;!-- nmea2tfpose --&gt; &lt;include file=\"$(find gnss_localizer)/launch/nmea2tfpose.launch\"/&gt; &lt;!-- ndt_matching --&gt; &lt;include file=\"$(find lidar_localizer)/launch/ndt_matching.launch\"&gt; &lt;arg name=\"get_height\" value=\"$(arg get_height)\" /&gt; &lt;/include&gt;&lt;/launch&gt; 主要启动launch/ndt_matching.launch文件 launch/ndt_matching.launch文件如下 1234567891011121314151617181920212223242526272829&lt;launch&gt; &lt;arg name=\"method_type\" default=\"0\" /&gt; &lt;!-- pcl_generic=0, pcl_anh=1, pcl_anh_gpu=2, pcl_openmp=3 --&gt; &lt;arg name=\"use_gnss\" default=\"1\" /&gt; &lt;arg name=\"use_odom\" default=\"false\" /&gt; &lt;arg name=\"use_imu\" default=\"false\" /&gt; &lt;arg name=\"imu_upside_down\" default=\"false\" /&gt; &lt;arg name=\"imu_topic\" default=\"/imu_raw\" /&gt; &lt;arg name=\"queue_size\" default=\"1\" /&gt; &lt;arg name=\"offset\" default=\"linear\" /&gt; &lt;arg name=\"get_height\" default=\"false\" /&gt; &lt;arg name=\"use_local_transform\" default=\"false\" /&gt; &lt;arg name=\"sync\" default=\"false\" /&gt; &lt;arg name=\"output_log_data\" default=\"false\" /&gt; &lt;node pkg=\"lidar_localizer\" type=\"ndt_matching\" name=\"ndt_matching\" output=\"log\"&gt; &lt;param name=\"method_type\" value=\"$(arg method_type)\" /&gt; &lt;param name=\"use_gnss\" value=\"$(arg use_gnss)\" /&gt; &lt;param name=\"use_odom\" value=\"$(arg use_odom)\" /&gt; &lt;param name=\"use_imu\" value=\"$(arg use_imu)\" /&gt; &lt;param name=\"imu_upside_down\" value=\"$(arg imu_upside_down)\" /&gt; &lt;param name=\"imu_topic\" value=\"$(arg imu_topic)\" /&gt; &lt;param name=\"queue_size\" value=\"$(arg queue_size)\" /&gt; &lt;param name=\"offset\" value=\"$(arg offset)\" /&gt; &lt;param name=\"get_height\" value=\"$(arg get_height)\" /&gt; &lt;param name=\"use_local_transform\" value=\"$(arg use_local_transform)\" /&gt; &lt;param name=\"output_log_data\" value=\"$(arg output_log_data)\" /&gt; &lt;remap from=\"/points_raw\" to=\"/sync_drivers/points_raw\" if=\"$(arg sync)\" /&gt; &lt;/node&gt;&lt;/launch&gt; 可以看到，主要是一些参数的设置 接着是启动ndt_matching这个节点 现在来到ndt_matching节点的入口main函数：","categories":[{"name":"Autoware.ai","slug":"Autoware-ai","permalink":"http://yoursite.com/categories/Autoware-ai/"}],"tags":[]},{"title":"第三讲-ORB_SLAM2-局部优化","slug":"SLAM代码课程/ORB_SLAM2/第三讲-ORB-SLAM2-局部优化","date":"2020-03-02T01:17:42.000Z","updated":"2020-03-02T01:59:12.000Z","comments":true,"path":"2020/03/02/SLAM代码课程/ORB_SLAM2/第三讲-ORB-SLAM2-局部优化/","link":"","permalink":"http://yoursite.com/2020/03/02/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB_SLAM2/%E7%AC%AC%E4%B8%89%E8%AE%B2-ORB-SLAM2-%E5%B1%80%E9%83%A8%E4%BC%98%E5%8C%96/","excerpt":"","text":"第三讲-ORB_SLAM2-局部优化","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"ORB_SLAM2","slug":"SLAM代码课程/ORB-SLAM2","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB-SLAM2/"}],"tags":[]},{"title":"2D-NDT-匹配算法","slug":"Autoware.ai/2D-NDT-匹配算法","date":"2020-02-29T12:35:18.000Z","updated":"2022-02-27T04:50:25.000Z","comments":true,"path":"2020/02/29/Autoware.ai/2D-NDT-匹配算法/","link":"","permalink":"http://yoursite.com/2020/02/29/Autoware.ai/2D-NDT-%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95/","excerpt":"","text":"正态分布变换(The Normal Distributions Transform) 算法提出 Biber和Straer提出了二维数据配准的正态分布变换(NDT)方法。该算法中的关键元素是参考扫描的表示。不是将当前扫描直接匹配到参考扫描的点，而是通过正态分布的线性组合来模拟在特定位置找到表面点的可能性。 算法应用 点云配准 地图匹配 算法特点 计算正态分布是一个一次性的工作（初始化），不需要消耗大量代价计算最近邻搜索匹配点。概率密度函数在两幅图像采集之间的时间可以离线计算出来 其他配准算法 ICP 要剔除不合适的点对（点对距离过大、包含边界点的点对） 基于点对的配准，并没有包含局部形状的信息 IDC ICP的一种改进，采用极坐标代替笛卡尔坐标进行最近点搜索匹配 PIC 考虑了点云的噪音和初始位置的不确定性 Point-based probabilistic registration Gaussian fields 和NDT正态分布变换类似，利用高斯混合模型考察点和点的距离和点周围表面的相似性 Likelihood-field matching——随机场匹配 CRF匹配 Branch-and-bound registration Registration using local geometric features 2D-NDT基本原理 NDT算法论文原文是从2D角度描述的。 概率密度计算 NDT利用局部正态分布建立了一次激光扫描所有重建二维点的分布模型，首先，将机器人周围的二维空间细分为固定大小的网格(类似于占据栅格地图)，然后对于每一个单元，进行下面3个操作 收集在这个窗口内的所有2D点 计算2D点集的质心\\(q=\\frac{1}{n}\\sum_{i} x_i\\) 计算协方差矩阵\\(\\Sigma=\\frac{1}{n}\\sum_i(x_i-q)(x_i-q)^T\\) 那么，在这个单元cell内观测到一个样本在该2D点\\(\\boldsymbol{x}=(u,v)^T\\) 的概率可以用下面的正态分布来描述: \\[ \\begin{aligned} p(x) \\sim \\exp (-\\frac{(x-q)^T \\Sigma^{-1}(x-q)}{2}) \\end{aligned} \\] 与占据栅格类似，NDT建立了平面的网格细分，但是占据栅格代表的是该栅格被占据的概率，而NDT的栅格代表的是在一个单元(cell)内的每个位置上，观测到一个样本的概率。这个操作有什么好处？好处在于使用概率密度的形式对二维平面进行了分段连续可微的描述。 在进一步描述example之前，需要提出两点需要注意的地方 为了最小化离散化的影响，我们决定使用四个重叠的网格，首先放置一个边长为l的单网格，第二个则水平平移\\(\\frac{l}{2}\\)长度，第三个则垂直方向平移\\(\\frac{l}{2}\\)长度，而最后一个则水平和垂直都平移\\(\\frac{l}{2}\\)长度。如下图所示，现在每个2D点都落入到这4个cell里面，因此，如果计算一个点的概率密度，即对所有四个单元的密度进行评估，并对结果进行求和。但是在下面的讨论中，暂时不考虑这样的情况，只需考虑只有1个cell即可。 另外一个点就是，如果在一个完全没有噪声的理想情况下，协方差矩阵会变成奇异的，无法求逆。在实际情况中，协方差矩阵有时候十分接近奇异，为了避免这种情况，进行检查，检查协方差矩阵的最小特征值是否至少是最大特征值的0.001倍，如果不是，则设置该值。 下图1展示了对激光扫描进行NDT之后的结果： 右图是NDT结果，这是通过计算每个点的概率密度得到的，高亮的部分表示着该处有较大的概率密度。接下来讨论这个变换怎么发挥作用在匹配中。 帧间配准(匹配) 给定两个机器人坐标系之间的空间映射T， \\[ \\begin{aligned} T= \\begin{pmatrix} x&#39; \\\\ y&#39; \\end{pmatrix} = \\begin{pmatrix} \\cos \\phi &amp; -\\sin \\phi \\\\ \\sin \\phi &amp; \\cos \\phi \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} + \\begin{pmatrix} t_x \\\\ t_y \\end{pmatrix} \\end{aligned} \\] 其中，\\((t_x,t_y)^T\\)表示平移，\\(\\phi\\)表示旋转——（两帧之间），帧间匹配就是要求出平移和旋转的量。 本文提出的基本流程是： 对第一帧进行NDT处理 参数(R,t)初始化，可设置为0或者使用里程计的数据 对于第二帧的每一个样本，利用待优化参数将第二帧的点反投影到第一帧的坐标系中 确定每个映射点对应的正态分布 ？ 参数(R,t)的得分是通过评估每个映射点的分布并对结果求和来确定的 计算一个新的参数估计试图优化评分。这是通过执行牛顿算法的一个步骤完成的 重复，直到收敛 前4步就是前文所说的计算NDT变换，接下来详细介绍剩下的步骤 参数约定： 待优化参数\\(\\boldsymbol{T}()=\\boldsymbol{P}=(p_i){i=1,2,3}=(t_x,t_y,\\phi)^T\\) 第二帧的第i个扫描点\\(x_i\\) 第二帧的第i个扫描点反投影回第一帧坐标系后得到的点\\(x_i&#39;=T(x_i,\\boldsymbol{P})\\) \\(\\Sigma_i,q_i\\)分别是第二帧反投影点\\(x_i&#39;\\)的联合高斯分布的协方差矩阵和均值，在第一帧的NDT变换中查找 评分函数 \\[ score(p)=\\sum_i \\exp ( \\frac{-(x_i&#39;-q_i)^T \\Sigma_i^{-1}(x_i&#39;-q_i)}{2}) \\] 这个其实就是联合高斯分布的表达，其中\\(\\Sigma_i^{-1}\\)就是信息矩阵，也就是协方差矩阵的逆 牛顿迭代法优化 由于优化问题通常被描述为最小化问题，我们将采用这个约定的符号。最优化可以表示为最小化\\(-socre\\)。牛顿迭代法可以表示为求解增量方程 \\[ \\boldsymbol{H\\Delta p}=-\\boldsymbol{g} \\] 其中， \\(\\boldsymbol{g}\\)是函数\\(f()\\)的梯度转置，也就是雅克比 \\(\\boldsymbol{H}\\)是对应的海森矩阵 这个方程的解是一个增量\\(\\Delta p\\)，用来更新估计值： \\[ \\boldsymbol{p} \\leftarrow \\boldsymbol{p} +\\Delta \\boldsymbol{p} \\] 如果矩阵\\(H\\)是正定的，那么\\(f(\\boldsymbol{p})\\)将会在增量\\(\\Delta \\boldsymbol{p}\\)的方向减小，否则使用\\(\\boldsymbol{H}&#39;=\\boldsymbol{H}+\\lambda I\\)来代替\\(\\boldsymbol{H}\\)，其中\\(\\lambda\\)用来使得矩阵\\(\\boldsymbol{H}\\)变成正定。 这个算法使用函数\\(-score\\)，通过收集方程3中所有和的偏导数来建立梯度和海森矩阵。 下面的\\(x_i\\)将表示第i帧的点集，不再是第i个点？ 于是，有 \\[ q=x_i&#39;-q_i \\] 所以，优化的目标函数可以写成 \\[ -score= s =- \\exp \\frac{- \\boldsymbol{q^T} \\Sigma^{-1} \\boldsymbol{q} }{2} \\] 于是，目标函数对优化变量的梯度为 \\[ \\begin{aligned} \\bar{g_i} &amp;= - \\frac{ \\partial s}{ \\partial p[i]}= - \\frac{ \\partial s}{ \\partial q} \\frac{q}{p[i]} \\\\ &amp;= \\boldsymbol{q^T} \\Sigma^{-1} \\frac{ \\partial q}{ \\partial p[i]} \\exp \\frac{- \\boldsymbol{q^T} \\Sigma^{-1}q}{2} \\end{aligned} \\] 根据变换等式2，使用线性化的来表示，有 \\[ \\begin{aligned} u&#39; = \\cos (p[3]) u -\\sin(p[3]) v+ p[1]\\\\ v&#39; = \\sin (p[3]) u -\\cos(p[3]) v + p[2] \\end{aligned} \\] 对应的雅克比可写成 \\[ \\begin{aligned} \\boldsymbol{J_T}= \\frac{\\partial \\boldsymbol{q} }{\\partial \\boldsymbol{T} }=\\frac{\\partial \\boldsymbol{q} }{\\partial \\boldsymbol{P} }= \\begin{pmatrix} 1 &amp; 0 &amp; -x \\sin \\phi -y \\cos \\phi \\\\ 0 &amp; 1 &amp; x \\cos \\phi - y \\sin \\phi \\end{pmatrix} \\end{aligned} \\] 海森矩阵\\(\\boldsymbol{H}\\): 其中，投影后的去质心点集\\(\\boldsymbol{q}\\)对变换\\(p[i],p[j]\\)的二阶导\\(\\frac{\\partial ^2 \\boldsymbol{q} }{ \\partial p[i] \\partial p[j]}\\)可以如下表示： \\[ \\frac{ \\partial ^2 \\boldsymbol{q} }{ \\partial p_i \\partial p_j}= \\left \\{ \\begin{aligned} \\begin{pmatrix} -x \\cos \\phi + y \\sin \\phi \\\\ -x \\sin \\phi - y \\cos \\phi \\end{pmatrix} ~~ i=j=3 \\\\ \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} ~~~~~~~~~~~~~~~ otherwise \\end{aligned} \\right. \\] 注意：上面的\\(p[i],p[j]\\)都是指同一个变换\\(P\\)里面的某个元素\\(t_x,t_y, \\phi\\)其中一个。 从这些方程可以看出，建立梯度和海森矩阵的计算成本较低，每点只有一次对指数函数的调用和少量的乘法。三角函数计算仅与估计的角度\\(\\phi\\)有关，因此每次迭代都需要计算一次。 应用于位置跟踪 下面把参考的激光扫描称为关键帧，在时间\\(t=t_k\\)，算法执行一下流程 设置一个从\\(t_k-1\\)到\\(t_k\\)的运动估计作为初值\\(\\delta\\) 将当前帧的激光扫描点根据这个\\(\\delta\\)反投影到上一个时刻的机器人坐标系下 使用当前帧的扫描、参考关键帧的NDT以及新的运动估计\\(\\delta\\)来实现优化迭代 检查参考关键帧与当前帧是否比较靠近，如果是，则继续迭代，否则，采用上一次成功匹配的激光扫描作为新的关键帧。 判断一个扫描是否仍然足够近是基于一个简单的经验标准，涉及到关键帧和当前帧之间的平移和角距离以及最终的评分. SLAM上的应用 定义地图就是对关键帧的采集以及各个关键帧的位姿。 对多次扫描进行定位 对于地图上的每帧的扫描\\(i\\)，都拥有其位姿，位姿指该帧在全局坐标系下的，当前机器人姿态由旋转矩阵R和平移向量t表示 添加关键帧以及优化地图 地图是由一些关键帧以及它们的全局坐标系位姿组成的，如果当前扫描与地图的重叠太小，那么只取到最后一次成功匹配的扫描来组成地图。然后，每个重叠的扫描分别匹配到新的关键帧，产生两个扫描之间的相对位姿，这意味着需要维护一个图，其中包含成对匹配结果的信息。 在这个图里面，每个关键帧都使用一个节点来代表，每个节点维护着对应关键帧的世界坐标系的位姿。两个节点之间的边表示对应的扫描已经成对匹配，并维护着两个扫描之间的相对位姿，作为优化的约束条件。 当一个新的关键帧插入，地图会通过优化损失函数来调整所有关键帧的位姿来进行调整。关键帧之间两两配准的结果被用来定义每一对匹配的二次误差模型如下：两次扫描的全局位姿参数可用来表示两次扫描之间的相对位姿。 如果使用\\(\\Delta T\\)来表示(使用两次扫描的全局位姿所构成的相对位姿)与(使用NDT匹配算法得到的相对位姿)之间的差，那么评分模型可以使用下面来描述 \\[ socre&#39;(\\Delta T)= score + \\frac{1}{2} (\\Delta T)^T H (\\Delta T) \\] 这种全局优化的做法，当关键帧的数量变得很大的时候，难以再实时进行，因为待优化的参数随关键帧呈线性增长\\(3N-3\\)，每个关键帧都需要3个参数，后面减3是因为第一个关键帧的位姿固定为(0,0,0)，为了减少在零空间的漂移，采用固定第一帧的做法。 为了避免这个问题，文章采用使用局部图的思想，只对一个局部地图进行优化，这个局部子图通过遍历所有的关键帧，只有与当前帧相连不超过3条边的，才参与组成这个局部子图。我们现在只针对参数优化上面的错误函数，这些参数属于这个子图中包含的关键帧。 当然，如果如果要形成回环，我们将不得不优化所有关键帧。 文章实现效果 2020-03-06更新： PCL中关于2D-NDT的代码及注释 PCL代码基本与论文一致 ndt_2d.h 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#pragma once#include &lt;pcl/pcl_macros.h&gt;#include &lt;pcl/registration/registration.h&gt;namespace pcl&#123;/** \\brief @b NormalDistributionsTransform2D provides an implementation of the * Normal Distributions Transform algorithm for scan matching. * * This implementation is intended to match the definition: * Peter Biber and Wolfgang Straßer. The normal distributions transform: A * new approach to laser scan matching. In Proceedings of the IEEE In- * ternational Conference on Intelligent Robots and Systems (IROS), pages * 2743–2748, Las Vegas, USA, October 2003. * * \\author James Crosby */// 2D-NDT点云配准template &lt;typename PointSource, typename PointTarget&gt;class NormalDistributionsTransform2D : public Registration&lt;PointSource, PointTarget&gt;&#123; using PointCloudSource = typename Registration&lt;PointSource, PointTarget&gt;::PointCloudSource; using PointCloudSourcePtr = typename PointCloudSource::Ptr; using PointCloudSourceConstPtr = typename PointCloudSource::ConstPtr; using PointCloudTarget = typename Registration&lt;PointSource, PointTarget&gt;::PointCloudTarget; using PointIndicesPtr = PointIndices::Ptr; using PointIndicesConstPtr = PointIndices::ConstPtr;public: using Ptr = shared_ptr&lt; NormalDistributionsTransform2D&lt;PointSource, PointTarget&gt; &gt;; using ConstPtr = shared_ptr&lt; const NormalDistributionsTransform2D&lt;PointSource, PointTarget&gt; &gt;; /** \\brief Empty constructor. */ // 空的构造函数 NormalDistributionsTransform2D () : Registration&lt;PointSource,PointTarget&gt; (), grid_centre_ (0,0), grid_step_ (1,1), grid_extent_ (20,20), newton_lambda_ (1,1,1) &#123; reg_name_ = \"NormalDistributionsTransform2D\"; &#125; /** \\brief Empty destructor */ ~NormalDistributionsTransform2D () &#123;&#125; /** \\brief centre of the ndt grid (target coordinate system) * \\param centre value to set */ // 设置NDT网格中心， 目标坐标系的， (也就是要将点云匹配过去的坐标系) virtual void setGridCentre (const Eigen::Vector2f&amp; centre) &#123; grid_centre_ = centre; &#125; /** \\brief Grid spacing (step) of the NDT grid * \\param[in] step value to set */ // 步长设置 virtual void setGridStep (const Eigen::Vector2f&amp; step) &#123; grid_step_ = step; &#125; /** \\brief NDT Grid extent (in either direction from the grid centre) * \\param[in] extent value to set */ // 从网格中心扩展多少，也就是NDT cell范围？ virtual void setGridExtent (const Eigen::Vector2f&amp; extent) &#123; grid_extent_ = extent; &#125; /** \\brief NDT Newton optimisation step size parameter * \\param[in] lambda step size: 1 is simple newton optimisation, smaller values may improve convergence */ // 设置优化步长， 1是简单的牛顿迭代， 更小的值可以提高收敛效果 virtual void setOptimizationStepSize (const double&amp; lambda) &#123; newton_lambda_ = Eigen::Vector3d (lambda, lambda, lambda); &#125; /** \\brief NDT Newton optimisation step size parameter * \\param[in] lambda step size: (1,1,1) is simple newton optimisation, * smaller values may improve convergence, or elements may be set to * zero to prevent optimisation over some parameters * * This overload allows control of updates to the individual (x, y, * theta) free parameters in the optimisation. If, for example, theta is * believed to be close to the correct value a small value of lambda[2] * should be used. */ // 重载函数， 就是说，当认为优化的时候某个变量如朝向角已经足够精确了，那么可以把 lambda[2]设置为一个小值，加快速度 virtual void setOptimizationStepSize (const Eigen::Vector3d&amp; lambda) &#123; newton_lambda_ = lambda; &#125;protected: /** \\brief Rigid transformation computation method with initial guess. * \\param[out] output the transformed input point cloud dataset using the rigid transformation found * \\param[in] guess the initial guess of the transformation to compute */ // 使用初始位姿计算点云之间的变换矩阵，输出： 利用变换将输入点云匹配到目标点云 void computeTransformation (PointCloudSource &amp;output, const Eigen::Matrix4f &amp;guess) override; using Registration&lt;PointSource, PointTarget&gt;::reg_name_; using Registration&lt;PointSource, PointTarget&gt;::target_; using Registration&lt;PointSource, PointTarget&gt;::converged_; using Registration&lt;PointSource, PointTarget&gt;::nr_iterations_; using Registration&lt;PointSource, PointTarget&gt;::max_iterations_; using Registration&lt;PointSource, PointTarget&gt;::transformation_epsilon_; using Registration&lt;PointSource, PointTarget&gt;::transformation_rotation_epsilon_; using Registration&lt;PointSource, PointTarget&gt;::transformation_; using Registration&lt;PointSource, PointTarget&gt;::previous_transformation_; using Registration&lt;PointSource, PointTarget&gt;::final_transformation_; using Registration&lt;PointSource, PointTarget&gt;::update_visualizer_; using Registration&lt;PointSource, PointTarget&gt;::indices_; Eigen::Vector2f grid_centre_; Eigen::Vector2f grid_step_; Eigen::Vector2f grid_extent_; Eigen::Vector3d newton_lambda_;public: PCL_MAKE_ALIGNED_OPERATOR_NEW&#125;;&#125; // namespace pcl#include &lt;pcl/registration/impl/ndt_2d.hpp&gt; ndt_2d.hpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546#ifndef PCL_NDT_2D_IMPL_H_#define PCL_NDT_2D_IMPL_H_#include &lt;pcl/registration/eigen.h&gt;#include &lt;pcl/registration/boost.h&gt;#include &lt;cmath&gt;#include &lt;memory&gt;namespace pcl&#123;namespace ndt2d&#123;/** \\brief Class to store vector value and first and second derivatives * (grad vector and hessian matrix), so they can be returned easily from * functions */// 储存一阶导数和二阶导数// 可以看做是增量方程template&lt;unsigned N=3, typename T=double&gt;struct ValueAndDerivatives&#123; ValueAndDerivatives () : hessian (), grad (), value () &#123;&#125; Eigen::Matrix&lt;T, N, N&gt; hessian; Eigen::Matrix&lt;T, N, 1&gt; grad; T value; static ValueAndDerivatives&lt;N,T&gt; Zero () &#123; ValueAndDerivatives&lt;N,T&gt; r; r.hessian = Eigen::Matrix&lt;T, N, N&gt;::Zero (); r.grad = Eigen::Matrix&lt;T, N, 1&gt;::Zero (); r.value = 0; return r; &#125; ValueAndDerivatives&lt;N,T&gt;&amp; operator+= (ValueAndDerivatives&lt;N,T&gt; const&amp; r) &#123; hessian += r.hessian; grad += r.grad; value += r.value; return *this; &#125;&#125;;/** \\brief A normal distribution estimation class. * * First the indices of of the points from a point cloud that should be * modelled by the distribution are added with addIdx (...). * * Then estimateParams (...) uses the stored point indices to estimate the * parameters of a normal distribution, and discards the stored indices. * * Finally the distriubution, and its derivatives, may be evaluated at any * point using test (...). */// 这是单个cell的NDT模型// 可以理解为某个celltemplate &lt;typename PointT&gt;class NormalDist&#123; using PointCloud = pcl::PointCloud&lt;PointT&gt;;public: NormalDist () : min_n_ (3), n_ (0) &#123; &#125; /** \\brief Store a point index to use later for estimating distribution parameters. * \\param[in] i Point index to store */ void addIdx (std::size_t i) &#123; pt_indices_.push_back (i); &#125; /** \\brief Estimate the normal distribution parameters given the point indices provided. Memory of point indices is cleared. * \\param[in] cloud Point cloud corresponding to indices passed to addIdx. * \\param[in] min_covar_eigvalue_mult Set the smallest eigenvalue to this times the largest. */ // 给定cell网格中的点云，估计正态分布参数 (主要是均值和方差) void estimateParams (const PointCloud&amp; cloud, double min_covar_eigvalue_mult = 0.001) &#123; Eigen::Vector2d sx = Eigen::Vector2d::Zero (); Eigen::Matrix2d sxx = Eigen::Matrix2d::Zero (); // sx： 对所有点的x，y分别求和 // sxx: 2维向量，分别是 点云的 x^2和， y^2和 for (auto i = pt_indices_.cbegin (); i != pt_indices_.cend (); i++) &#123; Eigen::Vector2d p (cloud[*i]. x, cloud[*i]. y); sx += p; sxx += p * p.transpose (); &#125; n_ = pt_indices_.size (); // 检查cell网格中的点云里面点的个数是否大于3 if (n_ &gt;= min_n_) &#123; // 求质心，存到mean_ mean_ = sx / static_cast&lt;double&gt; (n_); // Using maximum likelihood estimation as in the original paper // 计算协方差矩阵 Eigen::Matrix2d covar = (sxx - 2 * (sx * mean_.transpose ())) / static_cast&lt;double&gt; (n_) + mean_ * mean_.transpose (); // 求特征值 Eigen::SelfAdjointEigenSolver&lt;Eigen::Matrix2d&gt; solver (covar); // 如果最小的特征值比 0.001*最大的特征值小，则不需要修正协方差矩阵 if (solver.eigenvalues ()[0] &lt; min_covar_eigvalue_mult * solver.eigenvalues ()[1]) &#123; // 否则，修正协方差矩阵， PCL_DEBUG (\"[pcl::NormalDist::estimateParams] NDT normal fit: adjusting eigenvalue %f\\n\", solver.eigenvalues ()[0]); Eigen::Matrix2d l = solver.eigenvalues ().asDiagonal (); Eigen::Matrix2d q = solver.eigenvectors (); // set minimum smallest eigenvalue: // 将最小的特征值设置为最大特征值的0.0001倍 l (0,0) = l (1,1) * min_covar_eigvalue_mult; // 重新合成协方差矩阵 covar = q * l * q.transpose (); &#125; // 储存协方差矩阵的逆，即信息矩阵 covar_inv_ = covar.inverse (); &#125; // 清空点云 pt_indices_.clear (); &#125; /** \\brief Return the 'score' (denormalised likelihood) and derivatives of score of the point p given this distribution. * \\param[in] transformed_pt Location to evaluate at. * \\param[in] cos_theta sin(theta) of the current rotation angle of rigid transformation: to avoid repeated evaluation * \\param[in] sin_theta cos(theta) of the current rotation angle of rigid transformation: to avoid repeated evaluation * estimateParams must have been called after at least three points were provided, or this will return zero. * */ // 输入 要变换的点pt, 旋转变换的 cos，sin // estimateParams必须在至少提供了三个点之后调用，否则将返回零 ValueAndDerivatives&lt;3,double&gt; test (const PointT&amp; transformed_pt, const double&amp; cos_theta, const double&amp; sin_theta) const &#123; // 如果输入的点云数&lt;3，则返回 导数为0 if (n_ &lt; min_n_) return ValueAndDerivatives&lt;3,double&gt;::Zero (); // 开始计算导数 ValueAndDerivatives&lt;3,double&gt; r; // 取变换之后的点 const double x = transformed_pt.x; const double y = transformed_pt.y; const Eigen::Vector2d p_xy (transformed_pt.x, transformed_pt.y); // 该点减去目标点云的质心 const Eigen::Vector2d q = p_xy - mean_; // 求出将该点坐标代入 NDT 分布之后得到的值 exp(-0.5*[q.transpose () * covar_inv_*q]) const Eigen::RowVector2d qt_cvi (q.transpose () * covar_inv_); // 转成行向量1x2 const double exp_qt_cvi_q = std::exp (-0.5 * double (qt_cvi * q)); // 这是增量方程等式的右侧，即b r.value = -exp_qt_cvi_q; // 下面开始求雅克比 // 与论文一一对应 Eigen::Matrix&lt;double, 2, 3&gt; jacobian; jacobian &lt;&lt; 1, 0, -(x * sin_theta + y*cos_theta), 0, 1, x * cos_theta - y*sin_theta; // 储存梯度 for (std::size_t i = 0; i &lt; 3; i++) r.grad[i] = double (qt_cvi * jacobian.col (i)) * exp_qt_cvi_q; // second derivative only for i == j == 2: // 下面求海森矩阵， 只有在i=j=2的时候才有二阶导 const Eigen::Vector2d d2q_didj ( y * sin_theta - x*cos_theta, -(x * sin_theta + y*cos_theta) ); for (std::size_t i = 0; i &lt; 3; i++) for (std::size_t j = 0; j &lt; 3; j++) r.hessian (i,j) = -exp_qt_cvi_q * ( double (-qt_cvi*jacobian.col (i)) * double (-qt_cvi*jacobian.col (j)) + (-qt_cvi * ((i==2 &amp;&amp; j==2)? d2q_didj : Eigen::Vector2d::Zero ())) + (-jacobian.col (j).transpose () * covar_inv_ * jacobian.col (i)) ); //返回与增量方程相关的参数 r return r; &#125;protected: const std::size_t min_n_; std::size_t n_; std::vector&lt;std::size_t&gt; pt_indices_; Eigen::Vector2d mean_; Eigen::Matrix2d covar_inv_;&#125;;/** \\brief Build a set of normal distributions modelling a 2D point cloud, * and provide the value and derivatives of the model at any point via the * test (...) function. */// 一个点云中的NDT模型的集合(每个cell都有一个NDT)template &lt;typename PointT&gt;class NDTSingleGrid: public boost::noncopyable&#123; using PointCloud = pcl::PointCloud&lt;PointT&gt;; using PointCloudConstPtr = typename PointCloud::ConstPtr; using NormalDist = pcl::ndt2d::NormalDist&lt;PointT&gt;; // 一个cellpublic: // 构造 NDTSingleGrid (PointCloudConstPtr cloud, const Eigen::Vector2f&amp; about, const Eigen::Vector2f&amp; extent, const Eigen::Vector2f&amp; step) : min_ (about - extent), max_ (min_ + 2*extent), step_ (step), cells_ ((max_[0]-min_[0]) / step_[0], (max_[1]-min_[1]) / step_[1]), normal_distributions_ (cells_[0], cells_[1]) &#123; // about : 给定点云中，准备建立的某个cell的中心点的坐标？ // extent： cell划分范围 // step ： 步长？ // sort through all points, assigning them to distributions: std::size_t used_points = 0; // 遍历点云里面的所有点 for (std::size_t i = 0; i &lt; cloud-&gt;size (); i++) if (NormalDist* n = normalDistForPoint (cloud-&gt;at (i))) // 计算点P落在哪一个cell &#123; //n : 某个cell //向该cell添加这个点在总点云的索引i n-&gt;addIdx (i); used_points++; &#125; PCL_DEBUG (\"[pcl::NDTSingleGrid] NDT single grid %dx%d using %d/%d points\\n\", cells_[0], cells_[1], used_points, cloud-&gt;size ()); // then bake the distributions such that they approximate the // points (and throw away memory of the points) // 将点云中每个点都分配到各个cell之后，对各个cell进行参数计算 for (int x = 0; x &lt; cells_[0]; x++) for (int y = 0; y &lt; cells_[1]; y++) normal_distributions_.coeffRef (x,y).estimateParams (*cloud); &#125; /** \\brief Return the 'score' (denormalised likelihood) and derivatives of score of the point p given this distribution. * \\param[in] transformed_pt Location to evaluate at. * \\param[in] cos_theta sin(theta) of the current rotation angle of rigid transformation: to avoid repeated evaluation * \\param[in] sin_theta cos(theta) of the current rotation angle of rigid transformation: to avoid repeated evaluation */ ValueAndDerivatives&lt;3,double&gt; test (const PointT&amp; transformed_pt, const double&amp; cos_theta, const double&amp; sin_theta) const &#123; // 输入某个变换之后的点，以及cos ,sin // 得到变换之后的点所对应的cell对象 const NormalDist* n = normalDistForPoint (transformed_pt); // index is in grid, return score from the normal distribution from // the correct part of the grid: // 如果该点在范围内，即对应的cell对象存在 if (n) return n-&gt;test (transformed_pt, cos_theta, sin_theta); //根据参数计算并返回该cell的增量方程 return ValueAndDerivatives&lt;3,double&gt;::Zero (); &#125;protected: /** \\brief Return the normal distribution covering the location of point p * \\param[in] p a point */ // 这个函数输入点云中的一个点P，根据窗口范围、步长等参数，计算该点P落在哪一个cell // 然后返回那个cell的对象 NormalDist* normalDistForPoint (PointT const&amp; p) const &#123; // this would be neater in 3d... // 计算该3D点应该落在哪个cell？ Eigen::Vector2f idxf; for (std::size_t i = 0; i &lt; 2; i++) idxf[i] = (p.getVector3fMap ()[i] - min_[i]) / step_[i]; //idxf[]：储存对应cell的行号,列号 // 检查该点是否落在总的划分范围内 Eigen::Vector2i idxi = idxf.cast&lt;int&gt; (); for (std::size_t i = 0; i &lt; 2; i++) if (idxi[i] &gt;= cells_[i] || idxi[i] &lt; 0) return nullptr; // // const cast to avoid duplicating this function in const and // non-const variants... // 返回类型为NormalDist的东西，就是某个cell， return const_cast&lt;NormalDist*&gt; (&amp;normal_distributions_.coeffRef (idxi[0], idxi[1])); &#125; Eigen::Vector2f min_; Eigen::Vector2f max_; Eigen::Vector2f step_; Eigen::Vector2i cells_; // 将原始点云分割的网格数, [] //这个Matrix[i][j]表示将点云划分之后的 第i行第j列的cell //使用Eigen::Matrix 来储存 cell对象？ Eigen::Matrix&lt;NormalDist, Eigen::Dynamic, Eigen::Dynamic&gt; normal_distributions_;&#125;;/** \\brief Build a Normal Distributions Transform of a 2D point cloud. This * consists of the sum of four overlapping models of the original points * with normal distributions. * The value and derivatives of the model at any point can be evaluated * with the test (...) function. */// 建立一个二维点云的正态分布变换(这是4个NDT模型的叠加)// 这个是由四个重叠的模型组成的，每个模型有各自的原始点与正态分布// 一些值以及微分项由test函数计算template &lt;typename PointT&gt;class NDT2D: public boost::noncopyable&#123; using PointCloud = pcl::PointCloud&lt;PointT&gt;; using PointCloudConstPtr = typename PointCloud::ConstPtr; // 点云的&#123;所有cell的集合&#125;(储存着每个cell的NDT模型) // 一个NDTSingleGrid对应着总点云的中心、窗口大小、步长等参数 // 下面会使用4个不同的中心，得到同一个总点云的4组&#123;cell集合&#125; using SingleGrid = NDTSingleGrid&lt;PointT&gt;;public: /** \\brief * \\param[in] cloud the input point cloud * \\param[in] about Centre of the grid for normal distributions model * \\param[in] extent Extent of grid for normal distributions model * \\param[in] step Size of region that each normal distribution will model */ // 输入原始点云，中心，范围，步长 NDT2D (PointCloudConstPtr cloud, const Eigen::Vector2f&amp; about, const Eigen::Vector2f&amp; extent, const Eigen::Vector2f&amp; step) &#123; Eigen::Vector2f dx (step[0]/2, 0); Eigen::Vector2f dy (0, step[1]/2); //以窗口为中心，得到中心点进行偏移之后的cell集合， 一共得到4组cell集合 single_grids_[0].reset(new SingleGrid (cloud, about, extent, step)); single_grids_[1].reset(new SingleGrid (cloud, about +dx, extent, step)); single_grids_[2].reset(new SingleGrid (cloud, about +dy, extent, step)); single_grids_[3].reset(new SingleGrid (cloud, about +dx+dy, extent, step)); &#125; /** \\brief Return the 'score' (denormalised likelihood) and derivatives of score of the point p given this distribution. * \\param[in] transformed_pt Location to evaluate at. * \\param[in] cos_theta sin(theta) of the current rotation angle of rigid transformation: to avoid repeated evaluation * \\param[in] sin_theta cos(theta) of the current rotation angle of rigid transformation: to avoid repeated evaluation */ ValueAndDerivatives&lt;3,double&gt; test (const PointT&amp; transformed_pt, const double&amp; cos_theta, const double&amp; sin_theta) const &#123; // 输入某个来自当前帧的点P利用变换矩阵转换之后的投影点Pt，以及转换参数 cos , sin // 计算4组cell集合各自的增量方程，然后求和，得到一个新的增量方程，也就是最终的增量方程 ValueAndDerivatives&lt;3,double&gt; r = ValueAndDerivatives&lt;3,double&gt;::Zero (); for (const auto &amp;single_grid : single_grids_) r += single_grid-&gt;test (transformed_pt, cos_theta, sin_theta); return r; &#125;protected: std::shared_ptr&lt;SingleGrid&gt; single_grids_[4];&#125;;&#125; // namespace ndt2d&#125; // namespace pclnamespace Eigen&#123;/* This NumTraits specialisation is necessary because NormalDist is used as * the element type of an Eigen Matrix. */template&lt;typename PointT&gt; struct NumTraits&lt;pcl::ndt2d::NormalDist&lt;PointT&gt; &gt;&#123; using Real = double; using Literal = double; static Real dummy_precision () &#123; return 1.0; &#125; enum &#123; IsComplex = 0, IsInteger = 0, IsSigned = 0, RequireInitialization = 1, ReadCost = 1, AddCost = 1, MulCost = 1 &#125;;&#125;;&#125;//////////////////////////////////////////////////////////////////////////////////////////////////////////////////template &lt;typename PointSource, typename PointTarget&gt; voidpcl::NormalDistributionsTransform2D&lt;PointSource, PointTarget&gt;::computeTransformation (PointCloudSource &amp;output, const Eigen::Matrix4f &amp;guess)&#123; // 这是要输出的点云 PointCloudSource intm_cloud = output; nr_iterations_ = 0; converged_ = false; if (guess != Eigen::Matrix4f::Identity ()) &#123; transformation_ = guess; transformPointCloud (output, intm_cloud, transformation_); &#125; // build Normal Distribution Transform of target cloud: // 为目标点云创建NDT变换 // target_ndt里面包含了目标点云的所有cell的NDT分布 // 后面会调用target_ndt.test()函数，通过计算点落在哪一个cell中，根据该cell的NDT分布计算出关于该点P的增量方程 ndt2d::NDT2D&lt;PointTarget&gt; target_ndt (target_, grid_centre_, grid_extent_, grid_step_); // can't seem to use .block&lt;&gt; () member function on transformation_ // directly... gcc bug? // 设置初始值 Eigen::Matrix4f&amp; transformation = transformation_; // work with x translation, y translation and z rotation: extending to 3D // would be some tricky maths, but not impossible. const Eigen::Matrix3f initial_rot (transformation.block&lt;3,3&gt; (0,0)); const Eigen::Vector3f rot_x (initial_rot*Eigen::Vector3f::UnitX ()); // y/x const double z_rotation = std::atan2 (rot_x[1], rot_x[0]); // 从4x4的变换矩阵T，提取2D所需的3个维度，构成3x1向量 Eigen::Vector3d xytheta_transformation ( transformation (0,3), transformation (1,3), z_rotation ); // 开始迭代 while (!converged_) &#123; // 利用角度yaw求 cos , sin const double cos_theta = std::cos (xytheta_transformation[2]); const double sin_theta = std::sin (xytheta_transformation[2]); // 将当前变换保存 previous_transformation_ = transformation; // ValueAndDerivatives: 储存一阶导数和二阶导数的类 ndt2d::ValueAndDerivatives&lt;3, double&gt; score = ndt2d::ValueAndDerivatives&lt;3, double&gt;::Zero (); // 将源点云中的每个点intm_cloud[i]，代入到目标点云的NDT 正太分布函数，构造增量方程,增量方程参数储存在score for (std::size_t i = 0; i &lt; intm_cloud.size (); i++) score += target_ndt.test (intm_cloud[i], cos_theta, sin_theta); PCL_DEBUG (\"[pcl::NormalDistributionsTransform2D::computeTransformation] NDT score %f (x=%f,y=%f,r=%f)\\n\", float (score.value), xytheta_transformation[0], xytheta_transformation[1], xytheta_transformation[2] ); // 检查增量方程右侧是否为0 if (score.value != 0) &#123; // 通过特征值分解，进行检查 // 检查系数矩阵是否正定，否则修正系数矩阵 // test for positive definiteness, and adjust to ensure it if necessary: Eigen::EigenSolver&lt;Eigen::Matrix3d&gt; solver; solver.compute (score.hessian, false); double min_eigenvalue = 0; for (int i = 0; i &lt;3; i++) if (solver.eigenvalues ()[i].real () &lt; min_eigenvalue) min_eigenvalue = solver.eigenvalues ()[i].real (); // 如果最小的特征值&lt;0，则进行修正 通过加上 lambda * I 的对角矩阵 // ensure \"safe\" positive definiteness: this is a detail missing // from the original paper if (min_eigenvalue &lt; 0) &#123; double lambda = 1.1 * min_eigenvalue - 1; score.hessian += Eigen::Vector3d (-lambda, -lambda, -lambda).asDiagonal (); solver.compute (score.hessian, false); PCL_DEBUG (\"[pcl::NormalDistributionsTransform2D::computeTransformation] adjust hessian: %f: new eigenvalues:%f %f %f\\n\", float (lambda), solver.eigenvalues ()[0].real (), solver.eigenvalues ()[1].real (), solver.eigenvalues ()[2].real () ); &#125; // 异常检查 assert (solver.eigenvalues ()[0].real () &gt;= 0 &amp;&amp; solver.eigenvalues ()[1].real () &gt;= 0 &amp;&amp; solver.eigenvalues ()[2].real () &gt;= 0); // 直接得到增量 delta_T = -H^T*J Eigen::Vector3d delta_transformation (-score.hessian.inverse () * score.grad); // 利用增量计算得到新的变换矩阵 T_new = T_old + lambda * delta_T // cwiseProduct()函数允许Matrix直接进行点对点乘法 Eigen::Vector3d new_transformation = xytheta_transformation + newton_lambda_.cwiseProduct (delta_transformation); // 输出新的变换 xytheta_transformation = new_transformation; // update transformation matrix from x, y, theta: // 更新变换矩阵 transformation.block&lt;3,3&gt; (0,0).matrix () = Eigen::Matrix3f (Eigen::AngleAxisf (static_cast&lt;float&gt; (xytheta_transformation[2]), Eigen::Vector3f::UnitZ ())); transformation.block&lt;3,1&gt; (0,3).matrix () = Eigen::Vector3f (static_cast&lt;float&gt; (xytheta_transformation[0]), static_cast&lt;float&gt; (xytheta_transformation[1]), 0.0f); //std::cout &lt;&lt; \"new transformation:\\n\" &lt;&lt; transformation &lt;&lt; std::endl; &#125; else &#123; // 如果增量方程右侧=0， 无法求解 PCL_ERROR (\"[pcl::NormalDistributionsTransform2D::computeTransformation] no overlap: try increasing the size or reducing the step of the grid\\n\"); break; &#125; // 利用这次迭代出来的变换，将当前点云 变换到 目标点云坐标系上，得到intm_cloud transformPointCloud (output, intm_cloud, transformation); // 迭代次数+1 nr_iterations_++; // 更新可视化？ if (update_visualizer_) update_visualizer_ (output, *indices_, *target_, *indices_); //std::cout &lt;&lt; \"eps=\" &lt;&lt; std::abs ((transformation - previous_transformation_).sum ()) &lt;&lt; std::endl; // 检查与上一次变换的差，是否足够小，如果很小了，表示收敛，优化完成 Eigen::Matrix4f transformation_delta = transformation.inverse() * previous_transformation_; double cos_angle = 0.5 * (transformation_delta.coeff (0, 0) + transformation_delta.coeff (1, 1) + transformation_delta.coeff (2, 2) - 1); double translation_sqr = transformation_delta.coeff (0, 3) * transformation_delta.coeff (0, 3) + transformation_delta.coeff (1, 3) * transformation_delta.coeff (1, 3) + transformation_delta.coeff (2, 3) * transformation_delta.coeff (2, 3); if (nr_iterations_ &gt;= max_iterations_ || ((transformation_epsilon_ &gt; 0 &amp;&amp; translation_sqr &lt;= transformation_epsilon_) &amp;&amp; (transformation_rotation_epsilon_ &gt; 0 &amp;&amp; cos_angle &gt;= transformation_rotation_epsilon_)) || ((transformation_epsilon_ &lt;= 0) &amp;&amp; (transformation_rotation_epsilon_ &gt; 0 &amp;&amp; cos_angle &gt;= transformation_rotation_epsilon_)) || ((transformation_epsilon_ &gt; 0 &amp;&amp; translation_sqr &lt;= transformation_epsilon_) &amp;&amp; (transformation_rotation_epsilon_ &lt;= 0))) &#123; converged_ = true; &#125; &#125; // 输出 final_transformation_ = transformation; output = intm_cloud;&#125;#endif // PCL_NDT_2D_IMPL_H_ 参考资料 ndt算法学习 自动驾驶系列：激光雷达建图和定位(NDT) 如何使用正态分布变换（Normal Distributions Transform）进行配准 NDT 算法（与ICP对比）和一些常见配准算法 NDT方法 NDT（Normal Distributions Transform）算法原理与公式推导 原文：The Normal Distributions Transform: A New Approach to Laser Scan Matching","categories":[{"name":"Autoware.ai","slug":"Autoware-ai","permalink":"http://yoursite.com/categories/Autoware-ai/"}],"tags":[]},{"title":"ROS2-6-创建Package","slug":"ROS2/ROS2-6-创建Package","date":"2020-02-28T17:52:03.000Z","updated":"2020-02-29T17:13:22.000Z","comments":true,"path":"2020/02/29/ROS2/ROS2-6-创建Package/","link":"","permalink":"http://yoursite.com/2020/02/29/ROS2/ROS2-6-%E5%88%9B%E5%BB%BAPackage/","excerpt":"","text":"学习创建一个ROS 2 Package 目标：使用CMake或Python创建一个新程序包，并运行其可执行文件 什么是ROS 2软件包 可以将包视为ROS 2代码的容器。如果您希望能够安装代码或与他人共享代码，则需要将其组织在一个软件包中。使用软件包，您可以发布ROS 2的工作，并允许其他人轻松构建和使用它。 Package 的构成 C++ package.xml file containing meta information about the package CMakeLists.txt file that describes how to build the code within the package Python package.xml file containing meta information about the package setup.py containing instructions for how to install the package setup.cfg is required when a package has executables, so ros2 run can find them your_package_name - a file used by ROS 2 tools to find your package 最简单的程序包可能具有如下所示的文件结构： C++ 123my_package&#x2F; CMakeLists.txt package.xml Python 1234my_package&#x2F; setup.py package.xml resource&#x2F;my_package 工作空间中的Package 一个工作空间可以包含所需数量的程序包，每个程序包都位于其自己的文件夹中。您还可以在一个工作空间（CMake，Python等）中拥有不同构建类型的软件包。您不能有嵌套的程序包。 最佳做法是src在工作区中有一个文件夹，然后在其中创建包。这样可以使工作空间的顶层保持“干净”。 一个琐碎的工作区可能看起来像： 1234567891011121314workspace_folder&#x2F; src&#x2F; package_1&#x2F; CMakeLists.txt package.xml package_2&#x2F; setup.py package.xml resource&#x2F;my_package ... package_n&#x2F; CMakeLists.txt package.xml 开始 创建包 src运行软件包创建命令之前，请确保您位于文件夹中。 1cd 工作空间路径&#x2F;src 在ROS 2中创建新程序包的命令语法为： 1ros2 pkg create --build-type ament_cmake &lt;package_name&gt; 对于本教程，您将使用可选参数--node-name，该参数在包中创建一个简单的Hello World类型的可执行文件。 在终端中输入以下命令： 1ros2 pkg create --build-type ament_cmake --node-name my_node my_package 现在，在工作区的src目录中将有一个名为的新文件夹my_package。 运行命令后，您的终端将返回以下消息： 123456789101112131415161718going to create a new packagepackage name: my_packagedestination directory: 工作空间路径&#x2F;srcpackage format: 3version: 0.0.0description: TODO: Package descriptionmaintainer: [&#39;&lt;name&gt; &lt;email&gt;&#39;]licenses: [&#39;TODO: License declaration&#39;]build type: ament_cmakedependencies: []node_name: my_nodecreating folder .&#x2F;my_packagecreating .&#x2F;my_package&#x2F;package.xmlcreating source and include foldercreating folder .&#x2F;my_package&#x2F;srccreating folder .&#x2F;my_package&#x2F;include&#x2F;my_packagecreating .&#x2F;my_package&#x2F;CMakeLists.txtcreating .&#x2F;my_package&#x2F;src&#x2F;my_node.cpp 编译(构建)包 现在，您可以构建软件包： 1colcon build 若只构建某个Package，可以如下 1colcon build --packages-select my_package 运行包里面的可执行文件(节点) 先运行以下命令来获取工作空间： 1. install&#x2F;setup.bash 要--node-name在包创建期间运行使用参数创建的可执行文件，请输入以下命令： 1ros2 run my_package my_node 它将向您的终端返回一条消息： 1hello world my_package package image-20200229021320444","categories":[{"name":"ROS2","slug":"ROS2","permalink":"http://yoursite.com/categories/ROS2/"}],"tags":[]},{"title":"ROS2-5-ROS2bag包","slug":"ROS2/ROS2-5-ROS2bag包","date":"2020-02-28T17:06:12.000Z","updated":"2020-02-28T17:40:45.000Z","comments":true,"path":"2020/02/29/ROS2/ROS2-5-ROS2bag包/","link":"","permalink":"http://yoursite.com/2020/02/29/ROS2/ROS2-5-ROS2bag%E5%8C%85/","excerpt":"","text":"ROS2 bag----录制和回放 ros2 bag是用于记录系统中有关主题发布的数据的命令行工具。它累积在任何数量的主题上传递的数据，并将其保存在数据库中。然后，您可以重播数据以重现测试和实验的结果。录制主题也是共享您的作品并允许其他人重新创建作品的一种好方法。 安装ROS2bag 1sudo apt-get install ros-eloquent-ros2bag ros-eloquent-rosbag2* ROS2bag的使用 您将在turtlesim系统中记录键盘输入，以供以后保存和重播，因此首先要启动/turtlesimand /teleop_turtle节点。 打开一个新终端并运行： 1ros2 run turtlesim turtlesim_node 打开另一个终端并运行： 1ros2 run turtlesim turtle_teleop_key 同样，让我们创建一个新目录来存储保存的录音，这是一种很好的做法： 1mkdir bag_files 选择一个话题来记录 ros2 bag只能记录发布主题的数据。要查看系统主题列表，请打开一个新终端并运行以下命令： 1ros2 topic list 将返回： 12345&#x2F;parameter_events&#x2F;rosout&#x2F;turtle1&#x2F;cmd_vel&#x2F;turtle1&#x2F;color_sensor&#x2F;turtle1&#x2F;pose 在主题教程中，您了解到/turtle_teleop节点在该/turtle1/cmd_vel主题上发布了命令，以使乌龟在turtlesim中移动。 要查看/turtle1/cmd_vel正在发布的数据，请运行以下命令： 1ros2 topic echo &#x2F;turtle1&#x2F;cmd_vel 要记录发布到主题的数据，请使用命令语法： 1ros2 bag record &lt;topic_name&gt; 在您选择的主题上运行此命令之前，请打开一个新的终端并移至bag_files您先前创建的目录中，因为rosbag文件将保存在运行它的目录中。 运行命令： 1ros2 bag record &#x2F;turtle1&#x2F;cmd_vel 您将在终端中看到以下消息（日期和时间将有所不同）： 1234[INFO] [rosbag2_storage]: Opened database &#39;rosbag2_2019_10_11-05_18_45&#39;.[INFO] [rosbag2_transport]: Listening for topics...[INFO] [rosbag2_transport]: Subscribed to topic &#39;&#x2F;turtle1&#x2F;cmd_vel&#39;[INFO] [rosbag2_transport]: All requested topics are subscribed. Stopping discovery... 现在正在记录有关该主题的数据。返回到Teleop终端，然后再次移动乌龟 按Ctrl+C停止录制。 数据将被存储在一个具有以下格式的名称的bag文件中 rosbag2_year_month_day-hour_minute_second 录制多个Topic 您还可以记录多个主题，以及更改保存文件的名称。ros2 bag 运行以下命令： 1ros2 bag record -o subset &#x2F;turtle1&#x2F;cmd_vel &#x2F;turtle1&#x2F;pose 该-o选项允许您为包文件选择唯一的名称。在此情况下subset，以下字符串是文件名。 要一次记录一个以上的主题，只需列出每个主题并用空格分隔即可。 您将看到以下消息，确认正在记录两个主题。 123[INFO] [rosbag2_storage]：打开了数据库“子集”。[INFO] [rosbag2_transport]：正在听主题…[INFO] [rosbag2_transport]：已订阅主题&#39;&#x2F; turtle1 &#x2F; cmd_vel&#39;[INFO] [rosbag2_transport]：已订阅主题&#39;&#x2F; turtle1 &#x2F; pose&#39;[INFO] [rosbag2_transport]：所有请求的主题都已订阅。停止发现… 完成后，您可以移动乌龟并按Ctrl+C停止录制。 注意 您可以向命令添加另一个选项，该命令-a记录系统上的所有主题。但是，这可能会导致循环依赖关系并使系统崩溃。最好选择所需主题的子集。 查看bag信息 1ros2 bag info &lt;bag_file_name&gt; 在subsetbag文件上运行此命令将返回文件信息列表： 123456789Files: subset.db3Bag size: 228.5 KiBStorage id: sqlite3Duration: 48.47sStart: Oct 11 2019 06:09:09.12 (1570799349.12)End Oct 11 2019 06:09:57.60 (1570799397.60)Messages: 3013Topic information: Topic: &#x2F;turtle1&#x2F;cmd_vel | Type: geometry_msgs&#x2F;msg&#x2F;Twist | Count: 9 | Serialization Format: cdr Topic: &#x2F;turtle1&#x2F;pose | Type: turtlesim&#x2F;msg&#x2F;Pose | Count: 3004 | Serialization Format: cdr 该主题的信息仅为9, 这就是我们在录制时按箭头键的次数。 请注意，/turtle1/pose其Count值超过3000；在我们录制时，有关该主题的数据已发布3000次。 要了解位置数据的发布频率，可以运行以下命令： 1ros2 topic echo &#x2F;turtle1&#x2F;pose 要查看单个消息，您必须打开数据库（在本例中为sqlite3）进行检查，这超出了ROS 2的范围。 bag回放 在重播bag文件之前，请输入Ctrl+C运行Teleop的终端。然后，确保您的turtlesim窗口可见，以便您可以查看运行中的bag文件。 输入命令： 1ros2 bag play subset 终端将返回以下消息： 1[INFO] [rosbag2_storage]: Opened database &#39;subset&#39;. 扩展：ROS2bag 设计理念 ROS2 Design ROS2-Bag Design 动机 ROS1的最关键和必要组成部分之一是其持久的数据记录机制，称为rosbags。它已被证明是ROS1的核心和必要组成部分，因为记录和重播所有类型的系统数据的能力对于数据分析和调试目的至关重要。给定此数据记录的各种使用情况，rosbag可以包含非常简单的数据（例如机器人末端执行器的轨迹），也可以包含高度复杂的数据（例如具有多个冗余高分辨率传感器的自动驾驶汽车）。因此，它们的文件大小范围可以从只有几千字节的仅几条消息到几TB以及存储的数百万个消息实例。为了在记录时保持高性能，rosbag避免了已记录消息的序列化和反序列化。 在设计ROS2时，还必须具备高性能数据记录功能。 ROSbag在ROS2中的实现 下面将介绍在ROS2中实施rosbag的总体建议。与在ROS1中实现类似，该想法是将体系结构拆分为多个独立的程序包。 从下至上，我们定义了三层抽象：rosbag存储API，rosbag API，rosbag命令行界面。rosbag storage API在某种意义上是与ROS2无关的，因为它只能读写抽象的二进制消息，这些消息在某些元信息的基础上定义得很好。第二层是rosbag API，负责获取ROS2消息，对其进行序列化并充分订阅以供存储API编写。相反，它从存储API接收二进制表示并将其转换为完全定义的ROS2消息。最后，命令行工具提供了一个用户友好的入口点，用于操纵记录和重放rosbag。 下图描述了此体系结构。 rosbag2 system diagram rosbag存储API 我们将数据存储定义为以二进制格式存储传入的ros消息的基本方法。数据存储负责持久保存ros消息以及足够的元信息，以在加载时恢复其完整上下文。虽然其主要目的是存储ros消息，但抽象层应与ROS2无关，并且实际上仅处理二进制数据和通用元信息。如果有合适的元信息可用，这允许手动插入自定义数据，例如pcap记录。 资料格式 我们将数据格式定义为ros消息以二进制形式表示的格式。该格式必须唯一地描述，并链接到数据存储中的二进制表示形式，以便能够解释其二进制表示形式，从而恢复ros消息。 如动机部分所述，ROS2中可以支持多种表示形式。因此，rosbag存储API的要求是它可以处理多种数据格式。 数据存储 我们引入了单独的API层，用于与基础数据存储接口。为了编写消息，必须给出消息的抽象表示作为输入。这样的表示包括实际消息的二进制blob和元数据的键值对。数据格式描述是此元数据的一部分。 我们决定为此选择第三方技术，而不再使用ROS1中的自定义rosbag存储。在研究了现有的解决方案之后，我们决定为该API层实现可扩展的插件体系结构，该体系结构能够连接各种数据存储解决方案，因此使用户有机会根据其用例优化其数据存储。 鉴于经过广泛测试，积极维护并拥有广泛用户群，我们选择SQLite作为此实现的默认解决方案。// TODO（karsten1987）：基准和合格的评估结果为何我们选择sqlite 但是，考虑与现有ROS1 rosbag的集成或兼容性时，此插件体系结构已成为必需。由于ROS1 rosbag中存储了大量数据，因此ROS2的rosbag工具必须能够轻松应对旧版rosbag。这可以通过使用ROS1插件来完成，该插件可以读取现有的ROS1消息并将其桥接为ROS2消息格式，例如使用静态桥。请注意，此插件很可能将以只读方式实现，这意味着完全有可能读取现有的ROS1消息并将其填充到ROS2生态系统中，但是将不支持其他方法。 对于每个受支持的数据存储（例如SQLite或ROSbag格式2），必须正确解释这些键值对以正确存储消息。 查询格式 // TODO（karsten1987）：描述如何从数据存储中获取/查询数据 rosbag API rosbag API描述了将ros消息读写到bag文件中的必要接口。它负责将具有正确数据格式的传入消息存储在数据存储中。同样，API必须从数据存储中的二进制表示中恢复具有给定数据格式的ros消息。 该rosbag API对ROS2的rosidl typesupport包一个很强的依赖性，一般性的描述在这里 这个包的主要目的是向存储API发出查询，接收二进制数据和相应的元信息和消息转换成其相应的ROS2消息类型。","categories":[{"name":"ROS2","slug":"ROS2","permalink":"http://yoursite.com/categories/ROS2/"}],"tags":[]},{"title":"ROS2-4-Launch文件","slug":"ROS2/ROS2-4-Launch文件","date":"2020-02-28T16:08:19.000Z","updated":"2020-02-28T17:02:24.000Z","comments":true,"path":"2020/02/29/ROS2/ROS2-4-Launch文件/","link":"","permalink":"http://yoursite.com/2020/02/29/ROS2/ROS2-4-Launch%E6%96%87%E4%BB%B6/","excerpt":"","text":"ROS2-Launch ros2里面的launch是基于python的，与ros1的不一样。 编写Launch文件 turtlesim_mimic_launch.py通过在终端中输入以下命令来创建启动文件： 1touch launch&#x2F;turtlesim_mimic_launch.py 使用turtlesim软件包及其可执行文件将ROS 2启动文件放在一起。 复制完整的代码并将其粘贴到turtlesim_mimic_launch.py文件中： 12345678910111213141516171819202122232425262728293031#引入launch模块from launch import LaunchDescriptionfrom launch_ros.actions import Node#开始：#LaunchDescription是一个由三个节点组成的系统，#它们全部来自该turtlesim程序包def generate_launch_description(): return LaunchDescription([ Node( package&#x3D;&#39;turtlesim&#39;, node_namespace&#x3D;&#39;turtlesim1&#39;, node_executable&#x3D;&#39;turtlesim_node&#39;, node_name&#x3D;&#39;sim&#39; ), Node( package&#x3D;&#39;turtlesim&#39;, node_namespace&#x3D;&#39;turtlesim2&#39;, node_executable&#x3D;&#39;turtlesim_node&#39;, node_name&#x3D;&#39;sim&#39; ), Node( package&#x3D;&#39;turtlesim&#39;, node_executable&#x3D;&#39;mimic&#39;, node_name&#x3D;&#39;mimic&#39;, remappings&#x3D;[ (&#39;&#x2F;input&#x2F;pose&#39;, &#39;&#x2F;turtlesim1&#x2F;turtle1&#x2F;pose&#39;), (&#39;&#x2F;output&#x2F;cmd_vel&#39;, &#39;&#x2F;turtlesim2&#x2F;turtle1&#x2F;cmd_vel&#39;), ] ) ]) 该系统的目标是启动两个turtlesim窗口，并让其中一只乌龟模仿另一只乌龟的运动。 启动描述中的前两个动作将启动两个turtlesim窗口： 123456789101112Node( package&#x3D;&#39;turtlesim&#39;, node_namespace&#x3D;&#39;turtlesim1&#39;, node_executable&#x3D;&#39;turtlesim_node&#39;, node_name&#x3D;&#39;sim&#39;),Node( package&#x3D;&#39;turtlesim&#39;, node_namespace&#x3D;&#39;turtlesim2&#39;, node_executable&#x3D;&#39;turtlesim_node&#39;, node_name&#x3D;&#39;sim&#39;), 注意，两个节点之间的唯一区别是它们的node_namespace值。唯一的名称空间使系统可以启动两个模拟器，而不会出现节点名或主题名冲突的情况。 该系统中的两个海龟都接收有关同一主题的命令，并在同一主题上发布其姿势。如果没有唯一的名称空间，就无法区分用于一只乌龟或另一只乌龟的消息。 最后一个节点也来自turtlesim程序包，但是是一个不同的可执行文件：mimic。 123456789Node( package&#x3D;&#39;turtlesim&#39;, node_executable&#x3D;&#39;mimic&#39;, node_name&#x3D;&#39;mimic&#39;, remappings&#x3D;[ (&#39;&#x2F;input&#x2F;pose&#39;, &#39;&#x2F;turtlesim1&#x2F;turtle1&#x2F;pose&#39;), (&#39;&#x2F;output&#x2F;cmd_vel&#39;, &#39;&#x2F;turtlesim2&#x2F;turtle1&#x2F;cmd_vel&#39;), ]) 该节点以重新映射的形式添加了配置详细信息。 mimic的/input/pose主题已重新映射到/turtlesim1/turtle1/pose，主题也已映射/output/cmd_vel到/turtlesim2/turtle1/cmd_vel。这意味着mimic将订阅/turtlesim1/sim的pose主题，并将其重新发布以供/turtlesim2/sim速度指令主题订阅。换句话说，turtlesim2将模仿turtlesim1的动作。 启动Launch文件 要启动turtlesim_mimic_launch.py，请运行以下命令： 1ros2 launch turtlesim_mimic_launch.py 将打开两个turtlesim窗口，您将看到以下[INFO]消息，告诉您启动文件已启动了哪些节点： 1234[INFO] [launch]: Default logging verbosity is set to INFO[INFO] [turtlesim_node-1]: process started with pid [11714][INFO] [turtlesim_node-2]: process started with pid [11715][INFO] [mimic-3]: process started with pid [11716] 启动效果： 要查看运行中的系统，请打开一个新终端，然后在主题上运行命令以使第一个乌龟移动：ros2 topic pub``/turtlesim1/turtle1/cmd_vel 1ros2 topic pub -r 1 &#x2F;turtlesim1&#x2F;turtle1&#x2F;cmd_vel geometry_msgs&#x2F;msg&#x2F;Twist &#39;&#123;linear: &#123;x: 2.0, y: 0.0, z: 0.0&#125;, angular: &#123;x: 0.0, y: 0.0, z: -1.8&#125;&#125;&#39; 看到两只乌龟都遵循相同的路径： 使用rqt_graph 当系统仍在运行时，打开一个新终端并运行rqt_graph以更好地了解启动文件中节点之间的关系。 运行命令： 1rqt_graph 一个隐藏的节点（您运行的命令）正在将数据发布到该节点已预订的左侧主题。图的其余部分显示了先前描述的内容：订阅的位姿主题，并发布到的速度命令主题。ros2 topic pub``/turtlesim1/turtle1/cmd_vel``/turtlesim1/sim``mimic``/turtlesim1/sim``/turtlesim2/sim","categories":[{"name":"ROS2","slug":"ROS2","permalink":"http://yoursite.com/categories/ROS2/"}],"tags":[]},{"title":"ROS2-3-动作","slug":"ROS2/ROS2-3-动作","date":"2020-02-28T01:57:35.000Z","updated":"2020-02-28T02:23:44.000Z","comments":true,"path":"2020/02/28/ROS2/ROS2-3-动作/","link":"","permalink":"http://yoursite.com/2020/02/28/ROS2/ROS2-3-%E5%8A%A8%E4%BD%9C/","excerpt":"","text":"Action 动作是ROS 2中用于长时间运行任务的通信类型之一。它们由三部分组成：目标，结果和反馈。 动作基于主题和服务。它们的功能与服务相似，但动作是可抢占的（您可以在执行时将其取消）。与返回单个响应的服务相反，它们还提供稳定的反馈 操作使用类似于发布者-订阅者模型（在主题教程中进行描述）的客户端-服务器模型。“动作客户端”节点将目标发送到“动作服务器”节点，该节点确认目标并返回反馈和结果流。 测试Action 启动两个节点 启动两个turtlesim节点，/turtlesim和/teleop_turtle。 打开一个新终端并运行： 1ros2 run turtlesim turtlesim_node 打开另一个终端并运行： 1ros2 run turtlesim turtle_teleop_key 启动/teleop_turtle节点时，您将在终端中看到以下消息： 12Use arrow keys to move the turtle.Use G|B|V|C|D|E|R|T keys to rotate to absolute orientations. &#39;F&#39; to cancel a rotation. 让我们专注于第二行，它对应于一个动作。（第一条指令对应于“ cmd_vel”主题） 请注意，字母键在键盘上G|B|V|C|D|E|R|T的F键周围形成一个“框” 。每个关键点的位置F对应于turtlesim中的方向。例如，E会将乌龟的方向旋转到左上角。 注意/turtlesim节点正在运行的终端。每次按这些键之一，就将目标发送到属于该/turtlesim节点的动作服务器。 目标是旋转乌龟以使其朝向某个而特定的方向。 乌龟完成旋转后，将显示一条有关目标结果的消息： 该F键将取消目标的中间执行，证明操作具有可抢占的功能。 尝试C按键，然后F在乌龟完成旋转之前按键。在/turtlesim运行节点的终端中，您将看到以下消息： 客户端（您在Teleop中的输入）不仅可以抢占目标，而且服务器端（/turtlesim节点）也可以抢占目标。当服务器端抢占一个动作时，它“中止”了目标。 尝试按一下D键，然后G在第一次旋转之前完成键。在/turtlesim运行节点的终端中，您将看到以下消息： 服务器端中止了第一个目标，因为它被中断了。 查看节点信息 要查看/turtlesim节点的操作，请打开一个新终端并运行以下命令： 1ros2 node info &#x2F;turtlesim 这将返回/turtlesim的订阅者，发布者，服务，操作服务器和操作客户端的列表： 可以看到，/turtle1/rotate_absolute动作在/turtlesim的Action Servers之下。这意味着海龟是服务端，会对做出响应并提供反馈。 下面查看/teleop_turtle节点信息 1ros2 node info &#x2F;teleop_turtle 可以看到，这个节点是动作/turtle1/rotate_absolute: turtlesim/action/RotateAbsolute的客户端，发出指令，然后由服务器(海龟)做出响应。 查看动作列表 要标识ROS图中的所有动作，请运行以下命令： 1ros2 action list 返回： 操作具有类型，类似于主题和服务。要查找/turtle1/rotate_absolute的类型，请运行以下命令： 1ros2 action list -t 将返回： 1&#x2F;turtle1&#x2F;rotate_absolute [turtlesim&#x2F;action&#x2F;RotateAbsolute] 每个动作名称（仅在此情况下/turtle1/rotate_absolute）右侧的括号中是动作类型turtlesim/action/RotateAbsolute。当您想从命令行或代码执行操作时，将需要此功能。 查看动作信息 您可以/turtle1/rotate_absolute使用以下命令进一步检查操作： 1ros2 action info &#x2F;turtle1&#x2F;rotate_absolute 返回： 这意味着该节点/teleop_turtle有一个动作客户端，而节点/turtlesim有一个动作服务器。 查看动作接口 自己发送或执行动作目标之前，您需要获得的另一条信息是动作类型的结构。 在终端中输入以下命令以及操作类型： 1ros2 interface show turtlesim&#x2F;action&#x2F;RotateAbsolute.action 返回接口信息： 利用接口进行操作，控制海龟旋转 现在，让我们使用以下语法从命令行发送一个操作目标： 1ros2 action send_goal &lt;action_name&gt; &lt;action_type&gt; &lt;values&gt; &lt;values&gt; 必须为YAML格式。 留意turtlesim窗口，然后在终端中输入以下命令： 1ros2 action send_goal &#x2F;turtle1&#x2F;rotate_absolute turtlesim&#x2F;action&#x2F;RotateAbsolute &#123;&#39;theta: 1.57&#39;&#125; 可以看到，海龟在旋转，并且命令行返回如下： 所有目标都有唯一的ID，如返回消息所示。您还可以看到结果，一个名为的字段delta，它是到起始位置的位移。 要查看此目标的反馈，请添加--feedback到您运行的最后一个命令。首先，请确保您更改的值theta。运行上一个命令后，乌龟将已经处于1.57弧度方向，因此除非传递新的，否则它不会移动theta。 1ros2 action send_goal &#x2F;turtle1&#x2F;rotate_absolute turtlesim&#x2F;action&#x2F;RotateAbsolute &#123;&#39;theta: -1.57&#39;&#125; --feedback 终端将返回以下消息： 1234567891011121314151617Sending goal: theta: -1.57Goal accepted with ID: e6092c831f994afda92f0086f220da27Feedback: remaining: -3.1268222332000732Feedback: remaining: -3.1108222007751465…Result: delta: 3.1200008392333984Goal finished with status: SUCCEEDED 您将继续收到剩余弧度的反馈，直到完成目标。 总结 动作就像服务，可让您执行长时间运行的任务，提供定期反馈并可以取消。 机器人系统可能会使用动作进行导航。一个行动目标可以告诉机器人去某个位置。当机器人导航到该位置时，它可以沿途发送更新（即反馈），一旦到达目的地，便发送最终结果消息。 参考资料 了解ROS2动作","categories":[{"name":"ROS2","slug":"ROS2","permalink":"http://yoursite.com/categories/ROS2/"}],"tags":[]},{"title":"ORB_SLAM2-资料集合","slug":"SLAM代码课程/ORB_SLAM2/ORB_SLAM2-资料集合","date":"2020-02-27T18:00:31.000Z","updated":"2020-04-30T03:42:24.000Z","comments":true,"path":"2020/02/28/SLAM代码课程/ORB_SLAM2/ORB_SLAM2-资料集合/","link":"","permalink":"http://yoursite.com/2020/02/28/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB_SLAM2/ORB_SLAM2-%E8%B5%84%E6%96%99%E9%9B%86%E5%90%88/","excerpt":"","text":"资料下载 点击下载","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"ORB_SLAM2","slug":"SLAM代码课程/ORB-SLAM2","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB-SLAM2/"}],"tags":[]},{"title":"ROS2-2-turtlesim","slug":"ROS2/ROS2-2-turtlesim","date":"2020-02-27T16:50:53.000Z","updated":"2020-02-27T17:33:35.000Z","comments":true,"path":"2020/02/28/ROS2/ROS2-2-turtlesim/","link":"","permalink":"http://yoursite.com/2020/02/28/ROS2/ROS2-2-turtlesim/","excerpt":"","text":"安装turtlesim 123sudo apt updatesudo apt install ros-eloquent-turtlesim 检查软件包是否已安装： 1ros2 pkg executables turtlesim 上面的命令应该返回turtlesim可执行文件的列表： 1234turtlesim draw_squareturtlesim mimicturtlesim turtle_teleop_keyturtlesim turtlesim_node 开始运行 要启动turtlesim，请在终端中输入以下命令： 1ros2 run turtlesim turtlesim_node 终端会显示节点消息： 在这里，您可以看到默认乌龟的名称是turtle1，以及它产生的默认坐标。 控制turtlesim 打开一个新终端，然后再次获取ROS 2。 现在，您将运行一个新节点来控制第一个节点中的乌龟： 1ros2 run turtlesim turtle_teleop_key 此时，您应该打开三个窗口：一个正在运行turtlesim_node的终端，一个正在运行的终端turtle_teleop_key和turtlesim窗口。排列这些窗口，以便您可以看到turtlesim窗口，还可以使终端turtle_teleop_key处于活动状态，以便您可以在turtlesim中控制turtle。 使用键盘上的箭头键控制乌龟。它将使用其附带的“笔”在屏幕上四处移动，以绘制到目前为止所遵循的路径。 可以使用以下list命令查看节点及其关联的服务，主题和操作： 1234ros2 node listros2 topic listros2 service listros2 action list 安装Rqt 打开一个新的终端以安装rqt其插件： 123sudo apt updatesudo apt-get install ros-eloquent-rqt 运行rqt： 1rqt 第一次运行rqt后，该窗口将为空白。别担心; 只需从顶部菜单栏中选择插件 &gt; 服务 &gt; 服务调用方即可。 使用服务下拉列表左侧的刷新按钮，确保您的turtlesim节点的所有服务均可用。 单击服务下拉列表以查看turtlesim的服务，然后选择/spawn服务。 尝试spawn服务 让我们使用rqt调用/spawn服务。您可以从其名称中猜测，这/spawn将在turtlesim窗口中创建另一只乌龟。 给新乌龟一个唯一的名称，例如turtle2在“ 表达式”列中的空单引号之间双击。您可以看到该表达式对应于名称值，并且类型为string。 输入要生成的海龟的新坐标，例如和。x = 1.0``y = 1.0 注意 如果尝试生成与现有乌龟同名的新乌龟（如默认乌龟），turtle1则会在运行turtlesim_node以下终端中收到错误消息： 1[ERROR] [turtlesim]: A turtle named [turtle1] already exists 要生成turtle2，必须通过单击rqt窗口右上角的“ 呼叫”按钮来调用该服务。 您将在为x和y输入的坐标处看到一只新的乌龟（同样具有随机设计）。 尝试set_pen服务 现在，让我们使用该/set_pen服务为turtle1提供一支独特的笔： r，g和b的值介于0到255之间，将设置笔turtle1绘制的颜色，而width则设置线条的粗细。 要使turtle1用明显的红线绘制，请将r的值更改为255，将width的值更改为5。不要忘记在更新值后调用该服务。 如果返回到turtle_teleop_node正在运行的终端，然后按箭头键，您将看到turtle1的笔已更改。 现在有个问题： 无法移动turtle2。您可以通过将turtle1的cmd_vel主题重新映射到turtle2 来完成此操作。 重映射remap 在新的终端中，输入ROS 2，然后运行： 1ros2 run turtlesim turtle_teleop_key --ros-args --remap turtle1&#x2F;cmd_vel:&#x3D;turtle2&#x2F;cmd_vel 现在，您可以在此终端处于活动状态时移动turtle2，而在运行该终端的另一个终端处于活动状态时移动turtle1 turtle_teleop_key。","categories":[{"name":"ROS2","slug":"ROS2","permalink":"http://yoursite.com/categories/ROS2/"}],"tags":[]},{"title":"PnP求解--EPnP","slug":"SLAM代码课程/PnP求解-EPnP","date":"2020-02-26T11:59:39.000Z","updated":"2020-03-20T03:11:23.000Z","comments":true,"path":"2020/02/26/SLAM代码课程/PnP求解-EPnP/","link":"","permalink":"http://yoursite.com/2020/02/26/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/PnP%E6%B1%82%E8%A7%A3-EPnP/","excerpt":"","text":"1. PnP问题回顾 已知 世界坐标系下的3D点 这些3D点在相机坐标系下的, 经过相机模型投影形成的图像点(u,v) 相机内参矩阵K 求解 相机位姿Tcw(即世界坐标系到相机坐标系的变换) 2. EPnP EPnP算法将世界坐标系中的3D坐标表示为一组虚拟的控制点的加权和。对于一般情形，EPnP算法要求控制点的数目为4，且这4个控制点不能共面。因为摄像头的外参未知，这四个控制点在摄像头参考坐标系下的坐标是未知的。而如果能求解出这四个控制点在摄像头参考坐标系下的坐标，我们就可以计算出摄像头的位姿。 2.1. 摘要 EPnP主要idea是使用4个虚拟的控制点的加权来表示3D点的坐标, 使得求解[R,t]问题变成估计这些控制点在相机坐标系下的坐标的问题。 控制点在相机坐标系下的坐标又可以通过使用一个12x12矩阵的奇异值向量\\(v_i\\)的加权\\(\\beta_i v_i\\)来表示(也就是齐次线性方程组的最小二乘解)。 最终, 问题变成了最优化一个具有少量约束的二次等式的问题来选取合适的\\(\\beta\\)。另外，如果需要足够准确的值，那么可以通过闭式解的输出作为高斯牛顿迭代优化的初始值，使用优化方法来获取足够的精度。 2.2. 主要思路 使用一种方式来构造点云在相机坐标系下的表达，最终通过世界坐标系的点云和相机坐标系的点云进行ICP匹配。 3. 参数定义 3.1. 世界坐标系下的点 \\[ p_i, ~~ i=1,2,\\cdots,n \\] 3.2. 4个控制点 注意： 这4个控制点不能在同一平面上 \\[ \\begin{aligned} c_j=\\begin{bmatrix} c_{jx} \\\\ c_{jy} \\\\ c_{jz} \\\\ c_{jw} \\end{bmatrix} , ~~ j=1,2,3,4 \\end{aligned} \\] 3.3. 使用控制点来表示世界坐标系下的点 \\[ \\begin{aligned} p_i^{w}=\\sum_{j=1}^{4}\\alpha_{ij}c_{j}^{w},~~~with \\sum_{j=1}^{4} \\alpha_{ij}=1 \\end{aligned} \\] 其中, \\(\\alpha_{ij}\\)是齐次重心坐标\\((Homogeneous~Barycentric~Coordinates)\\)的权重，**在世界坐标系和相机坐标系都保持一致。[**这是个重要的假设] \\(c_j^w\\)表示4个控制点在世界坐标系的表示 3.4. 使用控制点来表示相机坐标系的点 同样的,有 \\[ \\begin{aligned} p_i^{c}=\\sum_{j=1}^{4}\\alpha_{ij}c_{j}^{c},~~~with \\sum_{j=1}^{4} \\alpha_{ij}=1 \\end{aligned} \\] 4. 确定世界坐标系的控制点\\(c_{j}^w\\) 理论上, 控制点可以任意选取. 但是实际实践中, 文章作者发现这个方法的稳定性取决于中心作为参考点 4.1. 第一个控制点 一般选择世界坐标系下3D点质心作为第一个控制点\\(c_{1}^w\\)，即 \\[ c_{1}^w=\\frac{1}{n} \\sum_{i=1}^{n} p_i^w \\] 4.2. 其他控制点的确定 4.2.1. 计算世界坐标系参考点的去质心坐标 \\[ \\begin{aligned} A=q_i^{w}= \\begin{bmatrix} p_1^{wT}-c_1^{wT} \\\\ \\vdots \\\\ p_n^{wT}-c_1^{wT} \\end{bmatrix} \\end{aligned} \\] 4.2.2. 对矩阵\\(A^TA\\)进行SVD分解 \\[ A^TA=V\\Sigma V^T \\] 为什么只有V，可参见SVD分解 取分解后的前3个特征值\\(\\lambda_1,\\lambda_2,\\lambda_3\\)，以及对应的特征向量\\(v_{1},v_{2},v_{3}\\)，这3个特征向量实际上就代表了点云的3个主方向，剩下的3个控制点使用这3个主方向来表示。 4.2.3. 剩下的3个控制点 \\[ \\begin{aligned} c_{2}^w &amp;=c_{1}^w + \\sqrt{\\frac{\\lambda_1}{n}} v_{1} \\\\ c_{3}^w &amp;=c_{1}^w + \\sqrt{\\frac{\\lambda_2}{n}} v_{2} \\\\ c_{4}^w &amp;=c_{1}^w + \\sqrt{\\frac{\\lambda_3}{n}} v_{3} \\end{aligned} \\] 5. 确定权重\\(\\alpha_{ij}\\) 对于权重来说，不论是在世界坐标系还是相机坐标系下，它的值都是一样的，我们只须通过世界坐标和世界坐标系下得到控制点得到权重。 5.1. 世界坐标系下点的表达 \\[ \\begin{aligned} p_i^{w}=\\sum_{j=1}^{4}\\alpha_{ij}c_{j}^{w},~~~with \\sum_{j=1}^{4} \\alpha_{ij}=1 \\end{aligned} \\] 对上式进一步展开(齐次形式，因为控制点有4个)， \\[ \\begin{aligned} \\begin{bmatrix} p_{i}^w \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} c_{1}^w &amp; c_{2}^w &amp; c_{3}^w &amp;c_{4}^w \\\\ 1 &amp; 1 &amp; 1 &amp; 1 \\end{bmatrix} \\begin{bmatrix} \\alpha_{i}^1 \\\\ \\alpha_{i}^2 \\\\ \\alpha_{i}^3 \\\\ \\alpha_{i}^4 \\end{bmatrix} \\end{aligned} \\] 5.2. 所以，\\(\\alpha\\)可以按下式确定： \\[ \\begin{aligned} \\begin{bmatrix} \\alpha_{i}^1 \\\\ \\alpha_{i}^2 \\\\ \\alpha_{i}^3 \\\\ \\alpha_{i}^4 \\end{bmatrix} = \\begin{bmatrix} c_{1}^w &amp; c_{2}^w &amp; c_{3}^w &amp;c_{4}^w \\\\ 1 &amp; 1 &amp; 1 &amp; 1 \\end{bmatrix}^{-1} \\begin{bmatrix} p_{i}^w \\\\ 1 \\end{bmatrix} \\end{aligned} \\] 5.3. 也可以按下面来确定(ORB_SLAM2采用的)： 因为 \\[ \\begin{aligned} \\begin{bmatrix} p_{i}^w \\\\ \\end{bmatrix} = \\begin{bmatrix} c_{1}^w &amp; c_{2}^w &amp; c_{3}^w &amp;c_{4}^w \\end{bmatrix} \\begin{bmatrix} \\alpha_{i}^1 \\\\ \\alpha_{i}^2 \\\\ \\alpha_{i}^3 \\\\ \\alpha_{i}^4 \\end{bmatrix} \\\\ \\Longrightarrow \\begin{bmatrix} c_1^w &amp; c_2^w-c_1^w &amp; c_3^w-c_1^w &amp; c_4^w-c_1^w \\end{bmatrix} \\begin{bmatrix} 1 \\\\ \\alpha_i^2 \\\\ \\alpha_i^3 \\\\ \\alpha_i^4 \\end{bmatrix} \\\\ \\Longrightarrow (p_{i}^w-p_0^{w})= \\begin{bmatrix} c_2^w-c_1^w &amp; c_3^w-c_1^w &amp; c_4^w-c_1^w \\end{bmatrix} \\begin{bmatrix} \\alpha_i^2 \\\\ \\alpha_i^3 \\\\ \\alpha_i^4 \\end{bmatrix} \\end{aligned} \\] 所以： \\[ \\begin{aligned} \\begin{bmatrix} \\alpha_i^2 \\\\ \\alpha_i^3 \\\\ \\alpha_i^4 \\end{bmatrix} = \\begin{bmatrix} c_2^w-c_1^w &amp; c_3^w-c_1^w &amp; c_4^w-c_1^w \\end{bmatrix}^{-1} [p_{i}^w-p_0^{w}] \\end{aligned} \\] \\[ \\alpha_i^1=1-\\alpha_i^2-\\alpha_i^3-\\alpha_i^4 \\] 6. 确定相机坐标系的控制点\\(c_{j}^c\\) 6.1. 构造约束 假设矩阵\\(A\\)相机内参, \\(u_i\\)为世界坐标系的点在经过相机模型之后的图像点, 则有: \\[ \\begin{aligned} w_i \\begin{bmatrix} \\boldsymbol{u_i} \\\\ 1 \\end{bmatrix} = w_i \\begin{bmatrix} u_i \\\\ v_i \\\\ 1 \\end{bmatrix} = A p_i^c = A\\sum_{j=1}^{4}\\alpha_{ij}c_{j}^c \\end{aligned} \\] 其中, \\(w_i\\)是投影的尺度参数 进一步展开, 得到 \\[ \\begin{aligned} w_i \\begin{bmatrix} u_i \\\\ v_i \\\\ 1 \\end{bmatrix} = A p_i^c &amp; = A\\sum_{j=1}^{4}\\alpha_{ij}c_{j}^c \\\\ &amp; = \\begin{bmatrix} f_u &amp; 0 &amp; u_c \\\\ 0 &amp; f_v &amp; v_c \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\sum_{j=1}^{4} \\alpha_{ij} \\begin{bmatrix} x_{j}^c \\\\ y_{j}^c \\\\ z_{j}^c \\end{bmatrix} \\end{aligned} \\] 其中, \\(c_{j}^c\\)表示每个控制点在相机坐标系下的表示 \\[ \\begin{aligned} c_j^{c}= \\begin{bmatrix} x_{j}^c \\\\ y_{j}^c \\\\ z_{j}^c \\end{bmatrix} \\end{aligned} \\] 根据上面等式的最后一行,有 \\[ w_i=\\sum_{j=1}^{4} \\alpha_{ij} z_{j}^c \\] 将这个约束回代到等式的第1,第2行, 消去尺度因子\\(w_i\\), 可得 \\[ \\begin{aligned} \\sum_{j=1}^{4} \\alpha_{ij}f_{u}x_{j}^c+ \\alpha_{ij}(u_c-u_i)z_{j}^c=0 \\\\ \\sum_{j=1}^{4} \\alpha_{ij}f_{v}y_{j}^c+ \\alpha_{ij}(v_c-v_i)z_{j}^c=0 \\end{aligned} \\] 于是, 对于每一个相机坐标系的3D点, 都可以得到两个这样的齐次方程 于是, 当有n个参考点的时候, 可以得到如下齐次线性方程组: \\[ \\begin{aligned} \\boldsymbol{Mx}=0 \\end{aligned} \\] 在构造系数矩阵\\(M\\)的时候，注意，式中的求和\\(\\sum\\)实际上是矩阵维度上的拼接，即\\(\\boldsymbol{M}\\)和\\(x\\)的形式如下： 图中的\\(c_{x0}\\)等于上面公式中的\\(x_{j}^c\\) \\(c_{y0}=y_{j}^c\\)、\\(c_{z0}=z_{j}^c\\) 其中, \\(\\boldsymbol{x}=[c_{1}^{cT},c_{2}^{cT},c_{3}^{cT},c_{4}^{cT}]\\) 是一个12维的向量, 也就是4个控制点的坐标,是未知数 矩阵\\(A\\)是一个\\((2n \\times 12)\\)的矩阵. 与DLT不同，由于不涉及图像参考系统，我们不需要对2D投影进行归一化 6.2. 求解齐次方程组 上面得到的齐次线性方程组的解就是矩阵\\(A\\)的零空间, 可以表示成下面的形式: \\[ \\boldsymbol{x}=\\sum_{i=1}^{N} \\beta_i \\boldsymbol{v_i} \\] 其中, \\(\\boldsymbol{v_i}\\)是矩阵\\(A\\)经过SVD分解后得到的右奇异矩阵的列向量, 也就是奇异值对应的特征向量，维度是\\(12\\times 1\\) \\(\\boldsymbol{v_i}\\)可以通过对\\(A^TA\\)进行SVD分解得到, 并且\\(A^TA\\)只是一个\\((12 \\times 12)\\)的矩阵 实际上, 计算\\(A^TA\\)是这个算法最花费时间的步骤, 具有\\(O(n)\\)的复杂度 6.3. 选择正确的线性组合[\\(\\boldsymbol{x}=\\sum_{i=1}^{N} \\beta_i \\boldsymbol{v_i} ~~, N=?\\)] 已知齐次线性方程组的解可以表示成\\(A^TA\\)的奇异值向量的线性组合, 问题实际上变成了求解\\(\\beta_i\\)合适的值. 理论上, 当给定十分完美的数据(至少6个点以及一个准确的相机模型), 这个\\(A^TA\\)的零空间的维度是十分准确的是1, 因为仅仅只有尺度的不确定性. 对比下, 如果考虑一个不那么精确的相机模型, 那么\\(A^TA\\)的零空间维度变成4, 因为有4个控制点的深度不确定. 实验表明，一个带有大焦距的相机可能会有an affine model, 因此零空间的维度是不确定的, 可能是1到4之间的值. 其带来的影响如下图 上图说明了, 矩阵\\(A^TA\\)的特征值个数与相机的焦距有关. 此外，由于噪声的存在，没有特征值严格为零，但可能很小. 另外, EPnP算法认为只需考虑特征值个数为\\(N=1,2,3,4\\)的情况, 当考虑了相机带有观测噪声时, N可能&gt;5, 但是经过仿真实验表示, 没有必要考虑N&gt;=5的情况 控制点之间必须保持一定的距离，这是为了保证控制点之间的距离可以使用几个少量的二次等式来表示, 用来求解系数\\(\\beta_i, i=1,2,3,4\\) 因此, EPnp选择对\\(N=1,2,3,4\\)的情况都进行计算, 最后选择产生最小的重投影误差的情况作为solution \\[ \\begin{aligned} res=\\sum_{i} dist^2(K*[R|t] \\begin{bmatrix} p_{ix}^w \\\\ p_{iy}^w \\\\ p_{iz}^w \\\\ 1 \\end{bmatrix} , \\boldsymbol{u_i}= \\begin{bmatrix} u_i \\\\ v_i \\end{bmatrix}) \\end{aligned} \\] 下面, 从N的各种情况来讨论这个二次约束 6.3.1. N=1 当N=1的时候，可以简化为\\(x=\\beta v\\)，\\(\\beta\\)(标量)的求解过程如下： \\[ \\begin{aligned} &amp;\\because x^{c}=\\beta v = [c_1^{cT},c_2^{cT},c_3^{cT},c_4^{cT}]_{1 \\times 12} \\\\ \\end{aligned} \\] 在相机坐标系下的控制点\\(c_{i}^{c}\\)之间的距离可以看做是等于世界坐标系下的控制点\\(c_{i}^{w}\\)之间的距离，即 \\[ \\begin{aligned} And: ~~~~~~~ dist(c_{i}^{c},c_{j}^{c}) &amp;=dist(c_{i}^{w},c_{j}^{w}) \\\\ ||\\beta v^{[i]}-\\beta v^{[j]}||^2 &amp;=||c_{i}^{w}-c_{j}^{w}||^2 \\end{aligned} \\] 其中，\\(v^{[i]}\\)表示向量\\(v\\)(或者是\\(x\\))中与第i个控制点相关的3维的向量，一共有4个，即\\(i=1,2,3,4\\). 又因为世界坐标系下的控制点之间的距离\\(||c_{i}^{w}-c_{j}^{w}||\\)是已知的，所以\\(\\beta\\)的闭式解(解析解)可以写成如下 \\[ \\begin{aligned} \\beta = \\frac {\\sum_{\\{i,j\\} \\in [1:4]} ||v^{[i]}-v^{[j]} || \\cdot ||c_{i}^{w}-c_{j}^{w}||} {\\sum_{\\{i,j\\} \\in [1:4]} ||v^{[i]}-v^{[j]}||^2} \\end{aligned} \\] 6.3.2. N=2 N=2时，有 \\[ x=\\beta_1 v_1 +\\beta_2 v_2 \\] 控制点的距离约束可写成： \\[ \\begin{aligned} dist(c_{i}^{c},c_{j}^{c}) =dist(c_{i}^{w},c_{j}^{w}) \\\\ \\Longrightarrow ||(\\beta_1 v_1^{[i]}+\\beta_2 v_2^{[i]})-(\\beta_1 v_1^{[j]}+\\beta_2 v_2^{[j]})||^2 &amp;=||c_{i}^{w}-c_{j}^{w}||^2 \\\\ \\Longrightarrow ||(\\beta_1 v_1^{[i]}-\\beta_1 v_1^{[j]})+(\\beta_2 v_2^{[i]}-\\beta_2 v_2^{[j]})||^2 &amp;=||c_{i}^{w}-c_{j}^{w}||^2 \\\\ \\Longrightarrow ||\\beta_1 \\underbrace{(v_1^{[i]}- v_1^{[j]})}_{V_1^{[ij]}}+\\beta_2 \\underbrace{(v_2^{[i]}- v_2^{[j]})}_{V_2^{[ij]}}||^2 &amp;=||c_{i}^{w}-c_{j}^{w}||^2 \\end{aligned} \\] 整理得到 \\[ \\begin{aligned} \\beta_1^2 {V_1^{[ij]}}^T V_1^{[ij]} +2 \\beta_1 \\beta_2 {V_1^{[ij]}}^T V_2^{[ij]} + \\beta_2^2 {V_2^{[ij]}}^T V_2^{[ij]} &amp;=||c_{i}^{w}-c_{j}^{w}||^2 \\\\ \\Longrightarrow \\beta_{11} {V_1^{[ij]}}^T V_1^{[ij]} +2 \\beta_{12} {V_1^{[ij]}}^T V_2^{[ij]} + \\beta_{22} {V_2^{[ij]}}^T V_2^{[ij]} &amp;=||c_{i}^{w}-c_{j}^{w}||^2 \\end{aligned} \\] 对上式左侧展开，可以得到关于\\(\\beta_1 \\beta_1\\)、\\(\\beta_1 \\beta_2\\)、\\(\\beta_2 \\beta_2\\)的二次项，将其分别表示为\\(\\beta_{11},\\beta_{12},\\beta_{22}\\)，把这三项作为未知数。 线性化求解：也就是把这个非线性方程线性化，把二次的未知数用一次未知数替换 因为有4个控制点，每两个控制点可以构成上面的一个线性化方程，那么一共可以构成\\(C_{4}^{2}=6\\)个方程，即有： \\[ \\begin{aligned} \\boldsymbol{L} \\boldsymbol{\\beta} = \\boldsymbol{\\rho} \\end{aligned} \\] 其中， \\(\\boldsymbol{L}\\)是一个\\(6 \\times 3\\)的矩阵，由系数\\(V_1^{[ij]}\\)和系数\\(V_2^{[ij]}\\)组成 \\(\\boldsymbol{\\rho}\\)是一个\\(6\\)维向量，代表的是控制点之间的平方距离\\(||c_{i}^{w}-c_{j}^{w}||^2\\) \\(\\boldsymbol{\\beta}=[\\beta_{11},\\beta_{12},\\beta_{22}]^T\\)则是待求的未知数 上面方程的求解使用了\\(\\boldsymbol{L}\\)矩阵的伪逆矩阵，还要选择\\(\\beta\\)的符号来使得相机坐标系下的所有点\\(p_{i}^c\\)都具有正的深度 原文提到： 求解得到\\(\\boldsymbol{\\beta}\\)，并进一步分解得到\\(\\beta_1\\)和&gt; \\(\\beta_2\\)之后，可进一步调整\\(\\beta_1\\)和\\(\\beta_2\\)的值： 使用下面公式求解得到一个通用的尺度\\(\\beta\\)来满足\\(c_{i}^{c}&gt; =\\beta(\\beta_1 v_1^{[i]}+\\beta_2 v_2^{[i]})\\) \\[ \\begin{aligned} \\beta =\\frac{\\sum_{\\{i,j\\} \\in [1:4]} ||v^{[i]}-v^{[j]} || \\cdot ||c_{i}^{w}-c_{j}^{w}||}{\\sum_{\\{i,j\\} \\in [1:4]} ||v^{[i]}-v^{[j]}||^2} \\end{aligned} \\] 这是[不理解的地方] 6.3.3. N=3 N=3的情况与N=2的情况处理方法基本一致，此时未知数有\\(\\boldsymbol{\\beta}=[\\beta_{11},\\beta_{12},\\beta_{13},\\beta_{22},\\beta_{23},\\beta_{33}]^T\\)，一共6个未知数。 同理，因为有4个控制点，每两个控制点可以构成上面的一个线性化方程，那么一共可以构成\\(C_{4}^{2}=6\\)个方程，即有： \\[ \\begin{aligned} \\boldsymbol{L} \\boldsymbol{\\beta} = \\boldsymbol{\\rho} \\end{aligned} \\] 其中， \\(\\boldsymbol{L}\\)是一个\\(6 \\times 6\\)的矩阵 求解这个非齐次线性方程组，与前面不同的是，这里可以直接求逆而不是求伪逆。 6.3.4. N=4 N=4时，继续尝试使用线性化的方法，此时未知数有\\(\\boldsymbol{\\beta}=[\\beta_{11},\\beta_{12},\\beta_{13},\\beta_{14},\\beta_{22},\\beta_{23},\\beta_{24},\\beta_{33},\\beta_{34},\\beta_{44}]\\)，一共10个未知数。所以，4个控制点产生的6个距离约束在这里已经不够用了，论文提出使用重线性化方法 注意到： \\(\\beta_{ab} \\beta_{cd}=\\beta_a \\beta_b \\beta_c \\beta_d=\\beta_{a&#39;} \\beta_{b&#39;} \\beta_{c&#39;} \\beta_{d&#39;}\\) \\(\\{a&#39;,b&#39;,c&#39;,d&#39;\\}\\)是对\\(\\{a,b,c,d\\}\\)的排列，即通过一些等价来介绍系数 例如：假设已知\\(\\beta_{11} ,\\beta_{12} ,\\beta_{13}\\)，则\\(\\beta_{23}\\)可表示为\\(\\beta_{23}=\\frac{\\beta_{12} \\beta_{13}}{\\beta_{11}}\\) 利用这个思想来减少未知数的个数 6.3.5. 除了上面各种情况的闭式解，还有一般形式的近似解(ORB_SLAM2采用的) 6.4. 优化\\(\\beta\\) 经过上面的步骤，已经得到了关于\\(\\beta\\)的闭式解 接下来通过使得下面的目标函数最小化，来对\\(\\boldsymbol{\\beta}=[\\beta_1,\\beta_2,\\beta_3,\\beta_4]^T\\)进行优化，求出更精确的\\(\\beta\\)。 6.4.1. 残差 \\[ e_{i,j}(\\beta)=||c_i^c - c_j^c||^2 - ||c_i^w - c_j^w||^2 \\] 6.4.2. 目标函数 \\[ \\begin{aligned} D =\\sum_{(i,j),s.t.i&lt;j} (||c_i^c - c_j^c||^2 - ||c_i^w - c_j^w||^2)^2 \\end{aligned} \\] 6.4.3. 优化目标 \\[ \\begin{aligned} \\beta^*= \\argmin_{\\beta} \\sum_{(i,j),s.t.i&lt;j} (||c_i^c - c_j^c||^2 - ||c_i^w - c_j^w||^2)^2 \\end{aligned} \\] 其中， 世界坐标系下的控制点之间的距离\\(||c_i^w - c_j^w||^2\\)是已知的 相机坐标系下的控制点可以使用\\(\\beta\\)作为系数，是矩阵\\(A^TA\\)奇异值向量的线性组合: \\[ c_{i}^{c}=\\sum_{j=1}^{4} \\beta_{j} v_{j}^{[i]} \\] 又因为\\(D_{k}^w=D_{ij}^w=||c_i^w - c_j^w||^2\\)已知，所以接下来并不关注这部分 目标函数中，需要关注的是相机坐标系下的控制点距离这个部分： \\[ \\begin{aligned} D_{k}^c=D_{ij}^c &amp;=||c_{i}^c-c_{j}^c|| \\\\ &amp;= ||(\\beta_1 v_{1}^i+\\beta_2 v_{2}^i +\\beta_3 v_{3}^i +\\beta_4 v_{4}^i)-(\\beta_1 v_{1}^j+\\beta_2 v_{2}^j +\\beta_3 v_{3}^j +\\beta_4 v_{4}^j)||^2 \\\\ &amp;=||\\beta_1 \\underbrace{(v_1^i-v_1^j)}_{dV_{1k}}+\\beta_2 \\underbrace{(v_2^i-v_2^j)}_{dV_{2k}}+\\beta_3 \\underbrace{(v_3^i-v_3^j)}_{dV_{3k}}+\\beta_4 \\underbrace{(v_4^i-v_4^j)}_{dV_{4k}}||^2 \\\\ &amp;=\\beta_1^2 [dV_{1k}]^T [dV_{1k}] + 2 \\beta_1 \\beta_2 [dV_{1k}]^T [dV_{2k}] + 2 \\beta_1 \\beta_3 [dV_{1k}]^T [dV_{3k}] + 2\\beta_1 \\beta_4 [dV_{1k}]^T[dV_{4k}]\\\\ &amp;+\\beta_2^2 [dV_{2k}]^T [dV_{2k}]+ 2 \\beta_2 \\beta_3 [dV_{2k}]^T[dV_{3k}] + 2 \\beta_2 \\beta_4 [dV_{2k}]^T[dV_{4k}]\\\\ &amp;+ \\beta_3^2 [dV_{3k}]^T[dV_{3k}] + 2\\beta_3 \\beta_4 [dV_{3k}]^T[dV_{4k}] \\\\ &amp;+ \\beta_4^2 [dV_{4k}]^T[dV_{4k}] \\\\ &amp;= \\boldsymbol{L\\beta} \\end{aligned} \\] 6.4.4. 求解雅克比 \\[ \\begin{aligned} J=\\frac{\\partial D_{6 \\times 1}}{\\partial \\beta^T} &amp;=\\frac{\\partial [\\sum_{k=1}^{6} D_{k}^{c}]}{\\partial \\beta^T} =\\sum_{k=1}^{6} \\frac{\\partial [D_{k}^{c}]}{\\partial [\\beta_1,\\beta_2,\\beta_3,\\beta_4]} \\\\ &amp;=\\sum_{k=1}^{6} 2 \\begin{pmatrix} [dV_{1k}]^T[dV_{1k}] + \\beta_2 [dV_{1k}]^T[dV_{2k}] + \\beta_3 [dV_{1k}]^T[dV_{4k}] + \\beta_4 [dV_{1k}]^T[dV_{4k}] \\\\ \\beta_1 [dV_{1k}]^T[dV_{2k}] + [dV_{2k}]^T[dV_{2k}] + \\beta_3 [dV_{2k}]^T[dV_{3k}]+ \\beta_4 [dV_{2k}]^T[dV_{4k}] \\\\ \\beta_1 [dV_{1k}]^T[dV_{3k}] + \\beta_2 [dV_{2k}]^T[dV_{3k}] + [dV_{3k}]^T[dV_{3k}] + \\beta_4 [dV_{3k}]^T[dV_{4k}] \\\\ \\beta_1 [dV_{1k}]^T[dV_{4k}] + \\beta_2 [dV_{2k}]^T[dV_{4k}] + \\beta_3 [dV_{3k}]^T[dV_{4k}] + [dV_{4k}]^T[dV_{4k}] \\end{pmatrix}_{4 \\times 1}^T \\\\ &amp;= \\sum_{k=1}^6 2 J_{k,1 \\times 4} \\\\ &amp;= J_{6 \\times 4} \\end{aligned} \\] 其中， \\(D_{6 \\times 1}\\)是控制点间的距离\\(C_{4}^2=6\\)，是6维向量 \\(D_{k}^c\\)是某两个控制点之间的距离，是标量 \\(\\boldsymbol{\\beta}=[\\beta_1,\\beta_2,\\beta_3,\\beta_4]^T\\)是未知数，是4维列向量 上面的求和\\(\\sum_{k=1}^6\\)不是相加，只是在维度上进行拼接 6.4.5. 增量方程 \\[ \\boldsymbol{J^TJ} \\delta \\boldsymbol{\\beta} = -\\boldsymbol{J^T} D_{6 \\times 1} \\] 6.4.6. 进行迭代 通过迭代，可以对\\(\\beta\\)的闭式解进一步调整优化，达到更高精度 6.5. 恢复[R | t] ——ICP问题求解 若变换关系为： \\[ p_i^c=R_{cw}p_i^w + t_{cw} \\] 接下来求解\\(R_{cw},t_{cw}\\) 6.5.1. 计算控制点在相机坐标系的坐标\\(c_{i}^c\\) \\[ c_{i}^c=\\sum_{j=1}^N \\beta_{j}v_{j}^{[i]} ~~ i=1,2,3,4 \\] \\(c_{i}^c\\) 是控制点的坐标，是\\(3 \\times 1\\)向量 \\(v_{j}^{[i]}\\) 是第j个特征值对应的特征向量的第i个控制点的分量，如果是第1个控制点，则对应前3个元素\\(v_{[j,1:3]}\\)，是一个3维向量 \\(\\beta_j\\)是线性组合的权重 6.5.2. 利用控制点\\(c_{i}^c\\)计算n个参考点在相机坐标系的坐标 \\[ p_i^c=\\sum_{j=1}^4 \\alpha_{ij}c_{j}^c , ~~~ i=1,2,\\cdots,n \\] 每个点都对应一组\\(\\alpha_i=[\\alpha_{i1},\\alpha_{i2},\\alpha_{i3},\\alpha_{i4}]\\)值 6.5.3. 计算相机坐标系下参考点\\(\\{p_{i}^c \\}_{i=1,\\cdots,n}\\)的质心\\(p_0^c\\)和去质心坐标 \\[ \\begin{aligned} p_0^c=\\frac{1}{n} \\sum_{i=1}^n p_{i}^c \\\\ q_i^{c}=\\begin{bmatrix} p_1^{cT}-p_0^{cT} \\\\ \\vdots \\\\ p_n^{cT}-p_0^{cT} \\end{bmatrix} \\end{aligned} \\] 6.5.4. 计算世界坐标系下参考点\\(\\{p_{i}^w \\}_{i=1,\\cdots,n}\\)的质心\\(p_0^w\\)和去质心坐标 \\[ \\begin{aligned} p_0^w=\\frac{1}{n} \\sum_{i=1}^n p_{i}^w \\\\ q_i^{w}=\\begin{bmatrix} p_1^{wT}-p_0^{wT} \\\\ \\vdots \\\\ p_n^{wT}-p_0^{wT} \\end{bmatrix} \\end{aligned} \\] 6.5.5. 开始进行ICP求解 ICP求解可参见《视觉SLAM14讲-第二版P197》 6.5.5.1. 先求旋转R 令 \\[ W_{3 \\times 3}=q_i^{cT} q_i^{w} \\] 对\\(W_{3 \\times 3}\\)进行SVD分解，得 \\[ W_{3\\times3}=U \\Sigma V^T \\] 为了满足\\(RR^T=I\\)，把SVD分解得到的奇异值矩阵\\(\\Sigma\\)变成\\(I\\) 得到旋转矩阵\\(R\\) \\[ R=UV^T \\] 如果旋转矩阵\\(R\\)的行列式\\(\\det R&lt;0\\)，那么取\\(R=-R\\) 6.5.5.2. 再求平移t \\[ t=p_0^c-Rp_0^w \\] EPnP总流程： 6.6. 参考资料 PNP的学习-EPNP PnP问题之EPnP解法 深入EPnP算法 ORBSLAM2中的EPnP算法 标量、向量、矩阵求导（两种布局方式）","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"}],"tags":[]},{"title":"ROS2_快速入门_1","slug":"ROS2/ROS2-快速入门-1","date":"2020-02-25T15:01:19.000Z","updated":"2020-02-25T16:45:04.000Z","comments":true,"path":"2020/02/25/ROS2/ROS2-快速入门-1/","link":"","permalink":"http://yoursite.com/2020/02/25/ROS2/ROS2-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-1/","excerpt":"","text":"1. ROS2 1.1. ROS2新技术 Zeroconf：零配置网络服务规范，用于自动生成可用IP地址的网络技术，不需要额外的手动配置和专属的配置服务器。 Protocol Buffers：Google公司开发的一种数据描述语言，类似于XML能够将结构化数据序列化，可用于数据存储、通信协议等方面。它不依赖于语言和平台并且可扩展性极强。 ZeroMQ（and the other MQs）：一个简单好用的传输层，相框架一样的一个socket library，它使的socket编程更加简单、简洁和性能更高。 Redis：一个高性能的key-value数据库。 WebSockets：HTML5开始提供的浏览器与服务器间进行全双工通讯的网络技术。 DDS（Data Distribution Service）：新一代分布式实时通信中间件技术规范，DDS采用发布/订阅体系架构，强调以数据为中心，提供丰富的Qos服务质量策略，能保障数据进行实时、高效、灵活的分发，可满足各种分布式实时通信应用要求， 多机器人控制，可以同时驾奴多个机器人。 多平台应用支持、可以在x86和ARM上跑。 1.2. ROS2与ROS1 架构比对 1.3. ROS2的提升 实时性增强：数据必须在deadline之前完成更新。 持续性增强：ROS1尽管存在数据队列的概念，但是还有很大的局限，订阅者无法接收到加入网络之前的数据； DDS可以为ROS提供数据历史的服务，就算新加入的节点，也可以获取发布的所有历史数据。 可靠性增强：通过DDS配置可靠性原则，用户可以根据需求选择性能模式（BEST_EFFORT）或者稳定模式（RELIABLE）。 参考自:https://blog.csdn.net/aiqinchao/article/details/90580478 2. 入门教程 2.1. 克隆样本仓库 git clone https://github.com/ros/ros_tutorials.git -b eloquent-devel 2.2. 安装依赖 在构建工作空间之前，您需要解决程序包依赖性。您可能已经具有所有依赖关系，但是最佳实践是每次克隆时都要检查依赖关系。您不会希望由于长时间缺少依赖关系而导致构建失败。 在工作区（ROS2）中，运行以下命令，安装依赖: sudo rosdep install -i --from-path src --rosdistro=${ROS_DISTRO} -y 如果已经拥有所有依赖项，则控制台将返回： 1#All required rosdeps installed successfully 软件包在package.xml文件中声明其依赖关系。该命令将遍历那些声明并安装缺少的那些声明。 2.3. 安装编译工具 colcon是ROS编译工具catkin_make，catkin_make_isolated，catkin_tools和ament_tools的换代。 sudo apt-get install python3-colcon-common-extensions 2.4. 构建项目 编译: 1colcon build 一些参数: --packages-up-to 构建所需的程序包，及其所有依赖项，而不是整个工作区（节省时间） --symlink-install 使您不必在每次调整python脚本时都需要重建 --event-handlers console_direct+在构建时显示控制台输出（否则可以在log目录中找到） 开始编译 编译完成 构建完成后，输入ls，您将看到colcon创建了新目录： 2.5. 覆盖空间 在运行编译完成的程序前, 需要在工作空间目录下执行以下指令 source ./install/local_setup.bash 或 source ./install/local_setup.zsh 这个操作会将overlap层中可用的软件包添加到您的环境中. 2.6. 运行 现在，可以turtlesim从叠加层运行该软件包： 1ros2 run turtlesim turtlesim_node 有一个问题是, 如何确定这是刚刚构建的turtlesim程序在运行, 而不是安装ros时自带的turtlesim在运行? 让我们在overlap层中修改turtlesim，以便可以看到效果： 您可以与底层分开修改和重建叠加中的包。 overlap层优先于参考层。 2.7. 修改程序 修改src/ros_tutorials/turtlesim/src/turtle_frame.cpp文件 , 使得程序窗口标题改变 重新构建编译 colcon build 运行 可以看到, 标题已经被修改, 可以证明, 现在运行的turtlesim确实是来自代码的, 而不是ros系统自带的. 2.8. 参考资料 ROS2-TUTORIALS","categories":[{"name":"ROS2","slug":"ROS2","permalink":"http://yoursite.com/categories/ROS2/"}],"tags":[]},{"title":"第二讲-ORB_SLAM2-视觉跟踪与重定位","slug":"SLAM代码课程/ORB_SLAM2/第二讲-ORB-SLAM2-视觉跟踪与重定位","date":"2020-02-25T00:53:42.000Z","updated":"2020-02-25T02:04:14.000Z","comments":true,"path":"2020/02/25/SLAM代码课程/ORB_SLAM2/第二讲-ORB-SLAM2-视觉跟踪与重定位/","link":"","permalink":"http://yoursite.com/2020/02/25/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB_SLAM2/%E7%AC%AC%E4%BA%8C%E8%AE%B2-ORB-SLAM2-%E8%A7%86%E8%A7%89%E8%B7%9F%E8%B8%AA%E4%B8%8E%E9%87%8D%E5%AE%9A%E4%BD%8D/","excerpt":"","text":"整体结构 视觉里程计基本原理 单目的初始化很复杂 工程上更加趋向于双目、RGB-D，可以直接初始化成功 初始化：得到第一、二帧的位姿，以及以第一帧相机坐标系的3D点 跟踪：定位-&gt;增加3D点-&gt;定位-&gt;... ORB_SLAM2程序主入口 跟踪与建图 由于相机在移动，所以在能看到初始化的时候生成的3D点会越来越少，因此会同时生成一些3D点(mappoint)，为了后面的移动可以观测到足够的3D点。 跟踪线程 重定位 参考资料","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"ORB_SLAM2","slug":"SLAM代码课程/ORB-SLAM2","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB-SLAM2/"}],"tags":[]},{"title":"SVD分解","slug":"utils/SVD分解","date":"2020-02-24T10:38:42.000Z","updated":"2020-02-24T15:13:34.000Z","comments":true,"path":"2020/02/24/utils/SVD分解/","link":"","permalink":"http://yoursite.com/2020/02/24/utils/SVD%E5%88%86%E8%A7%A3/","excerpt":"","text":"1. Introduction：SVD分解(奇异值分解) 奇异值分解（Singular Value Decompositionm,简称SVD）是在机器学习领域应用较为广泛的算法之一，也是学习机器学习算法绕不开的基石之一。SVD算法主要用在降维算法中的特征分解、推荐系统、自然语言处理计算机视觉等领域。（也是PCA降维的核心之一） 奇异值分解（SVD）通俗一点讲就是将一个线性变换分解为两个线性变换，一个线性变换代表旋转，一个线性变换代表拉伸。 SVD是将一个矩阵分解成两个正交矩阵和一个对角矩阵，我们知道正交矩阵对应的变换是旋转变换，对角矩阵对应的变换是伸缩变换 2. 特征值分解 在学习SVD奇异值分解之前，先来看一下特征值分解 2.1. 矩阵特征值与特征向量 若有 \\[ \\begin{aligned} Ax=\\lambda x \\end{aligned} \\] 其中，\\(A \\in R^{n \\times n}\\)是一个矩阵，如果上式成立，则称\\(\\lambda\\)是矩阵\\(A\\)的特征值，向量\\(x\\)是\\(\\lambda\\)对应的特征向量。 2.2. 特征分解 如果已经求出了矩阵\\(A\\)的\\(n\\)个特征值\\(\\lambda_1 \\leq \\lambda_2 \\cdots \\leq \\lambda_n\\)，以及这\\(n\\)个特征值所对应的特征向量\\(w_1,w_2,\\cdots , w_n\\)，如果这n个特征向量线性无关，则矩阵A可以用以下特征分解表示： \\[ A=W\\Sigma W^{-1} \\] 其中， \\[W=(w_1,w_2,\\cdots,w_n)\\] \\[ \\begin{aligned} \\Sigma= \\begin{pmatrix} \\lambda_1 &amp; &amp; &amp; \\\\ &amp; \\lambda_2 &amp; &amp; \\\\ &amp; &amp; \\cdots &amp; \\\\ &amp; &amp; &amp; \\lambda_n \\end{pmatrix} \\end{aligned} \\] 一般情况下，会把\\(W\\)的n个特征向量进行归一化，即\\(||w_i||_2=1\\)或者是\\(w_i^{T}w_i=1\\)，归一化之后，这n个特征向量则是标准正交基，满足\\(W^TW=I\\) 实际上，这个操作就是线性代数里面的对角化操作。 特征值分解有一个前提： 分解的矩阵必须是方阵 对于不是方阵的矩阵，该如何进行分解？ 这就是SVD的用处了 3. 奇异值分解(SVD) 对于一个非方阵的矩阵\\(A_{m \\times n}\\)来说，其SVD分解可写成如下： \\[ A=U\\Sigma V^T \\] 其中： \\(U\\)和\\(V\\)都是单位正交阵，则有\\(UU^T=I\\)、\\(VV^T=I\\)，其中\\(U\\)为\\(m \\times m\\)矩阵，\\(V\\)为\\(n\\times n\\)矩阵 \\(\\Sigma\\)是一个\\(m \\times n\\)矩阵，只有主对角线上的元素有值，其他元素均为0. 分解可如下表示 SVD分解的主要步骤就是求解\\(U,\\Sigma,V^T\\)，接下来继续讨论如何求解 3.1. 求解\\(U\\) 因为==&gt; \\[ \\begin{aligned} AA^T &amp;=(U\\Sigma V^T)(U\\Sigma V^T)^T \\\\ &amp;=U\\Sigma V^TV\\Sigma^TU^T \\\\ &amp;=U\\Sigma \\Sigma^TU^T \\end{aligned} \\] \\[ \\begin{aligned} A^TA &amp;=(U\\Sigma V^T)^T(U\\Sigma V^T) \\\\ &amp;=V\\Sigma^TU^TU\\Sigma V^T \\\\ &amp;=V\\Sigma^T\\Sigma V^T \\end{aligned} \\] 其中，这里的\\(\\Sigma \\Sigma^T\\)和\\(\\Sigma^T \\Sigma\\)在矩阵维度上面不相等，但是对角线上的元素是相等的。 \\[ \\begin{aligned} \\Sigma\\Sigma^T = \\left[ \\begin{matrix} \\sigma_1^2 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\sigma_2^2 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \\ddots &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\ddots \\\\ \\end{matrix} \\right]_{m\\times m}\\quad \\Sigma^T\\Sigma = \\left[ \\begin{matrix} \\sigma_1^2 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\sigma_2^2 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \\ddots &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; \\ddots\\\\ \\end{matrix} \\right]_{n\\times n} \\end{aligned} \\] 所以==&gt; 可以注意到，\\(AA^T\\)是方阵，于是对\\(AA^T\\)进行特征值分解，有 \\[ \\begin{aligned} M=(AA^T)&amp;=W\\Sigma W^{-1} \\\\ &amp;=U\\Sigma_u \\Sigma_u^TU^T \\end{aligned} \\] 可得： \\(AA^T\\)进行特征值分解之后的特征向量矩阵\\(W\\)就是矩阵\\(A\\)的右奇异向量矩阵\\(U\\) 即： \\[ W=V \\] 3.2. 求解\\(V\\) 于是==&gt; 同理可得： \\(A^TA\\)进行特征值分解之后的特征向量矩阵\\(W_r\\)就是矩阵\\(A\\)的左奇异向量矩阵\\(V\\) 即： \\[ W_r=V \\] 3.3. 求解\\(\\Sigma\\) 因为==&gt; \\[AA^T=U\\Sigma \\Sigma^TU^T\\] 其中， \\[ \\begin{aligned} \\Sigma\\Sigma^T = \\left[ \\begin{matrix} \\sigma_1^2 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\sigma_2^2 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \\ddots &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\ddots \\\\ \\end{matrix} \\right]_{m\\times m}= \\left[ \\begin{matrix} \\lambda_1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\lambda_2 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \\ddots &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; \\ddots\\\\ \\end{matrix} \\right]_{m\\times m} \\end{aligned} \\] 所以==&gt; \\(\\Sigma\\)的元素就是\\(\\Sigma\\Sigma^T\\)的主对角线元素的开方 （也就是说，\\(A\\)的奇异值\\(\\sigma\\)等于\\(AA^T\\)特征值的开方） \\[ \\begin{aligned} \\sigma_i=\\sqrt{\\lambda_i} \\end{aligned} \\] 3.4. 实际例子 3.4.1. 例1 3.4.2. 例2 3.5. SVD分解的结论 任意的矩阵A可以分解成3个矩阵 其中可得到\\(U\\)和\\(V\\)两个标准正交基 \\(\\Sigma\\)中的主对角线上的奇异值\\(\\sigma_i\\)按大到小向右下角排列，值越大，表示该维度的信息重要性越大 3.6. SVD分解的应用 数据降维(取奇异值大的几个维度) 数据压缩(图片压缩),例子见：奇异值分解应用 求解非齐次线性方程组 求解齐次线性方程组最小二乘解 3.7. 参考资料 奇异值分解——SVD算法解析与简单应用 降维——SVD原理以及示例 奇异值分解应用","categories":[{"name":"utils","slug":"utils","permalink":"http://yoursite.com/categories/utils/"}],"tags":[]},{"title":"protobuf_1","slug":"utils/protobuf-1","date":"2020-02-23T11:23:08.000Z","updated":"2020-02-23T14:33:43.000Z","comments":true,"path":"2020/02/23/utils/protobuf-1/","link":"","permalink":"http://yoursite.com/2020/02/23/utils/protobuf-1/","excerpt":"","text":"1. Protobuf Protobuf是一种平台无关、语言无关、可扩展且轻便高效的序列化数据结构的协议，可以用于网络通信和数据存储 2. Protobuf-Tutorials 应用举例 Tutorials示例：一个非常简单的“地址簿”应用程序，它可以在文件中读取和写入人们的联系方式。通讯录中的每个人都有一个姓名，一个ID，一个电子邮件地址和一个联系电话 在.proto 文件中定义消息格式 使用protocol buffer编译器 使用C++ protocol buffer API读写消息 使用protobuf，可以编写.proto文件来描述要储存的数据结构，protobuf编译器会创建一个类，该类以有效的二进制格式实现协议缓冲区数据的自动编码和解析。生成的类为构成协议缓冲区的字段提供获取器和设置器，并以协议为单位来详细阅读和写入协议缓冲区。重要的是，协议缓冲区格式支持随时间扩展格式的想法，以使代码仍可以读取以旧格式编码的数据。 2.1. 定义格式 为了创建“地址簿”应用程序，需要从.proto 文件开始。.proto 中的定义很简单：把要序列化的每个数据结构添加一条nessage，然后为消息中的每个字段指定名称和类型。 2.2. addressBook.proto 12345678910111213141516171819202122232425262728293031323334353637383940414243syntax = \"proto3\";package tutorial;import \"google/protobuf/timestamp.proto\";// [END declaration]// [START java_declaration]option java_package = \"com.example.tutorial\";option java_outer_classname = \"AddressBookProtos\";// [END java_declaration]// [START csharp_declaration]option csharp_namespace = \"Google.Protobuf.Examples.AddressBook\";// [END csharp_declaration]// [START messages]message Person &#123; string name = 1; int32 id = 2; // Unique ID number for this person. string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; string number = 1; PhoneType type = 2; &#125; repeated PhoneNumber phones = 4; google.protobuf.Timestamp last_updated = 5;&#125;// Our address book file is just one of these.message AddressBook &#123; repeated Person people = 1;&#125;// [END messages]&#125; 该.proto文件以程序包声明开头，这有助于防止不同项目之间的命名冲突。在C ++中，您生成的类将放置在与程序包名称匹配的名称空间中。 在上述示例中: Person消息包含PhoneNumber消息， 而AddressBook消息包含Person消息 甚至可以定义嵌套在其他消息中的消息类型 每个元素上的“ = 1”，“ = 2”标记标识该字段在二进制编码中使用的唯一“标记” 2.3. 编译protobuf，生成消息类 既然有了.proto，接下来需要做的是生成读取和写入AddressBook（Person和PhoneNumber）消息所需的类。 1protoc -I=$SRC_DIR --cpp_out=$DST_DIR $SRC_DIR/addressbook.proto 执行上述编译指令之后，将会在目的目录得到消息类文件： addressbook.pb.h addressbook.pb.cc 2.3.1. addressbook.pb.h 对于上述定义的字段，可以看到生成了这些类： 123456789101112namespace tutorial &#123;class AddressBook;class AddressBookDefaultTypeInternal;extern AddressBookDefaultTypeInternal _AddressBook_default_instance_;class Person;class PersonDefaultTypeInternal;extern PersonDefaultTypeInternal _Person_default_instance_;class Person_PhoneNumber;class Person_PhoneNumberDefaultTypeInternal;extern Person_PhoneNumberDefaultTypeInternal _Person_PhoneNumber_default_instance_;&#125; // namespace tutorial 对应的UML类图 2.4. 解析和序列化 bool SerializeToString(string* output) const;：序列化消息并将字节存储在给定的字符串中。请注意，字节是二进制的，而不是文本；我们仅将string类用作方便的容器。 bool ParseFromString(const string&amp; data);:解析来自给定字符串的消息 bool SerializeToOstream(ostream* output) const;: 将消息写入给定的C ++ ostream bool ParseFromIstream(istream* input);: 解析来自给定C ++的消息istream 2.5. C++调用 2.5.1. 示例：将个人详细信息写入地址簿文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#include &lt;ctime&gt;#include &lt;fstream&gt;#include &lt;google/protobuf/util/time_util.h&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include \"addressbook.pb.h\"using namespace std;using google::protobuf::util::TimeUtil;void PromptForAddress(tutorial::Person* person) &#123; //设置ID cout &lt;&lt; \"Enter person ID number: \"; int id; cin &gt;&gt; id; person-&gt;set_id(id); cin.ignore(256, '\\n'); //设置name cout &lt;&lt; \"Enter name: \"; getline(cin, *person-&gt;mutable_name()); //设置email cout &lt;&lt; \"Enter email address (blank for none): \"; string email; getline(cin, email); if (!email.empty()) &#123; person-&gt;set_email(email); &#125; //设置phone while (true) &#123; cout &lt;&lt; \"Enter a phone number (or leave blank to finish): \"; string number; getline(cin, number); if (number.empty()) &#123; break; &#125; tutorial::Person::PhoneNumber* phone_number = person-&gt;add_phones(); phone_number-&gt;set_number(number); cout &lt;&lt; \"Is this a mobile, home, or work phone? \"; string type; getline(cin, type); if (type == \"mobile\") &#123; phone_number-&gt;set_type(tutorial::Person::MOBILE); &#125; else if (type == \"home\") &#123; phone_number-&gt;set_type(tutorial::Person::HOME); &#125; else if (type == \"work\") &#123; phone_number-&gt;set_type(tutorial::Person::WORK); &#125; else &#123; cout &lt;&lt; \"Unknown phone type. Using default.\" &lt;&lt; endl; &#125; &#125; //时间戳 *person-&gt;mutable_last_updated() = TimeUtil::SecondsToTimestamp(time(NULL));&#125;int main(int argc, char* argv[]) &#123; // 宏定义用于确定protobuf版本,版本不一致则抛出异常 GOOGLE_PROTOBUF_VERIFY_VERSION; //输入一个文件，如果没有，则会新建一个 if (argc != 2) &#123; cerr &lt;&lt; \"Usage: \" &lt;&lt; argv[0] &lt;&lt; \" ADDRESS_BOOK_FILE\" &lt;&lt; endl; return -1; &#125; //这是由.proto编译生成的类 tutorial::AddressBook address_book; //尝试从已有数据文件读取,没有则创建 &#123; // Read the existing address book. fstream input(argv[1], ios::in | ios::binary); if (!input) &#123; cout &lt;&lt; argv[1] &lt;&lt; \": File not found. Creating a new file.\" &lt;&lt; endl; &#125; else if (!address_book.ParseFromIstream(&amp;input)) &#123; cerr &lt;&lt; \"Failed to parse address book.\" &lt;&lt; endl; return -1; &#125; &#125; //地址簿新增一个人的信息 PromptForAddress(address_book.add_people()); //保存到文件 &#123; //准备输出 fstream output(argv[1], ios::out | ios::trunc | ios::binary); // 序列化输出 if (!address_book.SerializeToOstream(&amp;output)) &#123; cerr &lt;&lt; \"Failed to write address book.\" &lt;&lt; endl; return -1; &#125; &#125; // Optional: Delete all global objects allocated by libprotobuf. google::protobuf::ShutdownProtobufLibrary(); return 0;&#125; CMakeList.txt 1234567891011121314cmake_minimum_required(VERSION 2.8)project(protobuf3_learn)set(CMAKE_INCLUDE_CURRENT_DIR TRUE)# Find required protobuf packagefind_package(protobuf CONFIG REQUIRED)if(protobuf_VERBOSE) message(STATUS \"Using Protocol Buffers $&#123;Protobuf_VERSION&#125;\")endif()add_executable(addFile addressbook.pb.cc add_person.cc )target_link_libraries(addFile protobuf::libprotobuf) 2.5.1.1. 运行效果 2.5.2. 示例：从地址簿文件读取信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// See README.txt for information and build instructions.#include &lt;fstream&gt;#include &lt;google/protobuf/util/time_util.h&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include \"addressbook.pb.h\"using namespace std;using google::protobuf::util::TimeUtil;//读取信息void ListPeople(const tutorial::AddressBook&amp; address_book) &#123; for (int i = 0; i &lt; address_book.people_size(); i++) &#123; const tutorial::Person&amp; person = address_book.people(i); cout &lt;&lt; \"Person ID: \" &lt;&lt; person.id() &lt;&lt; endl; cout &lt;&lt; \" Name: \" &lt;&lt; person.name() &lt;&lt; endl; if (person.email() != \"\") &#123; cout &lt;&lt; \" E-mail address: \" &lt;&lt; person.email() &lt;&lt; endl; &#125; for (int j = 0; j &lt; person.phones_size(); j++) &#123; const tutorial::Person::PhoneNumber&amp; phone_number = person.phones(j); switch (phone_number.type()) &#123; case tutorial::Person::MOBILE: cout &lt;&lt; \" Mobile phone #: \"; break; case tutorial::Person::HOME: cout &lt;&lt; \" Home phone #: \"; break; case tutorial::Person::WORK: cout &lt;&lt; \" Work phone #: \"; break; default: cout &lt;&lt; \" Unknown phone #: \"; break; &#125; cout &lt;&lt; phone_number.number() &lt;&lt; endl; &#125; if (person.has_last_updated()) &#123; cout &lt;&lt; \" Updated: \" &lt;&lt; TimeUtil::ToString(person.last_updated()) &lt;&lt; endl; &#125; &#125;&#125;// Main function: Reads the entire address book from a file and prints all// the information inside.int main(int argc, char* argv[]) &#123; // Verify that the version of the library that we linked against is // compatible with the version of the headers we compiled against. GOOGLE_PROTOBUF_VERIFY_VERSION; if (argc != 2) &#123; cerr &lt;&lt; \"Usage: \" &lt;&lt; argv[0] &lt;&lt; \" ADDRESS_BOOK_FILE\" &lt;&lt; endl; return -1; &#125; tutorial::AddressBook address_book; &#123; // Read the existing address book. fstream input(argv[1], ios::in | ios::binary); if (!address_book.ParseFromIstream(&amp;input)) &#123; cerr &lt;&lt; \"Failed to parse address book.\" &lt;&lt; endl; return -1; &#125; &#125; ListPeople(address_book); // Optional: Delete all global objects allocated by libprotobuf. google::protobuf::ShutdownProtobufLibrary(); return 0;&#125; 1234567891011121314151617cmake_minimum_required(VERSION 2.8)project(protobuf3_learn)set(CMAKE_INCLUDE_CURRENT_DIR TRUE)# Find required protobuf packagefind_package(protobuf CONFIG REQUIRED)if(protobuf_VERBOSE) message(STATUS \"Using Protocol Buffers $&#123;Protobuf_VERSION&#125;\")endif()add_executable(addFile addressbook.pb.cc add_person.cc )add_executable(readFile addressbook.pb.cc list_people.cc)target_link_libraries(addFile protobuf::libprotobuf)target_link_libraries(readFile protobuf::libprotobuf) 2.5.2.1. 运行效果","categories":[{"name":"utils","slug":"utils","permalink":"http://yoursite.com/categories/utils/"}],"tags":[]},{"title":"Cartographer论文阅读","slug":"Cartographer-Google相关/Cartographer论文阅读","date":"2020-02-23T01:42:30.000Z","updated":"2020-02-23T10:06:52.000Z","comments":true,"path":"2020/02/23/Cartographer-Google相关/Cartographer论文阅读/","link":"","permalink":"http://yoursite.com/2020/02/23/Cartographer-Google%E7%9B%B8%E5%85%B3/Cartographer%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"1. Real-Time Loop Closure in 2D LIDAR SLAM 2. 摘要 提出的方法应用在一个小型背包平台，可以达到实时的建图和定位，回环精度为5CM。为了达到实时的回环检测，使用了分枝定界为帧扫描和子图的匹配运算进行加速，这个方法达到了state-of-art。 3. 介绍 相反，本文的贡献在于提出了一种新的方法来降低从激光数据计算回环约束的计算要求，这种技术使SLAM能够绘制非常大的楼层，数万平方米的面积，同时实时为操作员提供完全优化的结果。 4. 相关工作 4.1. Scan-to-scan matching 常用于计算相对位姿的变化，具有累计误差。 4.2. Scan-to-map matching 有助于限制累计误差，其中一种方法是使用高斯-牛顿法在线性插值的地图上找到局部最优解。在这种情况下，通过使用足够高的数据率激光雷达提供良好的姿态初始估计，局部优化的扫描到地图匹配是有效和稳健的，在不稳定平台上，可以利用惯性测量单元(IMU)估计重力方向。 4.3. Pixel-accurate scan matching 可进一步减少局部累计误差，尽管需要更进一步的计算力，但是这个方法对于回环检测十分有用。一些方法侧重于通过匹配从激光扫描中提取的特征来提高计算cost，其他方法还有使用基于直方图匹配的，基于扫描特征提取的，还有使用机器学习的。 4.4. Else 处理剩余的局部误差积累的两种常用方法是粒子滤波和基于图的方法 4.5. 粒子滤波 粒子滤波器必须在每个粒子中维护一个完整系统状态的表示，对于基于网格的SLAM，随着地图变大，这很快就会成为资源密集型系统。 4.6. 图优化 基于图的方法在一组表示姿态和特征的节点上工作，图中的边是由观察产生的约束，可以使用各种优化方法来最小化所有约束带来的误差。 5. 系统概述 谷歌的Cartographer提供了一个实时的室内测绘解决方案，它采用了一个配备传感器的背包，可以生成分辨率为r = 5厘米的2D网格地图，该系统的操作员可以在穿过建筑物时看到正在创建的地图。 激光扫描被插入到子图上的一个最优位姿，在短时间内具有足够的准确度。扫描匹配是针对最近的子图进行的，因此它只依赖于最近的扫描，并且世界帧中的姿态估计的误差会累积。 为了解决积累的误差，我们定期运行一个位姿优化。当一个子图完成，就不会再新的一帧被插入，这个子图将会成为回环检测的一部分。所有完成的子图和激光扫描都被自动的被考虑到回环检测中。如果它们（激光扫描和子图之间）根据当前的位姿估计足够接近，则扫描匹配器尝试在子图中找到对应的激光扫描。 如果在当前估计位姿附近所创建的搜索窗口中找到了足够好的匹配，将会增加一条回环约束到最优化问题中。通过每几秒计算一次优化问题，可以看到，每当重新回到某个已经到达过的位置时，将会立即得到回环约束。 6. 局部2D-SLAM 系统结合了分离的局部和全局的方法来实现2D-SLAM。每一种方法的目的都是取优化位姿\\(\\xi\\),\\(\\xi=(\\xi_x,\\xi_y,\\xi_\\theta)\\)由平移量\\((x,y)\\)和旋转量\\(\\xi_\\theta\\)组成。对于激光雷达的观测，基本上就是一帧的激光扫描。在一个不稳定的平台上，比如我们的背包，一个IMU被用来估计重力的方向，从水平安装的激光雷达投射扫描到2D世界。 在我们的局部方法中，每个连续的扫描都是针对世界的一小块区域进行匹配的，称为子图\\(M\\)，使用了非线性优化的方法将一帧扫描和当前子图对齐，这个过程进一步称为扫描匹配。扫描匹配会随着时间积累错误，稍后通过全局方法消除这些错误。 6.1. Scans 子图的构造是对扫描和子图坐标系进行多次对齐的迭代过程，又称帧。基于一帧扫描的坐标原点，可以写出所有激光点\\(H=\\{h_k\\}_{k=1,\\cdots,K},h_k \\in R^2\\)。这一帧的扫描在子图坐标系的位姿\\(\\xi\\)可以使用变换\\(T_{\\xi}\\)来表示，即如下的变换： 6.2. Submaps 一些连续的激光扫描用于构建一个子图，这些子图具有概率网格的形式\\(M:rZ \\times rZ \\rightarrow [p_{min},p_{max}]\\)，这些离散网格具有分别率，如5cm一个网格点。每一个网格所对应的值可以看做是该网格被占据的概率。对于每一个网格点，定义相应的像素，使该像素由最接近网格点的所有点组成。 当一帧扫描被插入到概率网格，将计算网格点的\\(hits\\)和\\(misses\\)。对于每一次命中，我们都将最近的网格点插入命中集，对于每个未命中，我们插入与每个像素相关的网格点，这些像素与扫描原点和每个扫描点之间的射线相交，不包括已经在命中集中的网格点。 每个以前未观测到的网格点都被分配一个概率\\(phit\\)或\\(pmiss\\)，如果它在这些集合中的一个。 如果一个网格点x之前已经被观测过，那么就更新命中和未命中的概率，如下： 6.3. 在 scan matching使用Ceres 在将扫描插入子图之前，该帧相对于当前子图的位姿\\(\\xi\\)使用Ceres的Scan matcher优化得到。Scan matcher的作用是寻找一个位姿pose，该位姿使子图中扫描点(激光点？)的概率最大化，可以写成一个非线性最小二乘的问题： 其中，\\(T_\\xi\\)表示根据位姿\\(\\xi\\)把激光扫描中的点(雷达坐标系下的点)转换到子图坐标系下。\\(M_{smooth}: R^2 \\rightarrow R\\)是子图概率值的平滑函数。我们使用双三次插值，结果，会出现[0,1]之外的值，但可认为是无害的。 这种光滑函数的数学优化通常比网格的分辨率精度更高，由于这是一个局部优化，所以需要好的初始估计。IMU可以测量角速度可以用来估计旋转值\\(\\xi_\\theta\\)。在没有IMU的情况下，可以使用更高频率的扫描匹配或像素精确的扫描匹配方法，尽管这需要更大的计算量。 7. 回环 由于一帧扫描只与(包含几个最近扫描)的子图匹配，因此上面描述的方法会慢慢积累误差。 较大的空间通过创建许多小的子图来处理，我们的方法，优化所有扫描和子图的姿态，遵循稀疏姿态调整。每一个相对位姿所对应的激光扫描，都被插入到内存中储存，用来回环优化。除了这些相对位姿，其他的每一帧扫描和一帧子图之间的构成的所有匹配对也会被考虑到回环中，一旦该子图不再改变。扫描匹配(scan matcher)程序在后台运行，如果找到了合适的匹配，这个相关联的相对位姿会被加入到优化问题中。 7.1. 优化问题 回环优化，如scan matching，也可以使用非线性最小二乘问题来表示，每隔几秒，就使用Ceres对下面的优化问题进行求解： 其中，世界坐标系下的子图的位姿\\(\\Xi^m=\\{\\xi_i^{m} \\}_{i=1,\\cdots,m}\\)以及扫描的位姿\\(\\Xi^s=\\{\\xi_j^{s} \\}_{j=1,\\cdots,n}\\)将由给定的约束进行优化。 这些约束采用相对位姿\\(\\xi_{ij}\\)以及对应的协方差矩阵\\(\\Sigma_{ij}\\)组成。对弈每一对{子图\\(i\\)，扫描\\(j\\)}，相对位姿\\(\\xi_{ij}\\)描述了该激光扫描在子图坐标系中的匹配位置。协方差矩阵\\(\\Sigma_{ij}\\)也可以被估计。这样一个约束的残差\\(E\\)可以如下表示， 另外，损失函数\\(\\rho\\)可以使用\\(Huber\\)损失，用来减少outliers （错误约束）带来的影响。这种情况常发生在局部特征相似的情况，如办公室的隔间。 7.2. 分枝定界的scan matching 7.2.1. 目标函数 系统对像素的准确度匹配优化问题感兴趣，即： 其中，\\(w\\)是搜索窗口，\\(M_{nearest}\\)是M扩展到最接近的像素点，这就是将网格点的值扩展到相应的像素。匹配的质量可以使用CS来进一步提高。 通过仔细选择步长来提高效率，选择角度步长\\(\\delta_\\theta\\)使得激光扫描到的最远的点不会移动超过\\(r\\)，也就是一个像素的范围。使用余弦定理，可以得到： 我们计算可以覆盖给定线性和角搜索窗口大小的整数步长，如给定\\(W_x=W_y=7m\\)和 \\(W_\\theta=30 \\degree\\)，那么转换为像素就是： 这将导致在估计的位姿\\(\\xi_0\\)附近形成一个搜索集合，且\\(\\xi_0\\)是搜索窗口的中心。 对应的寻找最优位姿\\(\\xi^{*}\\)的算法可以写成如下流程，但对于搜索窗口的大小，我们认为它将是太慢。运算复杂度\\(O(n^3)\\)? 7.2.2. 分枝定界 为此，使用分枝定界法来高效的计算最优位姿\\(\\xi^{*}\\)，以便于在更大的搜索窗口进行搜索。一个通用的分枝定界算法流程如下： 其主要思想是将可能性的子集表示为树中的节点，其中根节点表示所有可能的解，在最优位姿搜索的这个情况就是搜索窗口W。 每个节点的子节点形成其父节点的一个分区，因此它们一起表示相同的一组可能性。 叶节点是单节点;每一个都代表一个可行的解决方案 注意到算法是精确的，它提供了与朴素方法相同的解决方案，其中的前提条件是只要内部某个节点\\(c\\)的得分\\(Score(c)\\)是其所有子节点得分的上限 在这种情况下，当一个节点有界(上限)时，这个节点的所有子节点就不存在比已知的最好的解决方案更好的解决方案 7.2.3. 分枝定界树的构建 为了将问题转换为分枝定界数搜索问题，需要确定节点选择、分支和上界计算的方法。 7.2.3.1. 节点选择 算法使用深度优先搜索(DFS)作为默认选择，该算法的效率很大程度上取决于被修剪的树。后一部分借助于DFS，它可以快速计算许多叶节点。 由于我们不希望添加坏的匹配作为回环约束，所以我们还引入了一个分数阈值，低于这个阈值时我们对于给出的结果不感兴趣。因为在实践中，这个门槛不会经常被超越，这降低了选择节点或寻找初始启发式解决方案的重要性。（降低了初值的敏感性）。 对于在DFS期间访问子节点的顺序，需要计算每个子节点得分的上界，首先访问最有希望的子节点和最大的上界，即如下： 最佳分数设置为给定的阈值 计算和储存集合\\(C_0\\)的每一个元素的得分 对集合\\(C_0\\)按得分排序，初始化堆栈，分数最高的在顶部。 如果堆栈\\(C\\)不为空，则进入遍历： 从堆栈\\(C\\)弹出顶部元素\\(c\\)（得分最高的） 如果\\(c\\)的得分比最佳分数高 同时也是一个叶子节点（表示一种可能的解决方案），就记录下此时\\(c\\)所代表的位姿\\(\\xi_c\\)，最佳分数也设置为新的值。 否则，若元素\\(c\\)不是一个叶子节点，即还没有展开到最底层，那么对元素\\(c\\)进一步展开，得到元素\\(c\\)的子集\\(C_c\\)，计算和储存元素\\(c\\)的子集\\(C_c\\)里面每一个元素的得分，最后将\\(C_c\\)推入堆栈\\(C\\)，按得分排序，最大分数在最顶部。 遍历堆栈\\(C\\)的所有元素之后，得到最佳分数和对应的位姿。 7.2.3.2. 分支法则 树中的每一个叶子节点由一组整数的元素\\(c\\)来描述，\\(c=(c_x,c_y,c_\\theta,c_h) \\in Z^4\\)。 在高度为\\(c_h\\)的节点有\\(2^{c_h} \\times 2^{c_h}\\)种可能的平移，但是旋转量是固定的。即： 对于叶子节点，其高度\\(c_h=0\\)，对应着一种可能的解决方案\\(\\xi_c=\\xi_0+(rc_x,rc_y,\\delta_\\theta c_\\theta)\\)，这个解的意思就是在给定初始值\\(\\xi_0\\)的基础上加上一个偏移。 在算法3中，根节点包含了所有的可行解，不显式出现并分支成一组初始节点\\(C_0\\)，在高度\\(h_0\\)包括了如下的搜索窗口： 其中，\\(w_x,w_y,w_\\theta\\)都是给定的搜索范围。 对于某一个高度为\\(c_h&gt;1\\)的节点\\(c\\)，又可以分支成4个高度为\\(c_{h-1}\\)的子节点： 7.2.3.3. 计算上界 在计算量和质量的角度上考虑，选取以下来作为节点上界的计算。 其中，\\(\\overline{W}\\)是给定搜索窗口(全解)，\\(\\overline {\\overline {W_c}}\\)是指定高度的某个节点所对应的全部可能的平移所组成的集合，而\\(\\overline{W_c}\\)则是上述搜索窗口与平移集合的交集。 为了高效的计算出最大值，使用了预计算的网格地图\\(M_{precomp}^{c_h}\\)。为每一个可能的高度\\(c_h\\)预计算一个网格地图，可以使得计算量与扫描激光点的数量成线性。预计算的网格地图\\(M_{precomp}^{c_h}\\)与元地图有同样的像素结构（width × height），但是每个像素取的是\\(2^h \\times 2^h\\)大小的范围内的最大值，如下： 为了确定上界，还计算指定高度的某个节点所对应的全部可能的平移所组成的集合了\\(\\overline {\\overline {W_c}}\\)的最高分数值，这个分数值大于或等于\\(\\overline{W_c}\\)的最大值。那么，某一个高度\\(c_h\\)节点的上界可以按如下确定： 7.2.3.4. 操作流程 为了将构建（预计算网格地图）的计算工作量保持在较低的水平，我们要等到概率网格不再更新的时候，然后我们计算一组预计算的网格地图，并开始与之匹配。","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"使用QT-Creator-Ros阅读Google-Cartographer代码_解决依赖-跳转问题-全绿_","slug":"Cartographer-Google相关/使用QT-Creator-Ros阅读Google-Cartographer代码-解决依赖-跳转问题-全绿","date":"2020-02-22T12:55:52.000Z","updated":"2020-02-22T16:08:30.000Z","comments":true,"path":"2020/02/22/Cartographer-Google相关/使用QT-Creator-Ros阅读Google-Cartographer代码-解决依赖-跳转问题-全绿/","link":"","permalink":"http://yoursite.com/2020/02/22/Cartographer-Google%E7%9B%B8%E5%85%B3/%E4%BD%BF%E7%94%A8QT-Creator-Ros%E9%98%85%E8%AF%BBGoogle-Cartographer%E4%BB%A3%E7%A0%81-%E8%A7%A3%E5%86%B3%E4%BE%9D%E8%B5%96-%E8%B7%B3%E8%BD%AC%E9%97%AE%E9%A2%98-%E5%85%A8%E7%BB%BF/","excerpt":"","text":"1. 背景 阅读Cartographer代码，需要解决一些函数的跳转关系，但是这个项目有点庞大，Qt-creator-ros也不能直接对整个克隆下来的项目进行分析其中的依赖关系，导致很多函数跳转不能实现。 本文通过修改CMakeList.txt 以及 一些文件位置， 使得Qt-Creator可以解决跳转的问题，可以自由在代码海洋中穿梭。对于阅读Cartographer有更好的效果。 2. 下载&amp;编译源码 2.1. 下载&amp;编译 进入官方说明网页：https://google-cartographer-ros.readthedocs.io/en/latest/ 按照指示进行编译。 1234567891011mkdir catkin_wscd catkin_wswstool init srcwstool merge -t src https://raw.githubusercontent.com/googlecartographer/cartographer_ros/master/cartographer_ros.rosinstallwstool update -t srcsrc/cartographer/scripts/install_proto3.sh 1234567src/cartographer/scripts/install_proto3.sh# sudo rosdep init 这步可以省略rosdep updaterosdep install --from-paths src --ignore-src --rosdistro=$&#123;ROS_DISTRO&#125; -y 2.2. 注意 其中，上面有些步骤是需要设置代理才能执行的，这些步骤分别是 wstool merge -t src rosdep update 否则，会报错如下： &gt; https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/sources.list.d/20-default.list Website may be down. 2.3. 编译完成之后的提示 3. 创建QT-Ros的工作空间 3.1. 初始化src文件夹 在工作空间目录中，执行： wstool init src catkin_make 一下 3.2. 把下载下来的Cartographer/src复制到src目录下 3.2.1. 把下载下来的Cartographer/src复制到src目录下 3.3. 进入QT-creator查看 3.4. 使用qt-cerator尝试进行编译 报错如下： This workspace contains non-catkin packages in it, and catkin cannot build a non-homogeneous workspace without isolation. Try the 'catkin_make_isolated' command instead. 这个错误的意思是，这个项目里面包含了不是ros的package，不能使用catkin_make进行编译，需要使用\"catkin_make_isolate\"进行编译，这种编译方式就是说普通的C++项目，就使用cmake来编译，对于ros的package，就使用catkin_make来编译。 3.4.1. 修改一下，在qt——creator使用catkin_make_isolate编译 点击左侧“项目” 构建步骤 把原来的构建步骤删除 添加Build步骤 添加“自定义进程步骤” 3.4.2. 点一下小锤子，进行编译 可以开始正常编译了，编译过程如下 有时候会报一个关于 ascii 字符编码的错误，不用管，再次点小锤子，就可以继续编译。大概会遇到三次这样子： 编译完成： 3.4.3. 既然编译通过，那看看代码依赖问题是否解决了 虽然通过编译，但是依赖问题没有解决，还是不能实现跳转，而且左侧有很多报错，提示找不到这些头文件 可以发现，qt-creator-ros很操蛋，对于使用自定义的\"catkin_make_isolate\"不认，不能识别依赖，只认catkin_make操作 4. 在qt使用catkin_make编译 由于项目中有两个package不是ros项目，“cartographer” 和“ceres-solver” 都是要使用cmake进行编译的，因此需要将它们移出去。 4.1. 移除“cartographer” 和“ceres-solver” 4.2. 尝试使用catkin_make进行编译 这时候，开始报错啦，注意了 报错如下： CMake Error at cartographer_ros/&gt;cartographer_ros/CMakeLists.txt:38 (find_package): By not providing \"Findcartographer.cmake\" in CMAKE_MODULE_PATH this project has asked CMake to find a package configuration file provided by \"cartographer\", but CMake did not find one. Could not find a package configuration file provided by \"cartographer\" with any of the following names: cartographerConfig.cmake cartographer-config.cmake 报错的原因是：Cartographer原本只是一个C++库，注意，是库。Cartographer-Ros是对这个库的封装和调用，我们把Cartographer移出去了，Cartographer-Ros就找不到关于这个库的头文件和动态库文件了。 解决思路 修改Cartographer-Ros的CMakeList.txt文件，修复依赖关系。 4.3. 先对cartographer_ros操作 4.3.1. CMakeList.txt 增加一行内容，用来指向查找cartographer库的 注意，下面的路径对应自己实际情况修改（将cartographer指向第一步下载下来并编译好的）： 123456#增加这一行set(cartographer_DIR /你的路径/cartographer/install_isolated/share/cartographer)find_package(cartographer REQUIRED)include(\"$&#123;CARTOGRAPHER_CMAKE_DIR&#125;/functions.cmake\") 4.4. 再对cartographer_rviz的CMakeList.txt操作 进行同样的操作即可 4.4.1. CMakeList.txt 增加一行内容，用来指向查找cartographer库的 注意，下面的路径对应自己实际情况修改（将cartographer指向第一步下载下来并编译好的）： 123456#增加这一行set(cartographer_DIR /你的路径/cartographer/install_isolated/share/cartographer)find_package(cartographer REQUIRED)include(\"$&#123;CARTOGRAPHER_CMAKE_DIR&#125;/functions.cmake\") 5. 再次使用catkin_make编译 先切换到构建release版本 5.1. 可以看到，这次可以使用catkin_make编译啦 编译过程 编译完成 6. 现在来看看代码头文件依赖情况吧 绿了吧 跳转正常","categories":[{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"}],"tags":[]},{"title":"第一讲-ORB-SLAM2-预备知识-2-ORB特征提取&外点剔除","slug":"SLAM代码课程/ORB_SLAM2/第一讲-ORB-SLAM2-预备知识-2-ORB特征提取&外点剔除","date":"2020-02-18T02:35:51.000Z","updated":"2020-02-22T15:52:06.000Z","comments":true,"path":"2020/02/18/SLAM代码课程/ORB_SLAM2/第一讲-ORB-SLAM2-预备知识-2-ORB特征提取&外点剔除/","link":"","permalink":"http://yoursite.com/2020/02/18/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB_SLAM2/%E7%AC%AC%E4%B8%80%E8%AE%B2-ORB-SLAM2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86-2-ORB%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&%E5%A4%96%E7%82%B9%E5%89%94%E9%99%A4/","excerpt":"","text":"图像变换","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"ORB_SLAM2","slug":"SLAM代码课程/ORB-SLAM2","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB-SLAM2/"}],"tags":[]},{"title":"第一讲-ORB-SLAM2-词袋模型","slug":"SLAM代码课程/ORB_SLAM2/第一讲-ORB-SLAM2-词袋模型","date":"2020-02-17T02:31:06.000Z","updated":"2020-02-17T03:34:39.000Z","comments":true,"path":"2020/02/17/SLAM代码课程/ORB_SLAM2/第一讲-ORB-SLAM2-词袋模型/","link":"","permalink":"http://yoursite.com/2020/02/17/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB_SLAM2/%E7%AC%AC%E4%B8%80%E8%AE%B2-ORB-SLAM2-%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"词袋模型 思路: 词袋: 将图像---&gt;描述子的映射, CNN自编码: 图像----&gt;向量 正向检索: 逆向检索: 参考资料","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"ORB_SLAM2","slug":"SLAM代码课程/ORB-SLAM2","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB-SLAM2/"}],"tags":[]},{"title":"第一讲-ORB_SLAM2_预备知识_1","slug":"SLAM代码课程/ORB_SLAM2/第一讲-ORB-SLAM2-预备知识-1","date":"2020-02-17T00:24:20.000Z","updated":"2020-03-03T09:07:55.000Z","comments":true,"path":"2020/02/17/SLAM代码课程/ORB_SLAM2/第一讲-ORB-SLAM2-预备知识-1/","link":"","permalink":"http://yoursite.com/2020/02/17/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB_SLAM2/%E7%AC%AC%E4%B8%80%E8%AE%B2-ORB-SLAM2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86-1/","excerpt":"","text":"1. ORB_SLAM2 2. 预备知识【1】 2.1. ICP SE3/Sim3求解 2.1.1. 已知n对匹配的3D点----3点法求R 这3个点实际上是世界坐标系W中的点，即世界坐标系中的点\\(p_1,p_2,p_3\\)构造出一个新的坐标系O，其中\\(p_1\\)的意义就相当于相机的坐标 根据这3个点\\(p_1,p_2,p_3\\)，可以得到坐标系O的三个轴的方向在世界坐标系W的表示 根据坐标系O的三个轴的方向在世界坐标系W的表示，可以写出从世界坐标系W到坐标系O的旋转变换\\(R_{w2o}=[\\bar{x},\\bar{y},\\bar{z}]\\)，(我自己而言还是比较习惯写成\\(R_{o\\leftarrow w}=[\\bar{x},\\bar{y},\\bar{z}]\\)的形式) 如果知道两组这样的的点，并且这两组点一一匹配 那么就可以写出这从上面坐标系O到下面坐标系O'的旋转变换\\(R_{o2o&#39;}=R_{w2o&#39;}R_{w2o}^T\\)，(我自己而言还是比较习惯写成\\(R_{o&#39;\\leftarrow o}=R_{o&#39;\\leftarrow w}R_{o\\leftarrow w}^T\\)的形式) 当匹配对数n&gt;3，则可以采用最小二乘的方法，最小化误差 2.1.2. 求Sim3尺度因子 上图中，\\(p_i&#39;=p_i-p^-\\)，\\(q_i&#39;=q_i-q^-\\) 2.1.2.1. 尺度因子的正解： 2.1.3. 求旋转R的四元数方法 2.2. 3D-2D PnP 2.2.1. EPnP 需要4个点是因为原点+3个方向 得到4个控制点分别是c0, c1, c2, c3 模长均为1 世界坐标系下的每个点\\(x_i^w\\)都可以用4个控制点以及映射关系\\([\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4]^T\\)来表示 EPNP 省略一部分 2.2.2. DLT算法 2.3. 2D-3D 三角化 2.3.1. 单目 2.3.2. 双目立体 2.4. 2D-2D Homography/Fundamental 对极几何 2.4.1. 基础矩阵与本质矩阵 极线\\(l&#39;=e&#39; \\times u\\) 的意思是, 这里的 极线 \\(l&#39;\\) 指的是这条极线在相机平面上的法向量 换句话说, 相机平面上极线上的两个点叉乘, 即向量叉乘\\(e&#39; \\times u\\) , 得到极线所在平面上的法向量\\((a,b,c)\\) 这个法向量可以构成极线点法式方程, 设极点\\(e(e_x,e_y,1)\\) , 那么极线方程为 \\(ae_x+be_y+c=0\\) 利用这个法向量, 可以出点\\(p_{proj}=[p_x,p_y,1]^T\\)到这条直线的距离 \\(d=\\frac{|ae_x+be_y+c|}{\\sqrt{a^2+b^2}}=\\frac{l&#39;*p_{proj}}{\\sqrt{a^2+b^2}}\\) 因此, 这个距离也就是极线约束, 利用这个距离可以判断基础矩阵F的好坏 (ORB_SLAM2 Initializer::CheckFundamental()函数就是这么计算初始化的基础矩阵F得分 ) e'和u不是指二维像素点坐标(u,v)，二维没法做叉乘， e'应该指的是相机坐标系O'到像素点e'的向量，u类比，这样才能做叉乘，叉乘完之后得到的是极线l'在平面上的法向量，这个法向量用来计算投影点到极线的距离。(点法式方程) 注意 8点法的8个点不能在同一个平面上, 如墙壁 原因是3D点共面时, 就满足单应性\\(\\bar{x}&#39;=H\\bar{x}\\) 后话: 所以, 一般操作时都会计算F和H, 两种情况, 看哪种情况下更好 另外: H矩阵的筛选点能力要强一些( 去除outlier ? ) 另外: 纯旋转不能用求F 由基础矩阵约束 \\(u_2^T*F*u_1=0\\) 可以得到,使用归一化的点代入,有: \\(\\bar{u}_2^T \\bar{F} \\bar{u}_1&#39;=0\\) 因此,使用归一化的点代入约束方程,可以求出\\(\\bar{F}\\) 又因为\\(\\bar{u}_2&#39;=T_2 u_2 , \\bar{u}_1&#39;=T_1 u_1\\) \\(\\bar{u}_2^T \\bar{F} \\bar{u}_1&#39; = (T_2 u_2)^T \\bar{F} (T_1 u_1) = u_2^T(T_2^T \\bar{F} * T_1)* u_1 = 0\\) 所以,最终要求归一化之前的F \\(u_2^T(T_2^T \\bar{F} * T_1)* u_1=u_2^T*F*u_1=0\\) \\(F=T_2^T \\bar{F} * T_1\\) ORB_SLAM2中归一化变换代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253void Initializer::Normalize(const vector&lt;cv::KeyPoint&gt; &amp;vKeys, vector&lt;cv::Point2f&gt; &amp;vNormalizedPoints, cv::Mat &amp;T)&#123; ///归一化变换 // 见:https://epsilonjohn.gitee.io/2020/02/17/%E7%AC%AC%E4%B8%80%E8%AE%B2-ORB-SLAM2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86-1/#d-2d-homographyfundamental-%E5%AF%B9%E6%9E%81%E5%87%A0%E4%BD%95 float meanX = 0; float meanY = 0; const int N = vKeys.size(); // 这是要输出的归一化之后的点 vNormalizedPoints.resize(N); //求平均值 for(int i=0; i&lt;N; i++) &#123; meanX += vKeys[i].pt.x; meanY += vKeys[i].pt.y; &#125; meanX = meanX/N; meanY = meanY/N; float meanDevX = 0; float meanDevY = 0; for(int i=0; i&lt;N; i++) &#123; vNormalizedPoints[i].x = vKeys[i].pt.x - meanX; vNormalizedPoints[i].y = vKeys[i].pt.y - meanY; meanDevX += fabs(vNormalizedPoints[i].x); meanDevY += fabs(vNormalizedPoints[i].y); &#125; // 尺度缩放 meanDevX = meanDevX/N; meanDevY = meanDevY/N; float sX = 1.0/meanDevX; float sY = 1.0/meanDevY; for(int i=0; i&lt;N; i++) &#123; vNormalizedPoints[i].x = vNormalizedPoints[i].x * sX; vNormalizedPoints[i].y = vNormalizedPoints[i].y * sY; &#125; // 构建归一化矩阵 T = cv::Mat::eye(3,3,CV_32F); T.at&lt;float&gt;(0,0) = sX; T.at&lt;float&gt;(1,1) = sY; T.at&lt;float&gt;(0,2) = -meanX*sX; T.at&lt;float&gt;(1,2) = -meanY*sY;&#125; ORB_SLAM2中计算基础矩阵F的代码(8点法) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115void Initializer::FindFundamental(vector&lt;bool&gt; &amp;vbMatchesInliers, float &amp;score, cv::Mat &amp;F21)&#123; // Number of putative matches const int N = vbMatchesInliers.size(); // Normalize coordinates // 归一化点 vector&lt;cv::Point2f&gt; vPn1, vPn2; cv::Mat T1, T2; Normalize(mvKeys1,vPn1, T1); Normalize(mvKeys2,vPn2, T2); cv::Mat T2t = T2.t(); // Best Results variables // 输出 score = 0.0; vbMatchesInliers = vector&lt;bool&gt;(N,false); // Iteration variables vector&lt;cv::Point2f&gt; vPn1i(8); vector&lt;cv::Point2f&gt; vPn2i(8); cv::Mat F21i; vector&lt;bool&gt; vbCurrentInliers(N,false); float currentScore; // Perform all RANSAC iterations and save the solution with highest score for(int it=0; it&lt;mMaxIterations; it++) &#123; // Select a minimum set for(int j=0; j&lt;8; j++) &#123; int idx = mvSets[it][j]; //mvMatches12[i]=pair(参考帧特征点idx,当前帧特征点idx) vPn1i[j] = vPn1[mvMatches12[idx].first]; vPn2i[j] = vPn2[mvMatches12[idx].second]; &#125; //计算出归一化特征点对应的基础矩阵 //由基础矩阵约束 u2'*F*u1=0 //可以得到,使用归一化的点代入,有: _u2' * _F * _u1 =0 //下面求出来的Fn就是 上式子的 _F cv::Mat Fn = ComputeF21(vPn1i,vPn2i); //又根据 _u2=T2*u2 , _u1=T1*u1 //可得: _u2' * _F * _u1 = (T2*u2)' * _F *(T1*u1) = u2'*(T2' * _F * T1)* u1 = 0 //即 :u2'*(T2' * _F * T1)* u1 = u2' * F * u1=0 //所以: 当我们求解[u2'*F*u1=0]中的F的时候, 实际上这个F应该等于(T2' * _F * T1) //转换成归一化前特征点对应的基础矩阵 //也就是求出没有归一化的点代入方程[u2'*F*u1=0]得到的F F21i = T2t*Fn*T1; //在参数 mSigma下，能够通过F21li， //重投影成功的点有哪些，并返回分数 currentScore = CheckFundamental(F21i, vbCurrentInliers, mSigma); //储存最高分的情况下的基础矩阵F if(currentScore&gt;score) &#123; F21 = F21i.clone(); //F vbMatchesInliers = vbCurrentInliers; //内点判断(std::vector)(判断哪些特征点对是内点) score = currentScore; &#125; &#125;&#125; //8点法求基础矩阵F,并根据约束进行调整Fcv::Mat Initializer::ComputeF21(const vector&lt;cv::Point2f&gt; &amp;vP1,const vector&lt;cv::Point2f&gt; &amp;vP2)&#123; const int N = vP1.size(); cv::Mat A(N,9,CV_32F); //八点法计算F //经过线性变换 DLT //构造矩阵A=u2^T F for(int i=0; i&lt;N; i++) &#123; const float u1 = vP1[i].x; const float v1 = vP1[i].y; const float u2 = vP2[i].x; const float v2 = vP2[i].y; A.at&lt;float&gt;(i,0) = u2*u1; A.at&lt;float&gt;(i,1) = u2*v1; A.at&lt;float&gt;(i,2) = u2; A.at&lt;float&gt;(i,3) = v2*u1; A.at&lt;float&gt;(i,4) = v2*v1; A.at&lt;float&gt;(i,5) = v2; A.at&lt;float&gt;(i,6) = u1; A.at&lt;float&gt;(i,7) = v1; A.at&lt;float&gt;(i,8) = 1; &#125; cv::Mat u,w,vt; cv::SVDecomp(A,w,u,vt,cv::SVD::MODIFY_A | cv::SVD::FULL_UV); //用SVD算出基础矩阵 //vt [8x8] : 由特征向量组成的矩阵, 每个特征向量都是9维的 //vt.row(8):矩阵A经过SVD分解之后最小奇异值对应的特征向量9 维 //重新reshape成3x3矩阵,得到基础矩阵F cv::Mat Fpre = vt.row(8).reshape(0, 3); ///下面进行对基础矩阵F进行约束调整 //将基础矩阵svd分解 cv::SVDecomp(Fpre,w,u,vt,cv::SVD::MODIFY_A | cv::SVD::FULL_UV); //根据基础矩阵的性质分解出来的w第三个元素应该为0 w.at&lt;float&gt;(2)=0; //返回复合要求的基础矩阵 return u*cv::Mat::diag(w)*vt;&#125; ORB_SLAM2中利用基础矩阵F约束进行重投影的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100//利用基础矩阵F进行重投影,计算得分 [理解对极约束]float Initializer::CheckFundamental(const cv::Mat &amp;F21, vector&lt;bool&gt; &amp;vbMatchesInliers, float sigma)&#123; const int N = mvMatches12.size(); const float f11 = F21.at&lt;float&gt;(0,0); const float f12 = F21.at&lt;float&gt;(0,1); const float f13 = F21.at&lt;float&gt;(0,2); const float f21 = F21.at&lt;float&gt;(1,0); const float f22 = F21.at&lt;float&gt;(1,1); const float f23 = F21.at&lt;float&gt;(1,2); const float f31 = F21.at&lt;float&gt;(2,0); const float f32 = F21.at&lt;float&gt;(2,1); const float f33 = F21.at&lt;float&gt;(2,2); //std::vector&lt;bool&gt; vbMatchesInliers是输出,输出哪些匹配点对是内点 vbMatchesInliers.resize(N); float score = 0; const float th = 3.841; const float thScore = 5.991; const float invSigmaSquare = 1.0/(sigma*sigma); for(int i=0; i&lt;N; i++) //遍历每一个特征点对 &#123; bool bIn = true; //mvMatches12[i]=pair(参考帧特征点idx,当前帧特征点idx) ,这两个特征点认为相互匹配, 现在取出来看是否真的匹配 const cv::KeyPoint &amp;kp1 = mvKeys1[mvMatches12[i].first]; const cv::KeyPoint &amp;kp2 = mvKeys2[mvMatches12[i].second]; const float u1 = kp1.pt.x; const float v1 = kp1.pt.y; const float u2 = kp2.pt.x; const float v2 = kp2.pt.y; /**************************************************** * 利用F重投影 * (0)由极线约束的示意图可知: 极线l'在图像平面上的法向量可以由 * 极线上的两点叉乘得到 * (1)根据公式l'=F*u ==&gt; 极线法向量 l2=F21 * x1 ===&gt;极线法向量(a,b,c) * (2)于是可以得到极线点法式方程: a(X-u1)+b(Y-v1)+c=0 * (3)假设在第一帧的点 x1 =[u1,v1,1]^T * (4)根据点到直线距离公式 dist= |a*u1+b*u2+c|/ sqrt(a^2+b^2) ****************************************************/ ///1. 将第一帧的特征点重投影到第二帧,计算误差 // l2=F21x1=[a2,b2,c2]^T (3x1)列向量 // F= [ f11 f12 f13 // f21 f22 f23 // f31 f32 f33 ] // // f1=[f11 f12 f13] U1=[u1 v1 1]^T ===&gt; a2=f1*U1 // 这里计算得到极线向量l2=[a2,b2,c2] const float a2 = f11*u1+f12*v1+f13; // (Fu)_x const float b2 = f21*u1+f22*v1+f23; // (Fu)_y const float c2 = f31*u1+f32*v1+f33; // 计算点x1到直线l2距离 const float num2 = a2*u2+b2*v2+c2; // 距离的平方 const float squareDist1 = num2*num2/(a2*a2+b2*b2); const float chiSquare1 = squareDist1*invSigmaSquare; //判断距离是否超过阈值,并计算得分,距离越大,得分越小 if(chiSquare1&gt;th) bIn = false; else score += thScore - chiSquare1; ///2. 将第二帧的特征点重投影到第一帧,计算误差(思路基本同上,计算点到直线距离) // l1 =x2tF21=[a1,b1,c1] (1x3) 行向量 const float a1 = f11*u2+f21*v2+f31; const float b1 = f12*u2+f22*v2+f32; const float c1 = f13*u2+f23*v2+f33; const float num1 = a1*u1+b1*v1+c1; const float squareDist2 = num1*num1/(a1*a1+b1*b1); const float chiSquare2 = squareDist2*invSigmaSquare; //判断距离是否超过阈值,并计算得分,距离越大,得分越小 if(chiSquare2&gt;th) bIn = false; else score += thScore - chiSquare2; //设置标志: 描述这对特征点是否是inlier if(bIn) vbMatchesInliers[i]=true; else vbMatchesInliers[i]=false; &#125; return score;&#125; ORB_SLAM2中分解基础矩阵F得到R,t 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115bool Initializer::ReconstructF(vector&lt;bool&gt; &amp;vbMatchesInliers, cv::Mat &amp;F21, cv::Mat &amp;K, cv::Mat &amp;R21, cv::Mat &amp;t21, vector&lt;cv::Point3f&gt; &amp;vP3D, vector&lt;bool&gt; &amp;vbTriangulated, float minParallax, int minTriangulated)&#123; int N=0; //匹配点中 for(size_t i=0, iend = vbMatchesInliers.size() ; i&lt;iend; i++) if(vbMatchesInliers[i]) N++; // Compute Essential Matrix from Fundamental Matrix // 从基础矩阵F计算出本质矩阵E (利用内参K) cv::Mat E21 = K.t()*F21*K; cv::Mat R1, R2, t; // Recover the 4 motion hypotheses (从E分解出4种可能的情况) // 从矩阵E分解出R,t ,其中分解出两个R DecomposeE(E21,R1,R2,t); // t又可以分为+t和-t cv::Mat t1=t; cv::Mat t2=-t; // Reconstruct with the 4 hyphoteses and check vector&lt;cv::Point3f&gt; vP3D1, vP3D2, vP3D3, vP3D4; vector&lt;bool&gt; vbTriangulated1,vbTriangulated2,vbTriangulated3, vbTriangulated4; float parallax1,parallax2, parallax3, parallax4; //mvKeys1:第一帧特征点 mvKeys2:第二帧特征点 //mvMatches12:储存着匹配点对在参考帧F1特征点数组和当前帧F2特征点数组中的序号 //vbMatchesInliers:有效的匹配点对 int nGood1 = CheckRT(R1,t1,mvKeys1,mvKeys2,mvMatches12,vbMatchesInliers,K, vP3D1, 4.0*mSigma2, vbTriangulated1, parallax1); int nGood2 = CheckRT(R2,t1,mvKeys1,mvKeys2,mvMatches12,vbMatchesInliers,K, vP3D2, 4.0*mSigma2, vbTriangulated2, parallax2); int nGood3 = CheckRT(R1,t2,mvKeys1,mvKeys2,mvMatches12,vbMatchesInliers,K, vP3D3, 4.0*mSigma2, vbTriangulated3, parallax3); int nGood4 = CheckRT(R2,t2,mvKeys1,mvKeys2,mvMatches12,vbMatchesInliers,K, vP3D4, 4.0*mSigma2, vbTriangulated4, parallax4); //取得分最高的 int maxGood = max(nGood1,max(nGood2,max(nGood3,nGood4))); R21 = cv::Mat(); t21 = cv::Mat(); //minTriangulated=50 int nMinGood = max(static_cast&lt;int&gt;(0.9*N),minTriangulated); //如果有两种情况的R,t得分都差不多,没有明显差别,nsimilar将&gt;1,这次初始化失败 int nsimilar = 0; if(nGood1&gt;0.7*maxGood) nsimilar++; if(nGood2&gt;0.7*maxGood) nsimilar++; if(nGood3&gt;0.7*maxGood) nsimilar++; if(nGood4&gt;0.7*maxGood) nsimilar++; // If there is not a clear winner or not enough triangulated points reject initialization //nsimilar&gt;1表明没有哪个模型明显胜出 //匹配点三角化重投影成功数过少 if(maxGood&lt;nMinGood || nsimilar&gt;1) &#123; return false; &#125; // If best reconstruction has enough parallax initialize // 如果某种情况的R,t得分比较高,则取该情况的R,t // 并将三角化的点拷贝,R,t拷贝,三角化标志位拷贝 if(maxGood==nGood1) &#123; //如果模型一对应的视差角大于最小值 if(parallax1&gt;minParallax) &#123; vP3D = vP3D1; vbTriangulated = vbTriangulated1; R1.copyTo(R21); t1.copyTo(t21); return true; &#125; &#125;else if(maxGood==nGood2) &#123; if(parallax2&gt;minParallax) &#123; vP3D = vP3D2; vbTriangulated = vbTriangulated2; R2.copyTo(R21); t1.copyTo(t21); return true; &#125; &#125;else if(maxGood==nGood3) &#123; if(parallax3&gt;minParallax) &#123; vP3D = vP3D3; vbTriangulated = vbTriangulated3; R1.copyTo(R21); t2.copyTo(t21); return true; &#125; &#125;else if(maxGood==nGood4) &#123; if(parallax4&gt;minParallax) &#123; vP3D = vP3D4; vbTriangulated = vbTriangulated4; R2.copyTo(R21); t2.copyTo(t21); return true; &#125; &#125; return false;&#125; 2.4.2. Homography模型 \\(d\\)表示的是平面到相机坐标系原点O的距离, 上面的\"其中d表示~\"说法有误。 下面给出\"白巧克力亦违心\"的博客内容: 注意: 上面的单应矩阵\\(\\hat{H}\\)是包含了尺度项\\(\\lambda\\), 所以\\(\\hat{H}=\\lambda H\\) , 可以把h9看做是包含了\\(\\lambda\\)的项, 所以, 这里(ORB_SLAM2)的 H 矩阵参数为9个 这里 \\(Ah=0\\) 与&lt;视觉SLAM14讲-第二版 P171 公式7.20&gt;的两个约束是对应的, 不同的地方是这里没有把h9看做是1, 这里的h9包含\\(\\lambda\\)项, 把它看做参数一起求了. ORB_SLAM2计算单应矩阵H代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104void Initializer::FindHomography(vector&lt;bool&gt; &amp;vbMatchesInliers, float &amp;score, cv::Mat &amp;H21)&#123; // Number of putative matches //假定匹配的数量 const int N = mvMatches12.size(); // Normalize coordinates // 坐标归一化 vector&lt;cv::Point2f&gt; vPn1, vPn2; cv::Mat T1, T2; Normalize(mvKeys1,vPn1, T1); Normalize(mvKeys2,vPn2, T2); cv::Mat T2inv = T2.inv(); //求出T2^&#123;-1&#125; // Best Results variables // 这是要输出的,描述某个特征点是否内点 score = 0.0; vbMatchesInliers = vector&lt;bool&gt;(N,false); // Iteration variables vector&lt;cv::Point2f&gt; vPn1i(8); vector&lt;cv::Point2f&gt; vPn2i(8); cv::Mat H21i, H12i; vector&lt;bool&gt; vbCurrentInliers(N,false); float currentScore; // Perform all RANSAC iterations and save the solution with highest score for(int it=0; it&lt;mMaxIterations; it++) &#123; // RANSAC迭代200次,取得分最高情况下算出来的单应矩阵H // Select a minimum set 每个集合8对点(8点法) // mvSets[当前迭代次数][0~7]= 某个最小集合随机索引idx for(size_t j=0; j&lt;8; j++) &#123; int idx = mvSets[it][j]; //idx用来取某一堆匹配点对 //mvMatches12[i]=pair(参考帧特征点idx,当前帧特征点idx), 这是匹配的特征点 vPn1i[j] = vPn1[mvMatches12[idx].first]; vPn2i[j] = vPn2[mvMatches12[idx].second]; &#125; //计算H cv::Mat Hn = ComputeH21(vPn1i,vPn2i); H21i = T2inv*Hn*T1; //注意: 这里是T2的逆,不是转置, 原因是约束方程里是叉乘关系, u2 X H * u1 = 0 H12i = H21i.inv(); //在参数 mSigma下，能够通过H21，H12重投影成功的点有哪些，并返回分数 currentScore = CheckHomography(H21i, H12i, vbCurrentInliers, mSigma); //只取最高得分情况下的H以及内点判断vbMatchesInliers if(currentScore&gt;score) &#123; H21 = H21i.clone(); vbMatchesInliers = vbCurrentInliers; score = currentScore; &#125; &#125;&#125;//SVD分解求H21矩阵cv::Mat Initializer::ComputeH21(const vector&lt;cv::Point2f&gt; &amp;vP1, const vector&lt;cv::Point2f&gt; &amp;vP2)&#123; const int N = vP1.size(); cv::Mat A(2*N,9,CV_32F); //虽然书上说最少用4个点对就可以解出单应矩阵，但是这里依然用的是8个点对 for(int i=0; i&lt;N; i++) &#123; //构造A矩阵 const float u1 = vP1[i].x; const float v1 = vP1[i].y; const float u2 = vP2[i].x; const float v2 = vP2[i].y; A.at&lt;float&gt;(2*i,0) = 0.0; A.at&lt;float&gt;(2*i,1) = 0.0; A.at&lt;float&gt;(2*i,2) = 0.0; A.at&lt;float&gt;(2*i,3) = -u1; A.at&lt;float&gt;(2*i,4) = -v1; A.at&lt;float&gt;(2*i,5) = -1; A.at&lt;float&gt;(2*i,6) = v2*u1; A.at&lt;float&gt;(2*i,7) = v2*v1; A.at&lt;float&gt;(2*i,8) = v2; A.at&lt;float&gt;(2*i+1,0) = u1; A.at&lt;float&gt;(2*i+1,1) = v1; A.at&lt;float&gt;(2*i+1,2) = 1; A.at&lt;float&gt;(2*i+1,3) = 0.0; A.at&lt;float&gt;(2*i+1,4) = 0.0; A.at&lt;float&gt;(2*i+1,5) = 0.0; A.at&lt;float&gt;(2*i+1,6) = -u2*u1; A.at&lt;float&gt;(2*i+1,7) = -u2*v1; A.at&lt;float&gt;(2*i+1,8) = -u2; &#125; cv::Mat u,w,vt; //SVD分解A=u*w*vt cv::SVDecomp(A,w,u,vt,cv::SVD::MODIFY_A | cv::SVD::FULL_UV); //返回了vt最后一个行向量 9维的向量 //reshape成3x3 return vt.row(8).reshape(0, 3);&#125; ORB_SLAM2利用单应矩阵H进行重投影约束代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596//通过单应矩阵H21以及H21_inv 反投影,计算误差,得到当前单应矩阵H的分数float Initializer::CheckHomography(const cv::Mat &amp;H21, const cv::Mat &amp;H12, vector&lt;bool&gt; &amp;vbMatchesInliers, float sigma)&#123; const int N = mvMatches12.size(); const float h11 = H21.at&lt;float&gt;(0,0); const float h12 = H21.at&lt;float&gt;(0,1); const float h13 = H21.at&lt;float&gt;(0,2); const float h21 = H21.at&lt;float&gt;(1,0); const float h22 = H21.at&lt;float&gt;(1,1); const float h23 = H21.at&lt;float&gt;(1,2); const float h31 = H21.at&lt;float&gt;(2,0); const float h32 = H21.at&lt;float&gt;(2,1); const float h33 = H21.at&lt;float&gt;(2,2); const float h11inv = H12.at&lt;float&gt;(0,0); const float h12inv = H12.at&lt;float&gt;(0,1); const float h13inv = H12.at&lt;float&gt;(0,2); const float h21inv = H12.at&lt;float&gt;(1,0); const float h22inv = H12.at&lt;float&gt;(1,1); const float h23inv = H12.at&lt;float&gt;(1,2); const float h31inv = H12.at&lt;float&gt;(2,0); const float h32inv = H12.at&lt;float&gt;(2,1); const float h33inv = H12.at&lt;float&gt;(2,2); vbMatchesInliers.resize(N); float score = 0; //判断通过单应矩阵重投影是否成功的阈值 const float th = 5.991; const float invSigmaSquare = 1.0/(sigma*sigma); //遍历所有的匹配点 for(int i=0; i&lt;N; i++) &#123; bool bIn = true; const cv::KeyPoint &amp;kp1 = mvKeys1[mvMatches12[i].first]; const cv::KeyPoint &amp;kp2 = mvKeys2[mvMatches12[i].second]; const float u1 = kp1.pt.x; const float v1 = kp1.pt.y; const float u2 = kp2.pt.x; const float v2 = kp2.pt.y; // Reprojection error in first image // x2=[u2,v2,1]^T x1=[u1,v1,1]^T // 这里的 H_21_inv = [h11_inv h12_inv h12_inv // h21_inv h22_inv h23_inv // h31_inv h32_inv h33_inv ] // H模型: 原模型: x2 = \\hat&#123;H_21&#125; * x1 逆模型(左乘\\hat&#123;H_21&#125;): H_21^&#123;-1&#125; * x2 = x1 // 逆模型就是将第2帧的特征点利用H21_inv矩阵反投影到第一帧 // 理解的时候,可以结合&lt;视觉SLAM14讲-第二版 P171 公式7.20&gt;来看 const float w2in1inv = 1.0/(h31inv*u2+h32inv*v2+h33inv); //把H矩阵第3行的约束嵌入到第一第二行中,相当于归一化? const float u2in1 = (h11inv*u2+h12inv*v2+h13inv)*w2in1inv; const float v2in1 = (h21inv*u2+h22inv*v2+h23inv)*w2in1inv; //计算u2，v2投影到F1后与u1,v1的距离的平方，也就是重投影误差 //H模型几何距离,使用对称转移误差,见&lt;计算机视觉中的多视图几何&gt; P58 公式3.7 const float squareDist1 = (u1-u2in1)*(u1-u2in1)+(v1-v2in1)*(v1-v2in1); const float chiSquare1 = squareDist1*invSigmaSquare; //chiSquare1&gt;th说明匹配的点对F1投影到F2，重投影失败 if(chiSquare1&gt;th) bIn = false; else score += th - chiSquare1; // Reprojection error in second image // x1in2 = H21*x1 // H模型: 原模型: x2 = \\hat&#123;H_21&#125; * x1 // 步骤基本同上 const float w1in2inv = 1.0/(h31*u1+h32*v1+h33); const float u1in2 = (h11*u1+h12*v1+h13)*w1in2inv; const float v1in2 = (h21*u1+h22*v1+h23)*w1in2inv; const float squareDist2 = (u2-u1in2)*(u2-u1in2)+(v2-v1in2)*(v2-v1in2); const float chiSquare2 = squareDist2*invSigmaSquare; if(chiSquare2&gt;th) bIn = false; else score += th - chiSquare2; //bIn标志着此对匹配点是否重投影成功 if(bIn) vbMatchesInliers[i]=true; else vbMatchesInliers[i]=false; &#125; return score;&#125; 2.4.3. 2D-2D模型约束与外点剔除 下面是分解的方法推导, 可暂时不看 Faugeras SVD 解法求R,t 对右侧得到的3个方程(2) (3) (4) 两两之间乘以\\(t^{&#39;}\\)的系数, 例如将方程(2)乘以\\(x_2\\) , 将方程(3)乘以\\(x_1\\), 两式相减, 可以得到一个消去\\(t^{&#39;}\\)的方程, 两两操作, 一共得到三个新的方程如下 技巧1: 利用旋转变换不改变向量模长的性质, 可以对等式两边同时取范数, 即可消去旋转矩阵\\(R\\) 技巧2: 根据克莱姆法则，系数行列式delta不等于0时, 线性方程组只有唯一零解。因此, 要使齐次线性方程组有非零解, 则系数矩阵的行列式要等于0 . 性质用于上面的方程(6) 证明中: 由于\\([x_1,x_2,x_3]^T\\)是法向量\\(n^{&#39;}\\), 所以 模长不可能为0 最后得到距离\\(d^{&#39;}\\)等于特征值\\(d_2\\) 先求R' , 再求t' 最后由约束\\(n^T t &lt;d\\) (两个相机位姿平移量远小于相机坐标系原点到3D点平面的距离) , 来使得3D点均在相机同一面, 剩下4种符合的情况 然后实际上又可以通过判断3D点(路标点) 是否在相机的正前方, 以及视差角, 在正前方的点 这些数据来筛选出最终的R,t 由于\\(d&#39;\\) 可以为\\(+d_2\\)或者\\(-d_2\\) , 每种情况下又有4种符合, 所以一共得到8种情况 (8种情况下3D点都在两个相机位姿的同一面) 对这8种情况进行筛选, 选出3D点在相机正前方的情况 最后再选取最符合实际情况(比如正前方3D点最多的)一种作为最终的解 , 求出 $R' , t' $ Malis 解法求R,t 关于左侧\\(det(\\hat H^T \\hat H -\\lambda I)=0\\) 也没说清楚, 貌似不太严谨? opencv是这么做了 这里还不能求出\\(y_1 , y_2 , y_3\\), 只能求出\\(z_1, z_2, z_3\\) 因为前面令\\(x=\\frac{R^T t}{|| R^T t||}=[x_1,x_2,x_3]^T\\) , 显然 \\(x\\)是单位向量,而且 旋转矩阵R 不改变向量模长, 因此 可以得到\\(x_1^2+x_2^2+x_3^2=1\\) Zhang SVD 解法求R,t 求齐次方程组最小二乘解-SVD 2.5. 参考资料 Homography 知多少？ 深蓝学院-SLAM代码讲解","categories":[{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"ORB_SLAM2","slug":"SLAM代码课程/ORB-SLAM2","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB-SLAM2/"}],"tags":[]},{"title":"第五讲(上)_最小二乘求解器Solver流程&代码","slug":"VIO/第五讲/第五讲_最小二乘求解器Solver流程&滑动窗口&代码","date":"2020-02-15T16:25:44.000Z","updated":"2020-03-01T10:18:56.000Z","comments":true,"path":"2020/02/16/VIO/第五讲/第五讲_最小二乘求解器Solver流程&滑动窗口&代码/","link":"","permalink":"http://yoursite.com/2020/02/16/VIO/%E7%AC%AC%E4%BA%94%E8%AE%B2/%E7%AC%AC%E4%BA%94%E8%AE%B2_%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B1%82%E8%A7%A3%E5%99%A8Solver%E6%B5%81%E7%A8%8B&%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3&%E4%BB%A3%E7%A0%81/","excerpt":"","text":"第五讲(上)_最小二乘求解器Solver流程&amp;代码 非线性最小二乘 关于舒尔补操作消元,可参考 求解过程的细节操作 解释: 使用LM算法可以强行使得信息矩阵H满秩, 但是有可能造成整条轨迹相对世界坐标系发生漂移, 尽管整条轨迹的残差已经达到最小值, 也就是所说的零空间变化. 举例: 对整条轨迹的漂移问题, 可以对整条轨迹乘以一个变换矩阵\\(T\\), 使轨迹变换到原来的状态. 固定某个位姿顶点\\(\\xi_i\\), 通常是固定第0个姿态\\(\\xi_0\\)为(0,0,0,0,0,0), 这相当于人为的给整条轨迹BA的信息矩阵添加先验信息(添加了额外的观测), 使得原本不是满秩的信息矩阵H变成满秩. 针对尺度不可观的问题, 可采取 (1)对某个固定之后的位姿\\(\\xi_i\\)所能观测到的某个路标点\\(L_i\\)也进行固定, 使得整个BA的尺度固定下来. (2)对连续两个位姿\\(\\xi_i\\)和\\(\\xi_{i+1}\\)进行固定, 使得轨迹的尺度确定下来. 具体操作: g2o论文: 对第一个位姿\\(\\xi_1\\)对应的信息矩阵加上单位阵I, 使得位姿\\(\\xi_1\\)对应的增量\\(\\delta x_1\\)被强行约束为0. \\[ \\begin{aligned} \\begin{bmatrix} H_{11}+I\\\\ H_{12} \\\\ \\vdots \\end{bmatrix} \\Delta X = b \\\\ \\Longrightarrow \\delta x_1 = 0 \\end{aligned} \\] 添加超强先验: 直接把位姿\\(\\xi_1\\)对应的信息矩阵设置为无穷大, 使得\\(\\delta x_1\\)无限接近0 g2o实现: 把位姿\\(\\xi_1\\)对应的雅克比设置为0, 直观上意味着残差=0, 残差=0, 意味着不用优化该位姿, \\(\\delta x_1\\)=0. 第五讲(下)_滑动窗口","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第五讲","slug":"VIO/第五讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%BA%94%E8%AE%B2/"}],"tags":[]},{"title":"第三讲(上)_基于优化的IMU与视觉信息融合(上)","slug":"VIO/第三讲/第三讲(上)_基于优化的IMU与视觉信息融合","date":"2020-02-15T16:18:02.000Z","updated":"2020-03-01T10:20:35.000Z","comments":true,"path":"2020/02/16/VIO/第三讲/第三讲(上)_基于优化的IMU与视觉信息融合/","link":"","permalink":"http://yoursite.com/2020/02/16/VIO/%E7%AC%AC%E4%B8%89%E8%AE%B2/%E7%AC%AC%E4%B8%89%E8%AE%B2(%E4%B8%8A)_%E5%9F%BA%E4%BA%8E%E4%BC%98%E5%8C%96%E7%9A%84IMU%E4%B8%8E%E8%A7%86%E8%A7%89%E4%BF%A1%E6%81%AF%E8%9E%8D%E5%90%88/","excerpt":"","text":"1. 第三讲(上)_基于优化的IMU与视觉信息融合(上) 第三讲(上): (1)最小二乘问题的求解推导 (2)其中有LM算法的相关推导以及鲁棒核函数的推导 1.1. 最小二乘与非线性优化 1.1.1. 最小二乘 1.1.2. 非线性最小二乘 1.1.2.1. LM算法增量\\(\\Delta X\\)表达式推导 求解如下: \\[ \\begin{aligned} &amp;(\\boldsymbol{J}^T\\boldsymbol{J}+\\mu\\boldsymbol{I})\\boldsymbol{\\Delta X}=-\\boldsymbol{J}^T\\boldsymbol{f} \\\\ &amp;\\Longrightarrow (\\boldsymbol{V \\Lambda V^T}+\\mu \\boldsymbol{I})\\boldsymbol{\\Delta X}=-\\boldsymbol{J}^T\\boldsymbol{f} \\\\ &amp;\\Longrightarrow(\\boldsymbol{V} (\\boldsymbol{\\Lambda}+\\mu \\boldsymbol{I})\\boldsymbol{V}^T) \\boldsymbol{\\Delta X}=-\\boldsymbol{J}^T\\boldsymbol{f} \\\\ &amp;\\Longrightarrow(\\boldsymbol{\\Lambda}+\\mu \\boldsymbol{I})\\boldsymbol{V}^T\\boldsymbol{\\Delta X}=-\\boldsymbol{V}^T\\boldsymbol{J}^T\\boldsymbol{f} \\\\ &amp;\\Longrightarrow(\\boldsymbol{\\Lambda}+\\mu \\boldsymbol{I})\\boldsymbol{V}^T\\boldsymbol{\\Delta X}=-\\boldsymbol{V}^T F^{&#39;}(x)^T \\\\ &amp;\\Longrightarrow\\boldsymbol{V}^T\\boldsymbol{\\Delta X}=-(\\boldsymbol{\\Lambda}+\\mu \\boldsymbol{I})^{-1}\\boldsymbol{V}^T F^{&#39;}(x)^T \\\\ \\end{aligned} \\] \\[ \\begin{aligned} \\boldsymbol{V}^T\\boldsymbol{\\Delta X}=- \\begin{bmatrix} \\frac{1}{\\lambda_1+\\mu}&amp;0&amp;0&amp; \\cdots \\\\ 0 &amp; \\frac{1}{\\lambda_2+\\mu} &amp; 0 &amp;\\cdots \\\\ 0 &amp; \\cdots &amp; &amp; \\frac{1}{\\lambda_j+\\mu} \\end{bmatrix} \\boldsymbol{V}^T F^{&#39;}(x)^T \\end{aligned} \\] \\[ \\begin{aligned} \\boldsymbol{\\Delta X}=- \\begin{bmatrix} \\boldsymbol{v_1} &amp; \\cdots &amp;\\boldsymbol{v_j} \\end{bmatrix} \\begin{bmatrix} \\frac{1}{\\lambda_1+\\mu}&amp;0&amp;0&amp; \\cdots \\\\ 0 &amp; \\frac{1}{\\lambda_2+\\mu} &amp; 0 &amp;\\cdots \\\\ 0 &amp; \\cdots &amp; &amp; \\frac{1}{\\lambda_j+\\mu} \\end{bmatrix} \\begin{bmatrix} \\boldsymbol{v_1} \\\\ \\vdots \\\\ \\boldsymbol{v_j} \\end{bmatrix} F^{&#39;}(x)^T \\end{aligned} \\] \\[ \\begin{aligned} \\therefore \\boldsymbol{\\Delta X}= -\\sum_{j=1}^{n}\\frac{\\boldsymbol{v}_j^T {\\boldsymbol{F&#39;}}^T}{\\lambda_j+\\mu} \\boldsymbol{v}_j \\end{aligned} \\] 从上图可以看到,由于\\(\\mu\\)的值在抖动,使得\\(\\Delta X\\)的步长在来回震荡变化,使得loss值也随着抖动,有一部分的计算是多余的. 1.1.2.2. 鲁棒核函数相关推导","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第三讲","slug":"VIO/第三讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%B8%89%E8%AE%B2/"}],"tags":[]},{"title":"第三讲(下)[未完成]_VIO残差函数的构建及雅克比推导","slug":"VIO/第三讲/第三讲(下)_VIO残差函数的构建","date":"2020-02-15T16:18:02.000Z","updated":"2020-03-01T10:21:03.000Z","comments":true,"path":"2020/02/16/VIO/第三讲/第三讲(下)_VIO残差函数的构建/","link":"","permalink":"http://yoursite.com/2020/02/16/VIO/%E7%AC%AC%E4%B8%89%E8%AE%B2/%E7%AC%AC%E4%B8%89%E8%AE%B2(%E4%B8%8B)_VIO%E6%AE%8B%E5%B7%AE%E5%87%BD%E6%95%B0%E7%9A%84%E6%9E%84%E5%BB%BA/","excerpt":"","text":"第三讲(下)_VIO残差函数的构建及雅克比推导[未完成] \\(x_i\\)是15维的状态量,因为姿态\\(q_{wbi}\\)是指更新量\\(\\delta\\) IMU预积分 预积分量的方差 F是状态量\\(x_k\\)对状态量\\(x_{k-1}\\)所携带的误差量\\(\\delta x_{k-1}\\)的雅克比矩阵 G是状态量\\(x_k\\)对输入量\\(u_{k-1}\\)所携带的误差量\\(\\delta u_{k-1}\\)的雅克比矩阵","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第三讲","slug":"VIO/第三讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%B8%89%E8%AE%B2/"}],"tags":[]},{"title":"SLAM综述_2020_Baichuan_Huang","slug":"文献阅读/SLAM综述_2020_Baichuan_Huang","date":"2020-02-15T10:19:19.000Z","updated":"2020-03-01T10:21:59.000Z","comments":true,"path":"2020/02/15/文献阅读/SLAM综述_2020_Baichuan_Huang/","link":"","permalink":"http://yoursite.com/2020/02/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/SLAM%E7%BB%BC%E8%BF%B0_2020_Baichuan_Huang/","excerpt":"","text":"1. SLAM综述_2020_Baichuan_Huang 2. 摘要 文章对激光SLAM，视觉SLAM以及它们的融合进行回顾。对于激光或者视觉slam而言，文章阐述了传感器的基本类型和产品、开源系统的种类和历史，深度学习的嵌入，挑战以及未来。另外的，视觉惯性里程计VIO也有被提及。对于激光和视觉融合的SLAM，本文重点提到了关于多传感器的标定，硬件、数据、任务层级的融合。最后，文章讲述了一些开放的问题以及前言的思考。文章的贡献可总结如下： 提供了SLAM领域高质量和全面的overview 对于新入门的研究者十分容易的理解SLAM的发展历史 可作为一部SLAM词典供研究者 3. 介绍 SLAM的主要任务：定位和建图。 1990年，“Randall Smith, Matthew Self, and Peter Cheeseman. Estimating un-certain spatial relationships in robotics. InAutonomous robot vehicles,pages 167–193. Springer, 1990.”首先提出了利用EKF进行增量式的位姿和地图估计，事实上，从未知环境的未知位置出发，机器人在运动过程中通过反复观察环境特征来确定自己的位置和姿态，然后根据周围环境的位置，绘制出一幅递增的周边环境地图。定位是近年来一个非常复杂和热点的问题。定位技术取决于环境和对成本、精度、频率和鲁棒性的要求，可以通过gps(全球定位系统)、IMU(惯性测量单元)和无线信号等来实现。但GPS只能在户外工作，IMU系统存在累积误差[5]。无线技术作为一种主动系统，无法在成本和精度之间取得平衡。近年来，随着激光雷达、相机、IMU等传感器的迅速发展，SLAM系统应运而生 从基于滤波器的SLAM开始，目前基于图优化的SLAM占据主导地位，该算法由卡尔曼滤波(KF)、EKF和粒子滤波(PF)演化为基于图的优化算法，该算法由卡尔曼滤波(KF)、EKF和粒子滤波(PF)演化为基于图的优化算法。SLAM技术也从最早的军事原型发展到后来多传感器融合的机器人应用。 4. 激光SLAM 4.1. 激光传感器 激光传感器分为2D和3D激光雷达，具体区分是以传感器的激光束数量来定义。在生产过程中，激光雷达也可以分为机械雷达、MEMS (micro- electromechanical)等混合固态激光雷达和固态激光雷达。固态激光雷达可以通过相控阵技术和flash技术来实现。 Velodyne：在机械激光雷达，它有VLP-16, HDL - 32E和HDL-64E。在混合固态激光雷达，它有Ultra Puck auto-32E SLAMTEC：低成本激光雷达和机器人平台，如RPLIDAR A1, A2和R3 Ouster：16到128线的机械激光雷达 Quanergy：S3是世界上第一个发布的固态激光雷达，M8是机械激光雷达。S3-QI是微小型固态激光雷达 Ibeo：在机械激光雷达中，有Lux 4L和Lux 8L。与Valeo公司合作，它发布了一款名为Scala的混合固态激光器 在未来的发展趋势中，小型化、轻量化的固体无级变速器将会占据市场并满足大多数的应用，其他激光雷达公司包括但不限于sick, Hokuyo, HESAI, RoboSense, LeddarTech, ISureStar, benewake, Livox, Innovusion, Innoviz, Trimble, LeishenIntelligent System 4.2. SLAM 激光SLAM在理论和实际应用中是可靠的。《概率机器人》阐述了基于概率的二维激光雷达同步定位与建图的数学理论。“An evalu-ation of 2d slam techniques available in robot operating system”对2D激光SLAM做了一个综述。 4.2.1. 2D 激光SLAM Gmapping：它是基于RBPF(Rao-Blackwellisation Partical Filter)方法的机器人中最常用的SLAM包，使用了扫描匹配(Scan matching)方法来估计位置(《概率机器人》、Improvedtechniques for grid mapping with rao-blackwellized particle filter.2007)。它是基于占据地图的FastSLAM的进阶版本。 HectorSlam：使用扫描匹配(Scan matching)和IMU传感器实现了结合2D SLAM和3D导航。（A flexible and scalable slam system with full 3d motionestimation.2011） KartoSLAM：一种基于图的SLAM系统（Efficient sparse pose adjustmentfor 2d mappin.2010） LagoSLAM：基于图的SLAM，讨论了非线性非凸的损失函数。（A linear approximation for graph-based simultaneous localization andmapping.2012） CoreSLAM/Tiny SLAM：可以理解为性能损失最小的算法（A slam algorithm in less than200 lines c-language program.2010） Cartographer：Google的SLAM系统，采用了子图和回环检测技术达到了最好的产品级别性能。算法可以提供2D和3D的多平台和传感器配置。（ Real-time loop closure in 2d lidar slam.2016） 4.2.2. 3D 激光SLAM Loam：是一种利用三维激光雷达进行状态估计和建图的实时方法。它也有前后旋转版本和连续扫描2D激光雷达版本(Loam: Lidar odometry and mapping inreal-time.2014) Lego-Loam：采用点云从VelodyneVLP-16激光雷达(水平放置)和（可选的）IMU作为数据输入。系统实时输出6D位姿估计，具有全局最优化和回环检测功能。（Lego-loam: Lightweight and ground-optimized lidar odometry and mapping on variable terrain 2018） Cartographer：支持2D和3D SLAM IMLS-SLAM：基于（扫描-模型匹配）框架，提出了一种基于三维激光雷达数据的低漂移SLAM算法（Imls-slam: scan-to-model matching basedon 3d data.2018） 4.2.3. 深度学习Deep Learn在激光SLAM中的应用 特征提取和检测： PointNetVLAD——提供了端到端的训练以及推理来实现从给定的3D点云中提取全局描述符，解决基于点云的位置识别检索问题（ointnetvlad: Deeppointcloud based retrieval for large-scale place recognition）。 VoxelNet——一个通用的三维检测网络，它将特征提取和边界框预测统一到一个单阶段模型，端到端可训练的网络（Voxelnet: End-to-end learning for pointcloud based 3d object detection.） BirdNet、LMNet：描述了效率的单阶段卷积神经网络，用来检测物体病输出一个对象映射和每个点的边界框偏移值。 PIXOR：是一个无提议的单阶段检测器，它从像素级别的神经网络中进行解码，输出3D物体的姿态估计（Pixor: Real-time 3d objectdetection from point clouds） Yolo3D：基于2D透视图像空间中单阶段回归架构的成功，将其扩展到从激光雷达点云生成定向三维物体边界盒（Yolo3d: End-to-end real-time 3d oriented objectbounding box detection from lidar point cloud） PointCNN：提出了从输入点云中学习X变换，X变换应用于典型卷积（点乘）运算符的元素-向量积和求和运算（Pointcnn: Convolution on x-transformed points.） MV3D：将激光雷达点云和RGB图像作为输入，并预测带姿态方向的的3D边界框（Multi-view3d object detection network for autonomous driving） PU-GAN：提出一种新的点云上采样网络，基于generative adversarial network (GAN)，其他类似的工作可以参考CVPR2018等最佳论文。（ Pu-gan: A point cloud upsampling adversarial network.） 识别与分割 实际上，对三维点云的分割方法可以分为基于边缘、区域生长、模型拟合、混合方法，机器学习和深度学习方法。（A review of point cloudssegmentation and classification algorithms） PointNet：设计了一种直接利用点云的新型神经网络，具有分类、分割和语义分析的功能（Pointnet:Deep learning on point sets for 3d classification and segmentation） Point-Net++：通过增加上下文的规模来获得层次特征（Pointnet++: Deephierarchical feature learning on point sets in a metric space.） VoteNet：构建点云三维检测pipline作为端到端三维目标探测网络，基于Point-Net++。（eephough voting for 3d object detection in point clouds） SegMap：基于3D点云的语义分割作为一种SLAM问题中的地图表示（SegMap: 3d segment mapping usingdata-driven descriptors. ） SqueezeSeg：使用循环CRF (Conditionalrandom fields)进行实时道路目标分割的三维激光雷达点云的卷积神经网络 （queezeseg:Convolutional neural nets with recurrent crf for real-timeroad-objectsegmentation from 3d lidar point cloud. / queezesegv2: Improved model structure and unsuperviseddomain adaptation for road-object segmentation from a lidar pointcloud / A lidar point cloud generator: from a virtualworld to autonomous driving ) PointSIFT：一个三维点云的语义分割框架，它基于一个简单的模块，从八个方向的邻域点提取特征。（Pointsift: A sift-like network module for 3d point cloud semanticsegmentation.） PointWise：提出了一种基于三维点云的语义分割和目标识别的神经网络（Pointwise convo-lutional neural networks.） 3P-RNN：（3d recurrent neural networks with context fusion for point cloudsemantic segmentation. ）提出了一种基于两水平方向的非结构化点云语义分割的端到端方法，利用了云的上下文特征，其他类似的工作如SPG 以及 综述（A review of point cloudssegmentation and classification algorithms.） SegMatch：基于3D 分割（线段？）的检测和匹配的回环检测方法。（Segmatch: Segment based place recognitionin 3d point clouds. ） Kd-Network：专为三维模型识别任务和工作与非结构化点云（ Escape from cells: Deep kd-networks for the recognition of 3d point cloud models） DeepTempo-ralSeg：提出了一种基于深度卷积神经网络(DCNN)的激光雷达语义分割算法（eeptemporalseg: Temporallyconsistent semantic segmentation of 3d lidar scans） LU-Net：实现了语义分割的功能，代替了传统的全局三维分割方法（Lu-net: An efficient network for 3d lidar pointcloud semantic segmentation based on end-to-end-learned 3d featuresand u-net） ，其他类似的工作如 PointRCNN (Pointrcnn: 3d ob-ject proposal generation and detection from point cloud.) 定位 L3-Net：是一种新的基于学习的激光雷达定位系统，达到厘米级定位精度（L3-net: Towards learning based lidar localization for autonomous driving.2019）[This work is supported by Baidu Autonomous DrivingBusiness Unit (Baidu ADU) in conjunction with the ApolloProject (http://apollo.auto/)] SuMa++：在像素点云级别标签基础上为全部扫描计算语义分割结果，允许我们建立语义丰富的图元标签地图，利用语义约束改进投影扫描匹配(Suma++:Efficient lidar-based semantic slam 2019) 挑战和未来 成本和适应性：激光雷达的优点是可以提供三维信息，不受夜晚和光线变化的影响，另外，视角相对较大，可以达到360度。但是，激光雷达的技术门槛很高，发展周期长，成本大。未来的发展趋势是小型化、合理化、固态、高可靠性和适应性 低纹理和动态环境：大多数SLAM系统只能在一个固定的环境下工作，但事情总是在不断变化。此外，长走廊、大管道等低结构环境会给激光雷达SLAM带来麻烦。（Imu-assisted 2d slam method for low-texture and dynamic environments）使用IMU协助2D SLAM来解决上面的问题。（Dynamic pose graph slam: Long-term mapping in lowdynamic environments）在绘图过程中加入时间维度，使机器人在动态环境中工作时能够保持精确的地图。如何使激光雷达对低纹理和动态环境具有更强的鲁棒性，以及如何保持地图的更新是需要深入考虑的问题。 对抗传感器攻击：深度神经网络容易受到反样本的攻击，这一点在基于摄像头的感知中也得到了证明。在基于激光的感知中，这是非常重要的，但是还没有被开拓。通过攻击，（Illusionand dazzle: Adversarial optical channel exploits against lidars forautomotive applications.）该算法首先对输出数据和距离估计进行干扰，使得基于VLP-16的激光雷达无法感知某个方向上的距离。（Adversarial sensor attack on lidar-based perception in autonomousdriving.）探索了通过战略控制来愚弄机器学习模型的可能性，把它看作一个优化问题，根据输入的扰动函数和目标函数进行建模，这将攻击成功率提高到大约75%。对抗式的传感器攻击将对基于激光雷达点云的SLAM系统进行欺骗，是无形的，很难被发现和保护在这种情况下，如何防止激光SLAM系统受到敌方传感器的攻击应该成为一个新的课题。 5. 视觉SLAM 随着CPU和GPU的发展，图形处理的能力越来越强大，相机传感器变得更便宜，更轻，同时更多功能。过去的十年见证了视觉SLAM的飞速发展。视觉SLAM使用相机也使系统更便宜和更小，和激光SLAM相比，视觉SLAM系统可以在微PC和嵌入式设备上运行，甚至可以在智能手机等移动设备上运行。 a versatile and accurate monocular slam system. Vins-mono: A robust andversatile monocular visual-inertial state estimator Parallel tracking and mapping on acamera phone ery High Frame Rate Volumetric Integration ofDepthImages on Mobile Device. Get out of my lab: Large-scale, real-time visual-inertial localization.) 视觉SLAM包括传感器数据的收集(如相机或惯性测量单元)，前端的：视觉里程计、视觉惯性里程计， 后端的：回环检测和优化，建图。《视觉SLAM 14讲》。重定位模块是增加稳定性和准确率的模块。（Visual slamalgorithms: A survey from 2010 to 2016） 在视觉里程计中，除了基于特征或模板匹配的方法，或相关方法来确定相机的运动，还有一种方法依赖于傅里叶-梅林变换（An fft-based techniquefor translation, rotation, and scale-invariant image registration.）。 文献（Visual odometry based on thefourier-mellin transform for a rover using a monocular ground-facingcamera）和（Visualodometry based on the fourier transform using a monocular ground-facing camera）给出了一个在没有明显视觉特征的环境下，使用面向地面的相机的例子。 5.1. 视觉传感器 照相机可分为单目照相机、立体照相机、RGB-D照相机、事件照相机等 单目相机：基于单目摄像机的视觉slam对真实大小的轨迹和地图有一个比例尺。也就是说，单目相机无法获得真实的深度，这就是所谓的尺度模糊。（A survy of monocularsimultaneous localization and mapping，2016）。基于单目摄像机的SLAM必须进行初始化，并面临漂移问题 立体相机：立体摄像机是由两个单目摄像机组合而成，但两个单目摄像机之间的基线距离是已知的，虽然深度可以通过校准、校正、匹配和计算得到，但这个过程是浪费资源的 RGB-D camera：RGB-D相机也称为深度相机，相机可以直接以像素输出深度，深度相机可以通过立体、结构光和TOF技术来实现。结构光理论是指红外激光对物体表面发出具有结构特征的图案，然后红外相机将收集由于不同深度的表面图案的变化，然后红外相机将收集由于不同深度的表面图案的变化。 事件相机：（Event-based vision: A survey. 2019)事件相机不是以固定的速率捕获图像，而是异步地测量每个像素的亮度变化,事件相机有非常高的动态范围(140 dB vs. 60 dB)，高时间分辨率(按us的顺序)，低功耗，不受运动模糊的影响。因此，事件相机在高速、高动态范围内的性能优于传统相机。以动态视觉传感器为例，（A 128x128 120db 15us latency asynchronous temporal contrast vision sensor. / a 640×480 dynamic vision sensor with a 9μm pixel and 300meps address-event representation / A microbolometer asynchronous dynamicvision sensor for lwir./ sparc-compatible general purpose address-event processor with 20-bit l0ns-resolution asynchronous sensor data interface in 0.18μm cmos.) 接下来介绍视觉传感器的产品和公司: Microsoft: Kinectc v1(structured-light), Kinect v2(TOF),Azure Kinect(with microphone and IMU) Intel：200 Series, 300 Series, Module D400 Series,D415(Active IR Stereo, Rolling shutter), D435(Active IRStereo, Global Shutter), D435i(D435 with IMU) Stereolabs ZED：ZED Stereo camera(depth up to 20m) MYNTAI：D1000 Series(depth camera), D1200(for smartphone), S1030 Series(standard stereo camera) Occipital Structure：Structure Sensor(Suitable for ipad) Samsung：Gen2 and Gen3 dynamic vision sensors andevent-based vision solution 其他深度相机还有：Leap Motion,Orbbec Astra,Pico Zense,DUO,Xtion,Camboard,IMI,Humanplus,PERCIPIO,Prime-Sense. 事件相机有：toiniVation,AIT,SiliconEye,Prophesee,CelePixel,Dilusense。 5.2. 视觉SLAM系统 利用图像信息的方法可分为直接法和基于特征的方法，直接法产生半密度和稠密构造，而基于特征的方法产生了稀疏构造 5.2.1. 稀疏视觉SLAM： MonoSLAM：（单目）第一个实时单目SLAM，基于EKF（Monoslam: Real-time single camera slam.2007） PTAM：（单目）第一个并行跟踪和建图的SLAM系统。首先采用了BA优化和关键帧的概念（Parallel tracking and mapping forsmall ar workspaces. 2007），后一个版本支持一个简单但有效的重定位方法（Improving the agility of keyframe-based slam.2008） ORB-SLAM：（单目）使用三个线程:跟踪、Local mapping和闭环检测（Orb: An efficient alternative to sift or surf，2011）； ORB-SLAM v2：支持单目，立体相机，和深度相机（Orb-slam2: An open-source slamsystem for monocular, stereo, and rgb-d cameras.2016）； CubemapSLAM：一个单目的鱼眼相机SLAM系统，基于ORB-SLAM。Visual Inertial ORB-SLAM：阐述了IMU的初始化过程和可视化信息的联合优化（isual-inertial monocular slamwith map reuse. / On-manifold preintegration for real-time visual–inertial odom-etry.） proSLAM：（立体相机）这是一个轻量级的视觉SLAM系统，易于理解（ProSLAM: GraphSLAM froma Programmer’s Perspective.2017） ENFT-sfm：（单目）一种高效的可以在一帧或者多帧视频序列中进行特征点匹配，的特征跟踪方法。其更新版本ENFT-SLAM可以运行在大的场合。(fficient non-consecutive feature tracking forrobust structure-from-motion.2016) OpenVSLAM：（适用各种相机）基于具有稀疏特征的非直接（间接）SLAM算法。OpenVSLAM的优秀之处在于，该系统支持透视、鱼眼和等矩形，甚至支持您设计的相机模型。(Openvslam: aversatile visual slam framework.2019) TagSLAM：意识到SLAM可以用AprilTag，AprilTag是一个视觉基准库，在AR，机器人，相机校准领域广泛使用。通过特定的标志（与二维码相似，但是降低了复杂度以满足实时性要求），可以快速地检测标志，并计算相对位置。此外，它提供了一个前端的GT-SAM因素图优化器，可以设计大量的实验(agslam: Robustslam withfiducial markers.2019) 5.2.2. 半稠密视觉SLAM LSD-SLAM：（单目）提出了一种基于李代数和直接法的直接跟踪方法，（Lsd-slam: Large-scale direct monocular slam.2014），（Large-scale directslam with stereo cameras.2015）使其支持立体相机。 SVO：（单目）半直接法视觉里程计（Svo: Semidirect visual odometry formonocular and multicamera systems.2016）它采用基于稀疏模型的图像对齐来获得更快的速度。其更新的版本扩展应用于鱼眼相机。（On-manifold preintegration for real-time visual–inertial odom-etry.2016）文献给出了关于VIO的详细理论推导和证明。CNN-SVO是一个从单图像深度预测网络中获取深度预测值的SVO版本。 DSO：（单目）（Direct sparseodometry. 2016 / 2017）是LSD-SLAM作者的另一个新的工作。这是一个不需要检测特征点和描述符的，基于直接法和稀疏法的的视觉里程计。 EVO：（事件相机）（Evo: A geometric approach to event-based 6-dofparalleltracking and mapping in real time.2016）提出了一种基于事件的视觉里程计算法，算法不受运动模糊的影响，并在具有挑战性的，高动态范围条件下与强烈的照明变化运行得很好。其他的基于事件相机的半稠密SLAM系统可以见（Semi-dense 3d reconstruction with a stereoevent camera.） 5.2.3. 稠密视觉SLAM DTAM：（单目）可实时重建3D模型基于最小化全局空间正则化能量函数，使用一种新的非凸优化框架，称之为直接法。（Inversedepth parametrization for monocular slam 2008 / Dtam: Dense tracking and mapping in real-time.2011） MLM SLAM：（单目）可以不使用GPU在线重建3D稠密模型，其关键贡献在于多分辨率深度估计和空间平滑过程。（Multi-level mapping: Real-time dense monocular slam.2016） Kinect Fusion：（RGB-D摄像机）几乎是第一个使用深度相机进行3D重建的系统（Kinectfusion: Real-time dense surface mapping and tracking 2011 / Kinectfusion: real-time 3drecon-struction and interaction using a moving depth camera 2011） DVO：（RGB-D相机）提出一种稠密视觉SLAM方法，一种基于熵的关键帧选择和闭环检测的相似度度量方法，使用G2O框架（Real-time visual odometry from dense rgb-d images.2011 / Robust odometryestimation for rgb-d cameras.2013 / Dense visual slamfor rgb-d cameras.2013) RGBD-SLAM-V2：（RGB-D相机）在不借助其他传感器的情况下重建出准确的三维致密模型（3-d mapping with an rgb-d camera.2014） Kintinuous：（RGB-D相机）一个带有实时全局一致的点和网格重构的视觉SLAM系统（Kintinuous: Spatially extendedkinectfusion 2012） RTAB-MAP：（RGB-D相机）支持SLAM，但难以作为算法开发的基础（Online global loop closuredetection for large-scale multi-session graph-based slam.2014）， 其后版本支持了视觉和激光SLAM（ Rtab-map as an open-sourcelidar and visual simultaneous localization and mapping library forlarge-scale and long-term online operation.2019） Dynamic Fusion：（RGB-D相机）第一个具有实时重建重建非刚性变形的场景的稠密SLAM系统，基于Kinect Fusion（Dynamicfu-sion: Reconstruction and tracking of non-rigid scenes in real-time.2015）。VolumeDeform也实现了实时非刚性重建，但不是开源的，其他相似的工作有Fusion4D。 Elastic Fusion：（RGB-D相机）一个实时稠密的视觉SLAM系统，能够捕获全面的、基于全局一致性的基于平面的房间尺度环境地图，使用RGB-D摄像机进行探索（Elasticfusion: Dense slam without a pose graph 2015） InfiniTAM：（RGB-D相机）在Linux、IOS、Android平台运行的，具有CPU的实时三维重构系统（finiTAM v3: A Framework forLarge-Scale 3D Reconstruction with Loop Closure 2017 / Real-timelarge-scale dense 3d reconstruction with loop closure 2018） Bundle Fusion：（RGB-D相机）支持鲁棒跟踪从严重跟踪故障中恢复，并实时重新估计3d模型，以确保全局一致性（Bundlefusion: Real-time globally consistent 3d re-construction using on-the-fly surface re-integration 2017） KO-Fusion：（RGB-D相机）提出一种基于动态和里程计测量的轮式移动机器人的稠密RGB-D视觉SLAM系统（Ko-fusion: Dense visual slam with tightly-coupled kinematic and odo-metric tracking 2019） SOFT-SLAM：（立体相机）（Soft-slam: Computationally efficient stereo visual slam for autonomousuavs 2017）得益于大范围的回环检测，系统可以创建稠密地图，基于SOFT进行位姿估计。（Stereo odometry based on careful featureselection and tracking. 2015） 5.2.4. 视觉惯性里程计SLAM 确定性在SLAM在技术上具有挑战性。单目视觉SLAM存在必要的初始化、尺度模糊和尺度漂移等问题（Scaledrift-awarelarge scale monocular slam 2010），虽然立体摄像机和RGB-D摄像机可以解决初始化和缩放的问题，但是有些障碍是不能忽视的，比如快速移动（可以用全局快门、鱼眼、全景相机等解决），以及小视场，大计算，遮挡，特征丢失，动态场景和变化的光线等问题。近年来，视觉惯性测程（VIO）SLAM技术成为研究热点。 首先（Keyframe-based visual–inertial odometry using non-linear optimization.2015 / Towards consis-tent visual-inertial navigation 2014 / igh-precision, consistentekf-based visual-inertial odometry 2013）在VIO方面进行了尝试。文献（Visual-inertial monocular slamwith map reuse.2017 / On-manifold preintegration for real-time visual–inertial odom-etry 2016 ）在VIO进行了理论上的证明和推导。（Fast and robustinitialization for visual-inertial slam. 2019）使用几轮的视觉-惯性BA来为VIO进行稳健的初始化。特别的，tango（Aninvestigationof google tangoR©tablet for low cost 3d scanning 2017）、Dyson 360 Eye 以及 hololens （ Real-time high resolution 3ddata on the hololens. 2016）都是VIO类的真实产品，并且得到了较好的反馈。 除此以外，苹果的ARkit (filter-based) ，Google的ARcore (filter-based) 以及从内到外的uSens等都是VIO的技术。PennCOSYVIO（Penncosyvio: A challenging visual inertial odometry benchmark 2017）从一个VI传感器（立体相机和IMU）中进行数据同步，两个tang相关手持设备，以及三个GoProHero 4摄像头，内部校准，外部校准。 下面是一些开源的VIO系统（A benchmarkcomparisonof monocular visual-inertial odometry algorithms for flying robots) 2018： SSF：（松耦合、基于滤波器）基于EKF的时间延迟补偿的单传感器和多传感器融合框架(Vision based navigation for micro helicopters 2012) MSCKF：（紧耦合、基于滤波器）Google Tango产品所采用的，基于EKF滤波器（A multi-state con-straint kalman filter for vision-aided inertial navigation. 2007）。相似的工作有MSCKF-VIO，是开源的（Robuststereo visual inertial odometry for fast autonomous flight 2018） ROVIO：（紧耦合、基于滤波器）基于使用跟踪全部3D路标点和图像块特征的EKF滤波器，支持单目相机。（Robust visual inertial odometry using a direct ekf-based approach. 2015） OKVIS：（紧耦合、基于优化）一个开放的和经典的基于关键帧的视觉惯性SLAM，它支持单目和立体摄像机的滑动窗口估计。（Monocular visual-inertial state estimation for mobile augmented reality 2017） VINS：VINS-Mono（紧耦合、基于优化方法）是一个实时的单目视觉-惯性SLAM框架，开源源码在Linux上运行，并与ROS完全集成。（Monocular visual-inertial state estimation for mobile augmented reality. 2017 / Online temporal calibration for monocularvisual-inertial systems.2018）VINS-Mobile是一个实时的单目视觉-惯性里程计VIO在IOS设备上运行。VINS-Fusion支持多个视觉-惯性（VI）传感器 (GPS, 单目相机 + IMU,立体相机 + IMU, 或甚至单个立体相机)它包括在线空间校准、在线时间校准和视觉回环检测。 ICE-BA：（紧耦合、基于优化方法）提出了一种增量式的、一致性的、高效的BA优化的视觉-惯性SLAM，在基于滑动窗口的小范围local的BA和在所有关键帧上的全局BA优化同时进行，实时的为每一帧输出相机位姿和更新地图上的点。（ice-ba: Incremental, consistent and efficient bundle adjustmentfor visual-inertial slam 2018）。 Maplab：（紧耦合、基于优化方法）一个开放的，面向研究的可视化惯性建图框架，用c++编写，用于创建，处理和多区域的地图。一方面，maplab可以被认为是一个现成的视觉惯性建图和定位系统，另一方面，maplab为研究社区提供了一套多区域建图工具，包括地图合并、视觉-惯性批处理优化、回环检测、3D稠密场景重建。（maplab: An open framework forresearch in visual-inertial mapping and localization 2018） 还有：VI-ORB（紧耦合、基于优化方法）是ORB-SLAM作者的另外的工作，但不是开源的。StructVIO、RKSLAM可以可靠地处理快速运动和强旋转的AR应用（Structvio: Visual-inertial odometry with structural regularity of man-made environments 2019 / Robust keyframe-basedmonocular slam for augmented reality.2018)。mi-VINS使用了多个IMU，用来应对IMU传感器失效的情况（Sensor-failure-resilient multi-imu visual-inertial navigation 2019）。其他工作还有（Continuous-time visual-inertial odometry for event cameras 2018 / Event-basedvisual inertial odometry.2017 / Event-based visual-inertial odometry on a fixed-wingunmanned aerial vehicle 2019） 另外，基于深度学习的VIO SLAM系统可以参见文献（Unsupervised deep visual-inertial odometry with onlineerror correction for rgb-d imagery. 2019）该方法提出了一个VIO的网络，而不需要IMU的内参以及IMU和相机的外部标定（外参）。文献（Visual-inertial odometry for unmanned aerial vehicle using deep learning 2019）提供了一个避免IMU和相机之间的标定的网络。 5.2.5. 基于深度学习的视觉SLAM 目前，深度学习在计算机视觉的维护中起着至关重要的作用，随着视觉SLAM的发展，越来越多的人将目光投向了深度学习。“语义SLAM”指包括了语义信息到SLAM过程处理，通过提供高层次的理解、健壮的性能、资源意识和任务驱动的感知来提高SLAM表现和表示。下面介绍带有语义信息的SLAM的实现： 特征和检测： Pop-up SLAM（单目）提出了一种实时单目平面SLAM的方法，证明了场景理解可以改善状态估计和稠密建图，特别是在低纹理环境中。平面测量来自应用于每张图像的三维平面模型。文献（6-dof object pose from semantickeypoints 2017）通过卷积神经网络获取了语义的关键点预测。 LIFT可以比SIFT获取更多的稠密的特征点（Lift:Learned invariant feature transform 2016）。 在捕捉特征点的任务上，DeepSLAM有显著的性能差距表现（Towardgeometric deep slam. 2017）。 SuperPoint提出了一种用于训练兴趣点检测器和描述符的自监督框架，该框架适用于计算机视觉中大量的多视图几何问题Su-perpoint: Self-supervised interest point detection and description 2018）。 文献（Stereo vision-based semantic3d object and ego-motion tracking for autonomous driving.2018）提出了使用易于标注的二维检测和离散视点分类，并结合轻量级语义推理方法来获得粗略的三维目标测量结果。 GCN-SLAM提出了一个基于深度的网络GCNv2，用于生成关键点和描述符。 文献（Volumetric instance-aware semantic mapping and 3d object discovery 2019）融合了关于3D形状、位置、甚至是语义类别的信息。 SalientDSO借助深度学习实现视觉显著性和环境感知。文献（Structure aware slam using quadrics and planes.2018）将检测到的目标作为二次模型集成到SLAM系统中。 CubeSLAM（单目）一个3D物体检测和SLAM系统，基于立方体模型，实现了对象级别的建图、定位和动态对象跟踪。 文献（Monocular objectand plane slamin structured environments 2019）与基于特征点的SLAM相比，结合了cubeSLAM(高级对象)和Pop-up SLAM(平面地标)的系统使地图更密集、更紧凑、语义更有意义。 MonoGRNet一个几何推理网络，用于单目3D目标检测和定位。其他的基于特征方法在事件相机的应用有文献（Fast event-based corner detection 2017 / Event-basedfeatures for robotic vision 2013）。 另外关于检测方面的深度学习综述，还有文献（Recent advances indeep learning for object detection 2019） 识别和分割： SLAM++（cad模型）介绍了一种新的面向对象的3D SLAM范式的主要优点，充分利用先验知识的循环，如许多场景由重复的、领域特定的对象和结构组成。 文献（Semi-dense 3d semantic mappingfrom monocular slam. 2016）结合了先进的深度学习方法和基于单目摄像机视频流的LSD-SLAM，二维语义信息通过具有空间一致性的连接关键帧之间的对应关系转移到三维映射中。 Semanticfusion（RGBD）结合了CNN和先进的SLAM系统，ElasticFusion用来构建语义的3D地图。 文献（Meaningful maps with object-oriented semantic mapping. ）采用了基于特征的RGB-DSLAM，基于图像的深度学习对象检测和3d无监督分割。 MarrNet提出了一个端到端的可训练框架，顺序估计2.5D草图和3D物体形状。 3DMV（RGBD）结合RGB颜色和几何信息对RGB-D扫描进行三维语义分割。 Pix3D研究三维形状建模从单一的图像。 ScanComplete一种数据驱动的方法，以一个不完整的三维场景扫描作为输入，并预测一个完整的三维模型，以及每体素语义标签。 Fusion++ 一个在线对象级的SLAM系统，它可以为任意的被测对象建立一个精确的三维图形映射。 当RGB-D摄像机浏览杂乱的室内场景时，Mask-RCNN的实例分割用于初始化紧凑的对象截断函数重建。 SegMap基于3d片段的地图表示，允许机器人定位、环境重建和语义提取。 3D-SIS一种商用的RGB-D扫描三维语义实例分割的新型神经网络结构。 DA-RNN采用一种新的递归神经网络结构对RGB-D视频进行语义标注。 DenseFusion从RGB-D图像中估计一组已知对象的6d位姿的通用框架。 其他用于事件相机的可参考文献（An event-based classifier for dynamicvision sensor and synthetic data 2017 / Event-based gesture recog-nition with dynamic background suppression using smartphone com-putational capabilities. 2018 / Investigation of event-based mem-ory surfaces for high-speed detection, unsupervised feature extraction,and object recognition.2018） 尺度恢复： CNN-SLAM（单目）使用深度学习估计深度，其他工作还有DeepVO、GS3D。 UnDeepVO基于深度学习，使用单目相机可以得到6自由度的姿势。 谷歌提出了文献（Learning the depths of moving peopleby watching frozen people.2019）提出了一种基于无监督学习的单目摄像机和人在场景中自由移动的稠密深度场景预测方法。 其他基于单目相机获取真实尺度的工作还有（Recovering stable scale inmonocular slam using object-supplemented bundle adjustment.2018）（Bayesian scale estimation formonocular slam based on generic object detection for correcting scaledrift.2017）。 GeoNet一种用于从视频中估计单目深度、光流和帧间运动估计的联合无监督学习框架。 CodeSLAM提出了一种从单张图片获取深度图的网络，该深度图可以与位姿变量一起有效地优化。 Mono-stixels使用动态场景中的深度、动作和语义信息来估计深度？？？ GANVO使用无监督学习框架，用来从无标签的图像中获取6D姿态估计和单目深度图，使用GAN网络。 GEN-SLAM利用传统的几何网格和单目的拓扑约束输出稠密地图。 其他的还有DeepMVS、DeepV2D 姿态输出和优化： 文献（Learning visual odom-etry with a convolutional network 2015）是同步的立体的VO。 文献（Exploring representation learning with cnns for frame-to-frame ego-motion estimation 2015）利用CNN从光流中估计运动。 PoseNet可以从单个RGB图像在没有优化的情况下得到6自由度的姿态估计。 VInet（单目）首先实现对VIO中的运动进行估计，减少了对人工同步和校准的依赖。 DeepVO（单目）提出了一种利用深度递归卷积神经网络(RCNNs)实现单目的端到端VO框架，类似的工作还有SFMlearner、SFM-Net。 VSO提出了提出了一种新的视觉语义里程计(VSO)框架，利用语义实现对点的中期连续跟踪。 MID-Fusion(RGBD,稠密点云)使用面向对象的跟踪方法估计每个存在的移动对象的姿态，将分割的MASK与现有模型关联起来，并逐步将相应的颜色、深度、语义和前景对象概率融合到每个对象模型中。 长时间定位： 文献（Probabilistic data association for semantic slam. 2017）提出了一个基于传感器状态和语义地标位置的优化问题，集成了度量信息、语义信息和数据关联。 文献（Lightweight unsupervised deep loopclosure.2018）提出了一种新颖的无监督的特征嵌入深度神经网络，该网络用于视觉的回环检测问题。 文献（Long-term visuallocalization using semantically segmented images 2018）提出的方法展示了语义信息比传统的描述符在长期视觉定位中更有效。 X-View利用语义图描述符匹配进行全局定位，使得不同视点下的定位成为可能。 文献（Multimodal seman-tic slam with probabilistic data association. 2019）提出了一个解决方案，表示假设作为等效非高斯传感器模型的多模态，来预测目标类别标签和测量路标点的相关性。 动态SLAM： RDSLAM提出了一种能在动态环境下鲁棒工作的实时单目SLAM系统，基于新的在线关键帧表示以及更新的方法。 DS-SLAM一个带有语义信息的SLAM系统，基于优化的ORB-SLAM，语义信息可以使得SLAM系统在动态环境下得到更好的鲁棒性。 MaskFusion（RGBD，稠密点云）一个实时的、关注对象的、语义的、动态的RGB-D SLAM系统，基于Mask R-CNN，该系统对物体进行语义的标签，相似的工作还有Co-Fusion(RGBD)。 Detect-SLAM将SLAM与基于深度神经网络的目标检测相结合，使这两种功能在未知动态环境中相互受益。 DynaSLAM在静态地图的帮助下的一个单目立体、RGB-D相机SLAM系统，适用与动态环境。 StaticFusion提出了一种动态环境下的鲁棒稠密RGB-D SLAM方法，该方法检测运动目标并同时对背景结构进行重建。 最近，还有一些工作利用深度学习来主导SLAM的整个过程，SimVODIS可以输出深度和帧之间的相对位姿，同时检测对象和分割对象边界框。 5.3. 挑战和未来 鲁棒性和可移植性 视觉SLAM仍然面临着光照条件、高动态环境、快速运动、强烈旋转和低纹理环境等重要障碍，首先，全局快门代替滚动快门是实现精确相机姿态估计的基础，像动态视觉传感器这样的事件相机每秒可以产生多达100万个事件，这对于高速和高动态范围的快速运动来说已经足够了。其次，使用语义特征，如边缘、平面、表面特征，甚至减少特征依赖，如跟踪接合边缘、直接跟踪或机器学习的组合可能成为更好的选择。三是基于SfM/SLAM的数学机制，最好使用精确的数学公式，使其性能更优。可以预见，SLAM的未来将是基于智能手机或无人机等嵌入式平台的，另一个方面就是3D场景重建，基于深度学习的场景理解。如何平衡实时性和准确性是一个重要的开放性问题，针对动态、非结构化、复杂、不确定和大规模环境的解决方案有待探索。（Simultaneous localization andmapping in the epoch of semantics: A survey. 2019） 多传感器融合 实际的机器人和硬件设备通常不只是携带一种传感器，通常是多种传感器的融合。例如，目前对手机VIO的研究将视觉信息和IMU信息结合起来，实现了两个传感器的互补优势，为SLAM的小型化和低成本提供了非常有效的解决方案。DeLS-3D是一个融合了摄像机视频、运动传感器(GPS/IMU)的传感器融合方案，以及一个3D的语义地图来达到系统的鲁棒性和效率。目前常用的有以下传感器，但不限于激光雷达，声纳，IMU，红外，相机，GPS，雷达等，传感器的选择取决于环境和所需的地图类型。 语义SLAM 事实上，人类识别物体的运动是基于感知，而不是图像的特征，在SLAM系统中，深度学习可以实现目标识别和分割，有助于SLAM系统更好地感知周围环境。语义SLAM对全局优化、回环检测以及重定位有一定的帮助。文献（ A unifying view of geometry, semantics, and data associationin slam. 2018）提出：传统的SLAM系统依赖几何特征（如点、线——PL-SLAM、StructSLAM和平面来推断环境结构）。在大规模场景中，高精度实时定位的目标可以通过语义SLAM来实现。 硬件和软件 SLAM不是一个算法，而是一个集成的、复杂的技术。它不仅依赖于软件，而且还依赖于硬件，未来的SLAM系统将侧重于算法和传感器的深度结合。基于以上的说明，该领域的特定处理器而不是通用的处理器，集成的传感器模块而不是单独的传感器就像照相机将显示出巨大的潜力。 6. 激光和视觉SLAM系统 6.1. 多传感器标定 相机和IMU： Kalibr（kalibr: Calibrating the extrinsics ofmultiple imus and of individual axes.）是一个用来解决以下标定问题的工具箱：多相机标定、视觉-惯性传感器标定（相机-IMU）以及旋转快门相机标定。 Vins-Fusion有在线空间校准和在线时间校准。 MSCKF-VIO有相机和IMU传感器之间的校准。 mc-VINS可以标定所有多相机和IMU之间的外参和时间偏移量。 另外，IMU-TK可以标定IMU的内参。 除此以外，文献（Selective sensor fusion forneural visual-inertial odometry 2019）提出了一个端到端的单目VIO网络，融合来自摄像头和IMU的数据。 相机和深度： BAD SLAM为这个任务提出一个使用同步全局快门、RGB和深度相机的计算基准。 相机之间： mcptam是一个使用多相机的SLAM系统，可以校准内部和外部参数。 MultiCol-SLAM是一个多鱼眼相机的SLAM系统。此外，升级版的SVO也支持多相机。 激光雷达和IMU： LIO-mapping介绍了一种紧耦合的Lidar-IMU融合方法。 Lidar-Align一种简单的方法来寻找三维激光雷达和6自由度姿态传感器之间的外参。 激光雷达的外部校准可参见（Extrinsic calibration of 2d laser rangefinders using an existingcuboid-shaped corridor as the reference 2018 / Extrinsiccalibration of 2d laser rangefinders based on a mobile sphere. 2018) 相机和激光雷达： 文献（Automatic onlinecalibration ofcameras and lasers. 2013）介绍了一种概率监测算法和一种连续校准优化器，实现了相机和激光雷达在线自动校准。 Lidar-Camera初步试验利用3D-3D点对相关性寻找激光雷达和相机之间的精确的刚体变换（外参）。 RegNet第一个利用(CNN)推导出多模态传感器之间的6个自由度的外参校准，并以激光雷达和单目摄像机为例进行了验证。 LIMO提出一种从激光雷达测量中提取深度的算法，用于相机特征跟踪和运动估计。 CalibNet一个自我监督的深度网络能够实时自动估计三维激光雷达和二维摄像机之间的6自由度刚体转换。 Autoware是一个可以标定激光和相机光束的标定工具。 其他工作如SVIn2展示了融合声呐、视觉、IMU、深度传感器的水下SLAM系统，基于OKVIS。文献（nvironment driven under-water camera-imu calibration for monocular visual-inertial slam. 2019）提出了一种新的水下摄像机-IMU标定模型，文献（Improving underwater obstacle detection using semanticimage segmentation.2019）利用语义图像分割来检测水下障碍物。WiFi-SLAM演示了一种名为WiFi的新型无线信号SLAM技术。文献（Leveraging mmwave imaging and communications for simul-taneous localization and mapping 2019）使用毫米波来定位NLOS机器人。KO-Fusion融合视觉和轮式里程计，文献（ Keyframe-based direct thermalinertial odometry 2019）在视觉退化的环境（如黑暗）中使用了热成像摄像机和IMU。 6.2. 激光雷达和视觉融合 硬件层：来自HESAI的Pandora是集成40线激光雷达的软硬件解决方案，5中彩色摄像机和识别算法。集成的解决方案可以使开发人员便于时间和空间上的同步问题。 数据层：激光雷达深度数据稀疏、精度高，而摄像机深度数据密集、精度低，这将可以实现基于图像的深度上采样。 文献（mage guided depth upsampling using anisotropictotal generalized variation.2013）提出了一种深度图上采样的方法。 文献（In defense of classicalimage processing: Fast depth completion on the cpu.2018）仅依靠基本的图像处理操作来完成激光雷达稀疏的深度数据补全。 在深度学习方面， 文献（Sparse-to-dense: Depth predictionfrom sparse depth samples and a single image2018）提出了使用一个深度回归网络直接从RGB-D原始数据中进行学习，并探讨了深度样本数量的影响。 文献（Sparsity invariant cnns. 2017）使用CNN对稀疏的输入进行操作，应用与对稀疏激光雷达扫描数据的深度数据补全。 DFuseNet提出了一种基于从高分辨率图像中提取的上下文线索来对稀疏的范围测量进行上采样的CNN网络。 LIC-Fusion融合IMU测量、稀疏视觉特征和提取激光雷达点。 任务层： 文献（Intersection safety using lidar and stereo vision sensors.2011）融合了立体相机和激光雷达进行感知。 文献（Multiple sensorfusion and classification for moving object detection and tracking.2015）融合了雷达、激光雷达和相机对运动物体进行检测和分类。 文献（Real-time depth enhancedmonocular odometry 2014）可以通过（RGB-D、和相机关联的激光雷达）的深度信息来增强VO，尽管这些信息是稀疏的。 V-Loam提出了一种结合视觉里程计和激光里程计的通用融合框架。在线的方法从视觉里程计和基于激光里程计的扫描匹配开始，同时运动估计和点云配准。 VI-SLAM考虑了结合精确激光里程计并使用视觉的环境识别进行回环检测。( Visual-LiDAR SLAM with loop closure.2018) 文献（Slam of robot based onthe fusion of vision and lidar.2018）目的是在SLAM的跟踪部分使用RGB-D相机和2D低成本激光雷达来完成鲁棒性的室内SLAM，基于模式转换和数据融合。 VIL-SLAM对（紧耦合的VIO）与激光雷达建图进行组合，并利用激光雷达提高视觉上的回环检测（Stereo visual inertial lidar simultaneous localization and mapping 2019）。 文献（Lidar-aided cam-era feature tracking and visual slam for spacecraft low-orbit navigationand planetary landing. 2015）结合了单目相机图片和激光距离测量使视觉SLAM系统消除尺度不确定性带来的误差。 在深度学习方面，许多方法来检测和识别融合的来自摄像机和激光雷达数据，如PointFusion、RoarNet、AVOD、MV3D、FuseNet。此外，文献（Deepcontinuous fusion for multi-sensor 3d object detection. 2018）利用端到端的学习架构以激光雷达和相机数据输入，获得了十分精确的定位性能表现。 6.3. 挑战和未来 数据关联：未来的SLAM必须集成多传感器，但是不同的传感器具有不同的数据类型、时间戳和坐标系统表达式，需要统一处理。此外，还需要考虑多传感器之间的物理模型建立、状态估计和优化问题。 硬件整合：目前，尚无合适的芯片和集成硬件使SLAM技术更容易成为产品。另一方面，如果传感器的准确性由于故障而下降，非正常条件，或老化，传感器测量的质量(如噪音、偏差)与噪声模型不匹配，那么鲁棒性和硬件的整合也要跟随。前端传感器应具备数据处理能力，从硬件层向算法层演进，再由功能层向软件开发工具包(SDK)进行应用。 协同：分散的视觉SLAM对于多机器人在绝对位置系统不可用的环境下十分有用。协同优化视觉多机器人SLAM需要分散数据和优化，这被称为协同。 高精地图：高清晰度地图对机器人（无人车）来说是至关重要的，但是哪种地图最适合机器人呢，密集地图或稀疏地图可以进行导航、定位和路径规划吗？一个相关的开放问题是长期建图需要多久更新一次地图上的信息，以及如何决定哪些信息是过时的需要被去除的。 适应性、鲁棒性、可伸缩性：当前还没有一个SLAM系统可以覆盖所有的场景。为了在给定的场景中正确工作，大多数都需要大量的参数调优。为了让机器人像人类一样感知，我们倾向于使用基于外观的方法，而不是基于特征的方法，这将有助于在白天和夜晚之间或不同季节之间形成语义信息的循环。 抗风险和约束的能力：完美的系统应该是故障安全的和故障感知的，这里不是关于重定位或者回环检测的问题。SLAM系统必须具备对风险或失败做出反应的能力，同时，一个理想的SLAM解决方案应该能够在不同的平台上运行，而不受到平台算力条件的限制。如何平衡准确性、鲁棒性和有限的资源是一个挑战性的问题。 应用：SLAM技术有着广泛的应用如：大范围的位置、导航、3D和语义地图的重建，环境识别和理解，地面机器人，无人机，VR、AR、MR、AGV，自动驾驶，虚拟装潢，虚拟室内拟合，沉浸式游戏，抗震救灾等。 开放问题：端到端学习会攻占SLAM吗？","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"线性方程组求解","slug":"utils/线性方程组求解","date":"2020-02-14T09:57:46.000Z","updated":"2020-02-15T03:30:23.000Z","comments":true,"path":"2020/02/14/utils/线性方程组求解/","link":"","permalink":"http://yoursite.com/2020/02/14/utils/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E6%B1%82%E8%A7%A3/","excerpt":"","text":"1. 线性方程组求解的直观感受 1.1. 非齐次线性方程组 求解下面的非齐次线性方程组 \\[ \\begin{cases} \\text{ } 2x_{1}+3x_{2}+x_{3}=2 \\\\ \\text{ } x_{1}-2x_{2}+2x_{3}=4 \\\\ \\text{ } 3x_{1}+x_{2}+3x_{3}=6 \\end{cases} \\] 1.1.1. 第一步：列出增广矩阵 \\[ \\begin{pmatrix} 2&amp; 3&amp; 1&amp; | 2 \\\\ 1&amp; -2&amp; 2&amp;|4 \\\\ 3&amp; 1&amp; 3&amp; |6 \\\\ \\end{pmatrix} \\] 1.1.2. 第二步:高斯消元,化成阶梯矩阵 1.1.2.1. 先把第2行换到第1行 \\[ \\begin{pmatrix} 1&amp; -2&amp; 2&amp;|4 \\\\ 2&amp; 3&amp; 1&amp; | 2 \\\\ 3&amp; 1&amp; 3&amp; |6\\\\ \\end{pmatrix} \\] #### 1.1.2.2. 第2行减第1行的2倍，第3行减第1行的3倍，得到 \\[ \\begin{pmatrix} 1&amp; -2&amp; 2&amp;|4 \\\\ 0&amp; 7&amp; -3&amp; | -6 \\\\ 0&amp; 7&amp; -3&amp; |-6\\\\ \\end{pmatrix} \\] #### 1.1.2.3. 第3行减第2行，得到 \\[ \\begin{pmatrix} 1&amp; -2&amp; 2&amp;|4 \\\\ 0&amp; 7&amp; -3&amp; | -6 \\\\ 0&amp; 0&amp; 0&amp; |0\\\\ \\end{pmatrix} \\] #### 1.1.2.4. 化简后的方程组，等于 \\[ \\begin{cases} 2x_{1}+3x_{2}+x_{3}=2 \\\\ 7x_{2}-3x_{3}=6 \\\\ 0x_{1}+0x_{2}+0x_{3}=0 \\\\ \\end{cases} \\] 这样，\\(x_2\\)可以通过\\(x_3\\)来表示，\\(x_1\\)也可以通过\\(x_3\\)来表示，这样\\(x_3\\)就叫做自由变量，\\(x_3\\)可以取任意值。所以\\(x_1\\),\\(x_2\\),\\(x_3\\)就有无穷多个解。 对于非齐次线性方程组, 对线性方程组进行初等变换（高斯消元法），化为最简型（阶梯形）矩阵, 得到如下结论 考查系数矩阵r(A)，增广矩阵r(A,b)，以及方程组未知数个数n 如果系数矩阵的秩r(A)小于增广矩阵的秩r(A,b)，r(A)&lt;r(A,b)，那么方程组无解 如果系统矩阵的秩小于方程组未知数个数但是等于増广矩阵的秩，r(A)=r(A,b)&lt;n，那么方程组有多个解 如果系统矩阵的秩等于方程组未知数个数，r(A)=r(A,b)=n，那么方程组有唯一解 1.2. 齐次方程组 \\[ \\begin{cases} \\text{ } 2x_{1}+3x_{2}+x_{3}=0 \\\\ \\text{ } x_{1}-2x_{2}+2x_{3}=0 \\\\ \\text{ } 3x_{1}+x_{2}+3x_{3}=0 \\\\ \\end{cases} \\] 齐次线性方程组，就是方程组的等式右边全部是0的方程组，只有系数矩阵，不需要增广矩阵，所以不会出现{0=d}形式的不相容方程。所以不会出现无解的情况，只需要考虑是多个解，还是唯一解。 对于齐次线性方程组， - 有多个解叫做有非零解。 - 唯一解叫做零解。 1.2.1. 判断零解 对于Ax=0的齐次线性方程组，列出其系数矩阵（不需要增广矩阵），使用高斯消元法化简，化为阶梯形矩阵，化简后，判断有效方程组个数(系数矩阵的秩)是否小于未知数个数 如果有效方程组个数小于未知数个数，叫做有非零解（多个解） 如果等于，叫做只有零解（唯一解） 直接判断系数矩阵的行列式 det A 判断detA，如果detA==0，则有非零解（无穷多个解） 判断detA，如果detA≠0，则只有零解（只有唯一解） 2. 线性方程组(更通用的定义) 2.1. 定义1: 线性方程组 \\[ \\begin{aligned} &amp;a_{11}x_1 + a_{12}x_2 + \\dots + a_{1n}x_n = b_1\\\\ &amp;a_{21}x_1 + a_{22}x_2 + \\dots + a_{2n}x_n = b_2\\\\ &amp;\\dots\\\\ &amp;a_{m1}x_1 + a_{m2}x_2 + \\dots + a_{mn}x_n = b_m\\\\ \\end{aligned} \\] 其中，矩阵 \\[ \\begin{aligned} A = \\left( \\begin{array}{ccc} a_{11} &amp; \\dots &amp; a_{1n}\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ a_{m1} &amp;\\dots &amp; a_{mn}\\\\ \\end{array} \\right) \\end{aligned} \\] 称为该线性方程组的系数矩阵，而所有满足这个方程组的\\(X = (x_1, \\dots, x_n)^T\\)的集合称为它的解集合 2.2. 定义2: 增广矩阵 上面线性方程组的系数矩阵如果加上右侧的\\((b_1, b_2, \\dots, b_n)^T\\), 就构成了该方程组的增广矩阵 \\[ \\begin{aligned} A = \\left( \\begin{array}{ccc|c} a_{11} &amp; \\dots &amp; a_{1n} &amp; b_1\\\\ \\vdots &amp; \\ddots &amp; &amp; \\vdots\\\\ a_{m1} &amp;\\dots &amp; a_{mn} &amp; b_n\\\\ \\end{array} \\right) \\end{aligned} \\] 2.3. 高斯消去法 消元法是最常用的解线性方程组的方法，核心在于对增广矩阵进行初等变换（即数乘，倍加和对调） (具体案例见上面例子) 2.4. 线性方程组解的结构 2.4.1. 有无解的判定 2.4.2. 齐次方程组解的结构 对于齐次线性方程组，任意解的线性组合还是解 2.4.3. 定义: 基础解系 (只有齐次方程组才有) 齐次线性方程组的一组解向量\\(\\eta_1, \\eta_2, \\dots, \\eta_t\\), 如果满足两个条件: - (1) \\(\\eta_1, \\eta_2, \\dots, \\eta_t\\)线性无关 (即其中任意一个向量不能被剩余的其他向量线性组合表示) - (2)若该齐次线性方程组的任何一个解都能表示成\\(\\eta_1, \\eta_2, \\dots, \\eta_t\\)的线性组合,那么称\\(\\eta_1, \\eta_2, \\dots, \\eta_t\\)为该方程组的基础解系 齐次线性方程组基础解系的解向量个数: \\[ n-r(A) \\] 其中,\\(n\\)是方程组未知数个数,\\(r(A)\\)是系数矩阵的秩 基础解析解向量个数&gt;=2, 若计算出来解向量只有1个的时候, 很有个可能这个方程组是非齐次线性方程组, 因为自由变量就有0和1两个选择, 至少会生成两个解向量 应用特性进行证明 题一 题二 2.4.4. 求基础解系步骤: 初等行变换, 将系数矩阵A化为阶梯型 得到的阶梯型系数矩阵的非零行数就是矩阵的秩序r(A) 把每个非零行最左端的非0系数对应的未知量\\(x_i\\)保留在等式左端, 其余\\(n-r\\)个未知量移到等式右端 再令右端的\\(n-r\\)个未知量的其中一个\\(x_{(n-r),k}\\)为1, 其余为0, 代入方程中计算出左侧未知量\\(x_i\\) 对步骤(4)进行\\(n-r\\)次操作, 就可以得到\\(n-r\\)个解向量\\(\\eta_j\\), 这些解向量共同构成基础解系 基础解系可以写成\\(k_1 \\eta_1+ k_2 \\eta_2 \\cdots +k_{n-r}\\eta_{n-r}\\) 例子1 例子2 例子3 2.4.5. 非齐次线性方程组解的结构 假定有非齐次方程组: \\[ \\begin{aligned} &amp;a_{11}x_1 + a_{12}x_2 + \\dots + a_{1n}x_n = b_1\\\\ &amp;a_{21}x_1 + a_{22}x_2 + \\dots + a_{2n}x_n = b_2\\\\ &amp;\\dots\\\\ &amp;a_{m1}x_1 + a_{m2}x_2 + \\dots + a_{mn}x_n = b_m\\\\ \\end{aligned} \\] 其中,方程组右侧\\(b_m\\)不全为0 2.4.5.1. 定义: 导出组 把非齐次线性方程组的等式右侧全部为0, 变成齐次方程组, 该齐次方程组也称为这个非线性方程组的导出组 \\[ \\begin{aligned} &amp;a_{11}x_1 + a_{12}x_2 + \\dots + a_{1n}x_n = 0\\\\ &amp;a_{21}x_1 + a_{22}x_2 + \\dots + a_{2n}x_n = 0\\\\ &amp;\\dots\\\\ &amp;a_{m1}x_1 + a_{m2}x_2 + \\dots + a_{mn}x_n = 0\\\\ \\end{aligned} \\] 2.4.5.2. 特点 非齐次线性方程组任意两个解的差是它的导出组的解, 根据线性性质, 方程组右侧等于\\([b-b]_{m \\times 1}=[0]_{m \\times 1}\\), 对应齐次线性方程组 非齐次线性方程组的任意解与它的导出组的和还是该非齐次线性方程组的解(很好理解,基本同上面一致) 2.4.5.3. 定理: 假设\\(\\gamma_0\\)是非齐次线性方程组的一个特解（符合方程条件的一个解就行），那么该非齐次线性方程组的任意一个解都可以表示成： \\[ \\begin{aligned} \\gamma = \\gamma_0 + k_1 \\eta_1 + k_2 \\eta_2 + \\dots + k_n \\eta_n \\end{aligned} \\] 其中,\\(k_1 \\eta_1 + k_2 \\eta_2 + \\dots + k_n \\eta_n\\)是导出组基础解系的线性组合 根据定理, 可以得到非齐次线性方程组有唯一解的条件：即它的导出组只有零解, 对应的是r(A)满秩 参考: 1. 线性方程组解的分析：唯一解，无穷多解以及无解 2. 线性方程组什么时候无解？多个解？唯一解？","categories":[{"name":"utils","slug":"utils","permalink":"http://yoursite.com/categories/utils/"}],"tags":[]},{"title":"第六讲_三角化","slug":"VIO/第六讲/第六讲-三角化","date":"2020-02-14T07:41:41.000Z","updated":"2020-03-04T15:44:06.000Z","comments":true,"path":"2020/02/14/VIO/第六讲/第六讲-三角化/","link":"","permalink":"http://yoursite.com/2020/02/14/VIO/%E7%AC%AC%E5%85%AD%E8%AE%B2/%E7%AC%AC%E5%85%AD%E8%AE%B2-%E4%B8%89%E8%A7%92%E5%8C%96/","excerpt":"","text":"三角化 当估计出相机运动之后, 需要利用相机运动估计出特征点的空间位置，三角测量（三角化）就是用来解决这个问题的。三角化主要是单目mono使用 image-20200214160321348 问题描述： ​ 现在假设有两帧图像，其中两帧图像(Frame1,Frame2)的特征点匹配已有，相机的相对运动T_{21}(从第一帧到第二帧的变换)也已经获得，如何求解出某个特征点的空间坐标（以第一帧的相机坐标系为参考）？ 假设： 在第一帧坐标系下的某个路标点\\(P\\in R^4\\)，(下式右侧) 已知相机的位姿\\(T_k=[R_k,t_k]\\)，也就是第一帧坐标系转换到第二帧坐标系的变换矩阵\\(T_{21}\\)或者说是\\(T_{CW}\\)(如果第一帧是初始化帧的话)。 利用相机的相对运动\\(T_{21}\\)(从第一帧到第二帧的变换)将路标点\\(P\\)投影到第二帧相机坐标系下，得到预测点的归一化平面坐标为\\(p_2=x_k=[u_k,v_k,1]^T\\)(下式左侧) 即： \\[ \\frac{1}{\\lambda_k}x_k= \\frac{1}{\\lambda_k} \\begin{bmatrix} u_k \\\\ v_k \\\\ 1 \\end{bmatrix}_{1:3} =\\bigg\\{ T_k \\begin{bmatrix} p_x \\\\ p_y \\\\ p_z \\\\ 1 \\end{bmatrix}\\bigg\\}_{1:3} = \\bigg\\{ \\begin{bmatrix} R_{k,3\\times 3} &amp; t_k \\\\ 0 &amp; I \\end{bmatrix} \\begin{bmatrix} p_x \\\\ p_y \\\\ p_z \\\\ 1 \\end{bmatrix} \\bigg\\}_{1:3} \\] 其中，\\(\\lambda_k\\)是逆深度，也就是\\(\\frac{1}{z_k}\\) 问题是：如何求解上式右侧的第一帧坐标系下的某个路标点\\(P\\) ？ 根据上式子的第三行，可以得到 \\[ \\frac{1}{\\lambda_k}=T_{k,3}^T P= \\begin{bmatrix} R_{k,3} &amp; t_{k,3} \\end{bmatrix}_{1\\times4} \\begin{bmatrix} p_x \\\\ p_y \\\\ p_z \\\\ 1 \\end{bmatrix} \\] 将（1）的前两行中的逆深度\\(\\frac{1}{\\lambda_k}\\)用上式等号右侧替换，得到 \\[ T_{k,3}^T P u_k = T_{k,1}^T P \\\\ T_{k,3}^T P v_k = T_{k,2}^T P \\] 于是，一帧就可以得到两个这样的方程，当有两帧或以上时，则： \\[ \\begin{bmatrix} T_{1,3}^T u_1 - T_{1,1} \\\\ T_{1,3}^T v_1 - T_{1,2} \\\\ \\vdots \\\\ T_{n,3}^T u_1 - T_{n,1} \\\\ T_{n,3}^T v_1 - T_{n,2} \\\\ \\end{bmatrix} y = 0 \\Longrightarrow Dy=0 \\] 于是，把问题转化为求线性方程组的问题。 当观测次数&gt;=2时，即有多帧观测到同一个路标点\\(P\\)，且这些帧对应的相机位姿已经知道的时候，由于各种测量噪声的影响，（投影回去的点并不是同一点），方程组的系数矩阵D很有可能满秩，（齐次线性方程组有唯一解），那么这个方程组就只有零解 于是，通常使用SVD分解来求这个方程组的最小二乘解 \\[ \\min_y || Dy ||_2^2 \\] 其中， \\[ ||y||=1 \\] 求解方法：对\\(D^TD\\)进行SVD分解，得到 \\[ \\begin{aligned} D^TD &amp;=U \\Sigma V^T = \\sum_{i=1}^{4} \\sigma_{i}^2 u_i u_j^T \\notag \\\\ &amp;= \\begin{bmatrix} u_{1,4 \\times 1} &amp; u_{2} &amp; u_{3} &amp; u_{4} \\end{bmatrix}_{4 \\times 4} \\begin{bmatrix} \\sigma_1^2 &amp; 0 &amp; 0 &amp;0 \\\\ 0 &amp; \\sigma_2^2 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\sigma_3^2 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\sigma_4^2 \\end{bmatrix} \\begin{bmatrix} u_{1,4 \\times 1}^T \\\\ u_{2}^T \\\\ u_{3}^T \\\\ u_{4}^T \\end{bmatrix}_{4 \\times 4} \\end{aligned} \\] 其中，\\(u_1,u_2,u_3,u_4\\)都是SVD分解产生的相互正交的单位向量，\\(y\\)也是单位向量 现在，回到要求解的问题上，即最小化目标函数： \\[ \\min_y ||Dy||_2^2=(Dy)^T(Dy)=y^TD^TDy \\] \\(y\\)可以有\\(D^TD\\)分解之后的空间向量\\(u_i\\)经过线性组合得到，即 \\[ y=\\sum_{i}^4 k_i u_i= u_m+v \\] 其中，\\(u_m\\)为任意的\\(D^TD\\)分解之后的空间向量\\(u_i\\)，另外\\(v\\)与\\(u_m\\)相互正交，即有： \\[ v=\\sum_{j,j\\neq u}^4 k_j u_j \\] 假设\\(u_m=u_4\\)，将\\(y\\)代入目标函数，得到 \\[ \\begin{aligned} \\min_y ||Dy||_2^2 &amp;=y^TD^TDy=(u_m+v)^T D^TD(u_m+v) \\notag \\\\ &amp;= [u_m+v]^T_{1 \\times 4} ~ \\begin{bmatrix} u_{1} &amp; u_{2} &amp; u_{3} &amp; u_{4} \\end{bmatrix}_{4 \\times 4} \\begin{bmatrix} \\sigma_1^2 &amp; 0 &amp; 0 &amp;0 \\\\ 0 &amp; \\sigma_2^2 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\sigma_3^2 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\sigma_4^2 \\end{bmatrix} \\begin{bmatrix} u_{1}^T \\\\ u_{2}^T \\\\ u_{3}^T \\\\ u_{4}^T \\end{bmatrix}_{4 \\times 4} [u_m+v]_{4 \\times 1} \\notag \\\\ &amp;= \\begin{bmatrix} v^Tu_1 &amp; v^Tu_2 &amp; v^Tu_3 &amp; u_4^T u_4 \\end{bmatrix} \\begin{bmatrix} \\sigma_1^2 &amp; 0 &amp; 0 &amp;0 \\\\ 0 &amp; \\sigma_2^2 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\sigma_3^2 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\sigma_4^2 \\end{bmatrix} \\begin{bmatrix} u_1^Tv \\\\ u_2^Tv \\\\ u_3^Tv \\\\ u_4^Tu_4 \\end{bmatrix} \\notag \\\\ &amp;= \\sigma_1^2v^Tu_1u_1^Tv+ \\sigma_2^2v^Tu_2u_2^Tv+ \\sigma_3^2v^Tu_3u_3^Tv+ \\sigma_4^2u_4^Tu_4u_4^Tu_4 \\notag \\\\ &amp;= (\\sigma_1^2+\\sigma_2^2+\\sigma_3^2)v^Tv+\\sigma_4^2 \\end{aligned} \\] 同理，当\\(u_m=u_1\\)时 \\[ y^TD^TDy=(\\sigma_4^2+\\sigma_2^2+\\sigma_3^2)v^Tv+\\sigma_1^2 \\] 当\\(u_m=u_2\\)时 \\[ y^TD^TDy=(\\sigma_1^2+\\sigma_4^2+\\sigma_3^2)v^Tv+\\sigma_2^2 \\] 当\\(u_m=u_3\\)时 \\[ y^TD^TDy=(\\sigma_1^2+\\sigma_2^2+\\sigma_4^2)v^Tv+\\sigma_3^2 \\] 当且仅当\\(u_m=u_4\\)且\\(v=0\\)时，目标函数\\(y^TD^TDy\\)取最小值\\(\\sigma_4^2\\) 综上，当\\(y\\)等于奇异值向量\\(u_4\\)时，为最小二乘解。 另外，\\(y\\)是单位向量，需要进行scale把z值恢复到相机坐标系z=1的归一化平面，此时即可得到对应的坐标P 或者, 如果需要恢复完整的点P而不是归一化到z=1平面上的点, 那么可以进行scale, 对\\(y\\)向量的齐次化维, 即第4维进行归一化, 即可得到真正的点P \\[ P= \\frac{y_{1:4}}{y[4]} = \\begin{bmatrix} y_1/y_4 \\\\ y_2/y_4 \\\\ y_3/y_4 \\\\ y_4/y_4 \\end{bmatrix} = \\begin{bmatrix} P_x \\\\ P_y \\\\ P_z \\\\ 1 \\end{bmatrix} \\] 相关代码 代码之前, 有一些细节需要注意: 结论: \\(\\color{red}{t_{cw} \\neq -t_{wc}}\\) , 之间还差了一个旋转变换 若已知从相机坐标系到世界坐标系的变换\\(T_{wc}=[R_{wc},t_{wc}]\\) 则有相机坐标系的点转换到世界坐标系的转换\\(P_{w}=R_{wc}P_c + t_{wc}\\) 那么从世界坐标系到相机坐标系的变换\\(T_{cw}=[R_{cw} , t_{cw}]=[R_{wc}^T,-R_{wc}^T t_{wc}]\\) , 原因是, 根据上面\"相机坐标系到世界坐标系的转换 \", 反推出世界坐标系到相机坐标系的转换 \\(P_{c}=R_{wc}^{-1}( P_w - t_{wc})=R_{cw}( P_w - t_{wc})\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//// Created by hyj on 18-11-11.//#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;random&gt; #include &lt;Eigen/Core&gt;#include &lt;Eigen/Geometry&gt;#include &lt;Eigen/Eigenvalues&gt;#include &lt;Eigen/Jacobi&gt;#include &lt;Eigen/SVD&gt;struct Pose&#123; Pose(Eigen::Matrix3d R, Eigen::Vector3d t):Rwc(R),qwc(R),twc(t) &#123;&#125;; Eigen::Matrix3d Rwc; Eigen::Quaterniond qwc; Eigen::Vector3d twc; Eigen::Vector2d uv; // 这帧图像观测到的特征坐标&#125;;int main()&#123; int poseNums = 10; double radius = 8; double fx = 1.; double fy = 1.; std::vector&lt;Pose&gt; camera_pose; for(int n = 0; n &lt; poseNums; ++n ) &#123; double theta = n * 2 * M_PI / ( poseNums * 4); // 1/4 圆弧 // 绕 z轴 旋转 Eigen::Matrix3d R; R = Eigen::AngleAxisd(theta, Eigen::Vector3d::UnitZ()); Eigen::Vector3d t = Eigen::Vector3d(radius * cos(theta) - radius, radius * sin(theta), 1 * sin(2 * theta)); camera_pose.push_back(Pose(R,t)); &#125; // 随机数生成 1 个 三维特征点 std::default_random_engine generator; std::uniform_real_distribution&lt;double&gt; xy_rand(-4, 4.0); std::uniform_real_distribution&lt;double&gt; z_rand(8., 10.); double tx = xy_rand(generator); double ty = xy_rand(generator); double tz = z_rand(generator); Eigen::Vector3d Pw(tx, ty, tz); // 这个特征从第三帧相机开始被观测，i=3 int start_frame_id = 3; int end_frame_id = poseNums; for (int i = start_frame_id; i &lt; end_frame_id; ++i) &#123; Eigen::Matrix3d Rcw = camera_pose[i].Rwc.transpose(); //注意这里, // pose结构体里面关于相机位姿它这里并不是world-&gt;camera, 而是camera-&gt;world // 而实际的投影应该是 Pc= Rcw*Pw + tcw // 但是仅有的参数只有 Rwc 和 twc // 从等式 Pw= Rwc*Pc + twc // 可以得到 Pc= Rcw*Pc + tcw = Rwc*Pc -Rwc*twc // 所以,从世界坐标系到相机坐标系的平移量 tcw= -Rwc*twc Eigen::Vector3d Pc = Rcw * (Pw - camera_pose[i].twc); double x = Pc.x(); double y = Pc.y(); double z = Pc.z(); camera_pose[i].uv = Eigen::Vector2d(x/z,y/z); &#125; /// TODO::homework; 请完成三角化估计深度的代码 // 遍历所有的观测数据，并三角化 Eigen::Vector3d P_est; // 结果保存到这个变量 P_est.setZero(); /* your code begin */ //构造系数矩阵D Eigen::MatrixXd D(2*(camera_pose.size()-start_frame_id),4); for (int i=start_frame_id;i&lt;camera_pose.size();i++) &#123; Eigen::Isometry3d T_i=Eigen::Isometry3d::Identity(); T_i.rotate(camera_pose[i].Rwc.transpose()); //从世界坐标系到相机坐标系的平移量 tcw= -Rwc*twc T_i.pretranslate(-camera_pose[i].Rwc.transpose()*camera_pose[i].twc); D.row(2*(i-start_frame_id))=T_i.matrix().row(2)*camera_pose[i].uv[0]-T_i.matrix().row(0); D.row(2*(i-start_frame_id)+1)=T_i.matrix().row(2)*camera_pose[i].uv[1]-T_i.matrix().row(1); &#125; std::cout&lt;&lt;D&lt;&lt;std::endl; //对D^TD进行SVD分解 Eigen::JacobiSVD&lt;Eigen::MatrixXd&gt; svd(D.transpose()*D, Eigen::ComputeThinU | Eigen::ComputeThinV); Eigen:: MatrixXd U = svd.matrixU(); Eigen:: MatrixXd V = svd.matrixV(); Eigen:: MatrixXd A = svd.singularValues(); P_est=U.col(3).head(3); //std::cout&lt;&lt;U.col(3).norm()&lt;&lt;std::endl; P_est /= U.col(3)[3]; Eigen:: VectorXd b(2*(camera_pose.size()-start_frame_id)); b.setZero(); Eigen::Vector4d result; result=D.jacobiSvd(Eigen::ComputeThinU | Eigen::ComputeThinV).solve(b); std::cout&lt;&lt;result.transpose()&lt;&lt;std::endl; /* your code end */ std::cout &lt;&lt;\"ground truth: \\n\"&lt;&lt; Pw.transpose() &lt;&lt;std::endl; std::cout &lt;&lt;\"your result: \\n\"&lt;&lt; P_est.transpose() &lt;&lt;std::endl; return 0;&#125;","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第六讲","slug":"VIO/第六讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E5%85%AD%E8%AE%B2/"}],"tags":[]},{"title":"第四讲(下)_基于滑动窗口算法的VIO系统","slug":"VIO/第四讲/第四讲(下)_基于滑动窗口算法的VIO","date":"2020-02-14T07:11:11.000Z","updated":"2020-03-01T10:20:11.000Z","comments":true,"path":"2020/02/14/VIO/第四讲/第四讲(下)_基于滑动窗口算法的VIO/","link":"","permalink":"http://yoursite.com/2020/02/14/VIO/%E7%AC%AC%E5%9B%9B%E8%AE%B2/%E7%AC%AC%E5%9B%9B%E8%AE%B2(%E4%B8%8B)_%E5%9F%BA%E4%BA%8E%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%AE%97%E6%B3%95%E7%9A%84VIO/","excerpt":"","text":"1. 第四讲(下)_基于滑动窗口算法的VIO系统 1.1. 滑动窗口算法 1.1.1. 图的表示 解释: (假设矩阵左上角元素索引(1,1)) 1. \\(\\Lambda_1\\): (1,2)元素不为空, 表示第1个顶点与第2个顶点之间的残差\\(r_{12}\\)与顶点1\\2有关系 2. \\(\\Lambda_2\\): (1,3)元素不为空, 表示第1个顶点与第3个顶点之间的残差\\(r_{13}\\)与顶点1\\3有关系 3. 这部分可以参考&lt;&gt; 1.1.2. 基于边际概率的滑动窗口算法 根据第四讲(上)部分的叙述, 由于我们只有信息矩阵的数值形式, 但是没有各个状态量\\(x_1,x_2,x_3\\)各自相关的项的区分, 因此老的变量移除就涉及到边际概率信息矩阵的计算. 解释: 1. 在丢弃之前, 顶点2,3,4,5都只与顶点1相连 2. 丢弃顶点1之后, 利用边际概率方法更新信息矩阵, 更新之后的信息矩阵所对应的图表示: 丢弃顶点1之后, 顶点2,3,4,5之间相互连接起来了. 3. 总结: 当给定顶点1的情况下时, 顶点2,3,4,5之间是条件独立的, 当顶点1这个条件去掉之后, 顶点2,3,4,5又相互关联了. 1.1.3. 滑动窗口中的FEJ算法 1.1.3.1. 加入一个新的变量 解释: * 就是说, 如果没有进行marg的情况时, 求解过程中的信息矩阵\\(\\Lambda\\)是不满秩的, 此时系统可以有多个满足最小化损失函数的解\\(x\\) \\(\\color{red}{造成的问题就是:}\\) 对于 SLAM 系统而言(如单目 VO), 把原本多个解的问题变成只有一个确定的解 1.1.3.2. 可观性 1.1.3.3. 举例 解释: 单目SLAM: 就是说测量到的姿态和位置都是相对于某个坐标系的, 如果这个坐标系没有固定下来, 那么可以对(姿态,位置以及路标点landmark坐标)都乘以某个变换矩阵\\(T\\), 而残差函数\\(e\\)的值并不改变. 单目+IMU: IMU根据重力可以获取两个绝对的值:roll和pitch, 这两个值是相对于固定的坐标系的, 如东北天导航系. 另外, 由于IMU的测量信息, 把尺度的不确定性也消除了, 使得尺度因子变成可观. 最后: yaw角与重力没有关系, 没有了绝对的观测, 3维的位置也没有像GPS那样的绝对观测, 这4个自由度是不可观的, 即存在不确定性(最终的结果是一个相对的值而不是绝对的值). 1.1.3.4. 滑动窗口中出现的零空间问题 作业 1. 画出相机变量\\(\\xi_1\\)被marg之后的信息矩阵 2. 画出相机变量\\(\\xi_2\\)被marg之后的信息矩阵 (不知道是不是这样做?) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192//// Created by hyj on 18-11-11.//#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;random&gt; #include &lt;Eigen/Core&gt;#include &lt;Eigen/Geometry&gt;#include &lt;Eigen/Eigenvalues&gt;struct Pose //姿态结构体&#123; Pose(Eigen::Matrix3d R, Eigen::Vector3d t):Rwc(R),qwc(R),twc(t) &#123;&#125;; Eigen::Matrix3d Rwc; Eigen::Quaterniond qwc; Eigen::Vector3d twc;&#125;;int main()&#123; int featureNums = 20; //特征点数 int poseNums = 10; //姿态数 int diem = poseNums * 6 + featureNums * 3; //待优化变量总维度 double fx = 1.; double fy = 1.; Eigen::MatrixXd H(diem,diem); H.setZero(); std::vector&lt;Pose&gt; camera_pose; double radius = 8; for(int n = 0; n &lt; poseNums; ++n ) &#123; double theta = n * 2 * M_PI / ( poseNums * 4); // 总共旋转:1/4 圆弧 // 绕 z轴 旋转 Eigen::Matrix3d R; R = Eigen::AngleAxisd(theta, Eigen::Vector3d::UnitZ()); Eigen::Vector3d t = Eigen::Vector3d(radius * cos(theta) - radius, radius * sin(theta), 1 * sin(2 * theta)); camera_pose.push_back(Pose(R,t)); &#125; // 随机数生成三维特征点 std::default_random_engine generator; std::vector&lt;Eigen::Vector3d&gt; points; for(int j = 0; j &lt; featureNums; ++j) &#123; std::uniform_real_distribution&lt;double&gt; xy_rand(-4, 4.0); std::uniform_real_distribution&lt;double&gt; z_rand(8., 10.); double tx = xy_rand(generator); double ty = xy_rand(generator); double tz = z_rand(generator); //生成世界坐标系下的点 Eigen::Vector3d Pw(tx, ty, tz); points.push_back(Pw); for (int i = 0; i &lt; poseNums; ++i) &#123; // 世界坐标系的点转换到相机坐标系下 Eigen::Matrix3d Rcw = camera_pose[i].Rwc.transpose(); Eigen::Vector3d Pc = Rcw * (Pw - camera_pose[i].twc); //Pw= Rwc*pc + twc ==&gt; pc= Rcw(Pw-twc) double x = Pc.x(); double y = Pc.y(); double z = Pc.z(); double z_2 = z * z; /// 两个优化变量分别是位姿和世界坐标系3D点(路标) /// 因此,需要求误差e分别对 位姿6维 和 世界坐标系3D点求偏导 Eigen::Matrix&lt;double,2,3&gt; jacobian_uv_Pc; //这里只是图像点(u,v)对相机坐标系下3D点(x,y,z)求导 jacobian_uv_Pc&lt;&lt; fx/z, 0 , -x * fx/z_2, 0, fy/z, -y * fy/z_2; // 这里用了链式求导法则来求对世界坐标系3D点求偏导 Eigen::Matrix&lt;double,2,3&gt; jacobian_Pj = jacobian_uv_Pc * Rcw; //实际需要的是 图像点(u,v)对世界坐标系下3D点求导 Eigen::Matrix&lt;double,2,6&gt; jacobian_Ti; //图像点(u,v)对姿态6维求偏导,旋转在前,平移在后,推导见&lt;视觉SLAM第二版&gt;P187 jacobian_Ti &lt;&lt; -x* y * fx/z_2, (1+ x*x/z_2)*fx, -y/z*fx, fx/z, 0 , -x * fx/z_2, -(1+y*y/z_2)*fy, x*y/z_2 * fy, x/z * fy, 0,fy/z, -y * fy/z_2; /// 请补充完整作业信息矩阵块的计算 // H.block(j*3 + 6*poseNums,j*3 + 6*poseNums,3,3) +=????? // H.block(i*6,j*3 + 6*poseNums, 6,3) += ???; H.block(i*6,i*6,6,6) += jacobian_Ti.transpose() * jacobian_Ti; //左上角矩阵块 H.block(j*3 + 6*poseNums,j*3 + 6*poseNums,3,3) +=jacobian_Pj.transpose()*jacobian_Pj; //右下角矩阵块 H.block(i*6,j*3 + 6*poseNums, 6,3) += jacobian_Ti.transpose()*jacobian_Pj; //右上角矩阵块 H.block(j*3 + 6*poseNums,i*6 , 3,6) += jacobian_Pj.transpose() * jacobian_Ti; //左下角矩阵块 &#125; &#125;// std::cout &lt;&lt; H &lt;&lt; std::endl;// Eigen::SelfAdjointEigenSolver&lt;Eigen::MatrixXd&gt; saes(H);// std::cout &lt;&lt; saes.eigenvalues() &lt;&lt;std::endl; Eigen::JacobiSVD&lt;Eigen::MatrixXd&gt; svd(H, Eigen::ComputeThinU | Eigen::ComputeThinV); std::cout &lt;&lt; svd.singularValues() &lt;&lt;std::endl; return 0;&#125;","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第四讲","slug":"VIO/第四讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E5%9B%9B%E8%AE%B2/"}],"tags":[]},{"title":"第四讲(上)_基于滑动窗口算法的VIO系统原理","slug":"VIO/第四讲/第四讲(上)_基于滑动窗口算法的VIO","date":"2020-02-14T07:11:11.000Z","updated":"2020-03-01T10:19:30.000Z","comments":true,"path":"2020/02/14/VIO/第四讲/第四讲(上)_基于滑动窗口算法的VIO/","link":"","permalink":"http://yoursite.com/2020/02/14/VIO/%E7%AC%AC%E5%9B%9B%E8%AE%B2/%E7%AC%AC%E5%9B%9B%E8%AE%B2(%E4%B8%8A)_%E5%9F%BA%E4%BA%8E%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%AE%97%E6%B3%95%E7%9A%84VIO/","excerpt":"","text":"1. 第四讲(上)_基于滑动窗口算法的VIO系统原理 1.1. 高斯分布到信息矩阵 1.1.1. SLAM问题的模型 1.1.2. 举例 上面省略了一些步骤 \\[ \\begin{aligned} \\sum_{11}=Conv(x_1,x_1)=E([x_1-E(x_1)]^2) \\end{aligned} \\] 又因为: \\[ E(x_1)=E(w_1 v_2+v_1)=w_1 E(v_2)+E(v_1) \\] 且\\(v_1\\)和\\(v_2\\)都是0均值正态分布,所以 \\[E(x_1)=E(w_1 v_2+v_1)=w_1 E(v_2)+E(v_1)=0\\] 所以: \\[\\sum_{11}=Conv(x_1,x_1)=E([x_1-E(x_1)]^2)=E([x_1]^2)\\] 最终: \\[ \\begin{aligned} \\sum_{11}=Conv(x_1,x_1)&amp;=E([x_1-E(x_1)]^2) \\\\ &amp;=E([x_1]) \\\\ &amp;=w_1^2E(v_2^2)+2w_1E(v_1v_2)+E(v_1^2) \\\\ &amp;=w_1^2[E(v_2^2)-E(v_2)^2]+0+[E(v_1^2)-E(v_1)^2] \\\\ &amp;=w_1^2\\sigma_2^2+\\sigma_1^2 \\end{aligned} \\] 下面是关于期望: 协方差矩阵 以上参考自: * 期望、方差计算 * 协方差矩阵介绍 注意: * 上面的\\(\\color{red}{p(x_1,x_2,x_3)=p(x_2)p(x_1|x_2)p(x_3|x_2)}\\)是与给出的例子结合起来的, 例子是有室外的温度(即变量\\(x_2\\)), 而房间1和房间3的温度是分别仅与室外温度\\(x_2\\)相关. 一些特性 1. 如果协方差矩阵中,非对角元素\\(\\sum_{ij}&gt;0\\)表示两个变量正相关. 2. 在信息矩阵(协方差矩阵的逆)中,对应的非对角元素\\(\\sum_{ij}&lt;0\\)或\\(\\sum_{ij}=0\\). 如\\(\\Lambda_{12}&lt;0\\)则表示在变量\\(x_3\\)发生(确定)的条件下,元素\\(x_1\\)和\\(x_2\\)是正相关的. 注意: * 上面的\\(\\color{red}{p(x_1,x_2,x_3)=p(x_1)p(x_3)p(x_2|x_1,x_2)}\\)是与给出的例子2结合起来的, 例子2是变量\\(x_2\\)由\\(x_1,x_3\\)共同给出 注意: * 去除一个变量, 实际上就是将该变量所携带的信息转化为剩余变量的先验 ------------------------------------------------- 1.2. 舒尔补应用:边际概率,条件概率 这里可以往回看一下多元高斯分布,上几页ppt 解释: 1. 对\\(x=[a,b]^T\\)里面的变量\\(a\\)进行边际概率, 即把变量\\(b\\)去掉的时候, \\(a\\)的分布正比于\\(\\exp(-\\frac{1}{2}a^T A^{-1} a)\\), 也就是服从均值为0, 方差为A的正态分布 2. 此时的边际概率\\(P(a)\\)的协方差就是多元变量x的协方差矩阵\\(K\\)中的矩阵块, 在这个例子中就是矩阵块\\(A\\) \\[ K= \\begin{bmatrix} A &amp; C^T \\\\ C &amp; D \\end{bmatrix} \\] 3. 对应的关于条件概率\\(P(b|a)\\)则服从均值为\\(A^{-1}C^Tb\\), 方差为变量a的舒尔补\\(\\Delta_A\\)的正态分布. 解释: 1. 就是说,在SLAM问题里面,我们直接操作的只有多元变量\\(x=[a,b]^T\\)的信息矩阵(注意,是信息矩阵,不是协方差矩阵) \\[ K^{-1}= \\begin{bmatrix} A &amp; C^T \\\\ C &amp; D \\end{bmatrix} ^{-1} \\] 2. 根据公式(29), 即我们只有这样一个形式的信息矩阵: \\[ \\begin{aligned} K^{-1} &amp;= \\begin{bmatrix} A^{-1}+A^{-1}C^T \\Delta_{A}^{-1} C A^{-1} &amp; -A^{-1}C^T\\Delta_{A}^{-1} \\\\ -\\Delta_{A}^{-1} C A^{-1} &amp; \\Delta_{A}^{-1} \\end{bmatrix} \\end{aligned} \\] 3. 需要从上面形式的信息矩阵中恢复出变量\\(a\\)的信息矩阵,即矩阵\\(A^{-1}\\),则可利用公式(38) 注意: 1. 对某个多元高斯分布\\(P(a,b)\\)进行分解,可分解为: * \\(P(a,b)=P(a|b)P(a)\\): 这种情况就是不再关注变量b, 而边际分布\\(P(a)\\)的信息矩阵包含了就是把变量\\(b\\)所携带的信息, 就是说此时\\(P(a)\\)分布是包含了变量\\(b\\)信息的先验. (适用于去掉变量b) * \\(P(a,b)=P(b|a)P(b)\\): 这种情况就是不再关注变量a, 二边际分布\\(P(b)\\)的信息矩阵包含了就是把变量\\(a\\)所携带的信息, 就是说此时\\(P(b)\\)分布是包含了变量\\(a\\)信息的先验. (适用于去掉变量a) 解释: 1. 回顾例子(1),有3个变量\\(x_1,x_2,x_3\\), 如果去掉变量\\(x_3\\), 对应的信息矩阵就是原来信息矩阵中关于变量\\(x_3\\)的项全部消掉, 由于实际操作中并没有颜色标记, 所以应用了舒尔补公式来进行这个消掉\\(x_3\\)相关项的操作. 2. 具体操作就是:把\\((x_1,x_2)\\)看做是上面多元高斯分布\\(x=[a,b]^T\\)里面的\\(a\\), 把\\(x_3\\)看做是\\(b\\), 可以看到, b边缘化之后的分布(即边际概率)\\(P(x_1,x_2)\\)对应的信息矩阵可以用公式(38)得到. \\[ \\begin{aligned} P(x_1,x_2,x_3)=P(x_1,x_2)P(x_3|x_1,x_2) \\end{aligned} \\] 最终要保留的变量\\((x_1,x_2)\\)所对应的原信息矩阵子块就是\\(\\Lambda_{aa}\\), 消掉某个变量(\\(x_3\\))之后, 变量\\((x_1,x_2)\\)最终的信息矩阵由式(38)来计算. 换句话说: 当最终要保留的变量是\\((x_2,x_3)\\), 而要消掉的变量是\\(x_1\\)时, 变量\\((x_2,x_3)\\)在原信息矩阵\\(K^{-1}\\)所对应的矩阵子块为右下角的部分, 即原信息矩阵的右下角子块才是\\(\\Lambda_{aa}\\) 作业 1. 画出相机变量\\(\\xi_1\\)被marg之后的信息矩阵 2. 画出相机变量\\(\\xi_2\\)被marg之后的信息矩阵","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第四讲","slug":"VIO/第四讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E5%9B%9B%E8%AE%B2/"}],"tags":[]},{"title":"第四讲(拓展)_高斯过程(边缘化与条件作用)","slug":"VIO/第四讲/第四讲(拓展)_高斯过程(边缘化与条件作用)","date":"2020-02-14T07:11:11.000Z","updated":"2020-03-01T10:19:54.000Z","comments":true,"path":"2020/02/14/VIO/第四讲/第四讲(拓展)_高斯过程(边缘化与条件作用)/","link":"","permalink":"http://yoursite.com/2020/02/14/VIO/%E7%AC%AC%E5%9B%9B%E8%AE%B2/%E7%AC%AC%E5%9B%9B%E8%AE%B2(%E6%8B%93%E5%B1%95)_%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B(%E8%BE%B9%E7%BC%98%E5%8C%96%E4%B8%8E%E6%9D%A1%E4%BB%B6%E4%BD%9C%E7%94%A8)/","excerpt":"","text":"1. 高斯过程(边缘化与条件作用) 1.1. 高斯过程的直观解释 1.1.1. 多元高斯分布 高斯分布（也叫做正态分布）是高斯过程的基础构件。而我们最感兴趣的是多元高斯分布，其每个随机变量都呈正态分布，联合分布也是高斯的。一般来说，多元高斯分布由均值向量\\(\\mu\\)和协方差矩阵\\(\\sum\\)定义。 均值向量\\(\\mu\\)描述了该分布的期望值，它的每个组件描述了对应维度的均值 协方差矩阵\\(\\sum\\)对每个维度的方差进行建模，并确定不同随机变量之间的关联(协方差矩阵总是对称且半正定的) Σ 的对角线由第\\(i\\)个随机变量的标准差\\(\\sigma_i\\) 组成，而非对角线的元素则描述了每个元素\\(\\sigma_{ij}\\)之间的相关性 \\(X\\)符合正态分布。协方差矩阵协方差矩阵\\(\\sum\\)描述了该分布的形状 1.1.1.1. 二元高斯分布 从图形上来看，该分布以均值为中心，由协方差矩阵决定其形状。下图展示了这些参数对于一个二维高斯分布的影响。每个随机变量的标准差在协方差矩阵的对角线上，而其它的值则显示了它们之间的协方差。 高斯分布被广泛应用于为真实世界建模，有时在原分布未知的情况下作为替代品，有时用于中心极限定理。接下来我们会进一步讲解如何操纵高斯分布，以及如何从中获得有用的信息。 1.1.2. 边缘化与条件作用 高斯分布有一个很赞的代数性质：它在条件作用和边缘化情况下是封闭的。意思是，经过这些运算后，在结果中得到的分布依旧是高斯分布，这就使得很多统计学和机器学习中的问题变得易解。 边缘化: 对高斯分布进行边缘化和条件作用进行分解, 即\\(P(X,Y)=P(X)P(Y|X)=P(Y)P(X|Y)\\): 其中 X 和 Y 代表原始随机变量的子集。 给定随机变量 X 和 Y 组成的向量的正态概率分布\\(P(X,Y)\\), 我们可以用以下方法确定每个变量各自的边缘概率分布: 这个公式所表达的意思很直接了当：X 和 Y 这两个子集各自只依赖于它们 μ 和 Σ 中对应的值。因此，要从高斯分布中边缘化一个随机变量，我们只需把μ 和Σ里那些对应的变量丢掉就行。 通过边缘化，我们可以获取多元概率分布的一部分信息(这里对y进行边缘化,去掉变量y,得到关于x的边缘分布): \\[ \\begin{aligned} p_X(x)=\\int_y p_{X,Y}(x,y)dy&amp;= \\int_y p_{Y|X}(y|x)p_X(x)dy \\\\ &amp;= p_X(x)\\int_y p_{Y|X}(y|x)dy \\\\ &amp;=p_X(x) \\end{aligned} \\] 上式子的意思是: 如果我们只想考虑X=x的情况, 即只对X=x的概率感兴趣, 那么我们要考虑变量Y所有可能的值, 需要对变量Y进行积分.(下面有图) 条件作用 高斯过程的另一个重要运算是条件作用，它可以用于得到一个变量在另一个变量条件下的概率分布。和边缘化类似，这个运算也是封闭的，会得到一个不同的高斯分布。条件运算是高斯过程的基石，它使贝叶斯推断成为可能。条件作用如下定义: 新的均值只依赖于作为条件的变量，而协方差矩阵则和这个变量无关, 即: \\(X \\sim \\mathcal{N}(\\mu_X,\\sum_{XX})\\) 而 \\(P(Y|X) \\sim \\mathcal{N}(\\mu_Y+\\sum_{YX}\\sum_{XX}^{-1}(X-\\mu_{X}),\\sum_{YY}-\\sum_{YX}\\sum_{XX}\\sum_{XY})\\) 边缘化与条件作用的直观感受 边缘化可以理解为在高斯分布的一个维度上做累加，这也符合边缘分布的一般定义。 条件作用也有个很好的几何表达——我们可以把它想象成在多元分布上切下一刀，从而获得一个维数更少的高斯分布。 下面的例子是关于Y的边缘分布[MARGINALIZATION(Y)], 实际上就是去掉变量x, 把变量x边缘化掉 (注意哦,与前面的描述是相反的, 这个是去掉变量X) \\[ \\begin{aligned} p_Y(y)=\\int_x p_{X,Y}(x,y)dx&amp;= \\int_x p_{X|Y}(x|y)p_Y(y)dx \\\\ &amp;= p_Y(y)\\int_x p_{X|Y}(x|y)dx \\\\ &amp;=p_Y(y) \\end{aligned} \\] 上式的意思就是说, 求出来的边缘分布\\(P_Y\\)就是给定一个y值, 在原来的联合概率分布\\(P(X,Y)\\)上, 给定y值之后把变量\\(x\\)在给定的y值方向上做累加. 图左是 Y 的边缘分布,是边缘化掉变量 X 的结果，类似于沿着 Y 轴把所有的X值做累加 图右是以给定的 X 为条件的关于变量Y的条件分布，类似于在原始分布上切下一刀 图片来自:看得见的高斯过程(原文) 1.2. 相关理论推导 1.2.1. 高斯分布的表示 协方差矩阵+均值 信息矩阵+信息矢量 常见的是\"协方差矩阵+均值\"形式, \\[p(x)=\\eta \\exp\\{-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\}\\] 其中对称正定矩阵Σ为随机变量x的协方差矩阵，μ为x的均值，简记为 \\[p(x) = N(\\mu, \\Sigma)\\] 信息矩阵+信息矢量的形式可以由上式推导而来 \\[ \\begin{aligned} p(x)&amp;=\\eta \\exp\\{-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\} \\\\ &amp;=\\eta\\exp\\{-\\frac{1}{2}x^T\\Sigma^{-1}x+x^T\\Sigma^{-1}\\mu\\} \\end{aligned} \\] &gt; 其中,运算中产生的常数项都全部吸收到了 η 中. 现在定义信息矩阵\\(\\Lambda=\\Sigma^{-1}\\), 信息矢量\\(\\xi=\\Sigma^{-1}\\mu=\\Lambda\\mu\\), 则有 \\[ p(x)=\\eta\\exp\\{-\\frac{1}{2}x^T\\Lambda x+x^T\\xi\\} \\] 即 \\[p(x) = N^{-1}(\\xi, \\Lambda)\\] 1.2.2. 联合高斯分布的分解 设随机变量\\(X, Y\\)满足联合高斯分布\\(p(X,Y)\\) 于是有 \\[ p(X,Y)=p(X)p(Y|X)\\] 所谓边缘化操作就是求出上面的分布p(X) * 也就是把变量Y边缘化掉(去掉) 用\"协方差矩阵+均值\"形式给出联合分布的表示: \\[ p(X,Y) = N\\Bigg(\\begin{pmatrix} \\mu_X \\\\ \\mu_Y \\end{pmatrix}, \\begin{pmatrix} \\Sigma_{XX} &amp; \\Sigma_{XY} \\\\ \\Sigma_{YX} &amp; \\Sigma_{YY} \\end{pmatrix}\\Bigg) \\] 补充:舒尔补公式 \\[ \\begin{aligned} \\begin{bmatrix} I &amp; -BD^{-1} \\\\ 0 &amp; I \\end{bmatrix} \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix} = \\begin{bmatrix} \\Delta_D &amp; 0 \\\\ C &amp; D \\end{bmatrix} \\end{aligned} \\] \\[ \\Delta_D=A-BD^{-1}C \\] \\[ \\begin{aligned} \\begin{bmatrix} I &amp; 0 \\\\ -CA^{-1} &amp; I \\end{bmatrix} \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix} = \\begin{bmatrix} A &amp; B \\\\ 0 &amp; \\Delta_A \\end{bmatrix} \\end{aligned} \\] \\[ \\begin{aligned} \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix} \\begin{bmatrix} I &amp; -A^{-1}B \\\\ 0 &amp; I \\end{bmatrix} = \\begin{bmatrix} A &amp; 0 \\\\ C &amp; \\Delta_A \\end{bmatrix} \\end{aligned} \\] \\[\\Delta_A=D-CA^{-1}B\\] 将上面两式联合起来,就可以把矩阵变成对角型 \\[ \\begin{aligned} \\begin{bmatrix} I &amp; 0 \\\\ -CA^{-1} &amp; I \\end{bmatrix} \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix} \\begin{bmatrix} I &amp; -A^{-1}B \\\\ 0 &amp; I \\end{bmatrix} = \\begin{bmatrix} A &amp; 0 \\\\ 0 &amp; \\Delta_A \\end{bmatrix} \\end{aligned} \\] 也可以通过对角型恢复出原来的矩阵 \\[ \\begin{aligned} \\begin{bmatrix} I &amp; 0 \\\\ CA^{-1} &amp; I \\end{bmatrix} \\begin{bmatrix} A &amp; 0 \\\\ 0 &amp; \\Delta_A \\end{bmatrix} \\begin{bmatrix} I &amp; A^{-1}B \\\\ 0 &amp; I \\end{bmatrix} = \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix} \\end{aligned} \\] 就可以快速写出矩阵的逆 \\[ \\begin{aligned} \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix}^{-1} &amp;= \\begin{bmatrix} I &amp; A^{-1}B \\\\ 0 &amp; I \\end{bmatrix}^{-1} \\begin{bmatrix} A &amp; 0 \\\\ 0 &amp; \\Delta_A \\end{bmatrix}^{-1} \\begin{bmatrix} I &amp; 0 \\\\ CA^{-1} &amp; I \\end{bmatrix}^{-1} \\\\ &amp;= \\begin{bmatrix} I &amp; -A^{-1}B \\\\ 0 &amp; I \\end{bmatrix} \\begin{bmatrix} A^{-1} &amp; 0 \\\\ 0 &amp; \\Delta_A^{-1} \\end{bmatrix} \\begin{bmatrix} I &amp; 0 \\\\ -CA^{-1} &amp; I \\end{bmatrix} \\end{aligned} \\] 联合高斯分布p(X,Y)p(X,Y)的概率密度函数(\"信息矩阵+信息矢量形式\")的表示为: \\[ \\begin{aligned} p(X, Y)&amp;= \\eta \\exp\\Bigg\\{-\\frac{1}{2}\\begin{pmatrix} X-\\mu_X \\\\ Y-\\mu_Y \\end{pmatrix}^T\\begin{pmatrix} \\Sigma_{XX} &amp; \\Sigma_{XY} \\\\ \\Sigma_{YX} &amp; \\Sigma_{YY} \\end{pmatrix}^{-1}\\begin{pmatrix} X-\\mu_X \\\\ Y-\\mu_Y \\end{pmatrix}\\Bigg\\} \\\\ &amp;\\propto \\exp\\Bigg\\{-\\frac{1}{2}\\begin{pmatrix} a \\\\ b \\end{pmatrix}^T\\begin{pmatrix} A &amp; C^{T} \\\\ C &amp; D \\end{pmatrix}^{-1}\\begin{pmatrix} a \\\\ b \\end{pmatrix}\\Bigg\\} \\end{aligned} \\] 于是, 就得到了关于X的边缘分布\\(p(X)\\)和关于Y的条件概率分布\\(p(Y|X)\\) 关于X的边缘分布\\(p(X)\\) \\[ \\begin{aligned} p(X) &amp;=\\eta_1 \\exp \\Big\\{-\\frac{1}{2} (X-\\mu_X)^{T} \\Sigma_{XX}^{-1}(X-\\mu_X) \\Big\\} \\sim \\mathcal{N}(0,\\Sigma_{XX}) \\end{aligned} \\] &gt; 这说明了,边缘分布\\(p(X)\\)的协方差就是联合分布\\(P(X,Y)\\)的协方差矩阵中对应的矩阵块\\(\\Sigma_{XX}\\) 关于Y的条件概率分布 \\[ \\begin{aligned} p(Y|X)&amp;= \\eta_2\\exp\\{-\\frac{1}{2}[Y-(\\mu_Y+\\Sigma_{YX}\\Sigma_{XX}^{-1}(X-\\mu_X))]^T\\Theta_{A}^{-1}[Y-(\\mu_Y+\\Sigma_{YX}\\Sigma_{XX}^{-1}(X-\\mu_X))]\\} \\\\ &amp; \\propto \\eta_2\\exp\\{-\\frac{1}{2}[b-CA^{-1}a]^T\\Theta_{A}^{-1}[b-CA^{-1}a]\\} \\\\ \\end{aligned} \\] 其中,\\(\\Theta_A=\\Delta_A=D-CA^{-1}B=D-CA^{-1}C^{T}\\) 表示矩阵块A在联合概率分布\\(P(X|Y)\\)的协方差矩阵中的舒尔补 所以, \\[ \\Theta_A=\\Delta_A=\\Sigma_{YY}-\\Sigma_{YX}\\Sigma_{XX}^{-1}\\Sigma_{XY} \\] 这说明了,关于Y的条件分布\\(p(Y|X)\\)的协方差就是联合分布\\(P(X,Y)\\)的协方差矩阵关于子块\\(A=\\Sigma_{XX}\\)的舒尔补\\(\\Delta_A=\\Sigma_{YY}-\\Sigma_{YX}\\Sigma_{XX}^{-1}\\Sigma_{XY}\\) 假定现在我们只有联合概率分布\\(p(X,Y)\\)的信息矩阵 现在来讨论上面两个分布的信息矩阵 首先利用舒尔补写出联合概率分布\\(p(X,Y)\\)的信息矩阵 (也就是协方差矩阵的逆) \\[ \\begin{aligned} \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix}^{-1} &amp;= \\begin{bmatrix} I &amp; -A^{-1}B \\\\ 0 &amp; I \\end{bmatrix} \\begin{bmatrix} A^{-1} &amp; 0 \\\\ 0 &amp; \\Delta_A^{-1} \\end{bmatrix} \\begin{bmatrix} I &amp; 0 \\\\ -CA^{-1} &amp; I \\end{bmatrix} \\end{aligned} \\] \\[ \\begin{aligned} \\begin{bmatrix} A &amp; C^{T} \\\\ C &amp; D \\end{bmatrix}^{-1} &amp;= \\begin{bmatrix} A^{-1}+A^{-1}C^{T}\\Delta_{A}^{-1}CA^{-1} &amp; -A^{-1}C^{T}\\Delta_{A}^{-1} \\\\ -\\Delta_{A}^{-1}CA^{-1} &amp; \\Delta_{A}^{-1} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} \\Sigma_{XX}^{-1}+\\Sigma_{XX}^{-1}\\Sigma_{XY}\\Theta_{A}^{-1}\\Sigma_{YX}\\Sigma_{XX}^{-1} &amp; -\\Sigma_{XX}^{-1}\\Sigma_{XY}\\Theta_{A}^{-1} \\\\ -\\Theta_{A}^{-1}\\Sigma_{YX}\\Sigma_{XX}^{-1} &amp; \\Theta_{A}^{-1} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} \\Lambda_{XX} &amp; \\Lambda_{XY} \\\\ \\Lambda_{YX} &amp; \\Lambda_{YY} \\end{bmatrix} \\end{aligned} \\] 关于X的边缘分布\\(p(X)\\)的信息矩阵 &gt; 从前面的讨论, 已经知道了关于X的边缘分布\\(p(X)\\)的信息矩阵就是联合分布\\(P(X,Y)\\)的协方差矩阵中对应的矩阵块\\(\\Sigma_{XX}\\), 那么对应的信息矩阵就是\\(\\Sigma_{XX}^{-1}\\) 那么现在的目的就是: 利用原有的联合概率分布信息矩阵, 求出关于X的边缘分布\\(p(X)\\)的信息矩阵, 也就是边缘化掉变量Y之后的信息矩阵 易得 \\[ \\begin{aligned} \\Sigma_{XX}^{-1}=\\Lambda_{XX}-\\Lambda_{XY}\\Lambda_{YY}^{-1}\\Lambda_{YX} \\end{aligned} \\] 关于Y的条件概率分布的信息矩阵 &gt; 从前面的讨论, 已经知道了关于Y的条件概率分布的信息矩阵就是联合分布\\(P(X,Y)\\)的协方差矩阵关于子块\\(A=\\Sigma_{XX}\\)的舒尔补\\(\\Theta_A=\\Delta_A\\), 那么对应的信息矩阵就是\\(\\Theta_A^{-1}\\) 易得 \\[ \\Theta_A^{-1}=\\Lambda_{YY} \\] 1.3. 边缘化操作的作用 所谓边缘化，就是求某个联合概率分布的边缘分布。比如对于联合概率\\(p(X,Y)\\)，对\\(Y\\)进行边缘化，就是对\\(Y\\)在整个空间中积分，即 \\[ \\begin{aligned} p_X(x)=\\int_y p_{X,Y}(x,y)dy&amp;= \\int_y p_{Y|X}(y|x)p_X(x)dy \\\\ &amp;= p_X(x)\\int_y p_{Y|X}(y|x)dy \\\\ &amp;=p_X(x) \\end{aligned} \\] 因此，对\\(Y\\)边缘化的结果就是X的边缘化分布的\\(p(X)\\)，仍然是一个高斯函数。伴随着边缘化，\\(p(Y|X)\\)就是\\(p(X,Y)\\)对\\(X\\)的条件化。 最小二乘 在信息矩阵+信息矢量的表示方式下，边缘化和条件化与最小二乘法有密切关系。在许多基于最小二乘的优化问题中，常有如下形式的优化目标： \\[ \\min_x\\Vert e(x)\\Vert_W^2=\\min_x~e(x)^TW^{-1}e(x) \\] 其中\\(W\\)是\\(e(x)\\)的协方差矩阵。 高斯牛顿 为了寻找上式的最小值，常使用迭代优化的方法，每一次迭代都会寻找一个增量\\(\\Delta x\\)使目标函数减小。为了求增量，往往会将\\(e(x)\\)在当前\\(x\\)处展开为一阶近似（这种处理方式即Gauss-Newton Method），即: \\[ e(x+\\Delta x)\\simeq e(x)+J(x)\\Delta x \\] 其中, \\[ J(x)=\\frac{\\partial e}{\\partial x} \\] 于是, 可以生成新的优化目标: \\[ \\min_{\\Delta x}~[e(x)+J(x)\\Delta x]^TW^{-1}[e(x)+J(x)\\Delta x] \\] 这是关于\\(\\Delta x\\)的二次函数，对\\(\\Delta x\\)求导，并令导数等于0，有: \\[ \\begin{aligned} J(x)^TW^{-1}J(x)\\Delta x+J(x)^TW^{-1}e(x)=0 \\\\ \\Longrightarrow J(x)^TW^{-1}J(x)\\Delta x = -J(x)^TW^{-1}e(x) \\end{aligned} \\] 令\\(J(x)^TW^{-1}J(x) = H\\), 是变量\\(\\Delta x\\)的信息矩阵 令\\(-J(x)^TW^{-1}e(x)=b\\), 则有 \\[ H\\Delta x=b \\] 这就是非线性优化中的增量方程, 通过不断迭代求解\\(\\Delta x\\), 更新变量\\(x+=\\Delta x\\), 使得目标函数不断下降, 直到达到要求. SLAM问题求解 在很多优化问题中，待优化的变量有明确意义，比如在SLAM或者SfM问题中，要优化的是所有相机的位姿\\(c\\)以及地图中所有三维点(路标点)的坐标\\(p\\)，设\\(\\Delta x\\)由这两个分量的增量构成，即 \\[ \\Delta x = \\begin{pmatrix} \\Delta c \\\\ \\Delta p \\end{pmatrix} \\] 并且求出了对应的信息矩阵\\(\\Lambda\\) \\[ \\Lambda=\\begin{pmatrix} \\Lambda{cc} &amp; \\Lambda{cp} \\\\ \\Lambda{pc} &amp; \\Lambda{pp} \\end{pmatrix}, ~~~ b = \\begin{pmatrix} b_c \\\\ b_p \\end{pmatrix} \\] 于是有 \\[ \\begin{pmatrix} \\Lambda{cc} &amp; \\Lambda{cp} \\\\ \\Lambda{pc} &amp; \\Lambda{pp} \\end{pmatrix} \\begin{pmatrix} \\Delta c \\\\ \\Delta p \\end{pmatrix}= \\begin{pmatrix} b_c \\\\ b_p \\end{pmatrix} \\] 直接对信息矩阵求逆可以对上述方程求解, 但是当矩阵维度过大的时候, 直接求逆很难, 通常采用各种分解 可以采用上面的舒尔补公式进行消元, 也就是所说的高斯消元法 &gt;(1) 舒尔补公式 &gt;\\[ \\begin{aligned} \\begin{bmatrix} I &amp; -BD^{-1} \\\\ 0 &amp; I \\end{bmatrix} \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix} = \\begin{bmatrix} \\Delta_D &amp; 0 \\\\ C &amp; D \\end{bmatrix} \\end{aligned} &gt;\\] &gt;\\[ \\Delta_D=A-BD^{-1}C &gt;\\] 即对方程两边同时左乘 \\[ \\begin{bmatrix} I &amp; -\\Lambda{cp}\\Lambda{pp}^{-1} \\\\ 0 &amp; I \\end{bmatrix} \\] 得到一个下三角型的形式 \\[ \\begin{pmatrix} \\Lambda{cc}-\\Lambda{cp}\\Lambda{pp}^{-1}\\Lambda{pc} &amp; 0 \\\\ \\Lambda{pc} &amp; \\Lambda{pp} \\end{pmatrix} \\begin{pmatrix} \\Delta c \\\\ \\Delta p \\end{pmatrix}= \\begin{pmatrix} b_c-\\Lambda{cp}\\Lambda{pp}^{-1}b_c \\\\ b_p \\end{pmatrix} \\] 于是原方程可以转换为两个独立方程 \\[ \\begin{aligned} (\\Lambda{cc}-\\Lambda{cp}\\Lambda{pp}^{-1}\\Lambda{pc})\\Delta c &amp;= b_c-\\Lambda{cp}\\Lambda{pp}^{-1}b_c \\\\ \\Lambda_{pp}\\Delta p &amp;= b_p -\\Lambda_{pc}\\Delta c \\end{aligned} \\] 可以发现，\\(\\Delta c\\)的系数矩阵，与上文中边缘分布\\(p(X)\\)的信息矩阵和信息矢量有相同的形式。而\\(\\Delta p\\)的系数矩阵，则与关于Y的条件概率分布\\(p(Y|X)\\)的信息矩阵有相同形式。 也就是说，这里的高斯消元法，等价于对变量\\(\\Delta c\\)做了边缘化，先将\\(\\Delta p\\)边缘化掉,就是消掉路标点p，单独求相机位姿增量\\(\\Delta c\\)，然后再在\\(\\Delta c\\)已知的情况下求\\(\\Delta p\\)。 参考: 1. 高斯分布与边缘化 2. 看得见的高斯过程(译文) 3. 看得见的高斯过程(原文)","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第四讲","slug":"VIO/第四讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E5%9B%9B%E8%AE%B2/"}],"tags":[]},{"title":"第六讲_视觉前端","slug":"VIO/第六讲/第六讲-视觉前端","date":"2020-02-14T01:41:37.000Z","updated":"2020-02-14T07:36:29.000Z","comments":true,"path":"2020/02/14/VIO/第六讲/第六讲-视觉前端/","link":"","permalink":"http://yoursite.com/2020/02/14/VIO/%E7%AC%AC%E5%85%AD%E8%AE%B2/%E7%AC%AC%E5%85%AD%E8%AE%B2-%E8%A7%86%E8%A7%89%E5%89%8D%E7%AB%AF/","excerpt":"","text":"前端 image-20200214094912305 image-20200214095748303 image-20200214095757400 image-20200214095803446 image-20200214100352560 image-20200214100606867 ORB: 10--15毫秒 SIFT: 200+毫秒 GFTT: 10毫秒左右 直接法可能在实际应用中要好一点 image-20200214101228491 image-20200214101933123 特征点提取_匹配和光流法 image-20200214102149991 image-20200214102825118 image-20200214103119404 image-20200214103420368 image-20200214103634407 image-20200214103650613 image-20200214104008183 image-20200214104111176 关键帧与三角化 image-20200214104754044 image-20200214105105811 image-20200214105450166 image-20200214105656337 image-20200214105839030 三角化 image-20200214110028435 image-20200214110458552 image-20200214110711783 当系数矩阵D满秩的时候, 齐次方程组有唯一解, 也就是 零解 image-20200214115407894 参考资料","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第六讲","slug":"VIO/第六讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E5%85%AD%E8%AE%B2/"}],"tags":[]},{"title":"VIO-资料集合","slug":"VIO/手写VIO课程-资料集合","date":"2020-02-13T18:00:31.000Z","updated":"2020-04-30T03:40:49.000Z","comments":true,"path":"2020/02/14/VIO/手写VIO课程-资料集合/","link":"","permalink":"http://yoursite.com/2020/02/14/VIO/%E6%89%8B%E5%86%99VIO%E8%AF%BE%E7%A8%8B-%E8%B5%84%E6%96%99%E9%9B%86%E5%90%88/","excerpt":"","text":"资料下载 点击下载","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"}],"tags":[]},{"title":"第一讲_预备知识","slug":"VIO/第一讲/第一讲_预备知识","date":"2020-02-13T17:00:31.000Z","updated":"2020-03-01T10:18:39.000Z","comments":true,"path":"2020/02/14/VIO/第一讲/第一讲_预备知识/","link":"","permalink":"http://yoursite.com/2020/02/14/VIO/%E7%AC%AC%E4%B8%80%E8%AE%B2/%E7%AC%AC%E4%B8%80%E8%AE%B2_%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/","excerpt":"","text":"1. 第一讲_预备知识 ## 1.1. 四元数的基本运算 * 主要运算 * 四元数乘法 &gt; 乘法性质 &gt; 1. 满足结合律 &gt; 2. 不满足交换律 &gt; 3. 乘积的模等于模的乘积 &gt; 4. 乘积的逆等于各个四元数的逆以相反的顺序相乘 * 其他运算 *四元数部分参考：旋转矩阵、欧拉角、四元数理论及其转换关系 1.2. 四元数与旋转向量 &gt; 简单来说，四元数的思想就是把方向余弦矩阵的三次旋转表示为只绕一个旋转轴旋转一次完成，因此可以用4个数来表示这个过程，其中包括旋转轴向量的长度(θ)和旋转轴单位向量(x,y,z) 1.2.1. 四元数的表示 \\[ \\begin{aligned} \\begin{bmatrix} q_0 \\\\ q_1 \\\\ q_2 \\\\ q_3 \\end{bmatrix} = \\begin{bmatrix} \\cos \\frac{\\theta}{2} \\\\ x*\\sin \\frac{\\theta}{2} \\\\ y*\\sin \\frac{\\theta}{2} \\\\ z*\\sin \\frac{\\theta}{2} \\\\ \\end{bmatrix} \\end{aligned} \\] ## 1.3. 四元数对时间的导数 ### 1.3.1. 关于两个极限的近似(上面求极限用到的) ## 1.4. 旋转矩阵(李群SO3)对角速度\\(\\omega\\)的求导 ## 1.5. so(3) 导数 ### 1.5.1. 左乘模型 ### 1.5.2. 右乘模型 1.6. 旋转连乘的雅克比 1.6.1. 对R2求导 ### 1.6.2. 对R1求导 1.6.3. 伴随性质的证明 1.6.3.1. 即证明下式 \\[ \\begin{aligned} R~exp(\\phi \\hat{~} )~R^T=exp((R\\phi)\\hat{~}) \\end{aligned} \\] #### 1.6.3.2. 首先证明 \\[ Rp\\hat{~}R^T=(Rp)\\hat{~} \\] //或者:(上下是等价的) \\[ \\begin{aligned} R[a]_\\times=[Ra]_\\times R \\end{aligned} \\] ##### 1.6.3.2.1. 已知 若 \\[ \\begin{aligned} a=b\\times c \\end{aligned} \\] 则有 \\[ \\begin{aligned} &amp;R\\in SO3 \\\\ &amp;Ra=(Rb) \\times (Rc) \\end{aligned} \\] 1.6.3.2.2. 可证 \\[ \\begin{aligned} (Rp)\\hat{~}&amp;=(Rp)\\hat{~}I=(Rp)_\\times RR^{T}I \\\\ &amp;=(Rp)_\\times (R R^{T}I) \\\\ &amp;=R(p_\\times R^{T}I) \\\\ &amp;=Rp\\hat{~}R^T \\end{aligned} \\] 1.6.3.3. 再来证明原式 1.6.3.3.1. 等式右侧 \\[ \\begin{aligned} &amp;\\because Rp\\hat{~}R^T=(Rp)\\hat{~} \\\\ &amp;\\therefore e^{(Rp)\\hat{~}}=e^{Rp\\hat{~}R^T} \\approx I+Rp\\hat{~}R^T \\end{aligned} \\] ##### 1.6.3.3.2. 等式左侧 \\[ \\begin{aligned} Re^{(p\\hat{~})}R^T &amp;\\approx R(I+p\\hat{~})R^T \\\\ &amp;=RIR^T+Rp\\hat{~}R^T \\\\ &amp;=I+Rp\\hat{~}R^T \\end{aligned} \\] ##### 1.6.3.3.3. 证毕 ## 1.7. 不用SE3的讨论 1.8. 作业 1.8.1. 使用右乘SO3,求\\(\\frac{d(R^{-1}p)}{dR}\\) \\[ \\begin{aligned} \\frac{d(R^{-1}p)}{dR}&amp;=\\lim_{\\phi \\to 0} \\frac{d[(R\\exp(\\phi \\hat{~}))^{-1}-R^{-1}p]}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d[\\exp^{-1}(\\phi \\hat{~})~R^{-1}p-R^{-1}p]}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d[\\exp(-\\phi \\hat{~})~R^{-1}p-R^{-1}p]}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d[(I-\\phi \\hat{~})~R^{-1}p-R^{-1}p]}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{-\\phi\\hat{~}~R^{-1}p}{\\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{(R^{-1}p\\hat{~})\\phi}{\\phi} \\\\ &amp;=(R^{-1}p)\\hat{~} \\end{aligned} \\] 1.8.2. 使用右乘SO3,求\\(\\frac{d\\ln(R_1R_2^{-1})}{dR_2}\\) \\[ \\begin{aligned} \\frac{d\\ln(R_1R_2^{-1})}{dR_2}&amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln[R_1(R_2 \\exp(\\phi \\hat{~}))^{-1}]-ln(R_1R_2^{-1})}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln[R_1\\exp^{-1}(\\phi \\hat{~})R_2^{-1}]-ln(R_1R_2^{-1})}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln[R_1\\exp(-\\phi \\hat{~})R_2^{-1}]-ln(R_1R_2^{-1})}{d \\phi} \\end{aligned} \\] 再利用伴随性质 \\[ \\begin{aligned} R\\exp(\\phi \\hat{~} )R^T=\\exp((R\\phi)\\hat{~}) \\end{aligned} \\] 可得 \\[ \\begin{aligned} R_2\\exp(-\\phi \\hat{~})R_2^T=\\exp((R_2*(-\\phi))\\hat{~}) \\end{aligned} \\] 两边同时左乘\\(R_2^{-1}\\) \\[ \\begin{aligned} \\exp(-\\phi \\hat{~})R_2^{-1}=R_2^{-1}\\exp((R_2*(-\\phi))\\hat{~}) \\end{aligned} \\] 将上式带入 \\[ \\begin{aligned} \\frac{d\\ln(R_1R_2^{-1})}{dR_2}&amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln[R_1(R_2 \\exp(\\phi \\hat{~}))^{-1}]-\\ln(R_1R_2^{-1})}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln[R_1\\exp^{-1}(\\phi \\hat{~})R_2^{-1}]-\\ln(R_1R_2^{-1})}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln[R_1\\exp(-\\phi \\hat{~})R_2^{-1}]-\\ln(R_1R_2^{-1})}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln[R_1R_2^{-1}\\exp((R_2*(-\\phi))\\hat{~})]-\\ln(R_1R_2^{-1})}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln(R_1R_2^{-1})+J_r^{-1}R_2*(-\\phi)-\\ln(R_1R_2^{-1})}{d \\phi} \\\\ &amp;=\\lim_{\\phi \\to 0} \\frac{d \\ln(R_1R_2^{-1})-J_r^{-1}\\phi R_2-\\ln(R_1R_2^{-1})}{d \\phi} \\\\ &amp;=-J_r^{-1}(\\ln(R_1R_2^{-1}))R_2 \\end{aligned} \\] 1.8.3. CODEing 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;eigen3/Eigen/Core&gt;#include &lt;Eigen/Geometry&gt;#include &lt;sophus/so3.hpp&gt;using namespace Eigen;using namespace std;int main()&#123; //旋转向量 Eigen::AngleAxisd angleAxisVec=AngleAxisd(M_PI/2,Vector3d(0,0,1)); //Eigen 旋转矩阵 Eigen::Matrix3d R_mat=angleAxisVec.toRotationMatrix(); cout&lt;&lt;\"Eigen 绕z轴旋转90度的旋转矩阵\"&lt;&lt;R_mat&lt;&lt;endl; /********************************************************** * 当有一个计算出来的w,使用它来对旋转量进行更新 * 1.使用旋转矩阵 R=R*exp(w^) * 2.使用四元数 q=q * q[1,0.5w] * 结果:这两种更新方式都是一样的 **********************************************************/ ///1.使用旋转矩阵更新 Sophus::SO3d R; cout&lt;&lt;\"更新之前的R: \\n\"&lt;&lt;R.matrix()&lt;&lt;endl; Vector3d w(0.01,0.02,0.03);// cout&lt;&lt;\"更新量w的反对称矩阵:\\n\"&lt;&lt;Sophus::SO3d::hat(w)&lt;&lt;endl;// Matrix3d hat=R.matrix()*Sophus::SO3d::hat(w); //这个并不是更新之后的R Sophus::SO3d R_updated_sophus=R*Sophus::SO3d::exp(w); cout&lt;&lt;\"更新之后的R: \\n\"&lt;&lt;R_updated_sophus.matrix()&lt;&lt;endl; cout&lt;&lt;\"======================================================\"&lt;&lt;endl; ///2.使用四元数更新 Quaterniond q(R.matrix()); cout&lt;&lt;\"更新之前的q: \\n\"&lt;&lt;q.coeffs().transpose()&lt;&lt;endl; cout&lt;&lt;\"对应的旋转矩阵: \\n\"&lt;&lt;q.toRotationMatrix()&lt;&lt;endl; //注意:这里不是用旋转向量构造q, w是直接构造q的参数// Quaterniond q_update(Eigen::AngleAxisd(1,Vector3d(0.5*0.01,0.5*0.02,0.5*0.03))); //注意两种构造方式// Quaterniond(Vector4d(x,y,z,w))// Quaterniond(w,x,y,z,w) Quaterniond q_update(1,0.5*0.01,0.5*0.02,0.5*0.03); //构造更新量四元数q(w,x,y,z)// cout&lt;&lt;q_update.coeffs().transpose()&lt;&lt;endl; Quaterniond q_updated=q*q_update; cout&lt;&lt;\"更新之后的q对应的旋转矩阵:\\n\"&lt;&lt;q_updated.toRotationMatrix()&lt;&lt;endl; return 0;&#125; 1.8.3.1. Result","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第一讲","slug":"VIO/第一讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%B8%80%E8%AE%B2/"}],"tags":[]},{"title":"第二讲_IMU相关内容","slug":"VIO/第二讲/第二讲_IMU传感器相关","date":"2020-02-13T11:16:43.000Z","updated":"2020-02-13T16:53:09.000Z","comments":true,"path":"2020/02/13/VIO/第二讲/第二讲_IMU传感器相关/","link":"","permalink":"http://yoursite.com/2020/02/13/VIO/%E7%AC%AC%E4%BA%8C%E8%AE%B2/%E7%AC%AC%E4%BA%8C%E8%AE%B2_IMU%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9B%B8%E5%85%B3/","excerpt":"","text":"1. 第二讲_IMU相关内容 1.1. 旋转运动学 1.1.1. 运动半径\\(r\\)对\\(\\theta\\)的求导,再写成矩阵形式 \\(\\color{red}{下图中:半径a和高度h固定}\\) 从结果可以看到,矩阵形式的导数表示可以写成矩阵形式\\(\\omega \\times r\\),左侧为反对称矩阵w 1.1.2. 考虑更复杂的情况,假设旋转坐标系下的情况 1.1.2.1. 旋转坐标系下的运动学(暂时不考虑平移) 考虑两个坐标系,一个静止的坐标系,惯性坐标系i系,另外一个是旋转的坐标系即载体坐标系b系. 其中,关于旋转矩阵\\(R_{IB}\\)的导数\\(\\dot{R_{IB}}\\)可看第一讲的内容. &gt; 结果:一个有趣的现象是,物体在惯性系下的速度\\(\\dot{r}\\)并不是直接等于物体在b系下的速度乘以旋转矩阵\\(R_{IB}*v_{B}\\),后面还多了一项\\(-\\omega \\times r_I\\),这就是哥氏加速度带来的影响. * 补充: * \\(\\dot{R}_{IB}r_B=\\omega \\times r_I\\)的详细证明 (1)用到了性质\\(R[a]_\\times=[Ra]_\\times R\\) (2)用到了性质\\(\\dot{R}=R\\omega\\) \\[ \\begin{aligned} \\dot{R}_{IB}r_B &amp;= \\lim_{\\Delta t \\to 0} \\frac{R_{IB} \\exp([\\omega_{BB&#39;} \\Delta t]\\hat{~})r_B-R_{IB}r_B}{\\Delta t} \\\\ &amp;= \\lim_{\\Delta t \\to 0} \\frac{R_{IB} (I+[\\omega_{BB&#39;}\\Delta t]\\hat{~}) r_B-R_{IB}r_B}{\\Delta t} \\\\ &amp;= \\lim_{\\Delta t \\to 0} \\frac{R_{IB} [\\omega_{BB&#39;}\\Delta t]\\hat{~} r_B}{\\Delta t} \\\\ &amp;= \\lim_{\\Delta t \\to 0} \\frac{-R_{IB} r_B\\hat{~} (\\omega_{BB&#39;}\\Delta t)}{\\Delta t} \\\\ &amp;= {-R_{IB} r_B\\hat{~} (\\omega_{BB&#39;})} \\\\ &amp;= R_{IB}(\\omega_{BB&#39;})\\hat{~}r_B \\\\ &amp;=[R_{IB}\\omega_{BB&#39;}]_\\times R_{IB}r_B \\\\ &amp;=\\omega \\times r_I \\end{aligned} \\] 关于速度的求导部分的补充 因为有\\(\\dot{R_{IB}}=R_{IB}[\\omega_b]_\\times =[R_{IB}\\omega_b]_\\times R_{IB}\\)(根据性质-第一讲) 所以\\(\\dot{R_{IB}}v_b=R_{IB}[\\omega_b]_\\times v_b=[R_{IB}\\omega_b]_\\times R_{IB} v_{b}=\\omega \\times v\\) \\(\\dot{R_{IB}}\\omega_b=R_{IB}[\\omega_b]_\\times \\omega_b=R_{IB} \\omega_b \\hat{~}\\omega_b=0\\) 结果:结果表明,物体在惯性系的加速度a_i并不直接等于b系下的加速度乘以对应的旋转矩阵,而是要加上后面几项,其中,哥氏力是成对出现的,另外:由于w_{ie}为常量,所以\\(\\omega\\)求导后的\\(\\dot{\\omega}\\)为0,所以一般欧拉力为0?. 1.2. IMU测量模型和运动模型 1.2.1. 加速度测量 1.2.2. 角速度测量 主要利用科氏力来计算角速度 1.3. IMU误差模型 1.3.1. 确定性误差 * run-to-run : 每次上电的时候的bias叠加 * run-in-run : 每次上电时候的bias不一样 * 温度 1.3.2. 标定方法 1.3.2.1. 加速度计标定 1.3.2.2. 陀螺仪标定 1.3.2.3. 温度相关系数 1.3.2.4. 不确定性误差(随机误差) 1.3.2.5. Bias误差模型 1.3.2.6. 艾伦方差标定(常用) * 使用标定工具 * 美国:calibration alan * 港科大:imu_utils 1.3.2.7. 加速度计数学模型 1.3.2.8. 陀螺仪数学模型 1.4. 运动模型离散时间处理 1.4.1. 欧拉法 关于姿态q的离散积分: \\[ \\begin{aligned} \\because \\dot{q}_{wb_k}=q_{wb_k} \\otimes [0,\\frac{1}{2}\\omega]^T \\end{aligned} \\] \\[ \\begin{aligned} \\therefore q_{wb_{k+1}}&amp;=q_{wb_k}+\\dot{q}_{wb_k} \\delta t \\\\ &amp;= q_{wb_k}+q_{wb_k} \\otimes [0,\\frac{1}{2}\\omega]^T \\\\ &amp;=q_{wb_k} \\otimes [1,\\frac{1}{2}\\omega]^T \\end{aligned} \\] 1.4.2. 中值法 比欧拉法稍微精确一点 -- ## 1.5. 仿真 1.5.1. 知识补充 \\(\\color{red}{注意欧拉角(3维向量)形式的旋转积分:需要先使用旋转矩阵将b系下的角速度转换为世界坐标系的欧拉角速度}\\) 1.5.2. 个人理解 上面的关于欧拉角旋转的描述是基于ZYX321顺序的,其对应的坐标系是前右下,对应的导航坐标系是北东地,常用于无人机.下面用另外一种欧拉角顺序推导一遍,该顺序更常用于地面无人车. 1.5.2.1. 方向余弦矩阵的基本形式 一个向量的方向（姿态）我们可以用他在参考坐标系（地理坐标系）各个轴向的夹角的余弦来表示（及在各个轴的投影）。 类似的 一个坐标系 可以看成是3个向量组成，所以三个向量分别在坐标轴上的投影可以用来表示一个坐标系与参考坐标系的关系。这总共9个方向余弦组成了一个三阶矩阵，其对应方式如下图。 \\[ \\quad C_b^n= \\begin{bmatrix} c_{11} &amp; c_{12} &amp;c_{13} \\\\ c_{21} &amp; c_{22} &amp;c_{23} \\\\ c_{11} &amp; c_{12} &amp;c_{13} \\end{bmatrix} \\quad \\] 其中，第 i 行、 j 列的元素表示参考坐标系 i 轴和姿态坐标系 j 轴夹角的余弦。事实上方向余弦和欧拉角没有本质区别，因为方向余弦实际上就是用欧拉角表示的。 1.5.2.2. 方向余弦矩阵的举例推导 一个二维的坐标变换如下： 点F为固定点，在坐标系1下的表示为\\(F(r_{x1},r_{y1})\\)，在坐标系2下为\\(F_{2}(r_{x2},r_{y2})\\) 由图可知,注意观察使用图中两个红色的三角形 \\[ \\begin{aligned} r_{x2}&amp;=r_{x1}*\\cos \\alpha+ r_{y1}*\\sin \\alpha \\\\ r_{y2}&amp;=r_{x1}*(-\\sin \\alpha)+r_{y1}*\\cos \\alpha \\end{aligned} \\] 推广到三维的情况下，可看作是绕Z轴逆时针旋转，并写成矩阵形式： \\[ \\quad \\begin{bmatrix} r_{x2} \\\\ r_{y2} \\\\ r_{z2} \\end{bmatrix}= \\begin{bmatrix} \\cos \\alpha &amp; \\sin \\alpha &amp;0 \\\\ -\\sin \\alpha &amp; \\cos \\alpha &amp;0 \\\\ 0 &amp; 0 &amp;1 \\end{bmatrix} \\begin{bmatrix} r_{x1} \\\\ r_{y1} \\\\ r_{z1} \\end{bmatrix} \\quad \\] 由上面的例子，可推理余弦矩阵各个元素的意义 * 第1行表示旋转之后的X2轴在原坐标系(X1,Y1,Z1)轴下的投影 * 第2行表示旋转之后的Y2轴在原坐标系(X1,Y1,Z1)轴下的投影 * 第3行表示旋转之后的Z2轴在原坐标系(X1,Y1,Z1)轴下的投影 1.5.2.3. 东北天ENU----&gt;右前上的余弦矩阵\\(C_{n}^{b}\\)推导 假设我们现在有一个东北天坐标系和一个载体坐标系，现需要将东北天坐标系经过3次旋转，使得最终得到的坐标系与载体坐标系重合。 &gt; 在此之前，需要做出一些规定 &gt; * 旋转的正方向为：从旋转轴看的逆时针方向 &gt; * 旋转的顺序为：Z-X-Y &gt; * 对应的欧拉角：Yaw-Pitch-Roll 1.5.2.3.1. 绕Z轴逆时针旋转\\(\\psi\\)——Yaw 得到旋转矩阵\\(C_{n}^{1}\\) \\[ \\quad C_{n}^{1}= \\begin{bmatrix} \\cos \\psi &amp; \\sin \\psi &amp;0 \\\\ -\\sin \\psi &amp; \\cos \\psi &amp;0 \\\\ 0 &amp; 0 &amp;1 \\end{bmatrix} \\quad \\] 1.5.2.3.2. 绕X'轴逆时针旋转\\(\\theta\\)——Pitch 得到旋转矩阵\\(C_{1}^{2}\\) \\[ \\quad C_{1}^{2}= \\begin{bmatrix} 1 &amp; 0 &amp;0 \\\\ 0 &amp;\\cos \\theta &amp; \\sin \\theta \\\\ 0 &amp;-\\sin \\theta &amp; \\cos \\theta \\end{bmatrix} \\quad \\] 1.5.2.3.3. 绕Y''轴逆时针旋转\\(\\phi\\)——Roll 得到旋转矩阵\\(C_{2}^{3}\\) \\[ \\quad C_{2}^{3}= \\begin{bmatrix} \\cos \\phi &amp; 0 &amp;-\\sin \\phi \\\\ 0 &amp; 1&amp; 0 \\\\ \\sin \\phi &amp; 0&amp; \\cos \\phi \\end{bmatrix} \\quad \\] 1.5.2.3.4. 得到ENU导航坐标系到右前上载体坐标系的方向余弦矩阵\\(C_{n}^{b}\\) \\[ \\begin{aligned} C_{n}^{b}=&amp;C_{2}^{3}C_{1}^{2}C_{n}^{1} \\\\ =&amp; \\begin{bmatrix} \\cos \\phi &amp; 0 &amp;-\\sin \\phi \\\\ 0 &amp; 1&amp; 0 \\\\ \\sin \\phi &amp; 0&amp; \\cos \\phi \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 &amp;0 \\\\ 0 &amp;\\cos \\theta &amp; \\sin \\theta \\\\ 0 &amp;-\\sin \\theta &amp; \\cos \\theta \\end{bmatrix} \\begin{bmatrix} \\cos \\psi &amp; \\sin \\psi &amp;0 \\\\ -\\sin \\psi &amp; \\cos \\psi &amp;0 \\\\ 0 &amp; 0 &amp;1 \\end{bmatrix} \\\\ =&amp; \\begin{bmatrix} \\cos \\psi \\cos \\phi -\\sin \\psi \\sin \\theta \\sin \\phi &amp; \\sin \\psi \\cos \\phi+\\cos \\psi \\sin \\theta \\sin \\phi &amp; -\\cos \\theta \\sin \\phi \\\\ -\\sin \\psi \\cos \\theta &amp; \\cos \\psi \\cos \\theta &amp; \\sin \\theta \\\\ \\cos \\psi \\sin \\phi+ \\sin \\psi \\sin \\theta \\cos \\phi &amp; \\sin \\psi \\sin \\phi- \\cos \\psi \\sin \\theta \\cos \\phi &amp; \\cos \\theta \\cos \\phi \\end{bmatrix} \\\\ = &amp; \\begin{bmatrix} c_{11} &amp; c_{12} &amp;c_{13} \\\\ c_{21} &amp; c_{22} &amp;c_{23} \\\\ c_{11} &amp; c_{12} &amp;c_{13} \\end{bmatrix} \\end{aligned} \\] 1.5.2.4. \\({\\color{red}{(ZXY-312顺序)欧拉角微分}}\\) 上面的方向余弦矩阵\\(C_n^b\\)描述了将一个点. 1.5.2.5. 导航坐标系下欧拉角离散积分形式推导 \\(\\because\\)欧拉角形式积分: \\(\\vartheta_{wb&#39;}=\\vartheta_{wb&#39;}+ \\frac{d \\vartheta}{dt} \\Delta t\\).用到了欧拉角的微分形式 \\(\\therefore\\)需要求\\(\\frac{d \\vartheta}{dt}\\) 其中: (1)\\(\\vartheta=[\\theta_{pitch},\\Phi_{roll},\\psi_{yaw}]^T\\)表示在导航坐标系下的欧拉角速度 (2)\\(\\omega\\)表示在载体坐标系b系下的三个角速度 求:利用\\(\\omega\\)表示出导航坐标系下的欧拉角微分\\(\\frac{d \\vartheta}{dt}\\) 求解: 以下部分参考来自: &gt;1. 假设已经完成绕三个轴的旋转，则最后绕Y轴的角速度在载体坐标系和导航坐标系都是一样的，所以有如下公式： \\[ \\begin{aligned} \\omega_b(roll)=\\begin{bmatrix} 0\\\\ \\frac{d roll}{dt} \\\\ 0 \\end{bmatrix} \\\\ \\end{aligned} \\] &gt;2. 假设已经完成了前两组旋转，最后一组旋转没有完成，如果接着完成最后一步旋转，则和第一步一样，绕X轴的角速度在两个坐标系下是一样的，则有如下公式： \\[ \\begin{aligned} \\omega_b(pitch)=C_2^{3}\\begin{bmatrix} \\frac{d pitch}{dt}\\\\ 0 \\\\ 0 \\end{bmatrix} \\end{aligned} \\] &gt;3. 分析和第二步类似。假设已经完成了第一组旋转，最后两组旋转没有完成，如果接着完成最后两组旋转，则绕ZZZ轴的角速度在两个坐标系下是一样的，则有如下公式： \\[ \\begin{aligned} \\omega_b(yaw)=C_2^{3}C_1^{2}\\begin{bmatrix} 0\\\\ 0 \\\\ \\frac{d yaw}{dt} \\end{bmatrix} \\end{aligned} \\] 通过对三次旋转的理解,可以得出,载体坐标系的三轴角速度\\(\\omega\\)可以如下表示: \\[ \\begin{aligned} \\omega_b&amp;=\\omega_b(yaw)+\\omega_b(pitch)+\\omega_b(roll) \\\\ &amp;=C_2^{3}C_1^{2}\\begin{bmatrix} 0\\\\ 0 \\\\ \\frac{d yaw}{dt} \\end{bmatrix}+C_2^{3}\\begin{bmatrix} \\frac{d pitch}{dt}\\\\ 0 \\\\ 0 \\end{bmatrix}+\\begin{bmatrix} 0\\\\ \\frac{d roll}{dt} \\\\ 0 \\end{bmatrix} \\\\ &amp;=\\begin{bmatrix} \\cos \\phi &amp; 0 &amp; -\\sin \\phi \\cos \\theta \\\\ 0 &amp; 1 &amp; 0 \\\\ \\sin \\phi &amp; 0 &amp; \\cos \\theta \\cos \\phi \\end{bmatrix} \\cdot \\begin{bmatrix} \\frac{d pitch}{dt} \\\\ \\frac{d roll}{dt} \\\\ \\frac{d yaw}{dt} \\end{bmatrix} \\\\ &amp;=\\begin{bmatrix} \\cos \\phi &amp; 0 &amp; -\\sin \\phi \\cos \\theta \\\\ 0 &amp; 1 &amp; 0 \\\\ \\sin \\phi &amp; 0 &amp; \\cos \\theta \\cos \\phi \\end{bmatrix} \\cdot \\frac{d \\vartheta}{dt} \\end{aligned} \\] 于是,通过对矩阵求逆,可求出\\(\\frac{d \\vartheta}{dt}\\) \\[ \\begin{aligned} \\frac{d \\vartheta}{dt}= \\begin{bmatrix} \\frac{d pitch}{dt} \\\\ \\frac{d roll}{dt} \\\\ \\frac{d yaw}{dt} \\end{bmatrix} = \\begin{bmatrix} \\cos \\phi &amp; 0 &amp; \\sin \\phi \\\\ \\sin \\theta \\sin \\phi / \\cos \\theta &amp; 1 &amp; -\\sin \\theta \\cos \\phi / \\cos \\theta \\\\ -\\sin \\phi/ \\cos \\theta &amp; 0 &amp; \\cos \\phi /\\cos \\theta \\end{bmatrix} \\cdot \\omega_b \\end{aligned} \\] 另外的,还可以参照第一讲的旋转矩阵R的导数\\(\\dot{R}=Rw_\\times\\),具体参照下面资料 这部分参考资料: (1) (2) 1.6. IMU仿真","categories":[{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第二讲","slug":"VIO/第二讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%BA%8C%E8%AE%B2/"}],"tags":[]}],"categories":[{"name":"Fast-LIO系列","slug":"Fast-LIO系列","permalink":"http://yoursite.com/categories/Fast-LIO%E7%B3%BB%E5%88%97/"},{"name":"传感器标定","slug":"传感器标定","permalink":"http://yoursite.com/categories/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/"},{"name":"First_Principles_of_CV","slug":"First-Principles-of-CV","permalink":"http://yoursite.com/categories/First-Principles-of-CV/"},{"name":"文献阅读","slug":"文献阅读","permalink":"http://yoursite.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"},{"name":"多传感器融合定位","slug":"多传感器融合定位","permalink":"http://yoursite.com/categories/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88%E5%AE%9A%E4%BD%8D/"},{"name":"IMU相关","slug":"IMU相关","permalink":"http://yoursite.com/categories/IMU%E7%9B%B8%E5%85%B3/"},{"name":"SLAM代码课程","slug":"SLAM代码课程","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/"},{"name":"MSCKF","slug":"SLAM代码课程/MSCKF","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/MSCKF/"},{"name":"激光SLAM","slug":"激光SLAM","permalink":"http://yoursite.com/categories/%E6%BF%80%E5%85%89SLAM/"},{"name":"数据集整理","slug":"数据集整理","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%95%B4%E7%90%86/"},{"name":"BASALT","slug":"SLAM代码课程/BASALT","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/BASALT/"},{"name":"VINS-MONO","slug":"SLAM代码课程/VINS-MONO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/VINS-MONO/"},{"name":"控制相关","slug":"控制相关","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/"},{"name":"线性系统理论","slug":"控制相关/线性系统理论","permalink":"http://yoursite.com/categories/%E6%8E%A7%E5%88%B6%E7%9B%B8%E5%85%B3/%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"},{"name":"数学基础","slug":"数学基础","permalink":"http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"},{"name":"平台对比","slug":"平台对比","permalink":"http://yoursite.com/categories/%E5%B9%B3%E5%8F%B0%E5%AF%B9%E6%AF%94/"},{"name":"四元数的状态误差卡尔曼","slug":"四元数的状态误差卡尔曼","permalink":"http://yoursite.com/categories/%E5%9B%9B%E5%85%83%E6%95%B0%E7%9A%84%E7%8A%B6%E6%80%81%E8%AF%AF%E5%B7%AE%E5%8D%A1%E5%B0%94%E6%9B%BC/"},{"name":"DSO","slug":"SLAM代码课程/DSO","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/DSO/"},{"name":"Marker_SLAM","slug":"Marker-SLAM","permalink":"http://yoursite.com/categories/Marker-SLAM/"},{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Cartographer-Google相关","slug":"Cartographer-Google相关","permalink":"http://yoursite.com/categories/Cartographer-Google%E7%9B%B8%E5%85%B3/"},{"name":"C++","slug":"C","permalink":"http://yoursite.com/categories/C/"},{"name":"Autoware.ai","slug":"Autoware-ai","permalink":"http://yoursite.com/categories/Autoware-ai/"},{"name":"ORB_SLAM2","slug":"SLAM代码课程/ORB-SLAM2","permalink":"http://yoursite.com/categories/SLAM%E4%BB%A3%E7%A0%81%E8%AF%BE%E7%A8%8B/ORB-SLAM2/"},{"name":"ROS2","slug":"ROS2","permalink":"http://yoursite.com/categories/ROS2/"},{"name":"utils","slug":"utils","permalink":"http://yoursite.com/categories/utils/"},{"name":"VIO","slug":"VIO","permalink":"http://yoursite.com/categories/VIO/"},{"name":"第五讲","slug":"VIO/第五讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%BA%94%E8%AE%B2/"},{"name":"第三讲","slug":"VIO/第三讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%B8%89%E8%AE%B2/"},{"name":"第六讲","slug":"VIO/第六讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E5%85%AD%E8%AE%B2/"},{"name":"第四讲","slug":"VIO/第四讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E5%9B%9B%E8%AE%B2/"},{"name":"第一讲","slug":"VIO/第一讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%B8%80%E8%AE%B2/"},{"name":"第二讲","slug":"VIO/第二讲","permalink":"http://yoursite.com/categories/VIO/%E7%AC%AC%E4%BA%8C%E8%AE%B2/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"http://yoursite.com/tags/SLAM/"},{"name":"Cyber_RT","slug":"Cyber-RT","permalink":"http://yoursite.com/tags/Cyber-RT/"}]}